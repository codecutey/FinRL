{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e0ddb04",
   "metadata": {},
   "source": [
    "# [FinRL: 强化学习在量化金融中的应用](https://github.com/QYQSDTC/FinRL)\n",
    "*注：本文不构成任何投资建议，入市有风险，投资需谨慎。*\n",
    "## 小组成员\n",
    "钱以骞 物理学院 D202180035\n",
    "\n",
    "马瑞廷 计算机学院\n",
    "\n",
    "张文涛 计算机学院\n",
    "\n",
    "丛宇恒 计算机学院\n",
    "\n",
    "## 目标\n",
    "- 了解强化学习在量化金融中的应用\n",
    "- 通过强化学习的方法，实现一个简单的量化交易策略\n",
    "- 比较不同的强化学习算法在量化金融中的表现\n",
    "  - 钱以骞：DDPG\n",
    "  - 张文涛：SAC\n",
    "  - 丛宇恒：A2C\n",
    "  - 马瑞妍：PPO\n",
    "\n",
    "## 用到的Package\n",
    "- [FinRL](https://github.com/AI4Finance-Foundation/FinRL): 一个强化学习在量化金融中的应用的开源库\n",
    "- [Tushare](https://tushare.pro/): 一个免费的金融数据接口\n",
    "- [Quantopian Pyfolio](https://github.com/quantopian/pyfolio): 一个自动化回测工具包"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ac7297",
   "metadata": {
    "id": "42ac7297"
   },
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fluid-taylor",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T10:28:23.449076Z",
     "start_time": "2022-10-12T10:28:21.587829Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fluid-taylor",
    "outputId": "30383d78-b504-4216-e338-addc1689c3c3",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL Modules have been imported!\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 100, 'display.min_rows', 50,'display.max_columns', 100)\n",
    "from IPython import display\n",
    "import tushare as ts\n",
    "display.set_matplotlib_formats(\"svg\")\n",
    "\n",
    "from meta import config\n",
    "from meta.data_processors.tushare import Tushare, ReturnPlotter\n",
    "from meta.env_stock_trading.env_stocktrading_China_A_shares import StockTradingEnv\n",
    "from agents.stablebaselines3_models import DRLAgent\n",
    "from stable_baselines3.common.logger import configure\n",
    "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
    "import datetime\n",
    "    \n",
    "print(\"ALL Modules have been imported!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb601f4a",
   "metadata": {
    "id": "eb601f4a"
   },
   "source": [
    "## Create folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "339ab411",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T10:28:23.466632Z",
     "start_time": "2022-10-12T10:28:23.462467Z"
    },
    "id": "339ab411"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(\"./datasets\" ):\n",
    "    os.makedirs(\"./datasets\" )\n",
    "if not os.path.exists(\"./trained_models\"):\n",
    "    os.makedirs(\"./trained_models\" )\n",
    "if not os.path.exists(\"./tensorboard_log\"):\n",
    "    os.makedirs(\"./tensorboard_log\" )\n",
    "if not os.path.exists(\"./results\" ):\n",
    "    os.makedirs(\"./results\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ad0a26",
   "metadata": {
    "id": "74ad0a26"
   },
   "source": [
    "## Data preparation: download, cleansing and feature engineering\n",
    "我们用Tushare获取了A股市场近10年的数据 (2012/01/01 -- 2022/09/28)，包括开盘价、收盘价、最高价、最低价、成交量、成交额、涨跌幅等信息。我们用这些数据来训练我们的强化学习模型。\n",
    "### 个股的选择\n",
    "因为本项目的主要目的是研究强化学习在量化金融中的应用，所以个股的选择我们就简单的从上证50中选取了5只权重股，包括：贵州茅台，万华化学，中国平安，中国中免，恒瑞医药。\n",
    "\n",
    "如果想要更好的收益，可以用量化因子选股或者其它的一些量化方法，但是这不在本项目的讨论范围内。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "transsexual-crack",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T10:28:25.166286Z",
     "start_time": "2022-10-12T10:28:25.160526Z"
    },
    "id": "transsexual-crack"
   },
   "outputs": [],
   "source": [
    "train_start_date='2012-01-01'\n",
    "train_stop_date='2020-01-01'\n",
    "trade_start_date='2020-01-01'\n",
    "trade_stop_date='2022-09-30'\n",
    "\n",
    "# token='27080ec403c0218f96f388bca1b1d85329d563c91a43672239619ef5'\n",
    "token='829a1fbce8eb0e34f05ab19906d0e08227c6f64261a81272aa078ccd'\n",
    "\n",
    "pro = ts.pro_api(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6f4aa69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-11T11:09:45.032197Z",
     "start_time": "2022-10-11T11:09:44.912264Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_code</th>\n",
       "      <th>con_code</th>\n",
       "      <th>trade_date</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>601012.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>4.460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>600745.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>0.547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>600104.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>1.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>600690.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>1.440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>601088.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>1.602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>600028.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>0.881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>600809.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>2.270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>601995.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>0.309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>600519.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>18.058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>601919.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>1.071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>601166.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>3.718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>601668.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>1.658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>601601.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>1.068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>600436.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>1.236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>601066.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>0.462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>601318.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>6.916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>600030.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>2.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>600588.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>0.464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>600276.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>2.406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>600438.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>1.947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>600570.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>0.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>603501.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>0.874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>600837.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>1.284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>603288.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>1.768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>603986.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>0.961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>601688.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>1.095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>600036.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>6.395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>601857.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>0.765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>600196.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>0.577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>603799.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>1.255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>600887.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>2.593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>600111.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>0.889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>600031.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>1.267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>600048.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>1.985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>600905.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>0.742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>601398.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>2.341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>601633.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>0.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>601288.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>1.402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>600893.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>0.858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>601628.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>0.809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>600010.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>0.644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>600585.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>1.062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>600900.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>3.970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>603259.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>2.258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>601899.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>1.735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>601888.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>2.972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>600346.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>0.549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>601728.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>0.320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>601211.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>0.946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>600309.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>2.220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index_code   con_code trade_date  weight\n",
       "0   000016.SH  601012.SH   20220930   4.460\n",
       "1   000016.SH  600745.SH   20220930   0.547\n",
       "2   000016.SH  600104.SH   20220930   1.026\n",
       "3   000016.SH  600690.SH   20220930   1.440\n",
       "4   000016.SH  601088.SH   20220930   1.602\n",
       "5   000016.SH  600028.SH   20220930   0.881\n",
       "6   000016.SH  600809.SH   20220930   2.270\n",
       "7   000016.SH  601995.SH   20220930   0.309\n",
       "8   000016.SH  600519.SH   20220930  18.058\n",
       "9   000016.SH  601919.SH   20220930   1.071\n",
       "10  000016.SH  601166.SH   20220930   3.718\n",
       "11  000016.SH  601668.SH   20220930   1.658\n",
       "12  000016.SH  601601.SH   20220930   1.068\n",
       "13  000016.SH  600436.SH   20220930   1.236\n",
       "14  000016.SH  601066.SH   20220930   0.462\n",
       "15  000016.SH  601318.SH   20220930   6.916\n",
       "16  000016.SH  600030.SH   20220930   2.611\n",
       "17  000016.SH  600588.SH   20220930   0.464\n",
       "18  000016.SH  600276.SH   20220930   2.406\n",
       "19  000016.SH  600438.SH   20220930   1.947\n",
       "20  000016.SH  600570.SH   20220930   0.791\n",
       "21  000016.SH  603501.SH   20220930   0.874\n",
       "22  000016.SH  600837.SH   20220930   1.284\n",
       "23  000016.SH  603288.SH   20220930   1.768\n",
       "24  000016.SH  603986.SH   20220930   0.961\n",
       "25  000016.SH  601688.SH   20220930   1.095\n",
       "26  000016.SH  600036.SH   20220930   6.395\n",
       "27  000016.SH  601857.SH   20220930   0.765\n",
       "28  000016.SH  600196.SH   20220930   0.577\n",
       "29  000016.SH  603799.SH   20220930   1.255\n",
       "30  000016.SH  600887.SH   20220930   2.593\n",
       "31  000016.SH  600111.SH   20220930   0.889\n",
       "32  000016.SH  600031.SH   20220930   1.267\n",
       "33  000016.SH  600048.SH   20220930   1.985\n",
       "34  000016.SH  600905.SH   20220930   0.742\n",
       "35  000016.SH  601398.SH   20220930   2.341\n",
       "36  000016.SH  601633.SH   20220930   0.526\n",
       "37  000016.SH  601288.SH   20220930   1.402\n",
       "38  000016.SH  600893.SH   20220930   0.858\n",
       "39  000016.SH  601628.SH   20220930   0.809\n",
       "40  000016.SH  600010.SH   20220930   0.644\n",
       "41  000016.SH  600585.SH   20220930   1.062\n",
       "42  000016.SH  600900.SH   20220930   3.970\n",
       "43  000016.SH  603259.SH   20220930   2.258\n",
       "44  000016.SH  601899.SH   20220930   1.735\n",
       "45  000016.SH  601888.SH   20220930   2.972\n",
       "46  000016.SH  600346.SH   20220930   0.549\n",
       "47  000016.SH  601728.SH   20220930   0.320\n",
       "48  000016.SH  601211.SH   20220930   0.946\n",
       "49  000016.SH  600309.SH   20220930   2.220"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pro.index_weight(index_code = '000016.SH', start_date = '20220901')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8516b0f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T02:26:21.637035Z",
     "start_time": "2022-10-12T02:26:21.457615Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stocks: 50, stocks: ['601012.SH', '600745.SH', '600104.SH', '600690.SH', '601088.SH', '600028.SH', '600809.SH', '601995.SH', '600519.SH', '601919.SH', '601166.SH', '601668.SH', '601601.SH', '600436.SH', '601066.SH', '601318.SH', '600030.SH', '600588.SH', '600276.SH', '600438.SH', '600570.SH', '603501.SH', '600837.SH', '603288.SH', '603986.SH', '601688.SH', '600036.SH', '601857.SH', '600196.SH', '603799.SH', '600887.SH', '600111.SH', '600031.SH', '600048.SH', '600905.SH', '601398.SH', '601633.SH', '601288.SH', '600893.SH', '601628.SH', '600010.SH', '600585.SH', '600900.SH', '603259.SH', '601899.SH', '601888.SH', '600346.SH', '601728.SH', '601211.SH', '600309.SH']\n"
     ]
    }
   ],
   "source": [
    "# ticket_list=['600519.SH', '600309.SH', '601318.SH', '601888.SH', '600276.SH']\n",
    "# take 上证50成分股\n",
    "ticker_list = pro.index_weight(index_code = '000016.SH', start_date = '20220901').con_code.unique().tolist()\n",
    "ticker_list\n",
    "print(f'Number of stocks: {len(ticker_list)}, stocks: {ticker_list}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "preceding-selling",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T10:28:32.806106Z",
     "start_time": "2022-10-12T10:28:32.799771Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "preceding-selling",
    "outputId": "8b88552b-da4a-476f-d3a4-8ea79019819e"
   },
   "outputs": [],
   "source": [
    "# download and clean\n",
    "ts_processor = Tushare(data_source=\"tushare\", \n",
    "                                   start_date=train_start_date,\n",
    "                                   end_date=trade_stop_date,\n",
    "                                   time_interval=\"1d\",\n",
    "                                   token=token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f8bd9f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T02:27:00.374815Z",
     "start_time": "2022-10-12T02:26:26.066772Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:40<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (113660, 8)\n"
     ]
    }
   ],
   "source": [
    "ts_processor.download_data(ticker_list=ticker_list)\n",
    "ts_processor.dataframe.to_csv('./datasets/A_stock.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee219f3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T02:27:01.564972Z",
     "start_time": "2022-10-12T02:27:01.447768Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./datasets/A_stock.csv')\n",
    "len(df.tic.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde8a49b",
   "metadata": {},
   "source": [
    "### Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e895af9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T02:27:04.953291Z",
     "start_time": "2022-10-12T02:27:04.668086Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>tic</th>\n",
       "      <th>600010.SH</th>\n",
       "      <th>600028.SH</th>\n",
       "      <th>600030.SH</th>\n",
       "      <th>600031.SH</th>\n",
       "      <th>600036.SH</th>\n",
       "      <th>600048.SH</th>\n",
       "      <th>600104.SH</th>\n",
       "      <th>600111.SH</th>\n",
       "      <th>600196.SH</th>\n",
       "      <th>600276.SH</th>\n",
       "      <th>600309.SH</th>\n",
       "      <th>600346.SH</th>\n",
       "      <th>600436.SH</th>\n",
       "      <th>600438.SH</th>\n",
       "      <th>600519.SH</th>\n",
       "      <th>600570.SH</th>\n",
       "      <th>600585.SH</th>\n",
       "      <th>600588.SH</th>\n",
       "      <th>600690.SH</th>\n",
       "      <th>600745.SH</th>\n",
       "      <th>600809.SH</th>\n",
       "      <th>600837.SH</th>\n",
       "      <th>600887.SH</th>\n",
       "      <th>600893.SH</th>\n",
       "      <th>600900.SH</th>\n",
       "      <th>600905.SH</th>\n",
       "      <th>601012.SH</th>\n",
       "      <th>601066.SH</th>\n",
       "      <th>601088.SH</th>\n",
       "      <th>601166.SH</th>\n",
       "      <th>601211.SH</th>\n",
       "      <th>601288.SH</th>\n",
       "      <th>601318.SH</th>\n",
       "      <th>601398.SH</th>\n",
       "      <th>601601.SH</th>\n",
       "      <th>601628.SH</th>\n",
       "      <th>601633.SH</th>\n",
       "      <th>601668.SH</th>\n",
       "      <th>601688.SH</th>\n",
       "      <th>601728.SH</th>\n",
       "      <th>601857.SH</th>\n",
       "      <th>601888.SH</th>\n",
       "      <th>601899.SH</th>\n",
       "      <th>601919.SH</th>\n",
       "      <th>601995.SH</th>\n",
       "      <th>603259.SH</th>\n",
       "      <th>603288.SH</th>\n",
       "      <th>603501.SH</th>\n",
       "      <th>603799.SH</th>\n",
       "      <th>603986.SH</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-04</th>\n",
       "      <td>4.15</td>\n",
       "      <td>7.36</td>\n",
       "      <td>9.56</td>\n",
       "      <td>12.09</td>\n",
       "      <td>11.67</td>\n",
       "      <td>10.05</td>\n",
       "      <td>14.16</td>\n",
       "      <td>37.61</td>\n",
       "      <td>8.34</td>\n",
       "      <td>28.45</td>\n",
       "      <td>12.50</td>\n",
       "      <td>7.07</td>\n",
       "      <td>73.03</td>\n",
       "      <td>4.85</td>\n",
       "      <td>185.27</td>\n",
       "      <td>11.50</td>\n",
       "      <td>15.28</td>\n",
       "      <td>16.90</td>\n",
       "      <td>8.78</td>\n",
       "      <td>5.79</td>\n",
       "      <td>57.79</td>\n",
       "      <td>7.12</td>\n",
       "      <td>19.73</td>\n",
       "      <td>13.29</td>\n",
       "      <td>6.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.60</td>\n",
       "      <td>12.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.60</td>\n",
       "      <td>33.90</td>\n",
       "      <td>4.22</td>\n",
       "      <td>19.04</td>\n",
       "      <td>17.46</td>\n",
       "      <td>11.87</td>\n",
       "      <td>2.86</td>\n",
       "      <td>7.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.75</td>\n",
       "      <td>25.59</td>\n",
       "      <td>3.81</td>\n",
       "      <td>4.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-05</th>\n",
       "      <td>4.10</td>\n",
       "      <td>7.42</td>\n",
       "      <td>9.29</td>\n",
       "      <td>12.06</td>\n",
       "      <td>11.91</td>\n",
       "      <td>9.80</td>\n",
       "      <td>14.39</td>\n",
       "      <td>35.64</td>\n",
       "      <td>8.25</td>\n",
       "      <td>27.00</td>\n",
       "      <td>12.10</td>\n",
       "      <td>6.86</td>\n",
       "      <td>70.50</td>\n",
       "      <td>4.66</td>\n",
       "      <td>183.15</td>\n",
       "      <td>10.70</td>\n",
       "      <td>14.92</td>\n",
       "      <td>16.48</td>\n",
       "      <td>8.73</td>\n",
       "      <td>5.54</td>\n",
       "      <td>55.04</td>\n",
       "      <td>7.08</td>\n",
       "      <td>19.33</td>\n",
       "      <td>12.66</td>\n",
       "      <td>6.24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.29</td>\n",
       "      <td>12.71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.65</td>\n",
       "      <td>33.93</td>\n",
       "      <td>4.25</td>\n",
       "      <td>19.12</td>\n",
       "      <td>16.58</td>\n",
       "      <td>12.10</td>\n",
       "      <td>2.87</td>\n",
       "      <td>7.36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.80</td>\n",
       "      <td>24.17</td>\n",
       "      <td>3.78</td>\n",
       "      <td>4.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-06</th>\n",
       "      <td>4.34</td>\n",
       "      <td>7.48</td>\n",
       "      <td>9.39</td>\n",
       "      <td>12.06</td>\n",
       "      <td>11.99</td>\n",
       "      <td>9.71</td>\n",
       "      <td>14.20</td>\n",
       "      <td>36.32</td>\n",
       "      <td>8.08</td>\n",
       "      <td>26.55</td>\n",
       "      <td>12.06</td>\n",
       "      <td>6.40</td>\n",
       "      <td>70.08</td>\n",
       "      <td>4.72</td>\n",
       "      <td>186.64</td>\n",
       "      <td>10.67</td>\n",
       "      <td>14.72</td>\n",
       "      <td>16.23</td>\n",
       "      <td>8.79</td>\n",
       "      <td>5.76</td>\n",
       "      <td>53.69</td>\n",
       "      <td>7.30</td>\n",
       "      <td>19.66</td>\n",
       "      <td>12.95</td>\n",
       "      <td>6.22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.27</td>\n",
       "      <td>12.79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.66</td>\n",
       "      <td>33.85</td>\n",
       "      <td>4.28</td>\n",
       "      <td>19.23</td>\n",
       "      <td>16.73</td>\n",
       "      <td>11.81</td>\n",
       "      <td>2.87</td>\n",
       "      <td>7.49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.96</td>\n",
       "      <td>23.61</td>\n",
       "      <td>3.80</td>\n",
       "      <td>4.32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-09</th>\n",
       "      <td>4.48</td>\n",
       "      <td>7.75</td>\n",
       "      <td>9.75</td>\n",
       "      <td>12.55</td>\n",
       "      <td>12.38</td>\n",
       "      <td>10.17</td>\n",
       "      <td>14.90</td>\n",
       "      <td>39.02</td>\n",
       "      <td>8.34</td>\n",
       "      <td>27.40</td>\n",
       "      <td>12.47</td>\n",
       "      <td>6.64</td>\n",
       "      <td>70.10</td>\n",
       "      <td>4.89</td>\n",
       "      <td>188.01</td>\n",
       "      <td>11.00</td>\n",
       "      <td>15.55</td>\n",
       "      <td>16.58</td>\n",
       "      <td>9.07</td>\n",
       "      <td>6.00</td>\n",
       "      <td>54.59</td>\n",
       "      <td>7.62</td>\n",
       "      <td>20.13</td>\n",
       "      <td>13.39</td>\n",
       "      <td>6.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.01</td>\n",
       "      <td>13.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.68</td>\n",
       "      <td>34.73</td>\n",
       "      <td>4.31</td>\n",
       "      <td>19.73</td>\n",
       "      <td>17.28</td>\n",
       "      <td>12.26</td>\n",
       "      <td>2.93</td>\n",
       "      <td>7.79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.03</td>\n",
       "      <td>24.41</td>\n",
       "      <td>3.93</td>\n",
       "      <td>4.47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-10</th>\n",
       "      <td>4.54</td>\n",
       "      <td>7.79</td>\n",
       "      <td>10.12</td>\n",
       "      <td>13.31</td>\n",
       "      <td>12.56</td>\n",
       "      <td>10.35</td>\n",
       "      <td>15.25</td>\n",
       "      <td>40.39</td>\n",
       "      <td>8.66</td>\n",
       "      <td>27.75</td>\n",
       "      <td>13.21</td>\n",
       "      <td>7.02</td>\n",
       "      <td>72.00</td>\n",
       "      <td>5.10</td>\n",
       "      <td>194.48</td>\n",
       "      <td>11.34</td>\n",
       "      <td>16.59</td>\n",
       "      <td>17.02</td>\n",
       "      <td>9.42</td>\n",
       "      <td>6.21</td>\n",
       "      <td>57.00</td>\n",
       "      <td>7.93</td>\n",
       "      <td>20.58</td>\n",
       "      <td>13.79</td>\n",
       "      <td>6.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.76</td>\n",
       "      <td>13.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.69</td>\n",
       "      <td>36.29</td>\n",
       "      <td>4.35</td>\n",
       "      <td>20.40</td>\n",
       "      <td>18.23</td>\n",
       "      <td>12.46</td>\n",
       "      <td>3.08</td>\n",
       "      <td>8.13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.12</td>\n",
       "      <td>25.60</td>\n",
       "      <td>4.12</td>\n",
       "      <td>4.68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-11</th>\n",
       "      <td>4.79</td>\n",
       "      <td>7.70</td>\n",
       "      <td>10.08</td>\n",
       "      <td>13.13</td>\n",
       "      <td>12.49</td>\n",
       "      <td>10.31</td>\n",
       "      <td>15.10</td>\n",
       "      <td>42.63</td>\n",
       "      <td>8.63</td>\n",
       "      <td>27.70</td>\n",
       "      <td>13.25</td>\n",
       "      <td>7.14</td>\n",
       "      <td>72.85</td>\n",
       "      <td>5.06</td>\n",
       "      <td>189.68</td>\n",
       "      <td>11.25</td>\n",
       "      <td>16.38</td>\n",
       "      <td>17.79</td>\n",
       "      <td>9.26</td>\n",
       "      <td>6.13</td>\n",
       "      <td>57.67</td>\n",
       "      <td>7.85</td>\n",
       "      <td>20.61</td>\n",
       "      <td>13.72</td>\n",
       "      <td>6.38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.49</td>\n",
       "      <td>13.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.67</td>\n",
       "      <td>35.83</td>\n",
       "      <td>4.35</td>\n",
       "      <td>20.20</td>\n",
       "      <td>18.22</td>\n",
       "      <td>12.41</td>\n",
       "      <td>3.04</td>\n",
       "      <td>8.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.04</td>\n",
       "      <td>25.95</td>\n",
       "      <td>4.16</td>\n",
       "      <td>4.63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-12</th>\n",
       "      <td>4.77</td>\n",
       "      <td>7.66</td>\n",
       "      <td>10.03</td>\n",
       "      <td>13.22</td>\n",
       "      <td>12.62</td>\n",
       "      <td>10.39</td>\n",
       "      <td>15.29</td>\n",
       "      <td>43.46</td>\n",
       "      <td>8.58</td>\n",
       "      <td>27.37</td>\n",
       "      <td>13.31</td>\n",
       "      <td>7.07</td>\n",
       "      <td>73.99</td>\n",
       "      <td>5.03</td>\n",
       "      <td>190.35</td>\n",
       "      <td>11.05</td>\n",
       "      <td>16.51</td>\n",
       "      <td>17.14</td>\n",
       "      <td>9.23</td>\n",
       "      <td>6.28</td>\n",
       "      <td>55.89</td>\n",
       "      <td>7.85</td>\n",
       "      <td>20.50</td>\n",
       "      <td>14.10</td>\n",
       "      <td>6.41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.49</td>\n",
       "      <td>13.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.65</td>\n",
       "      <td>36.37</td>\n",
       "      <td>4.33</td>\n",
       "      <td>20.03</td>\n",
       "      <td>18.30</td>\n",
       "      <td>12.65</td>\n",
       "      <td>3.04</td>\n",
       "      <td>7.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.06</td>\n",
       "      <td>25.47</td>\n",
       "      <td>4.15</td>\n",
       "      <td>4.69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-13</th>\n",
       "      <td>4.69</td>\n",
       "      <td>7.62</td>\n",
       "      <td>9.80</td>\n",
       "      <td>12.92</td>\n",
       "      <td>12.49</td>\n",
       "      <td>10.28</td>\n",
       "      <td>14.69</td>\n",
       "      <td>44.96</td>\n",
       "      <td>8.31</td>\n",
       "      <td>26.80</td>\n",
       "      <td>12.83</td>\n",
       "      <td>6.81</td>\n",
       "      <td>71.73</td>\n",
       "      <td>4.87</td>\n",
       "      <td>188.69</td>\n",
       "      <td>10.49</td>\n",
       "      <td>15.75</td>\n",
       "      <td>16.51</td>\n",
       "      <td>8.83</td>\n",
       "      <td>6.50</td>\n",
       "      <td>53.98</td>\n",
       "      <td>7.71</td>\n",
       "      <td>20.22</td>\n",
       "      <td>13.26</td>\n",
       "      <td>6.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.33</td>\n",
       "      <td>13.28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.65</td>\n",
       "      <td>36.03</td>\n",
       "      <td>4.34</td>\n",
       "      <td>19.95</td>\n",
       "      <td>17.89</td>\n",
       "      <td>12.26</td>\n",
       "      <td>3.01</td>\n",
       "      <td>7.87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.20</td>\n",
       "      <td>24.93</td>\n",
       "      <td>4.06</td>\n",
       "      <td>4.48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-16</th>\n",
       "      <td>4.32</td>\n",
       "      <td>7.54</td>\n",
       "      <td>9.83</td>\n",
       "      <td>13.06</td>\n",
       "      <td>12.39</td>\n",
       "      <td>9.93</td>\n",
       "      <td>14.39</td>\n",
       "      <td>41.08</td>\n",
       "      <td>8.17</td>\n",
       "      <td>26.00</td>\n",
       "      <td>12.50</td>\n",
       "      <td>6.52</td>\n",
       "      <td>69.15</td>\n",
       "      <td>4.76</td>\n",
       "      <td>177.41</td>\n",
       "      <td>10.30</td>\n",
       "      <td>15.28</td>\n",
       "      <td>16.03</td>\n",
       "      <td>8.70</td>\n",
       "      <td>5.91</td>\n",
       "      <td>50.77</td>\n",
       "      <td>7.64</td>\n",
       "      <td>19.01</td>\n",
       "      <td>12.89</td>\n",
       "      <td>6.36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.02</td>\n",
       "      <td>13.32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.59</td>\n",
       "      <td>4.31</td>\n",
       "      <td>19.85</td>\n",
       "      <td>17.81</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.98</td>\n",
       "      <td>7.73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.09</td>\n",
       "      <td>23.59</td>\n",
       "      <td>3.96</td>\n",
       "      <td>4.38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-17</th>\n",
       "      <td>4.75</td>\n",
       "      <td>7.74</td>\n",
       "      <td>10.51</td>\n",
       "      <td>13.77</td>\n",
       "      <td>12.78</td>\n",
       "      <td>10.35</td>\n",
       "      <td>15.33</td>\n",
       "      <td>45.19</td>\n",
       "      <td>8.61</td>\n",
       "      <td>26.02</td>\n",
       "      <td>13.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.90</td>\n",
       "      <td>5.03</td>\n",
       "      <td>180.44</td>\n",
       "      <td>10.60</td>\n",
       "      <td>16.43</td>\n",
       "      <td>16.73</td>\n",
       "      <td>9.29</td>\n",
       "      <td>6.29</td>\n",
       "      <td>52.66</td>\n",
       "      <td>8.15</td>\n",
       "      <td>19.87</td>\n",
       "      <td>13.55</td>\n",
       "      <td>6.53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.38</td>\n",
       "      <td>13.60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.69</td>\n",
       "      <td>37.82</td>\n",
       "      <td>4.36</td>\n",
       "      <td>20.68</td>\n",
       "      <td>18.78</td>\n",
       "      <td>12.99</td>\n",
       "      <td>3.10</td>\n",
       "      <td>8.19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.32</td>\n",
       "      <td>24.72</td>\n",
       "      <td>4.36</td>\n",
       "      <td>4.82</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-18</th>\n",
       "      <td>4.73</td>\n",
       "      <td>7.58</td>\n",
       "      <td>10.47</td>\n",
       "      <td>13.69</td>\n",
       "      <td>12.52</td>\n",
       "      <td>10.12</td>\n",
       "      <td>15.21</td>\n",
       "      <td>45.46</td>\n",
       "      <td>8.47</td>\n",
       "      <td>24.66</td>\n",
       "      <td>13.26</td>\n",
       "      <td>6.77</td>\n",
       "      <td>63.81</td>\n",
       "      <td>4.93</td>\n",
       "      <td>177.38</td>\n",
       "      <td>10.48</td>\n",
       "      <td>16.82</td>\n",
       "      <td>16.49</td>\n",
       "      <td>9.08</td>\n",
       "      <td>6.19</td>\n",
       "      <td>51.61</td>\n",
       "      <td>8.07</td>\n",
       "      <td>19.14</td>\n",
       "      <td>13.32</td>\n",
       "      <td>6.48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.88</td>\n",
       "      <td>13.43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.69</td>\n",
       "      <td>37.45</td>\n",
       "      <td>4.31</td>\n",
       "      <td>20.50</td>\n",
       "      <td>18.45</td>\n",
       "      <td>12.77</td>\n",
       "      <td>3.05</td>\n",
       "      <td>8.22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.22</td>\n",
       "      <td>24.01</td>\n",
       "      <td>4.29</td>\n",
       "      <td>5.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-19</th>\n",
       "      <td>4.78</td>\n",
       "      <td>7.66</td>\n",
       "      <td>10.84</td>\n",
       "      <td>13.81</td>\n",
       "      <td>12.70</td>\n",
       "      <td>10.67</td>\n",
       "      <td>15.46</td>\n",
       "      <td>46.58</td>\n",
       "      <td>8.62</td>\n",
       "      <td>25.20</td>\n",
       "      <td>13.76</td>\n",
       "      <td>6.79</td>\n",
       "      <td>64.29</td>\n",
       "      <td>5.01</td>\n",
       "      <td>180.70</td>\n",
       "      <td>10.33</td>\n",
       "      <td>17.15</td>\n",
       "      <td>16.19</td>\n",
       "      <td>9.40</td>\n",
       "      <td>6.25</td>\n",
       "      <td>52.84</td>\n",
       "      <td>8.38</td>\n",
       "      <td>19.98</td>\n",
       "      <td>13.20</td>\n",
       "      <td>6.56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.10</td>\n",
       "      <td>13.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.70</td>\n",
       "      <td>38.51</td>\n",
       "      <td>4.36</td>\n",
       "      <td>21.22</td>\n",
       "      <td>19.00</td>\n",
       "      <td>12.88</td>\n",
       "      <td>3.09</td>\n",
       "      <td>8.48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.26</td>\n",
       "      <td>24.41</td>\n",
       "      <td>4.48</td>\n",
       "      <td>5.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-20</th>\n",
       "      <td>4.77</td>\n",
       "      <td>7.74</td>\n",
       "      <td>11.01</td>\n",
       "      <td>13.99</td>\n",
       "      <td>13.00</td>\n",
       "      <td>10.94</td>\n",
       "      <td>15.52</td>\n",
       "      <td>45.62</td>\n",
       "      <td>8.80</td>\n",
       "      <td>26.68</td>\n",
       "      <td>14.09</td>\n",
       "      <td>6.84</td>\n",
       "      <td>65.74</td>\n",
       "      <td>5.10</td>\n",
       "      <td>185.97</td>\n",
       "      <td>10.41</td>\n",
       "      <td>17.79</td>\n",
       "      <td>16.48</td>\n",
       "      <td>9.51</td>\n",
       "      <td>6.26</td>\n",
       "      <td>54.34</td>\n",
       "      <td>8.60</td>\n",
       "      <td>20.54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.48</td>\n",
       "      <td>14.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.72</td>\n",
       "      <td>39.10</td>\n",
       "      <td>4.36</td>\n",
       "      <td>21.84</td>\n",
       "      <td>19.33</td>\n",
       "      <td>12.99</td>\n",
       "      <td>3.14</td>\n",
       "      <td>8.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.26</td>\n",
       "      <td>25.01</td>\n",
       "      <td>4.47</td>\n",
       "      <td>5.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-30</th>\n",
       "      <td>4.75</td>\n",
       "      <td>7.70</td>\n",
       "      <td>10.68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.70</td>\n",
       "      <td>10.43</td>\n",
       "      <td>15.48</td>\n",
       "      <td>46.06</td>\n",
       "      <td>8.63</td>\n",
       "      <td>26.19</td>\n",
       "      <td>13.67</td>\n",
       "      <td>7.14</td>\n",
       "      <td>64.87</td>\n",
       "      <td>5.04</td>\n",
       "      <td>183.80</td>\n",
       "      <td>10.37</td>\n",
       "      <td>17.38</td>\n",
       "      <td>16.23</td>\n",
       "      <td>9.24</td>\n",
       "      <td>6.29</td>\n",
       "      <td>53.30</td>\n",
       "      <td>8.36</td>\n",
       "      <td>20.33</td>\n",
       "      <td>13.49</td>\n",
       "      <td>6.45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.68</td>\n",
       "      <td>13.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.68</td>\n",
       "      <td>38.60</td>\n",
       "      <td>4.27</td>\n",
       "      <td>21.11</td>\n",
       "      <td>18.90</td>\n",
       "      <td>12.73</td>\n",
       "      <td>3.07</td>\n",
       "      <td>8.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.13</td>\n",
       "      <td>25.10</td>\n",
       "      <td>4.49</td>\n",
       "      <td>5.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-31</th>\n",
       "      <td>4.87</td>\n",
       "      <td>7.76</td>\n",
       "      <td>10.69</td>\n",
       "      <td>14.21</td>\n",
       "      <td>12.65</td>\n",
       "      <td>10.50</td>\n",
       "      <td>15.09</td>\n",
       "      <td>46.56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.22</td>\n",
       "      <td>65.93</td>\n",
       "      <td>5.08</td>\n",
       "      <td>186.41</td>\n",
       "      <td>10.39</td>\n",
       "      <td>17.37</td>\n",
       "      <td>16.45</td>\n",
       "      <td>9.21</td>\n",
       "      <td>6.38</td>\n",
       "      <td>54.97</td>\n",
       "      <td>8.36</td>\n",
       "      <td>20.44</td>\n",
       "      <td>13.48</td>\n",
       "      <td>6.49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.85</td>\n",
       "      <td>13.86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.70</td>\n",
       "      <td>38.34</td>\n",
       "      <td>4.30</td>\n",
       "      <td>21.01</td>\n",
       "      <td>18.78</td>\n",
       "      <td>12.57</td>\n",
       "      <td>3.07</td>\n",
       "      <td>8.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.21</td>\n",
       "      <td>24.73</td>\n",
       "      <td>4.44</td>\n",
       "      <td>5.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-01</th>\n",
       "      <td>4.73</td>\n",
       "      <td>7.79</td>\n",
       "      <td>10.47</td>\n",
       "      <td>13.80</td>\n",
       "      <td>12.47</td>\n",
       "      <td>10.31</td>\n",
       "      <td>14.93</td>\n",
       "      <td>44.73</td>\n",
       "      <td>8.51</td>\n",
       "      <td>25.86</td>\n",
       "      <td>13.78</td>\n",
       "      <td>7.16</td>\n",
       "      <td>66.52</td>\n",
       "      <td>5.05</td>\n",
       "      <td>186.15</td>\n",
       "      <td>10.64</td>\n",
       "      <td>16.54</td>\n",
       "      <td>16.68</td>\n",
       "      <td>9.10</td>\n",
       "      <td>6.23</td>\n",
       "      <td>54.98</td>\n",
       "      <td>8.10</td>\n",
       "      <td>20.60</td>\n",
       "      <td>13.12</td>\n",
       "      <td>6.44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.57</td>\n",
       "      <td>13.56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.68</td>\n",
       "      <td>37.41</td>\n",
       "      <td>4.28</td>\n",
       "      <td>20.65</td>\n",
       "      <td>18.34</td>\n",
       "      <td>12.40</td>\n",
       "      <td>3.04</td>\n",
       "      <td>8.16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.18</td>\n",
       "      <td>24.71</td>\n",
       "      <td>4.37</td>\n",
       "      <td>5.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-02</th>\n",
       "      <td>4.83</td>\n",
       "      <td>7.86</td>\n",
       "      <td>10.80</td>\n",
       "      <td>14.06</td>\n",
       "      <td>12.87</td>\n",
       "      <td>10.56</td>\n",
       "      <td>15.22</td>\n",
       "      <td>45.57</td>\n",
       "      <td>8.64</td>\n",
       "      <td>26.24</td>\n",
       "      <td>14.05</td>\n",
       "      <td>7.19</td>\n",
       "      <td>66.67</td>\n",
       "      <td>5.25</td>\n",
       "      <td>186.43</td>\n",
       "      <td>10.77</td>\n",
       "      <td>16.90</td>\n",
       "      <td>17.14</td>\n",
       "      <td>9.19</td>\n",
       "      <td>6.33</td>\n",
       "      <td>55.72</td>\n",
       "      <td>8.53</td>\n",
       "      <td>20.92</td>\n",
       "      <td>13.31</td>\n",
       "      <td>6.48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.24</td>\n",
       "      <td>14.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.73</td>\n",
       "      <td>39.64</td>\n",
       "      <td>4.38</td>\n",
       "      <td>21.41</td>\n",
       "      <td>19.07</td>\n",
       "      <td>12.65</td>\n",
       "      <td>3.10</td>\n",
       "      <td>8.36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.21</td>\n",
       "      <td>25.10</td>\n",
       "      <td>4.46</td>\n",
       "      <td>5.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-03</th>\n",
       "      <td>4.83</td>\n",
       "      <td>7.81</td>\n",
       "      <td>10.90</td>\n",
       "      <td>13.94</td>\n",
       "      <td>12.98</td>\n",
       "      <td>10.68</td>\n",
       "      <td>15.40</td>\n",
       "      <td>45.61</td>\n",
       "      <td>8.76</td>\n",
       "      <td>26.39</td>\n",
       "      <td>14.42</td>\n",
       "      <td>7.37</td>\n",
       "      <td>66.89</td>\n",
       "      <td>5.25</td>\n",
       "      <td>186.48</td>\n",
       "      <td>11.00</td>\n",
       "      <td>16.72</td>\n",
       "      <td>17.70</td>\n",
       "      <td>9.17</td>\n",
       "      <td>6.40</td>\n",
       "      <td>57.00</td>\n",
       "      <td>8.47</td>\n",
       "      <td>20.90</td>\n",
       "      <td>13.79</td>\n",
       "      <td>6.52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.35</td>\n",
       "      <td>14.18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.75</td>\n",
       "      <td>40.15</td>\n",
       "      <td>4.41</td>\n",
       "      <td>21.86</td>\n",
       "      <td>19.30</td>\n",
       "      <td>12.54</td>\n",
       "      <td>3.10</td>\n",
       "      <td>8.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.22</td>\n",
       "      <td>24.89</td>\n",
       "      <td>4.50</td>\n",
       "      <td>5.31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-06</th>\n",
       "      <td>4.82</td>\n",
       "      <td>7.78</td>\n",
       "      <td>10.84</td>\n",
       "      <td>13.89</td>\n",
       "      <td>12.86</td>\n",
       "      <td>10.45</td>\n",
       "      <td>15.25</td>\n",
       "      <td>45.61</td>\n",
       "      <td>8.79</td>\n",
       "      <td>27.05</td>\n",
       "      <td>14.59</td>\n",
       "      <td>7.36</td>\n",
       "      <td>68.41</td>\n",
       "      <td>5.27</td>\n",
       "      <td>188.54</td>\n",
       "      <td>11.00</td>\n",
       "      <td>17.07</td>\n",
       "      <td>17.93</td>\n",
       "      <td>9.27</td>\n",
       "      <td>6.50</td>\n",
       "      <td>58.59</td>\n",
       "      <td>8.45</td>\n",
       "      <td>21.56</td>\n",
       "      <td>13.68</td>\n",
       "      <td>6.47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.35</td>\n",
       "      <td>14.17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.75</td>\n",
       "      <td>39.62</td>\n",
       "      <td>4.41</td>\n",
       "      <td>21.36</td>\n",
       "      <td>18.92</td>\n",
       "      <td>12.73</td>\n",
       "      <td>3.07</td>\n",
       "      <td>8.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.23</td>\n",
       "      <td>25.01</td>\n",
       "      <td>4.45</td>\n",
       "      <td>5.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-07</th>\n",
       "      <td>4.69</td>\n",
       "      <td>7.65</td>\n",
       "      <td>10.52</td>\n",
       "      <td>13.54</td>\n",
       "      <td>12.73</td>\n",
       "      <td>10.13</td>\n",
       "      <td>15.22</td>\n",
       "      <td>44.55</td>\n",
       "      <td>8.60</td>\n",
       "      <td>26.53</td>\n",
       "      <td>14.26</td>\n",
       "      <td>7.17</td>\n",
       "      <td>68.22</td>\n",
       "      <td>5.09</td>\n",
       "      <td>185.86</td>\n",
       "      <td>10.75</td>\n",
       "      <td>16.52</td>\n",
       "      <td>17.46</td>\n",
       "      <td>9.07</td>\n",
       "      <td>6.37</td>\n",
       "      <td>57.61</td>\n",
       "      <td>8.21</td>\n",
       "      <td>21.50</td>\n",
       "      <td>14.74</td>\n",
       "      <td>6.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.89</td>\n",
       "      <td>14.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.72</td>\n",
       "      <td>38.91</td>\n",
       "      <td>4.33</td>\n",
       "      <td>20.79</td>\n",
       "      <td>18.50</td>\n",
       "      <td>12.65</td>\n",
       "      <td>3.01</td>\n",
       "      <td>8.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.09</td>\n",
       "      <td>25.42</td>\n",
       "      <td>4.35</td>\n",
       "      <td>5.28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-08</th>\n",
       "      <td>4.90</td>\n",
       "      <td>7.78</td>\n",
       "      <td>10.95</td>\n",
       "      <td>13.88</td>\n",
       "      <td>12.99</td>\n",
       "      <td>10.42</td>\n",
       "      <td>15.59</td>\n",
       "      <td>48.51</td>\n",
       "      <td>8.79</td>\n",
       "      <td>26.59</td>\n",
       "      <td>14.81</td>\n",
       "      <td>7.38</td>\n",
       "      <td>68.80</td>\n",
       "      <td>5.20</td>\n",
       "      <td>188.29</td>\n",
       "      <td>11.04</td>\n",
       "      <td>17.15</td>\n",
       "      <td>17.90</td>\n",
       "      <td>9.28</td>\n",
       "      <td>6.76</td>\n",
       "      <td>59.17</td>\n",
       "      <td>8.67</td>\n",
       "      <td>21.80</td>\n",
       "      <td>15.24</td>\n",
       "      <td>6.47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.63</td>\n",
       "      <td>14.43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.41</td>\n",
       "      <td>21.75</td>\n",
       "      <td>19.24</td>\n",
       "      <td>12.98</td>\n",
       "      <td>3.09</td>\n",
       "      <td>8.36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.26</td>\n",
       "      <td>25.87</td>\n",
       "      <td>4.53</td>\n",
       "      <td>5.37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-09</th>\n",
       "      <td>4.88</td>\n",
       "      <td>7.69</td>\n",
       "      <td>10.87</td>\n",
       "      <td>13.77</td>\n",
       "      <td>12.99</td>\n",
       "      <td>10.56</td>\n",
       "      <td>15.49</td>\n",
       "      <td>47.57</td>\n",
       "      <td>8.87</td>\n",
       "      <td>26.93</td>\n",
       "      <td>14.91</td>\n",
       "      <td>7.55</td>\n",
       "      <td>68.77</td>\n",
       "      <td>5.26</td>\n",
       "      <td>190.75</td>\n",
       "      <td>11.11</td>\n",
       "      <td>17.40</td>\n",
       "      <td>17.98</td>\n",
       "      <td>9.33</td>\n",
       "      <td>6.67</td>\n",
       "      <td>59.40</td>\n",
       "      <td>8.57</td>\n",
       "      <td>21.32</td>\n",
       "      <td>15.13</td>\n",
       "      <td>6.41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.53</td>\n",
       "      <td>14.42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.73</td>\n",
       "      <td>39.88</td>\n",
       "      <td>4.42</td>\n",
       "      <td>21.26</td>\n",
       "      <td>19.07</td>\n",
       "      <td>12.98</td>\n",
       "      <td>3.08</td>\n",
       "      <td>8.27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.29</td>\n",
       "      <td>25.77</td>\n",
       "      <td>4.50</td>\n",
       "      <td>5.41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-10</th>\n",
       "      <td>5.08</td>\n",
       "      <td>7.67</td>\n",
       "      <td>10.97</td>\n",
       "      <td>13.88</td>\n",
       "      <td>12.89</td>\n",
       "      <td>10.91</td>\n",
       "      <td>15.45</td>\n",
       "      <td>47.50</td>\n",
       "      <td>8.90</td>\n",
       "      <td>26.63</td>\n",
       "      <td>14.66</td>\n",
       "      <td>7.68</td>\n",
       "      <td>68.61</td>\n",
       "      <td>5.32</td>\n",
       "      <td>190.51</td>\n",
       "      <td>11.06</td>\n",
       "      <td>17.51</td>\n",
       "      <td>17.70</td>\n",
       "      <td>9.33</td>\n",
       "      <td>6.68</td>\n",
       "      <td>59.00</td>\n",
       "      <td>8.65</td>\n",
       "      <td>21.76</td>\n",
       "      <td>15.29</td>\n",
       "      <td>6.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.45</td>\n",
       "      <td>14.24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.72</td>\n",
       "      <td>40.09</td>\n",
       "      <td>4.39</td>\n",
       "      <td>21.61</td>\n",
       "      <td>18.93</td>\n",
       "      <td>13.03</td>\n",
       "      <td>3.21</td>\n",
       "      <td>8.32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.31</td>\n",
       "      <td>25.91</td>\n",
       "      <td>4.50</td>\n",
       "      <td>5.47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-13</th>\n",
       "      <td>5.04</td>\n",
       "      <td>7.65</td>\n",
       "      <td>10.95</td>\n",
       "      <td>13.84</td>\n",
       "      <td>12.69</td>\n",
       "      <td>10.57</td>\n",
       "      <td>15.76</td>\n",
       "      <td>47.65</td>\n",
       "      <td>8.84</td>\n",
       "      <td>26.99</td>\n",
       "      <td>14.58</td>\n",
       "      <td>7.82</td>\n",
       "      <td>68.67</td>\n",
       "      <td>5.37</td>\n",
       "      <td>193.42</td>\n",
       "      <td>11.21</td>\n",
       "      <td>17.25</td>\n",
       "      <td>18.36</td>\n",
       "      <td>9.28</td>\n",
       "      <td>6.64</td>\n",
       "      <td>59.85</td>\n",
       "      <td>8.55</td>\n",
       "      <td>22.11</td>\n",
       "      <td>15.57</td>\n",
       "      <td>6.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.14</td>\n",
       "      <td>14.13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.71</td>\n",
       "      <td>40.28</td>\n",
       "      <td>4.37</td>\n",
       "      <td>21.41</td>\n",
       "      <td>18.64</td>\n",
       "      <td>13.41</td>\n",
       "      <td>3.16</td>\n",
       "      <td>8.37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.26</td>\n",
       "      <td>26.08</td>\n",
       "      <td>4.53</td>\n",
       "      <td>5.43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-14</th>\n",
       "      <td>5.01</td>\n",
       "      <td>7.66</td>\n",
       "      <td>10.87</td>\n",
       "      <td>13.69</td>\n",
       "      <td>12.66</td>\n",
       "      <td>10.62</td>\n",
       "      <td>15.52</td>\n",
       "      <td>47.50</td>\n",
       "      <td>8.89</td>\n",
       "      <td>26.87</td>\n",
       "      <td>14.31</td>\n",
       "      <td>7.89</td>\n",
       "      <td>69.29</td>\n",
       "      <td>5.38</td>\n",
       "      <td>193.82</td>\n",
       "      <td>11.27</td>\n",
       "      <td>17.10</td>\n",
       "      <td>18.06</td>\n",
       "      <td>9.24</td>\n",
       "      <td>6.78</td>\n",
       "      <td>60.71</td>\n",
       "      <td>8.49</td>\n",
       "      <td>22.09</td>\n",
       "      <td>15.42</td>\n",
       "      <td>6.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.14</td>\n",
       "      <td>14.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.70</td>\n",
       "      <td>39.58</td>\n",
       "      <td>4.35</td>\n",
       "      <td>20.83</td>\n",
       "      <td>18.39</td>\n",
       "      <td>13.38</td>\n",
       "      <td>3.16</td>\n",
       "      <td>8.37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.24</td>\n",
       "      <td>26.03</td>\n",
       "      <td>4.48</td>\n",
       "      <td>5.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-26</th>\n",
       "      <td>2.09</td>\n",
       "      <td>4.25</td>\n",
       "      <td>19.40</td>\n",
       "      <td>15.52</td>\n",
       "      <td>33.70</td>\n",
       "      <td>16.68</td>\n",
       "      <td>15.88</td>\n",
       "      <td>30.84</td>\n",
       "      <td>40.93</td>\n",
       "      <td>34.77</td>\n",
       "      <td>88.67</td>\n",
       "      <td>19.33</td>\n",
       "      <td>294.00</td>\n",
       "      <td>56.43</td>\n",
       "      <td>1898.00</td>\n",
       "      <td>32.44</td>\n",
       "      <td>31.81</td>\n",
       "      <td>20.00</td>\n",
       "      <td>24.33</td>\n",
       "      <td>62.51</td>\n",
       "      <td>286.93</td>\n",
       "      <td>9.51</td>\n",
       "      <td>36.19</td>\n",
       "      <td>48.17</td>\n",
       "      <td>23.39</td>\n",
       "      <td>6.28</td>\n",
       "      <td>53.06</td>\n",
       "      <td>25.88</td>\n",
       "      <td>31.26</td>\n",
       "      <td>17.88</td>\n",
       "      <td>14.72</td>\n",
       "      <td>2.82</td>\n",
       "      <td>43.12</td>\n",
       "      <td>4.35</td>\n",
       "      <td>20.29</td>\n",
       "      <td>29.44</td>\n",
       "      <td>35.35</td>\n",
       "      <td>5.01</td>\n",
       "      <td>13.13</td>\n",
       "      <td>3.74</td>\n",
       "      <td>5.44</td>\n",
       "      <td>192.41</td>\n",
       "      <td>9.15</td>\n",
       "      <td>13.78</td>\n",
       "      <td>41.81</td>\n",
       "      <td>89.55</td>\n",
       "      <td>79.16</td>\n",
       "      <td>92.10</td>\n",
       "      <td>80.15</td>\n",
       "      <td>114.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-29</th>\n",
       "      <td>2.07</td>\n",
       "      <td>4.26</td>\n",
       "      <td>19.37</td>\n",
       "      <td>15.56</td>\n",
       "      <td>33.28</td>\n",
       "      <td>16.61</td>\n",
       "      <td>15.50</td>\n",
       "      <td>30.59</td>\n",
       "      <td>40.61</td>\n",
       "      <td>34.23</td>\n",
       "      <td>87.80</td>\n",
       "      <td>19.29</td>\n",
       "      <td>291.09</td>\n",
       "      <td>56.78</td>\n",
       "      <td>1878.82</td>\n",
       "      <td>32.70</td>\n",
       "      <td>31.42</td>\n",
       "      <td>19.29</td>\n",
       "      <td>24.57</td>\n",
       "      <td>64.60</td>\n",
       "      <td>285.30</td>\n",
       "      <td>9.45</td>\n",
       "      <td>35.95</td>\n",
       "      <td>49.91</td>\n",
       "      <td>23.30</td>\n",
       "      <td>6.29</td>\n",
       "      <td>53.41</td>\n",
       "      <td>25.71</td>\n",
       "      <td>31.88</td>\n",
       "      <td>16.93</td>\n",
       "      <td>14.68</td>\n",
       "      <td>2.82</td>\n",
       "      <td>43.07</td>\n",
       "      <td>4.33</td>\n",
       "      <td>20.17</td>\n",
       "      <td>29.02</td>\n",
       "      <td>33.96</td>\n",
       "      <td>5.04</td>\n",
       "      <td>13.02</td>\n",
       "      <td>3.74</td>\n",
       "      <td>5.48</td>\n",
       "      <td>192.25</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.60</td>\n",
       "      <td>41.69</td>\n",
       "      <td>88.52</td>\n",
       "      <td>78.57</td>\n",
       "      <td>91.62</td>\n",
       "      <td>78.04</td>\n",
       "      <td>114.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-30</th>\n",
       "      <td>2.04</td>\n",
       "      <td>4.29</td>\n",
       "      <td>19.25</td>\n",
       "      <td>15.58</td>\n",
       "      <td>33.79</td>\n",
       "      <td>16.95</td>\n",
       "      <td>15.48</td>\n",
       "      <td>30.37</td>\n",
       "      <td>40.08</td>\n",
       "      <td>33.67</td>\n",
       "      <td>88.45</td>\n",
       "      <td>19.14</td>\n",
       "      <td>288.36</td>\n",
       "      <td>55.56</td>\n",
       "      <td>1870.00</td>\n",
       "      <td>33.33</td>\n",
       "      <td>30.99</td>\n",
       "      <td>20.07</td>\n",
       "      <td>25.40</td>\n",
       "      <td>64.96</td>\n",
       "      <td>284.09</td>\n",
       "      <td>9.41</td>\n",
       "      <td>36.13</td>\n",
       "      <td>47.88</td>\n",
       "      <td>23.28</td>\n",
       "      <td>6.21</td>\n",
       "      <td>52.80</td>\n",
       "      <td>25.60</td>\n",
       "      <td>30.52</td>\n",
       "      <td>16.82</td>\n",
       "      <td>14.68</td>\n",
       "      <td>2.82</td>\n",
       "      <td>42.89</td>\n",
       "      <td>4.36</td>\n",
       "      <td>20.47</td>\n",
       "      <td>29.50</td>\n",
       "      <td>34.20</td>\n",
       "      <td>5.07</td>\n",
       "      <td>13.11</td>\n",
       "      <td>3.74</td>\n",
       "      <td>5.47</td>\n",
       "      <td>190.40</td>\n",
       "      <td>8.90</td>\n",
       "      <td>14.41</td>\n",
       "      <td>41.51</td>\n",
       "      <td>87.35</td>\n",
       "      <td>78.25</td>\n",
       "      <td>93.26</td>\n",
       "      <td>77.72</td>\n",
       "      <td>112.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-31</th>\n",
       "      <td>2.01</td>\n",
       "      <td>4.27</td>\n",
       "      <td>19.52</td>\n",
       "      <td>15.75</td>\n",
       "      <td>35.05</td>\n",
       "      <td>17.30</td>\n",
       "      <td>15.47</td>\n",
       "      <td>30.14</td>\n",
       "      <td>40.36</td>\n",
       "      <td>34.66</td>\n",
       "      <td>88.57</td>\n",
       "      <td>19.20</td>\n",
       "      <td>300.99</td>\n",
       "      <td>52.88</td>\n",
       "      <td>1924.00</td>\n",
       "      <td>33.64</td>\n",
       "      <td>31.92</td>\n",
       "      <td>20.09</td>\n",
       "      <td>25.87</td>\n",
       "      <td>64.60</td>\n",
       "      <td>293.00</td>\n",
       "      <td>9.48</td>\n",
       "      <td>35.74</td>\n",
       "      <td>45.97</td>\n",
       "      <td>23.98</td>\n",
       "      <td>6.10</td>\n",
       "      <td>51.20</td>\n",
       "      <td>26.64</td>\n",
       "      <td>30.34</td>\n",
       "      <td>17.11</td>\n",
       "      <td>14.79</td>\n",
       "      <td>2.85</td>\n",
       "      <td>43.84</td>\n",
       "      <td>4.38</td>\n",
       "      <td>20.97</td>\n",
       "      <td>30.70</td>\n",
       "      <td>33.46</td>\n",
       "      <td>5.14</td>\n",
       "      <td>13.14</td>\n",
       "      <td>3.75</td>\n",
       "      <td>5.34</td>\n",
       "      <td>195.50</td>\n",
       "      <td>8.80</td>\n",
       "      <td>14.20</td>\n",
       "      <td>41.70</td>\n",
       "      <td>89.65</td>\n",
       "      <td>80.56</td>\n",
       "      <td>93.74</td>\n",
       "      <td>74.74</td>\n",
       "      <td>115.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-01</th>\n",
       "      <td>2.00</td>\n",
       "      <td>4.23</td>\n",
       "      <td>19.30</td>\n",
       "      <td>15.85</td>\n",
       "      <td>34.50</td>\n",
       "      <td>17.31</td>\n",
       "      <td>15.30</td>\n",
       "      <td>30.09</td>\n",
       "      <td>40.90</td>\n",
       "      <td>34.34</td>\n",
       "      <td>88.11</td>\n",
       "      <td>19.21</td>\n",
       "      <td>298.30</td>\n",
       "      <td>52.82</td>\n",
       "      <td>1880.89</td>\n",
       "      <td>34.50</td>\n",
       "      <td>31.60</td>\n",
       "      <td>20.37</td>\n",
       "      <td>26.21</td>\n",
       "      <td>62.71</td>\n",
       "      <td>292.58</td>\n",
       "      <td>9.39</td>\n",
       "      <td>34.55</td>\n",
       "      <td>45.88</td>\n",
       "      <td>23.91</td>\n",
       "      <td>6.00</td>\n",
       "      <td>51.65</td>\n",
       "      <td>26.80</td>\n",
       "      <td>31.11</td>\n",
       "      <td>17.11</td>\n",
       "      <td>14.73</td>\n",
       "      <td>2.83</td>\n",
       "      <td>43.65</td>\n",
       "      <td>4.36</td>\n",
       "      <td>20.82</td>\n",
       "      <td>30.45</td>\n",
       "      <td>32.25</td>\n",
       "      <td>5.15</td>\n",
       "      <td>13.00</td>\n",
       "      <td>3.76</td>\n",
       "      <td>5.36</td>\n",
       "      <td>186.80</td>\n",
       "      <td>8.65</td>\n",
       "      <td>13.70</td>\n",
       "      <td>41.17</td>\n",
       "      <td>87.75</td>\n",
       "      <td>78.61</td>\n",
       "      <td>90.58</td>\n",
       "      <td>74.86</td>\n",
       "      <td>112.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-02</th>\n",
       "      <td>2.00</td>\n",
       "      <td>4.26</td>\n",
       "      <td>19.24</td>\n",
       "      <td>15.61</td>\n",
       "      <td>34.32</td>\n",
       "      <td>17.02</td>\n",
       "      <td>15.26</td>\n",
       "      <td>30.16</td>\n",
       "      <td>40.21</td>\n",
       "      <td>33.90</td>\n",
       "      <td>86.95</td>\n",
       "      <td>19.15</td>\n",
       "      <td>296.11</td>\n",
       "      <td>52.21</td>\n",
       "      <td>1875.00</td>\n",
       "      <td>34.37</td>\n",
       "      <td>31.17</td>\n",
       "      <td>20.15</td>\n",
       "      <td>25.63</td>\n",
       "      <td>63.25</td>\n",
       "      <td>288.53</td>\n",
       "      <td>9.32</td>\n",
       "      <td>33.90</td>\n",
       "      <td>45.22</td>\n",
       "      <td>23.82</td>\n",
       "      <td>6.02</td>\n",
       "      <td>50.95</td>\n",
       "      <td>26.89</td>\n",
       "      <td>30.66</td>\n",
       "      <td>17.03</td>\n",
       "      <td>14.62</td>\n",
       "      <td>2.83</td>\n",
       "      <td>43.70</td>\n",
       "      <td>4.35</td>\n",
       "      <td>20.75</td>\n",
       "      <td>29.70</td>\n",
       "      <td>31.65</td>\n",
       "      <td>5.11</td>\n",
       "      <td>12.92</td>\n",
       "      <td>3.79</td>\n",
       "      <td>5.42</td>\n",
       "      <td>180.31</td>\n",
       "      <td>8.52</td>\n",
       "      <td>13.33</td>\n",
       "      <td>41.55</td>\n",
       "      <td>86.25</td>\n",
       "      <td>78.00</td>\n",
       "      <td>89.87</td>\n",
       "      <td>74.51</td>\n",
       "      <td>113.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-05</th>\n",
       "      <td>2.03</td>\n",
       "      <td>4.34</td>\n",
       "      <td>19.27</td>\n",
       "      <td>15.45</td>\n",
       "      <td>34.23</td>\n",
       "      <td>17.22</td>\n",
       "      <td>15.21</td>\n",
       "      <td>30.08</td>\n",
       "      <td>36.19</td>\n",
       "      <td>33.73</td>\n",
       "      <td>88.65</td>\n",
       "      <td>19.12</td>\n",
       "      <td>294.00</td>\n",
       "      <td>52.45</td>\n",
       "      <td>1835.00</td>\n",
       "      <td>33.73</td>\n",
       "      <td>31.01</td>\n",
       "      <td>19.79</td>\n",
       "      <td>25.58</td>\n",
       "      <td>62.27</td>\n",
       "      <td>282.78</td>\n",
       "      <td>9.40</td>\n",
       "      <td>33.37</td>\n",
       "      <td>45.77</td>\n",
       "      <td>23.82</td>\n",
       "      <td>6.07</td>\n",
       "      <td>50.49</td>\n",
       "      <td>27.31</td>\n",
       "      <td>32.56</td>\n",
       "      <td>17.08</td>\n",
       "      <td>14.84</td>\n",
       "      <td>2.84</td>\n",
       "      <td>43.80</td>\n",
       "      <td>4.36</td>\n",
       "      <td>20.90</td>\n",
       "      <td>29.86</td>\n",
       "      <td>31.19</td>\n",
       "      <td>5.17</td>\n",
       "      <td>13.05</td>\n",
       "      <td>3.82</td>\n",
       "      <td>5.56</td>\n",
       "      <td>180.10</td>\n",
       "      <td>8.59</td>\n",
       "      <td>13.24</td>\n",
       "      <td>41.74</td>\n",
       "      <td>83.80</td>\n",
       "      <td>76.25</td>\n",
       "      <td>88.52</td>\n",
       "      <td>73.20</td>\n",
       "      <td>111.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-06</th>\n",
       "      <td>2.05</td>\n",
       "      <td>4.41</td>\n",
       "      <td>19.48</td>\n",
       "      <td>15.73</td>\n",
       "      <td>33.62</td>\n",
       "      <td>17.63</td>\n",
       "      <td>15.42</td>\n",
       "      <td>30.85</td>\n",
       "      <td>35.42</td>\n",
       "      <td>33.88</td>\n",
       "      <td>91.50</td>\n",
       "      <td>19.58</td>\n",
       "      <td>294.02</td>\n",
       "      <td>56.87</td>\n",
       "      <td>1845.00</td>\n",
       "      <td>33.66</td>\n",
       "      <td>31.00</td>\n",
       "      <td>19.71</td>\n",
       "      <td>25.69</td>\n",
       "      <td>61.53</td>\n",
       "      <td>286.02</td>\n",
       "      <td>9.46</td>\n",
       "      <td>33.63</td>\n",
       "      <td>47.14</td>\n",
       "      <td>23.75</td>\n",
       "      <td>6.12</td>\n",
       "      <td>53.16</td>\n",
       "      <td>27.55</td>\n",
       "      <td>32.88</td>\n",
       "      <td>17.06</td>\n",
       "      <td>14.92</td>\n",
       "      <td>2.84</td>\n",
       "      <td>43.90</td>\n",
       "      <td>4.36</td>\n",
       "      <td>21.08</td>\n",
       "      <td>30.34</td>\n",
       "      <td>31.84</td>\n",
       "      <td>5.24</td>\n",
       "      <td>13.18</td>\n",
       "      <td>3.81</td>\n",
       "      <td>5.61</td>\n",
       "      <td>182.72</td>\n",
       "      <td>8.84</td>\n",
       "      <td>13.39</td>\n",
       "      <td>42.56</td>\n",
       "      <td>84.21</td>\n",
       "      <td>76.32</td>\n",
       "      <td>88.87</td>\n",
       "      <td>74.99</td>\n",
       "      <td>112.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-07</th>\n",
       "      <td>2.06</td>\n",
       "      <td>4.41</td>\n",
       "      <td>19.37</td>\n",
       "      <td>15.60</td>\n",
       "      <td>33.38</td>\n",
       "      <td>17.55</td>\n",
       "      <td>15.40</td>\n",
       "      <td>30.79</td>\n",
       "      <td>35.55</td>\n",
       "      <td>33.43</td>\n",
       "      <td>90.52</td>\n",
       "      <td>19.76</td>\n",
       "      <td>291.48</td>\n",
       "      <td>56.69</td>\n",
       "      <td>1818.01</td>\n",
       "      <td>33.59</td>\n",
       "      <td>30.41</td>\n",
       "      <td>19.62</td>\n",
       "      <td>25.80</td>\n",
       "      <td>61.67</td>\n",
       "      <td>278.12</td>\n",
       "      <td>9.47</td>\n",
       "      <td>33.22</td>\n",
       "      <td>47.24</td>\n",
       "      <td>23.57</td>\n",
       "      <td>6.13</td>\n",
       "      <td>53.46</td>\n",
       "      <td>26.94</td>\n",
       "      <td>32.61</td>\n",
       "      <td>17.09</td>\n",
       "      <td>14.88</td>\n",
       "      <td>2.83</td>\n",
       "      <td>43.60</td>\n",
       "      <td>4.35</td>\n",
       "      <td>20.98</td>\n",
       "      <td>30.25</td>\n",
       "      <td>32.09</td>\n",
       "      <td>5.23</td>\n",
       "      <td>13.14</td>\n",
       "      <td>3.82</td>\n",
       "      <td>5.58</td>\n",
       "      <td>183.95</td>\n",
       "      <td>8.94</td>\n",
       "      <td>13.44</td>\n",
       "      <td>42.73</td>\n",
       "      <td>84.24</td>\n",
       "      <td>75.65</td>\n",
       "      <td>89.00</td>\n",
       "      <td>75.36</td>\n",
       "      <td>116.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-08</th>\n",
       "      <td>2.04</td>\n",
       "      <td>4.41</td>\n",
       "      <td>19.31</td>\n",
       "      <td>15.75</td>\n",
       "      <td>33.30</td>\n",
       "      <td>17.58</td>\n",
       "      <td>15.35</td>\n",
       "      <td>30.29</td>\n",
       "      <td>33.96</td>\n",
       "      <td>33.73</td>\n",
       "      <td>92.01</td>\n",
       "      <td>19.70</td>\n",
       "      <td>293.75</td>\n",
       "      <td>56.50</td>\n",
       "      <td>1815.00</td>\n",
       "      <td>33.99</td>\n",
       "      <td>30.20</td>\n",
       "      <td>19.33</td>\n",
       "      <td>25.88</td>\n",
       "      <td>60.41</td>\n",
       "      <td>285.59</td>\n",
       "      <td>9.44</td>\n",
       "      <td>33.27</td>\n",
       "      <td>47.76</td>\n",
       "      <td>23.65</td>\n",
       "      <td>6.07</td>\n",
       "      <td>53.39</td>\n",
       "      <td>26.82</td>\n",
       "      <td>32.30</td>\n",
       "      <td>17.01</td>\n",
       "      <td>14.84</td>\n",
       "      <td>2.83</td>\n",
       "      <td>43.84</td>\n",
       "      <td>4.35</td>\n",
       "      <td>20.95</td>\n",
       "      <td>30.76</td>\n",
       "      <td>30.98</td>\n",
       "      <td>5.23</td>\n",
       "      <td>13.14</td>\n",
       "      <td>3.75</td>\n",
       "      <td>5.53</td>\n",
       "      <td>186.00</td>\n",
       "      <td>9.06</td>\n",
       "      <td>13.26</td>\n",
       "      <td>42.18</td>\n",
       "      <td>82.74</td>\n",
       "      <td>75.80</td>\n",
       "      <td>87.70</td>\n",
       "      <td>73.00</td>\n",
       "      <td>115.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-09</th>\n",
       "      <td>2.06</td>\n",
       "      <td>4.45</td>\n",
       "      <td>19.78</td>\n",
       "      <td>16.26</td>\n",
       "      <td>34.50</td>\n",
       "      <td>18.47</td>\n",
       "      <td>15.48</td>\n",
       "      <td>30.68</td>\n",
       "      <td>35.00</td>\n",
       "      <td>34.78</td>\n",
       "      <td>95.61</td>\n",
       "      <td>20.06</td>\n",
       "      <td>298.11</td>\n",
       "      <td>54.56</td>\n",
       "      <td>1844.79</td>\n",
       "      <td>35.30</td>\n",
       "      <td>31.37</td>\n",
       "      <td>19.54</td>\n",
       "      <td>26.50</td>\n",
       "      <td>60.70</td>\n",
       "      <td>291.21</td>\n",
       "      <td>9.54</td>\n",
       "      <td>33.70</td>\n",
       "      <td>48.03</td>\n",
       "      <td>23.91</td>\n",
       "      <td>6.08</td>\n",
       "      <td>53.18</td>\n",
       "      <td>27.49</td>\n",
       "      <td>32.73</td>\n",
       "      <td>17.38</td>\n",
       "      <td>15.07</td>\n",
       "      <td>2.84</td>\n",
       "      <td>44.69</td>\n",
       "      <td>4.36</td>\n",
       "      <td>21.47</td>\n",
       "      <td>31.50</td>\n",
       "      <td>31.31</td>\n",
       "      <td>5.36</td>\n",
       "      <td>13.28</td>\n",
       "      <td>3.80</td>\n",
       "      <td>5.59</td>\n",
       "      <td>191.09</td>\n",
       "      <td>9.19</td>\n",
       "      <td>13.29</td>\n",
       "      <td>42.70</td>\n",
       "      <td>84.83</td>\n",
       "      <td>79.40</td>\n",
       "      <td>88.92</td>\n",
       "      <td>76.98</td>\n",
       "      <td>114.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-13</th>\n",
       "      <td>2.05</td>\n",
       "      <td>4.43</td>\n",
       "      <td>19.83</td>\n",
       "      <td>16.30</td>\n",
       "      <td>35.35</td>\n",
       "      <td>18.09</td>\n",
       "      <td>15.65</td>\n",
       "      <td>31.47</td>\n",
       "      <td>34.44</td>\n",
       "      <td>35.52</td>\n",
       "      <td>93.00</td>\n",
       "      <td>20.03</td>\n",
       "      <td>302.00</td>\n",
       "      <td>54.99</td>\n",
       "      <td>1879.00</td>\n",
       "      <td>36.15</td>\n",
       "      <td>31.96</td>\n",
       "      <td>19.58</td>\n",
       "      <td>26.48</td>\n",
       "      <td>60.12</td>\n",
       "      <td>293.00</td>\n",
       "      <td>9.52</td>\n",
       "      <td>33.74</td>\n",
       "      <td>49.00</td>\n",
       "      <td>23.79</td>\n",
       "      <td>6.02</td>\n",
       "      <td>53.27</td>\n",
       "      <td>27.32</td>\n",
       "      <td>32.45</td>\n",
       "      <td>17.59</td>\n",
       "      <td>14.97</td>\n",
       "      <td>2.85</td>\n",
       "      <td>45.06</td>\n",
       "      <td>4.38</td>\n",
       "      <td>21.52</td>\n",
       "      <td>31.46</td>\n",
       "      <td>32.00</td>\n",
       "      <td>5.32</td>\n",
       "      <td>13.24</td>\n",
       "      <td>3.81</td>\n",
       "      <td>5.55</td>\n",
       "      <td>192.47</td>\n",
       "      <td>9.29</td>\n",
       "      <td>13.26</td>\n",
       "      <td>42.95</td>\n",
       "      <td>76.35</td>\n",
       "      <td>81.01</td>\n",
       "      <td>89.10</td>\n",
       "      <td>76.94</td>\n",
       "      <td>114.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-14</th>\n",
       "      <td>2.02</td>\n",
       "      <td>4.38</td>\n",
       "      <td>19.58</td>\n",
       "      <td>16.15</td>\n",
       "      <td>34.86</td>\n",
       "      <td>18.14</td>\n",
       "      <td>15.44</td>\n",
       "      <td>30.70</td>\n",
       "      <td>33.76</td>\n",
       "      <td>35.68</td>\n",
       "      <td>91.36</td>\n",
       "      <td>19.84</td>\n",
       "      <td>300.29</td>\n",
       "      <td>53.73</td>\n",
       "      <td>1869.00</td>\n",
       "      <td>36.30</td>\n",
       "      <td>31.59</td>\n",
       "      <td>19.71</td>\n",
       "      <td>26.49</td>\n",
       "      <td>59.67</td>\n",
       "      <td>292.30</td>\n",
       "      <td>9.46</td>\n",
       "      <td>33.60</td>\n",
       "      <td>49.23</td>\n",
       "      <td>23.70</td>\n",
       "      <td>5.94</td>\n",
       "      <td>52.55</td>\n",
       "      <td>26.81</td>\n",
       "      <td>32.35</td>\n",
       "      <td>17.38</td>\n",
       "      <td>14.81</td>\n",
       "      <td>2.85</td>\n",
       "      <td>44.65</td>\n",
       "      <td>4.36</td>\n",
       "      <td>21.26</td>\n",
       "      <td>31.63</td>\n",
       "      <td>31.74</td>\n",
       "      <td>5.26</td>\n",
       "      <td>13.11</td>\n",
       "      <td>3.81</td>\n",
       "      <td>5.52</td>\n",
       "      <td>191.55</td>\n",
       "      <td>9.00</td>\n",
       "      <td>13.12</td>\n",
       "      <td>39.00</td>\n",
       "      <td>75.32</td>\n",
       "      <td>81.90</td>\n",
       "      <td>88.34</td>\n",
       "      <td>76.26</td>\n",
       "      <td>112.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-15</th>\n",
       "      <td>2.00</td>\n",
       "      <td>4.40</td>\n",
       "      <td>19.53</td>\n",
       "      <td>16.20</td>\n",
       "      <td>36.01</td>\n",
       "      <td>18.85</td>\n",
       "      <td>15.34</td>\n",
       "      <td>30.01</td>\n",
       "      <td>33.04</td>\n",
       "      <td>35.49</td>\n",
       "      <td>91.50</td>\n",
       "      <td>19.46</td>\n",
       "      <td>298.56</td>\n",
       "      <td>51.30</td>\n",
       "      <td>1880.00</td>\n",
       "      <td>35.71</td>\n",
       "      <td>32.23</td>\n",
       "      <td>19.45</td>\n",
       "      <td>26.88</td>\n",
       "      <td>58.54</td>\n",
       "      <td>296.00</td>\n",
       "      <td>9.46</td>\n",
       "      <td>33.69</td>\n",
       "      <td>47.20</td>\n",
       "      <td>23.72</td>\n",
       "      <td>5.87</td>\n",
       "      <td>48.66</td>\n",
       "      <td>26.85</td>\n",
       "      <td>32.39</td>\n",
       "      <td>17.69</td>\n",
       "      <td>14.87</td>\n",
       "      <td>2.87</td>\n",
       "      <td>45.09</td>\n",
       "      <td>4.39</td>\n",
       "      <td>21.31</td>\n",
       "      <td>31.74</td>\n",
       "      <td>30.57</td>\n",
       "      <td>5.37</td>\n",
       "      <td>13.08</td>\n",
       "      <td>3.78</td>\n",
       "      <td>5.54</td>\n",
       "      <td>191.35</td>\n",
       "      <td>8.95</td>\n",
       "      <td>12.93</td>\n",
       "      <td>38.80</td>\n",
       "      <td>76.81</td>\n",
       "      <td>81.60</td>\n",
       "      <td>86.74</td>\n",
       "      <td>72.96</td>\n",
       "      <td>108.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-16</th>\n",
       "      <td>1.96</td>\n",
       "      <td>4.30</td>\n",
       "      <td>18.42</td>\n",
       "      <td>15.60</td>\n",
       "      <td>34.95</td>\n",
       "      <td>18.05</td>\n",
       "      <td>15.02</td>\n",
       "      <td>28.80</td>\n",
       "      <td>32.17</td>\n",
       "      <td>34.83</td>\n",
       "      <td>90.38</td>\n",
       "      <td>19.03</td>\n",
       "      <td>293.20</td>\n",
       "      <td>49.52</td>\n",
       "      <td>1859.00</td>\n",
       "      <td>33.99</td>\n",
       "      <td>31.19</td>\n",
       "      <td>19.53</td>\n",
       "      <td>26.06</td>\n",
       "      <td>55.60</td>\n",
       "      <td>289.50</td>\n",
       "      <td>9.05</td>\n",
       "      <td>32.88</td>\n",
       "      <td>46.88</td>\n",
       "      <td>23.46</td>\n",
       "      <td>5.68</td>\n",
       "      <td>48.30</td>\n",
       "      <td>24.97</td>\n",
       "      <td>30.96</td>\n",
       "      <td>17.22</td>\n",
       "      <td>14.12</td>\n",
       "      <td>2.85</td>\n",
       "      <td>43.93</td>\n",
       "      <td>4.36</td>\n",
       "      <td>20.88</td>\n",
       "      <td>31.06</td>\n",
       "      <td>28.88</td>\n",
       "      <td>5.15</td>\n",
       "      <td>12.41</td>\n",
       "      <td>3.75</td>\n",
       "      <td>5.37</td>\n",
       "      <td>188.51</td>\n",
       "      <td>8.68</td>\n",
       "      <td>12.56</td>\n",
       "      <td>37.45</td>\n",
       "      <td>73.74</td>\n",
       "      <td>80.94</td>\n",
       "      <td>83.70</td>\n",
       "      <td>71.47</td>\n",
       "      <td>106.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-19</th>\n",
       "      <td>1.91</td>\n",
       "      <td>4.18</td>\n",
       "      <td>18.42</td>\n",
       "      <td>14.97</td>\n",
       "      <td>35.09</td>\n",
       "      <td>18.44</td>\n",
       "      <td>15.01</td>\n",
       "      <td>28.34</td>\n",
       "      <td>32.19</td>\n",
       "      <td>34.69</td>\n",
       "      <td>91.36</td>\n",
       "      <td>18.82</td>\n",
       "      <td>289.50</td>\n",
       "      <td>49.87</td>\n",
       "      <td>1871.64</td>\n",
       "      <td>33.69</td>\n",
       "      <td>30.45</td>\n",
       "      <td>18.03</td>\n",
       "      <td>26.16</td>\n",
       "      <td>54.30</td>\n",
       "      <td>293.75</td>\n",
       "      <td>9.06</td>\n",
       "      <td>32.90</td>\n",
       "      <td>46.01</td>\n",
       "      <td>23.48</td>\n",
       "      <td>5.64</td>\n",
       "      <td>48.12</td>\n",
       "      <td>24.96</td>\n",
       "      <td>31.50</td>\n",
       "      <td>17.34</td>\n",
       "      <td>14.11</td>\n",
       "      <td>2.87</td>\n",
       "      <td>43.93</td>\n",
       "      <td>4.38</td>\n",
       "      <td>20.42</td>\n",
       "      <td>30.86</td>\n",
       "      <td>29.98</td>\n",
       "      <td>5.24</td>\n",
       "      <td>12.35</td>\n",
       "      <td>3.74</td>\n",
       "      <td>5.35</td>\n",
       "      <td>188.45</td>\n",
       "      <td>8.62</td>\n",
       "      <td>12.13</td>\n",
       "      <td>37.31</td>\n",
       "      <td>73.60</td>\n",
       "      <td>81.47</td>\n",
       "      <td>86.20</td>\n",
       "      <td>72.40</td>\n",
       "      <td>104.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-20</th>\n",
       "      <td>1.95</td>\n",
       "      <td>4.22</td>\n",
       "      <td>18.42</td>\n",
       "      <td>14.96</td>\n",
       "      <td>34.54</td>\n",
       "      <td>17.64</td>\n",
       "      <td>14.89</td>\n",
       "      <td>29.01</td>\n",
       "      <td>32.27</td>\n",
       "      <td>34.13</td>\n",
       "      <td>89.55</td>\n",
       "      <td>19.00</td>\n",
       "      <td>289.35</td>\n",
       "      <td>50.30</td>\n",
       "      <td>1878.00</td>\n",
       "      <td>32.77</td>\n",
       "      <td>29.58</td>\n",
       "      <td>18.19</td>\n",
       "      <td>25.87</td>\n",
       "      <td>52.96</td>\n",
       "      <td>296.09</td>\n",
       "      <td>9.09</td>\n",
       "      <td>32.66</td>\n",
       "      <td>45.75</td>\n",
       "      <td>23.42</td>\n",
       "      <td>5.69</td>\n",
       "      <td>50.04</td>\n",
       "      <td>24.85</td>\n",
       "      <td>31.35</td>\n",
       "      <td>17.08</td>\n",
       "      <td>14.18</td>\n",
       "      <td>2.84</td>\n",
       "      <td>43.24</td>\n",
       "      <td>4.37</td>\n",
       "      <td>20.10</td>\n",
       "      <td>29.84</td>\n",
       "      <td>29.83</td>\n",
       "      <td>5.11</td>\n",
       "      <td>12.33</td>\n",
       "      <td>3.73</td>\n",
       "      <td>5.16</td>\n",
       "      <td>194.23</td>\n",
       "      <td>8.70</td>\n",
       "      <td>12.22</td>\n",
       "      <td>37.30</td>\n",
       "      <td>74.05</td>\n",
       "      <td>80.78</td>\n",
       "      <td>85.84</td>\n",
       "      <td>74.60</td>\n",
       "      <td>105.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-21</th>\n",
       "      <td>1.98</td>\n",
       "      <td>4.25</td>\n",
       "      <td>18.43</td>\n",
       "      <td>15.06</td>\n",
       "      <td>34.41</td>\n",
       "      <td>17.83</td>\n",
       "      <td>14.92</td>\n",
       "      <td>30.48</td>\n",
       "      <td>31.70</td>\n",
       "      <td>33.43</td>\n",
       "      <td>87.94</td>\n",
       "      <td>18.43</td>\n",
       "      <td>281.08</td>\n",
       "      <td>50.09</td>\n",
       "      <td>1848.00</td>\n",
       "      <td>32.74</td>\n",
       "      <td>29.18</td>\n",
       "      <td>18.29</td>\n",
       "      <td>25.19</td>\n",
       "      <td>51.93</td>\n",
       "      <td>292.15</td>\n",
       "      <td>9.07</td>\n",
       "      <td>32.48</td>\n",
       "      <td>44.80</td>\n",
       "      <td>23.43</td>\n",
       "      <td>5.69</td>\n",
       "      <td>49.19</td>\n",
       "      <td>24.30</td>\n",
       "      <td>31.18</td>\n",
       "      <td>17.15</td>\n",
       "      <td>14.21</td>\n",
       "      <td>2.86</td>\n",
       "      <td>43.15</td>\n",
       "      <td>4.37</td>\n",
       "      <td>20.25</td>\n",
       "      <td>29.82</td>\n",
       "      <td>29.44</td>\n",
       "      <td>5.15</td>\n",
       "      <td>12.33</td>\n",
       "      <td>3.74</td>\n",
       "      <td>5.23</td>\n",
       "      <td>185.54</td>\n",
       "      <td>8.71</td>\n",
       "      <td>12.41</td>\n",
       "      <td>36.65</td>\n",
       "      <td>71.90</td>\n",
       "      <td>79.06</td>\n",
       "      <td>85.00</td>\n",
       "      <td>74.57</td>\n",
       "      <td>102.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-22</th>\n",
       "      <td>1.96</td>\n",
       "      <td>4.39</td>\n",
       "      <td>18.39</td>\n",
       "      <td>14.69</td>\n",
       "      <td>34.17</td>\n",
       "      <td>17.52</td>\n",
       "      <td>14.81</td>\n",
       "      <td>29.39</td>\n",
       "      <td>30.99</td>\n",
       "      <td>32.64</td>\n",
       "      <td>88.05</td>\n",
       "      <td>18.35</td>\n",
       "      <td>260.85</td>\n",
       "      <td>49.12</td>\n",
       "      <td>1820.81</td>\n",
       "      <td>32.80</td>\n",
       "      <td>28.73</td>\n",
       "      <td>18.49</td>\n",
       "      <td>24.56</td>\n",
       "      <td>51.93</td>\n",
       "      <td>292.44</td>\n",
       "      <td>9.12</td>\n",
       "      <td>32.00</td>\n",
       "      <td>46.60</td>\n",
       "      <td>23.42</td>\n",
       "      <td>5.69</td>\n",
       "      <td>49.18</td>\n",
       "      <td>24.37</td>\n",
       "      <td>31.99</td>\n",
       "      <td>17.05</td>\n",
       "      <td>14.25</td>\n",
       "      <td>2.86</td>\n",
       "      <td>42.48</td>\n",
       "      <td>4.39</td>\n",
       "      <td>20.26</td>\n",
       "      <td>29.91</td>\n",
       "      <td>28.63</td>\n",
       "      <td>5.12</td>\n",
       "      <td>12.33</td>\n",
       "      <td>3.76</td>\n",
       "      <td>5.34</td>\n",
       "      <td>187.10</td>\n",
       "      <td>8.65</td>\n",
       "      <td>12.27</td>\n",
       "      <td>36.48</td>\n",
       "      <td>70.15</td>\n",
       "      <td>78.00</td>\n",
       "      <td>83.00</td>\n",
       "      <td>73.07</td>\n",
       "      <td>101.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-23</th>\n",
       "      <td>1.96</td>\n",
       "      <td>4.47</td>\n",
       "      <td>18.36</td>\n",
       "      <td>14.42</td>\n",
       "      <td>34.36</td>\n",
       "      <td>17.55</td>\n",
       "      <td>14.77</td>\n",
       "      <td>28.73</td>\n",
       "      <td>30.48</td>\n",
       "      <td>32.93</td>\n",
       "      <td>87.76</td>\n",
       "      <td>18.26</td>\n",
       "      <td>252.69</td>\n",
       "      <td>49.30</td>\n",
       "      <td>1834.43</td>\n",
       "      <td>32.52</td>\n",
       "      <td>28.66</td>\n",
       "      <td>18.05</td>\n",
       "      <td>24.50</td>\n",
       "      <td>50.48</td>\n",
       "      <td>291.89</td>\n",
       "      <td>9.12</td>\n",
       "      <td>32.45</td>\n",
       "      <td>46.74</td>\n",
       "      <td>23.33</td>\n",
       "      <td>5.62</td>\n",
       "      <td>48.54</td>\n",
       "      <td>24.40</td>\n",
       "      <td>31.18</td>\n",
       "      <td>17.10</td>\n",
       "      <td>14.25</td>\n",
       "      <td>2.88</td>\n",
       "      <td>43.02</td>\n",
       "      <td>4.40</td>\n",
       "      <td>20.39</td>\n",
       "      <td>30.88</td>\n",
       "      <td>28.49</td>\n",
       "      <td>5.22</td>\n",
       "      <td>12.44</td>\n",
       "      <td>3.86</td>\n",
       "      <td>5.44</td>\n",
       "      <td>185.41</td>\n",
       "      <td>8.53</td>\n",
       "      <td>11.97</td>\n",
       "      <td>36.34</td>\n",
       "      <td>69.42</td>\n",
       "      <td>77.96</td>\n",
       "      <td>82.00</td>\n",
       "      <td>72.10</td>\n",
       "      <td>98.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-26</th>\n",
       "      <td>1.91</td>\n",
       "      <td>4.27</td>\n",
       "      <td>18.02</td>\n",
       "      <td>14.05</td>\n",
       "      <td>33.95</td>\n",
       "      <td>17.69</td>\n",
       "      <td>14.55</td>\n",
       "      <td>28.10</td>\n",
       "      <td>30.09</td>\n",
       "      <td>31.90</td>\n",
       "      <td>87.28</td>\n",
       "      <td>17.35</td>\n",
       "      <td>246.79</td>\n",
       "      <td>48.68</td>\n",
       "      <td>1863.00</td>\n",
       "      <td>32.04</td>\n",
       "      <td>28.33</td>\n",
       "      <td>17.76</td>\n",
       "      <td>24.95</td>\n",
       "      <td>50.52</td>\n",
       "      <td>299.65</td>\n",
       "      <td>8.97</td>\n",
       "      <td>32.36</td>\n",
       "      <td>45.29</td>\n",
       "      <td>23.05</td>\n",
       "      <td>5.45</td>\n",
       "      <td>48.80</td>\n",
       "      <td>23.75</td>\n",
       "      <td>30.36</td>\n",
       "      <td>16.75</td>\n",
       "      <td>14.01</td>\n",
       "      <td>2.85</td>\n",
       "      <td>42.49</td>\n",
       "      <td>4.35</td>\n",
       "      <td>19.90</td>\n",
       "      <td>30.82</td>\n",
       "      <td>28.70</td>\n",
       "      <td>5.15</td>\n",
       "      <td>12.21</td>\n",
       "      <td>3.82</td>\n",
       "      <td>5.11</td>\n",
       "      <td>194.51</td>\n",
       "      <td>7.82</td>\n",
       "      <td>11.26</td>\n",
       "      <td>35.67</td>\n",
       "      <td>70.47</td>\n",
       "      <td>79.70</td>\n",
       "      <td>83.55</td>\n",
       "      <td>73.45</td>\n",
       "      <td>98.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-27</th>\n",
       "      <td>1.91</td>\n",
       "      <td>4.28</td>\n",
       "      <td>18.07</td>\n",
       "      <td>14.37</td>\n",
       "      <td>33.90</td>\n",
       "      <td>17.67</td>\n",
       "      <td>14.65</td>\n",
       "      <td>28.30</td>\n",
       "      <td>30.45</td>\n",
       "      <td>33.65</td>\n",
       "      <td>87.66</td>\n",
       "      <td>17.74</td>\n",
       "      <td>264.07</td>\n",
       "      <td>49.32</td>\n",
       "      <td>1888.00</td>\n",
       "      <td>33.67</td>\n",
       "      <td>28.61</td>\n",
       "      <td>18.11</td>\n",
       "      <td>25.60</td>\n",
       "      <td>51.38</td>\n",
       "      <td>308.18</td>\n",
       "      <td>8.98</td>\n",
       "      <td>33.22</td>\n",
       "      <td>46.47</td>\n",
       "      <td>22.70</td>\n",
       "      <td>5.64</td>\n",
       "      <td>48.99</td>\n",
       "      <td>24.01</td>\n",
       "      <td>30.40</td>\n",
       "      <td>16.81</td>\n",
       "      <td>13.99</td>\n",
       "      <td>2.83</td>\n",
       "      <td>42.44</td>\n",
       "      <td>4.34</td>\n",
       "      <td>20.03</td>\n",
       "      <td>31.10</td>\n",
       "      <td>29.39</td>\n",
       "      <td>5.15</td>\n",
       "      <td>12.35</td>\n",
       "      <td>3.85</td>\n",
       "      <td>5.10</td>\n",
       "      <td>202.45</td>\n",
       "      <td>7.85</td>\n",
       "      <td>11.34</td>\n",
       "      <td>36.15</td>\n",
       "      <td>72.24</td>\n",
       "      <td>81.89</td>\n",
       "      <td>84.90</td>\n",
       "      <td>72.67</td>\n",
       "      <td>99.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-28</th>\n",
       "      <td>1.84</td>\n",
       "      <td>4.25</td>\n",
       "      <td>17.72</td>\n",
       "      <td>14.09</td>\n",
       "      <td>33.67</td>\n",
       "      <td>17.52</td>\n",
       "      <td>14.49</td>\n",
       "      <td>27.01</td>\n",
       "      <td>29.56</td>\n",
       "      <td>33.47</td>\n",
       "      <td>87.08</td>\n",
       "      <td>17.41</td>\n",
       "      <td>261.50</td>\n",
       "      <td>46.90</td>\n",
       "      <td>1883.00</td>\n",
       "      <td>33.51</td>\n",
       "      <td>28.30</td>\n",
       "      <td>17.84</td>\n",
       "      <td>25.30</td>\n",
       "      <td>49.32</td>\n",
       "      <td>306.85</td>\n",
       "      <td>8.82</td>\n",
       "      <td>33.26</td>\n",
       "      <td>43.98</td>\n",
       "      <td>22.46</td>\n",
       "      <td>5.55</td>\n",
       "      <td>47.90</td>\n",
       "      <td>23.42</td>\n",
       "      <td>30.64</td>\n",
       "      <td>16.84</td>\n",
       "      <td>13.86</td>\n",
       "      <td>2.85</td>\n",
       "      <td>41.89</td>\n",
       "      <td>4.35</td>\n",
       "      <td>20.08</td>\n",
       "      <td>31.48</td>\n",
       "      <td>28.11</td>\n",
       "      <td>5.10</td>\n",
       "      <td>12.26</td>\n",
       "      <td>3.83</td>\n",
       "      <td>5.07</td>\n",
       "      <td>202.48</td>\n",
       "      <td>7.48</td>\n",
       "      <td>11.05</td>\n",
       "      <td>35.83</td>\n",
       "      <td>70.80</td>\n",
       "      <td>83.00</td>\n",
       "      <td>82.63</td>\n",
       "      <td>65.40</td>\n",
       "      <td>97.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-29</th>\n",
       "      <td>1.84</td>\n",
       "      <td>4.26</td>\n",
       "      <td>17.40</td>\n",
       "      <td>13.85</td>\n",
       "      <td>33.15</td>\n",
       "      <td>17.28</td>\n",
       "      <td>14.27</td>\n",
       "      <td>26.97</td>\n",
       "      <td>29.61</td>\n",
       "      <td>34.97</td>\n",
       "      <td>89.49</td>\n",
       "      <td>17.15</td>\n",
       "      <td>266.10</td>\n",
       "      <td>47.98</td>\n",
       "      <td>1880.35</td>\n",
       "      <td>33.52</td>\n",
       "      <td>28.11</td>\n",
       "      <td>17.80</td>\n",
       "      <td>24.94</td>\n",
       "      <td>49.11</td>\n",
       "      <td>304.28</td>\n",
       "      <td>8.58</td>\n",
       "      <td>33.30</td>\n",
       "      <td>43.38</td>\n",
       "      <td>22.40</td>\n",
       "      <td>5.54</td>\n",
       "      <td>50.08</td>\n",
       "      <td>23.15</td>\n",
       "      <td>31.41</td>\n",
       "      <td>16.54</td>\n",
       "      <td>13.58</td>\n",
       "      <td>2.82</td>\n",
       "      <td>41.32</td>\n",
       "      <td>4.33</td>\n",
       "      <td>19.81</td>\n",
       "      <td>31.77</td>\n",
       "      <td>28.10</td>\n",
       "      <td>5.01</td>\n",
       "      <td>12.18</td>\n",
       "      <td>3.81</td>\n",
       "      <td>5.11</td>\n",
       "      <td>197.25</td>\n",
       "      <td>7.70</td>\n",
       "      <td>11.08</td>\n",
       "      <td>34.74</td>\n",
       "      <td>72.55</td>\n",
       "      <td>84.00</td>\n",
       "      <td>81.48</td>\n",
       "      <td>65.48</td>\n",
       "      <td>96.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-30</th>\n",
       "      <td>1.84</td>\n",
       "      <td>4.29</td>\n",
       "      <td>17.42</td>\n",
       "      <td>13.88</td>\n",
       "      <td>33.65</td>\n",
       "      <td>18.00</td>\n",
       "      <td>14.30</td>\n",
       "      <td>26.56</td>\n",
       "      <td>29.56</td>\n",
       "      <td>35.10</td>\n",
       "      <td>92.10</td>\n",
       "      <td>16.92</td>\n",
       "      <td>266.80</td>\n",
       "      <td>46.96</td>\n",
       "      <td>1872.50</td>\n",
       "      <td>33.89</td>\n",
       "      <td>28.81</td>\n",
       "      <td>17.60</td>\n",
       "      <td>24.77</td>\n",
       "      <td>47.67</td>\n",
       "      <td>302.89</td>\n",
       "      <td>8.66</td>\n",
       "      <td>32.98</td>\n",
       "      <td>41.95</td>\n",
       "      <td>22.74</td>\n",
       "      <td>5.63</td>\n",
       "      <td>47.91</td>\n",
       "      <td>23.17</td>\n",
       "      <td>31.64</td>\n",
       "      <td>16.65</td>\n",
       "      <td>13.67</td>\n",
       "      <td>2.86</td>\n",
       "      <td>41.58</td>\n",
       "      <td>4.35</td>\n",
       "      <td>20.33</td>\n",
       "      <td>31.63</td>\n",
       "      <td>27.80</td>\n",
       "      <td>5.15</td>\n",
       "      <td>12.12</td>\n",
       "      <td>3.83</td>\n",
       "      <td>5.13</td>\n",
       "      <td>198.25</td>\n",
       "      <td>7.84</td>\n",
       "      <td>11.02</td>\n",
       "      <td>34.41</td>\n",
       "      <td>71.69</td>\n",
       "      <td>82.82</td>\n",
       "      <td>80.13</td>\n",
       "      <td>64.34</td>\n",
       "      <td>93.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2613 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "tic         600010.SH  600028.SH  600030.SH  600031.SH  600036.SH  600048.SH  \\\n",
       "date                                                                           \n",
       "2012-01-04       4.15       7.36       9.56      12.09      11.67      10.05   \n",
       "2012-01-05       4.10       7.42       9.29      12.06      11.91       9.80   \n",
       "2012-01-06       4.34       7.48       9.39      12.06      11.99       9.71   \n",
       "2012-01-09       4.48       7.75       9.75      12.55      12.38      10.17   \n",
       "2012-01-10       4.54       7.79      10.12      13.31      12.56      10.35   \n",
       "2012-01-11       4.79       7.70      10.08      13.13      12.49      10.31   \n",
       "2012-01-12       4.77       7.66      10.03      13.22      12.62      10.39   \n",
       "2012-01-13       4.69       7.62       9.80      12.92      12.49      10.28   \n",
       "2012-01-16       4.32       7.54       9.83      13.06      12.39       9.93   \n",
       "2012-01-17       4.75       7.74      10.51      13.77      12.78      10.35   \n",
       "2012-01-18       4.73       7.58      10.47      13.69      12.52      10.12   \n",
       "2012-01-19       4.78       7.66      10.84      13.81      12.70      10.67   \n",
       "2012-01-20       4.77       7.74      11.01      13.99      13.00      10.94   \n",
       "2012-01-30       4.75       7.70      10.68        NaN      12.70      10.43   \n",
       "2012-01-31       4.87       7.76      10.69      14.21      12.65      10.50   \n",
       "2012-02-01       4.73       7.79      10.47      13.80      12.47      10.31   \n",
       "2012-02-02       4.83       7.86      10.80      14.06      12.87      10.56   \n",
       "2012-02-03       4.83       7.81      10.90      13.94      12.98      10.68   \n",
       "2012-02-06       4.82       7.78      10.84      13.89      12.86      10.45   \n",
       "2012-02-07       4.69       7.65      10.52      13.54      12.73      10.13   \n",
       "2012-02-08       4.90       7.78      10.95      13.88      12.99      10.42   \n",
       "2012-02-09       4.88       7.69      10.87      13.77      12.99      10.56   \n",
       "2012-02-10       5.08       7.67      10.97      13.88      12.89      10.91   \n",
       "2012-02-13       5.04       7.65      10.95      13.84      12.69      10.57   \n",
       "2012-02-14       5.01       7.66      10.87      13.69      12.66      10.62   \n",
       "...               ...        ...        ...        ...        ...        ...   \n",
       "2022-08-26       2.09       4.25      19.40      15.52      33.70      16.68   \n",
       "2022-08-29       2.07       4.26      19.37      15.56      33.28      16.61   \n",
       "2022-08-30       2.04       4.29      19.25      15.58      33.79      16.95   \n",
       "2022-08-31       2.01       4.27      19.52      15.75      35.05      17.30   \n",
       "2022-09-01       2.00       4.23      19.30      15.85      34.50      17.31   \n",
       "2022-09-02       2.00       4.26      19.24      15.61      34.32      17.02   \n",
       "2022-09-05       2.03       4.34      19.27      15.45      34.23      17.22   \n",
       "2022-09-06       2.05       4.41      19.48      15.73      33.62      17.63   \n",
       "2022-09-07       2.06       4.41      19.37      15.60      33.38      17.55   \n",
       "2022-09-08       2.04       4.41      19.31      15.75      33.30      17.58   \n",
       "2022-09-09       2.06       4.45      19.78      16.26      34.50      18.47   \n",
       "2022-09-13       2.05       4.43      19.83      16.30      35.35      18.09   \n",
       "2022-09-14       2.02       4.38      19.58      16.15      34.86      18.14   \n",
       "2022-09-15       2.00       4.40      19.53      16.20      36.01      18.85   \n",
       "2022-09-16       1.96       4.30      18.42      15.60      34.95      18.05   \n",
       "2022-09-19       1.91       4.18      18.42      14.97      35.09      18.44   \n",
       "2022-09-20       1.95       4.22      18.42      14.96      34.54      17.64   \n",
       "2022-09-21       1.98       4.25      18.43      15.06      34.41      17.83   \n",
       "2022-09-22       1.96       4.39      18.39      14.69      34.17      17.52   \n",
       "2022-09-23       1.96       4.47      18.36      14.42      34.36      17.55   \n",
       "2022-09-26       1.91       4.27      18.02      14.05      33.95      17.69   \n",
       "2022-09-27       1.91       4.28      18.07      14.37      33.90      17.67   \n",
       "2022-09-28       1.84       4.25      17.72      14.09      33.67      17.52   \n",
       "2022-09-29       1.84       4.26      17.40      13.85      33.15      17.28   \n",
       "2022-09-30       1.84       4.29      17.42      13.88      33.65      18.00   \n",
       "\n",
       "tic         600104.SH  600111.SH  600196.SH  600276.SH  600309.SH  600346.SH  \\\n",
       "date                                                                           \n",
       "2012-01-04      14.16      37.61       8.34      28.45      12.50       7.07   \n",
       "2012-01-05      14.39      35.64       8.25      27.00      12.10       6.86   \n",
       "2012-01-06      14.20      36.32       8.08      26.55      12.06       6.40   \n",
       "2012-01-09      14.90      39.02       8.34      27.40      12.47       6.64   \n",
       "2012-01-10      15.25      40.39       8.66      27.75      13.21       7.02   \n",
       "2012-01-11      15.10      42.63       8.63      27.70      13.25       7.14   \n",
       "2012-01-12      15.29      43.46       8.58      27.37      13.31       7.07   \n",
       "2012-01-13      14.69      44.96       8.31      26.80      12.83       6.81   \n",
       "2012-01-16      14.39      41.08       8.17      26.00      12.50       6.52   \n",
       "2012-01-17      15.33      45.19       8.61      26.02      13.39        NaN   \n",
       "2012-01-18      15.21      45.46       8.47      24.66      13.26       6.77   \n",
       "2012-01-19      15.46      46.58       8.62      25.20      13.76       6.79   \n",
       "2012-01-20      15.52      45.62       8.80      26.68      14.09       6.84   \n",
       "2012-01-30      15.48      46.06       8.63      26.19      13.67       7.14   \n",
       "2012-01-31      15.09      46.56        NaN      26.00        NaN       7.22   \n",
       "2012-02-01      14.93      44.73       8.51      25.86      13.78       7.16   \n",
       "2012-02-02      15.22      45.57       8.64      26.24      14.05       7.19   \n",
       "2012-02-03      15.40      45.61       8.76      26.39      14.42       7.37   \n",
       "2012-02-06      15.25      45.61       8.79      27.05      14.59       7.36   \n",
       "2012-02-07      15.22      44.55       8.60      26.53      14.26       7.17   \n",
       "2012-02-08      15.59      48.51       8.79      26.59      14.81       7.38   \n",
       "2012-02-09      15.49      47.57       8.87      26.93      14.91       7.55   \n",
       "2012-02-10      15.45      47.50       8.90      26.63      14.66       7.68   \n",
       "2012-02-13      15.76      47.65       8.84      26.99      14.58       7.82   \n",
       "2012-02-14      15.52      47.50       8.89      26.87      14.31       7.89   \n",
       "...               ...        ...        ...        ...        ...        ...   \n",
       "2022-08-26      15.88      30.84      40.93      34.77      88.67      19.33   \n",
       "2022-08-29      15.50      30.59      40.61      34.23      87.80      19.29   \n",
       "2022-08-30      15.48      30.37      40.08      33.67      88.45      19.14   \n",
       "2022-08-31      15.47      30.14      40.36      34.66      88.57      19.20   \n",
       "2022-09-01      15.30      30.09      40.90      34.34      88.11      19.21   \n",
       "2022-09-02      15.26      30.16      40.21      33.90      86.95      19.15   \n",
       "2022-09-05      15.21      30.08      36.19      33.73      88.65      19.12   \n",
       "2022-09-06      15.42      30.85      35.42      33.88      91.50      19.58   \n",
       "2022-09-07      15.40      30.79      35.55      33.43      90.52      19.76   \n",
       "2022-09-08      15.35      30.29      33.96      33.73      92.01      19.70   \n",
       "2022-09-09      15.48      30.68      35.00      34.78      95.61      20.06   \n",
       "2022-09-13      15.65      31.47      34.44      35.52      93.00      20.03   \n",
       "2022-09-14      15.44      30.70      33.76      35.68      91.36      19.84   \n",
       "2022-09-15      15.34      30.01      33.04      35.49      91.50      19.46   \n",
       "2022-09-16      15.02      28.80      32.17      34.83      90.38      19.03   \n",
       "2022-09-19      15.01      28.34      32.19      34.69      91.36      18.82   \n",
       "2022-09-20      14.89      29.01      32.27      34.13      89.55      19.00   \n",
       "2022-09-21      14.92      30.48      31.70      33.43      87.94      18.43   \n",
       "2022-09-22      14.81      29.39      30.99      32.64      88.05      18.35   \n",
       "2022-09-23      14.77      28.73      30.48      32.93      87.76      18.26   \n",
       "2022-09-26      14.55      28.10      30.09      31.90      87.28      17.35   \n",
       "2022-09-27      14.65      28.30      30.45      33.65      87.66      17.74   \n",
       "2022-09-28      14.49      27.01      29.56      33.47      87.08      17.41   \n",
       "2022-09-29      14.27      26.97      29.61      34.97      89.49      17.15   \n",
       "2022-09-30      14.30      26.56      29.56      35.10      92.10      16.92   \n",
       "\n",
       "tic         600436.SH  600438.SH  600519.SH  600570.SH  600585.SH  600588.SH  \\\n",
       "date                                                                           \n",
       "2012-01-04      73.03       4.85     185.27      11.50      15.28      16.90   \n",
       "2012-01-05      70.50       4.66     183.15      10.70      14.92      16.48   \n",
       "2012-01-06      70.08       4.72     186.64      10.67      14.72      16.23   \n",
       "2012-01-09      70.10       4.89     188.01      11.00      15.55      16.58   \n",
       "2012-01-10      72.00       5.10     194.48      11.34      16.59      17.02   \n",
       "2012-01-11      72.85       5.06     189.68      11.25      16.38      17.79   \n",
       "2012-01-12      73.99       5.03     190.35      11.05      16.51      17.14   \n",
       "2012-01-13      71.73       4.87     188.69      10.49      15.75      16.51   \n",
       "2012-01-16      69.15       4.76     177.41      10.30      15.28      16.03   \n",
       "2012-01-17      70.90       5.03     180.44      10.60      16.43      16.73   \n",
       "2012-01-18      63.81       4.93     177.38      10.48      16.82      16.49   \n",
       "2012-01-19      64.29       5.01     180.70      10.33      17.15      16.19   \n",
       "2012-01-20      65.74       5.10     185.97      10.41      17.79      16.48   \n",
       "2012-01-30      64.87       5.04     183.80      10.37      17.38      16.23   \n",
       "2012-01-31      65.93       5.08     186.41      10.39      17.37      16.45   \n",
       "2012-02-01      66.52       5.05     186.15      10.64      16.54      16.68   \n",
       "2012-02-02      66.67       5.25     186.43      10.77      16.90      17.14   \n",
       "2012-02-03      66.89       5.25     186.48      11.00      16.72      17.70   \n",
       "2012-02-06      68.41       5.27     188.54      11.00      17.07      17.93   \n",
       "2012-02-07      68.22       5.09     185.86      10.75      16.52      17.46   \n",
       "2012-02-08      68.80       5.20     188.29      11.04      17.15      17.90   \n",
       "2012-02-09      68.77       5.26     190.75      11.11      17.40      17.98   \n",
       "2012-02-10      68.61       5.32     190.51      11.06      17.51      17.70   \n",
       "2012-02-13      68.67       5.37     193.42      11.21      17.25      18.36   \n",
       "2012-02-14      69.29       5.38     193.82      11.27      17.10      18.06   \n",
       "...               ...        ...        ...        ...        ...        ...   \n",
       "2022-08-26     294.00      56.43    1898.00      32.44      31.81      20.00   \n",
       "2022-08-29     291.09      56.78    1878.82      32.70      31.42      19.29   \n",
       "2022-08-30     288.36      55.56    1870.00      33.33      30.99      20.07   \n",
       "2022-08-31     300.99      52.88    1924.00      33.64      31.92      20.09   \n",
       "2022-09-01     298.30      52.82    1880.89      34.50      31.60      20.37   \n",
       "2022-09-02     296.11      52.21    1875.00      34.37      31.17      20.15   \n",
       "2022-09-05     294.00      52.45    1835.00      33.73      31.01      19.79   \n",
       "2022-09-06     294.02      56.87    1845.00      33.66      31.00      19.71   \n",
       "2022-09-07     291.48      56.69    1818.01      33.59      30.41      19.62   \n",
       "2022-09-08     293.75      56.50    1815.00      33.99      30.20      19.33   \n",
       "2022-09-09     298.11      54.56    1844.79      35.30      31.37      19.54   \n",
       "2022-09-13     302.00      54.99    1879.00      36.15      31.96      19.58   \n",
       "2022-09-14     300.29      53.73    1869.00      36.30      31.59      19.71   \n",
       "2022-09-15     298.56      51.30    1880.00      35.71      32.23      19.45   \n",
       "2022-09-16     293.20      49.52    1859.00      33.99      31.19      19.53   \n",
       "2022-09-19     289.50      49.87    1871.64      33.69      30.45      18.03   \n",
       "2022-09-20     289.35      50.30    1878.00      32.77      29.58      18.19   \n",
       "2022-09-21     281.08      50.09    1848.00      32.74      29.18      18.29   \n",
       "2022-09-22     260.85      49.12    1820.81      32.80      28.73      18.49   \n",
       "2022-09-23     252.69      49.30    1834.43      32.52      28.66      18.05   \n",
       "2022-09-26     246.79      48.68    1863.00      32.04      28.33      17.76   \n",
       "2022-09-27     264.07      49.32    1888.00      33.67      28.61      18.11   \n",
       "2022-09-28     261.50      46.90    1883.00      33.51      28.30      17.84   \n",
       "2022-09-29     266.10      47.98    1880.35      33.52      28.11      17.80   \n",
       "2022-09-30     266.80      46.96    1872.50      33.89      28.81      17.60   \n",
       "\n",
       "tic         600690.SH  600745.SH  600809.SH  600837.SH  600887.SH  600893.SH  \\\n",
       "date                                                                           \n",
       "2012-01-04       8.78       5.79      57.79       7.12      19.73      13.29   \n",
       "2012-01-05       8.73       5.54      55.04       7.08      19.33      12.66   \n",
       "2012-01-06       8.79       5.76      53.69       7.30      19.66      12.95   \n",
       "2012-01-09       9.07       6.00      54.59       7.62      20.13      13.39   \n",
       "2012-01-10       9.42       6.21      57.00       7.93      20.58      13.79   \n",
       "2012-01-11       9.26       6.13      57.67       7.85      20.61      13.72   \n",
       "2012-01-12       9.23       6.28      55.89       7.85      20.50      14.10   \n",
       "2012-01-13       8.83       6.50      53.98       7.71      20.22      13.26   \n",
       "2012-01-16       8.70       5.91      50.77       7.64      19.01      12.89   \n",
       "2012-01-17       9.29       6.29      52.66       8.15      19.87      13.55   \n",
       "2012-01-18       9.08       6.19      51.61       8.07      19.14      13.32   \n",
       "2012-01-19       9.40       6.25      52.84       8.38      19.98      13.20   \n",
       "2012-01-20       9.51       6.26      54.34       8.60      20.54        NaN   \n",
       "2012-01-30       9.24       6.29      53.30       8.36      20.33      13.49   \n",
       "2012-01-31       9.21       6.38      54.97       8.36      20.44      13.48   \n",
       "2012-02-01       9.10       6.23      54.98       8.10      20.60      13.12   \n",
       "2012-02-02       9.19       6.33      55.72       8.53      20.92      13.31   \n",
       "2012-02-03       9.17       6.40      57.00       8.47      20.90      13.79   \n",
       "2012-02-06       9.27       6.50      58.59       8.45      21.56      13.68   \n",
       "2012-02-07       9.07       6.37      57.61       8.21      21.50      14.74   \n",
       "2012-02-08       9.28       6.76      59.17       8.67      21.80      15.24   \n",
       "2012-02-09       9.33       6.67      59.40       8.57      21.32      15.13   \n",
       "2012-02-10       9.33       6.68      59.00       8.65      21.76      15.29   \n",
       "2012-02-13       9.28       6.64      59.85       8.55      22.11      15.57   \n",
       "2012-02-14       9.24       6.78      60.71       8.49      22.09      15.42   \n",
       "...               ...        ...        ...        ...        ...        ...   \n",
       "2022-08-26      24.33      62.51     286.93       9.51      36.19      48.17   \n",
       "2022-08-29      24.57      64.60     285.30       9.45      35.95      49.91   \n",
       "2022-08-30      25.40      64.96     284.09       9.41      36.13      47.88   \n",
       "2022-08-31      25.87      64.60     293.00       9.48      35.74      45.97   \n",
       "2022-09-01      26.21      62.71     292.58       9.39      34.55      45.88   \n",
       "2022-09-02      25.63      63.25     288.53       9.32      33.90      45.22   \n",
       "2022-09-05      25.58      62.27     282.78       9.40      33.37      45.77   \n",
       "2022-09-06      25.69      61.53     286.02       9.46      33.63      47.14   \n",
       "2022-09-07      25.80      61.67     278.12       9.47      33.22      47.24   \n",
       "2022-09-08      25.88      60.41     285.59       9.44      33.27      47.76   \n",
       "2022-09-09      26.50      60.70     291.21       9.54      33.70      48.03   \n",
       "2022-09-13      26.48      60.12     293.00       9.52      33.74      49.00   \n",
       "2022-09-14      26.49      59.67     292.30       9.46      33.60      49.23   \n",
       "2022-09-15      26.88      58.54     296.00       9.46      33.69      47.20   \n",
       "2022-09-16      26.06      55.60     289.50       9.05      32.88      46.88   \n",
       "2022-09-19      26.16      54.30     293.75       9.06      32.90      46.01   \n",
       "2022-09-20      25.87      52.96     296.09       9.09      32.66      45.75   \n",
       "2022-09-21      25.19      51.93     292.15       9.07      32.48      44.80   \n",
       "2022-09-22      24.56      51.93     292.44       9.12      32.00      46.60   \n",
       "2022-09-23      24.50      50.48     291.89       9.12      32.45      46.74   \n",
       "2022-09-26      24.95      50.52     299.65       8.97      32.36      45.29   \n",
       "2022-09-27      25.60      51.38     308.18       8.98      33.22      46.47   \n",
       "2022-09-28      25.30      49.32     306.85       8.82      33.26      43.98   \n",
       "2022-09-29      24.94      49.11     304.28       8.58      33.30      43.38   \n",
       "2022-09-30      24.77      47.67     302.89       8.66      32.98      41.95   \n",
       "\n",
       "tic         600900.SH  600905.SH  601012.SH  601066.SH  601088.SH  601166.SH  \\\n",
       "date                                                                           \n",
       "2012-01-04       6.29        NaN        NaN        NaN      24.60      12.50   \n",
       "2012-01-05       6.24        NaN        NaN        NaN      24.29      12.71   \n",
       "2012-01-06       6.22        NaN        NaN        NaN      24.27      12.79   \n",
       "2012-01-09       6.29        NaN        NaN        NaN      26.01      13.04   \n",
       "2012-01-10       6.40        NaN        NaN        NaN      26.76      13.15   \n",
       "2012-01-11       6.38        NaN        NaN        NaN      26.49      13.02   \n",
       "2012-01-12       6.41        NaN        NaN        NaN      26.49      13.30   \n",
       "2012-01-13       6.35        NaN        NaN        NaN      26.33      13.28   \n",
       "2012-01-16       6.36        NaN        NaN        NaN      26.02      13.32   \n",
       "2012-01-17       6.53        NaN        NaN        NaN      27.38      13.60   \n",
       "2012-01-18       6.48        NaN        NaN        NaN      26.88      13.43   \n",
       "2012-01-19       6.56        NaN        NaN        NaN      27.10      13.78   \n",
       "2012-01-20       6.57        NaN        NaN        NaN      27.48      14.05   \n",
       "2012-01-30       6.45        NaN        NaN        NaN      26.68      13.83   \n",
       "2012-01-31       6.49        NaN        NaN        NaN      26.85      13.86   \n",
       "2012-02-01       6.44        NaN        NaN        NaN      26.57      13.56   \n",
       "2012-02-02       6.48        NaN        NaN        NaN      27.24      14.15   \n",
       "2012-02-03       6.52        NaN        NaN        NaN      27.35      14.18   \n",
       "2012-02-06       6.47        NaN        NaN        NaN      27.35      14.17   \n",
       "2012-02-07       6.33        NaN        NaN        NaN      26.89      14.02   \n",
       "2012-02-08       6.47        NaN        NaN        NaN      27.63      14.43   \n",
       "2012-02-09       6.41        NaN        NaN        NaN      27.53      14.42   \n",
       "2012-02-10       6.40        NaN        NaN        NaN      27.45      14.24   \n",
       "2012-02-13       6.39        NaN        NaN        NaN      27.14      14.13   \n",
       "2012-02-14       6.40        NaN        NaN        NaN      27.14      14.08   \n",
       "...               ...        ...        ...        ...        ...        ...   \n",
       "2022-08-26      23.39       6.28      53.06      25.88      31.26      17.88   \n",
       "2022-08-29      23.30       6.29      53.41      25.71      31.88      16.93   \n",
       "2022-08-30      23.28       6.21      52.80      25.60      30.52      16.82   \n",
       "2022-08-31      23.98       6.10      51.20      26.64      30.34      17.11   \n",
       "2022-09-01      23.91       6.00      51.65      26.80      31.11      17.11   \n",
       "2022-09-02      23.82       6.02      50.95      26.89      30.66      17.03   \n",
       "2022-09-05      23.82       6.07      50.49      27.31      32.56      17.08   \n",
       "2022-09-06      23.75       6.12      53.16      27.55      32.88      17.06   \n",
       "2022-09-07      23.57       6.13      53.46      26.94      32.61      17.09   \n",
       "2022-09-08      23.65       6.07      53.39      26.82      32.30      17.01   \n",
       "2022-09-09      23.91       6.08      53.18      27.49      32.73      17.38   \n",
       "2022-09-13      23.79       6.02      53.27      27.32      32.45      17.59   \n",
       "2022-09-14      23.70       5.94      52.55      26.81      32.35      17.38   \n",
       "2022-09-15      23.72       5.87      48.66      26.85      32.39      17.69   \n",
       "2022-09-16      23.46       5.68      48.30      24.97      30.96      17.22   \n",
       "2022-09-19      23.48       5.64      48.12      24.96      31.50      17.34   \n",
       "2022-09-20      23.42       5.69      50.04      24.85      31.35      17.08   \n",
       "2022-09-21      23.43       5.69      49.19      24.30      31.18      17.15   \n",
       "2022-09-22      23.42       5.69      49.18      24.37      31.99      17.05   \n",
       "2022-09-23      23.33       5.62      48.54      24.40      31.18      17.10   \n",
       "2022-09-26      23.05       5.45      48.80      23.75      30.36      16.75   \n",
       "2022-09-27      22.70       5.64      48.99      24.01      30.40      16.81   \n",
       "2022-09-28      22.46       5.55      47.90      23.42      30.64      16.84   \n",
       "2022-09-29      22.40       5.54      50.08      23.15      31.41      16.54   \n",
       "2022-09-30      22.74       5.63      47.91      23.17      31.64      16.65   \n",
       "\n",
       "tic         601211.SH  601288.SH  601318.SH  601398.SH  601601.SH  601628.SH  \\\n",
       "date                                                                           \n",
       "2012-01-04        NaN       2.60      33.90       4.22      19.04      17.46   \n",
       "2012-01-05        NaN       2.65      33.93       4.25      19.12      16.58   \n",
       "2012-01-06        NaN       2.66      33.85       4.28      19.23      16.73   \n",
       "2012-01-09        NaN       2.68      34.73       4.31      19.73      17.28   \n",
       "2012-01-10        NaN       2.69      36.29       4.35      20.40      18.23   \n",
       "2012-01-11        NaN       2.67      35.83       4.35      20.20      18.22   \n",
       "2012-01-12        NaN       2.65      36.37       4.33      20.03      18.30   \n",
       "2012-01-13        NaN       2.65      36.03       4.34      19.95      17.89   \n",
       "2012-01-16        NaN        NaN      35.59       4.31      19.85      17.81   \n",
       "2012-01-17        NaN       2.69      37.82       4.36      20.68      18.78   \n",
       "2012-01-18        NaN       2.69      37.45       4.31      20.50      18.45   \n",
       "2012-01-19        NaN       2.70      38.51       4.36      21.22      19.00   \n",
       "2012-01-20        NaN       2.72      39.10       4.36      21.84      19.33   \n",
       "2012-01-30        NaN       2.68      38.60       4.27      21.11      18.90   \n",
       "2012-01-31        NaN       2.70      38.34       4.30      21.01      18.78   \n",
       "2012-02-01        NaN       2.68      37.41       4.28      20.65      18.34   \n",
       "2012-02-02        NaN       2.73      39.64       4.38      21.41      19.07   \n",
       "2012-02-03        NaN       2.75      40.15       4.41      21.86      19.30   \n",
       "2012-02-06        NaN       2.75      39.62       4.41      21.36      18.92   \n",
       "2012-02-07        NaN       2.72      38.91       4.33      20.79      18.50   \n",
       "2012-02-08        NaN       2.75        NaN       4.41      21.75      19.24   \n",
       "2012-02-09        NaN       2.73      39.88       4.42      21.26      19.07   \n",
       "2012-02-10        NaN       2.72      40.09       4.39      21.61      18.93   \n",
       "2012-02-13        NaN       2.71      40.28       4.37      21.41      18.64   \n",
       "2012-02-14        NaN       2.70      39.58       4.35      20.83      18.39   \n",
       "...               ...        ...        ...        ...        ...        ...   \n",
       "2022-08-26      14.72       2.82      43.12       4.35      20.29      29.44   \n",
       "2022-08-29      14.68       2.82      43.07       4.33      20.17      29.02   \n",
       "2022-08-30      14.68       2.82      42.89       4.36      20.47      29.50   \n",
       "2022-08-31      14.79       2.85      43.84       4.38      20.97      30.70   \n",
       "2022-09-01      14.73       2.83      43.65       4.36      20.82      30.45   \n",
       "2022-09-02      14.62       2.83      43.70       4.35      20.75      29.70   \n",
       "2022-09-05      14.84       2.84      43.80       4.36      20.90      29.86   \n",
       "2022-09-06      14.92       2.84      43.90       4.36      21.08      30.34   \n",
       "2022-09-07      14.88       2.83      43.60       4.35      20.98      30.25   \n",
       "2022-09-08      14.84       2.83      43.84       4.35      20.95      30.76   \n",
       "2022-09-09      15.07       2.84      44.69       4.36      21.47      31.50   \n",
       "2022-09-13      14.97       2.85      45.06       4.38      21.52      31.46   \n",
       "2022-09-14      14.81       2.85      44.65       4.36      21.26      31.63   \n",
       "2022-09-15      14.87       2.87      45.09       4.39      21.31      31.74   \n",
       "2022-09-16      14.12       2.85      43.93       4.36      20.88      31.06   \n",
       "2022-09-19      14.11       2.87      43.93       4.38      20.42      30.86   \n",
       "2022-09-20      14.18       2.84      43.24       4.37      20.10      29.84   \n",
       "2022-09-21      14.21       2.86      43.15       4.37      20.25      29.82   \n",
       "2022-09-22      14.25       2.86      42.48       4.39      20.26      29.91   \n",
       "2022-09-23      14.25       2.88      43.02       4.40      20.39      30.88   \n",
       "2022-09-26      14.01       2.85      42.49       4.35      19.90      30.82   \n",
       "2022-09-27      13.99       2.83      42.44       4.34      20.03      31.10   \n",
       "2022-09-28      13.86       2.85      41.89       4.35      20.08      31.48   \n",
       "2022-09-29      13.58       2.82      41.32       4.33      19.81      31.77   \n",
       "2022-09-30      13.67       2.86      41.58       4.35      20.33      31.63   \n",
       "\n",
       "tic         601633.SH  601668.SH  601688.SH  601728.SH  601857.SH  601888.SH  \\\n",
       "date                                                                           \n",
       "2012-01-04      11.87       2.86       7.62        NaN       9.75      25.59   \n",
       "2012-01-05      12.10       2.87       7.36        NaN       9.80      24.17   \n",
       "2012-01-06      11.81       2.87       7.49        NaN       9.96      23.61   \n",
       "2012-01-09      12.26       2.93       7.79        NaN      10.03      24.41   \n",
       "2012-01-10      12.46       3.08       8.13        NaN      10.12      25.60   \n",
       "2012-01-11      12.41       3.04       8.00        NaN      10.04      25.95   \n",
       "2012-01-12      12.65       3.04       7.93        NaN      10.06      25.47   \n",
       "2012-01-13      12.26       3.01       7.87        NaN      10.20      24.93   \n",
       "2012-01-16        NaN       2.98       7.73        NaN      10.09      23.59   \n",
       "2012-01-17      12.99       3.10       8.19        NaN      10.32      24.72   \n",
       "2012-01-18      12.77       3.05       8.22        NaN      10.22      24.01   \n",
       "2012-01-19      12.88       3.09       8.48        NaN      10.26      24.41   \n",
       "2012-01-20      12.99       3.14       8.50        NaN      10.26      25.01   \n",
       "2012-01-30      12.73       3.07       8.20        NaN      10.13      25.10   \n",
       "2012-01-31      12.57       3.07       8.33        NaN      10.21      24.73   \n",
       "2012-02-01      12.40       3.04       8.16        NaN      10.18      24.71   \n",
       "2012-02-02      12.65       3.10       8.36        NaN      10.21      25.10   \n",
       "2012-02-03      12.54       3.10       8.35        NaN      10.22      24.89   \n",
       "2012-02-06      12.73       3.07       8.26        NaN      10.23      25.01   \n",
       "2012-02-07      12.65       3.01       8.05        NaN      10.09      25.42   \n",
       "2012-02-08      12.98       3.09       8.36        NaN      10.26      25.87   \n",
       "2012-02-09      12.98       3.08       8.27        NaN      10.29      25.77   \n",
       "2012-02-10      13.03       3.21       8.32        NaN      10.31      25.91   \n",
       "2012-02-13      13.41       3.16       8.37        NaN      10.26      26.08   \n",
       "2012-02-14      13.38       3.16       8.37        NaN      10.24      26.03   \n",
       "...               ...        ...        ...        ...        ...        ...   \n",
       "2022-08-26      35.35       5.01      13.13       3.74       5.44     192.41   \n",
       "2022-08-29      33.96       5.04      13.02       3.74       5.48     192.25   \n",
       "2022-08-30      34.20       5.07      13.11       3.74       5.47     190.40   \n",
       "2022-08-31      33.46       5.14      13.14       3.75       5.34     195.50   \n",
       "2022-09-01      32.25       5.15      13.00       3.76       5.36     186.80   \n",
       "2022-09-02      31.65       5.11      12.92       3.79       5.42     180.31   \n",
       "2022-09-05      31.19       5.17      13.05       3.82       5.56     180.10   \n",
       "2022-09-06      31.84       5.24      13.18       3.81       5.61     182.72   \n",
       "2022-09-07      32.09       5.23      13.14       3.82       5.58     183.95   \n",
       "2022-09-08      30.98       5.23      13.14       3.75       5.53     186.00   \n",
       "2022-09-09      31.31       5.36      13.28       3.80       5.59     191.09   \n",
       "2022-09-13      32.00       5.32      13.24       3.81       5.55     192.47   \n",
       "2022-09-14      31.74       5.26      13.11       3.81       5.52     191.55   \n",
       "2022-09-15      30.57       5.37      13.08       3.78       5.54     191.35   \n",
       "2022-09-16      28.88       5.15      12.41       3.75       5.37     188.51   \n",
       "2022-09-19      29.98       5.24      12.35       3.74       5.35     188.45   \n",
       "2022-09-20      29.83       5.11      12.33       3.73       5.16     194.23   \n",
       "2022-09-21      29.44       5.15      12.33       3.74       5.23     185.54   \n",
       "2022-09-22      28.63       5.12      12.33       3.76       5.34     187.10   \n",
       "2022-09-23      28.49       5.22      12.44       3.86       5.44     185.41   \n",
       "2022-09-26      28.70       5.15      12.21       3.82       5.11     194.51   \n",
       "2022-09-27      29.39       5.15      12.35       3.85       5.10     202.45   \n",
       "2022-09-28      28.11       5.10      12.26       3.83       5.07     202.48   \n",
       "2022-09-29      28.10       5.01      12.18       3.81       5.11     197.25   \n",
       "2022-09-30      27.80       5.15      12.12       3.83       5.13     198.25   \n",
       "\n",
       "tic         601899.SH  601919.SH  601995.SH  603259.SH  603288.SH  603501.SH  \\\n",
       "date                                                                           \n",
       "2012-01-04       3.81       4.50        NaN        NaN        NaN        NaN   \n",
       "2012-01-05       3.78       4.30        NaN        NaN        NaN        NaN   \n",
       "2012-01-06       3.80       4.32        NaN        NaN        NaN        NaN   \n",
       "2012-01-09       3.93       4.47        NaN        NaN        NaN        NaN   \n",
       "2012-01-10       4.12       4.68        NaN        NaN        NaN        NaN   \n",
       "2012-01-11       4.16       4.63        NaN        NaN        NaN        NaN   \n",
       "2012-01-12       4.15       4.69        NaN        NaN        NaN        NaN   \n",
       "2012-01-13       4.06       4.48        NaN        NaN        NaN        NaN   \n",
       "2012-01-16       3.96       4.38        NaN        NaN        NaN        NaN   \n",
       "2012-01-17       4.36       4.82        NaN        NaN        NaN        NaN   \n",
       "2012-01-18       4.29       5.10        NaN        NaN        NaN        NaN   \n",
       "2012-01-19       4.48       5.08        NaN        NaN        NaN        NaN   \n",
       "2012-01-20       4.47       5.05        NaN        NaN        NaN        NaN   \n",
       "2012-01-30       4.49       5.00        NaN        NaN        NaN        NaN   \n",
       "2012-01-31       4.44       5.08        NaN        NaN        NaN        NaN   \n",
       "2012-02-01       4.37       5.10        NaN        NaN        NaN        NaN   \n",
       "2012-02-02       4.46       5.33        NaN        NaN        NaN        NaN   \n",
       "2012-02-03       4.50       5.31        NaN        NaN        NaN        NaN   \n",
       "2012-02-06       4.45       5.30        NaN        NaN        NaN        NaN   \n",
       "2012-02-07       4.35       5.28        NaN        NaN        NaN        NaN   \n",
       "2012-02-08       4.53       5.37        NaN        NaN        NaN        NaN   \n",
       "2012-02-09       4.50       5.41        NaN        NaN        NaN        NaN   \n",
       "2012-02-10       4.50       5.47        NaN        NaN        NaN        NaN   \n",
       "2012-02-13       4.53       5.43        NaN        NaN        NaN        NaN   \n",
       "2012-02-14       4.48       5.39        NaN        NaN        NaN        NaN   \n",
       "...               ...        ...        ...        ...        ...        ...   \n",
       "2022-08-26       9.15      13.78      41.81      89.55      79.16      92.10   \n",
       "2022-08-29       9.02      13.60      41.69      88.52      78.57      91.62   \n",
       "2022-08-30       8.90      14.41      41.51      87.35      78.25      93.26   \n",
       "2022-08-31       8.80      14.20      41.70      89.65      80.56      93.74   \n",
       "2022-09-01       8.65      13.70      41.17      87.75      78.61      90.58   \n",
       "2022-09-02       8.52      13.33      41.55      86.25      78.00      89.87   \n",
       "2022-09-05       8.59      13.24      41.74      83.80      76.25      88.52   \n",
       "2022-09-06       8.84      13.39      42.56      84.21      76.32      88.87   \n",
       "2022-09-07       8.94      13.44      42.73      84.24      75.65      89.00   \n",
       "2022-09-08       9.06      13.26      42.18      82.74      75.80      87.70   \n",
       "2022-09-09       9.19      13.29      42.70      84.83      79.40      88.92   \n",
       "2022-09-13       9.29      13.26      42.95      76.35      81.01      89.10   \n",
       "2022-09-14       9.00      13.12      39.00      75.32      81.90      88.34   \n",
       "2022-09-15       8.95      12.93      38.80      76.81      81.60      86.74   \n",
       "2022-09-16       8.68      12.56      37.45      73.74      80.94      83.70   \n",
       "2022-09-19       8.62      12.13      37.31      73.60      81.47      86.20   \n",
       "2022-09-20       8.70      12.22      37.30      74.05      80.78      85.84   \n",
       "2022-09-21       8.71      12.41      36.65      71.90      79.06      85.00   \n",
       "2022-09-22       8.65      12.27      36.48      70.15      78.00      83.00   \n",
       "2022-09-23       8.53      11.97      36.34      69.42      77.96      82.00   \n",
       "2022-09-26       7.82      11.26      35.67      70.47      79.70      83.55   \n",
       "2022-09-27       7.85      11.34      36.15      72.24      81.89      84.90   \n",
       "2022-09-28       7.48      11.05      35.83      70.80      83.00      82.63   \n",
       "2022-09-29       7.70      11.08      34.74      72.55      84.00      81.48   \n",
       "2022-09-30       7.84      11.02      34.41      71.69      82.82      80.13   \n",
       "\n",
       "tic         603799.SH  603986.SH  \n",
       "date                              \n",
       "2012-01-04        NaN        NaN  \n",
       "2012-01-05        NaN        NaN  \n",
       "2012-01-06        NaN        NaN  \n",
       "2012-01-09        NaN        NaN  \n",
       "2012-01-10        NaN        NaN  \n",
       "2012-01-11        NaN        NaN  \n",
       "2012-01-12        NaN        NaN  \n",
       "2012-01-13        NaN        NaN  \n",
       "2012-01-16        NaN        NaN  \n",
       "2012-01-17        NaN        NaN  \n",
       "2012-01-18        NaN        NaN  \n",
       "2012-01-19        NaN        NaN  \n",
       "2012-01-20        NaN        NaN  \n",
       "2012-01-30        NaN        NaN  \n",
       "2012-01-31        NaN        NaN  \n",
       "2012-02-01        NaN        NaN  \n",
       "2012-02-02        NaN        NaN  \n",
       "2012-02-03        NaN        NaN  \n",
       "2012-02-06        NaN        NaN  \n",
       "2012-02-07        NaN        NaN  \n",
       "2012-02-08        NaN        NaN  \n",
       "2012-02-09        NaN        NaN  \n",
       "2012-02-10        NaN        NaN  \n",
       "2012-02-13        NaN        NaN  \n",
       "2012-02-14        NaN        NaN  \n",
       "...               ...        ...  \n",
       "2022-08-26      80.15     114.90  \n",
       "2022-08-29      78.04     114.49  \n",
       "2022-08-30      77.72     112.52  \n",
       "2022-08-31      74.74     115.97  \n",
       "2022-09-01      74.86     112.95  \n",
       "2022-09-02      74.51     113.25  \n",
       "2022-09-05      73.20     111.22  \n",
       "2022-09-06      74.99     112.71  \n",
       "2022-09-07      75.36     116.63  \n",
       "2022-09-08      73.00     115.30  \n",
       "2022-09-09      76.98     114.92  \n",
       "2022-09-13      76.94     114.19  \n",
       "2022-09-14      76.26     112.42  \n",
       "2022-09-15      72.96     108.60  \n",
       "2022-09-16      71.47     106.21  \n",
       "2022-09-19      72.40     104.55  \n",
       "2022-09-20      74.60     105.44  \n",
       "2022-09-21      74.57     102.30  \n",
       "2022-09-22      73.07     101.06  \n",
       "2022-09-23      72.10      98.24  \n",
       "2022-09-26      73.45      98.35  \n",
       "2022-09-27      72.67      99.91  \n",
       "2022-09-28      65.40      97.40  \n",
       "2022-09-29      65.48      96.24  \n",
       "2022-09-30      64.34      93.75  \n",
       "\n",
       "[2613 rows x 50 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sort_values([\"date\", \"tic\"], ignore_index=True)\n",
    "df.index = df.date.factorize()[0]\n",
    "merged_closes = df.pivot_table(index=\"date\", columns=\"tic\", values=\"close\")\n",
    "merged_closes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a439d02d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T02:27:07.928699Z",
     "start_time": "2022-10-12T02:27:07.811836Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>tic</th>\n",
       "      <th>600010.SH</th>\n",
       "      <th>600028.SH</th>\n",
       "      <th>600030.SH</th>\n",
       "      <th>600031.SH</th>\n",
       "      <th>600036.SH</th>\n",
       "      <th>600048.SH</th>\n",
       "      <th>600104.SH</th>\n",
       "      <th>600111.SH</th>\n",
       "      <th>600196.SH</th>\n",
       "      <th>600276.SH</th>\n",
       "      <th>600309.SH</th>\n",
       "      <th>600436.SH</th>\n",
       "      <th>600438.SH</th>\n",
       "      <th>600519.SH</th>\n",
       "      <th>600570.SH</th>\n",
       "      <th>600585.SH</th>\n",
       "      <th>600588.SH</th>\n",
       "      <th>600690.SH</th>\n",
       "      <th>600809.SH</th>\n",
       "      <th>600837.SH</th>\n",
       "      <th>600887.SH</th>\n",
       "      <th>600893.SH</th>\n",
       "      <th>600900.SH</th>\n",
       "      <th>601012.SH</th>\n",
       "      <th>601088.SH</th>\n",
       "      <th>601166.SH</th>\n",
       "      <th>601288.SH</th>\n",
       "      <th>601318.SH</th>\n",
       "      <th>601398.SH</th>\n",
       "      <th>601601.SH</th>\n",
       "      <th>601628.SH</th>\n",
       "      <th>601633.SH</th>\n",
       "      <th>601668.SH</th>\n",
       "      <th>601688.SH</th>\n",
       "      <th>601857.SH</th>\n",
       "      <th>601888.SH</th>\n",
       "      <th>601899.SH</th>\n",
       "      <th>601919.SH</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-04</th>\n",
       "      <td>4.15</td>\n",
       "      <td>7.36</td>\n",
       "      <td>9.56</td>\n",
       "      <td>12.09</td>\n",
       "      <td>11.67</td>\n",
       "      <td>10.05</td>\n",
       "      <td>14.16</td>\n",
       "      <td>37.61</td>\n",
       "      <td>8.34</td>\n",
       "      <td>28.45</td>\n",
       "      <td>12.50</td>\n",
       "      <td>73.03</td>\n",
       "      <td>4.85</td>\n",
       "      <td>185.27</td>\n",
       "      <td>11.50</td>\n",
       "      <td>15.28</td>\n",
       "      <td>16.90</td>\n",
       "      <td>8.78</td>\n",
       "      <td>57.79</td>\n",
       "      <td>7.12</td>\n",
       "      <td>19.73</td>\n",
       "      <td>13.29</td>\n",
       "      <td>6.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.60</td>\n",
       "      <td>12.50</td>\n",
       "      <td>2.60</td>\n",
       "      <td>33.90</td>\n",
       "      <td>4.22</td>\n",
       "      <td>19.04</td>\n",
       "      <td>17.46</td>\n",
       "      <td>11.87</td>\n",
       "      <td>2.86</td>\n",
       "      <td>7.62</td>\n",
       "      <td>9.75</td>\n",
       "      <td>25.59</td>\n",
       "      <td>3.81</td>\n",
       "      <td>4.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-05</th>\n",
       "      <td>4.10</td>\n",
       "      <td>7.42</td>\n",
       "      <td>9.29</td>\n",
       "      <td>12.06</td>\n",
       "      <td>11.91</td>\n",
       "      <td>9.80</td>\n",
       "      <td>14.39</td>\n",
       "      <td>35.64</td>\n",
       "      <td>8.25</td>\n",
       "      <td>27.00</td>\n",
       "      <td>12.10</td>\n",
       "      <td>70.50</td>\n",
       "      <td>4.66</td>\n",
       "      <td>183.15</td>\n",
       "      <td>10.70</td>\n",
       "      <td>14.92</td>\n",
       "      <td>16.48</td>\n",
       "      <td>8.73</td>\n",
       "      <td>55.04</td>\n",
       "      <td>7.08</td>\n",
       "      <td>19.33</td>\n",
       "      <td>12.66</td>\n",
       "      <td>6.24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.29</td>\n",
       "      <td>12.71</td>\n",
       "      <td>2.65</td>\n",
       "      <td>33.93</td>\n",
       "      <td>4.25</td>\n",
       "      <td>19.12</td>\n",
       "      <td>16.58</td>\n",
       "      <td>12.10</td>\n",
       "      <td>2.87</td>\n",
       "      <td>7.36</td>\n",
       "      <td>9.80</td>\n",
       "      <td>24.17</td>\n",
       "      <td>3.78</td>\n",
       "      <td>4.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-06</th>\n",
       "      <td>4.34</td>\n",
       "      <td>7.48</td>\n",
       "      <td>9.39</td>\n",
       "      <td>12.06</td>\n",
       "      <td>11.99</td>\n",
       "      <td>9.71</td>\n",
       "      <td>14.20</td>\n",
       "      <td>36.32</td>\n",
       "      <td>8.08</td>\n",
       "      <td>26.55</td>\n",
       "      <td>12.06</td>\n",
       "      <td>70.08</td>\n",
       "      <td>4.72</td>\n",
       "      <td>186.64</td>\n",
       "      <td>10.67</td>\n",
       "      <td>14.72</td>\n",
       "      <td>16.23</td>\n",
       "      <td>8.79</td>\n",
       "      <td>53.69</td>\n",
       "      <td>7.30</td>\n",
       "      <td>19.66</td>\n",
       "      <td>12.95</td>\n",
       "      <td>6.22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.27</td>\n",
       "      <td>12.79</td>\n",
       "      <td>2.66</td>\n",
       "      <td>33.85</td>\n",
       "      <td>4.28</td>\n",
       "      <td>19.23</td>\n",
       "      <td>16.73</td>\n",
       "      <td>11.81</td>\n",
       "      <td>2.87</td>\n",
       "      <td>7.49</td>\n",
       "      <td>9.96</td>\n",
       "      <td>23.61</td>\n",
       "      <td>3.80</td>\n",
       "      <td>4.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-09</th>\n",
       "      <td>4.48</td>\n",
       "      <td>7.75</td>\n",
       "      <td>9.75</td>\n",
       "      <td>12.55</td>\n",
       "      <td>12.38</td>\n",
       "      <td>10.17</td>\n",
       "      <td>14.90</td>\n",
       "      <td>39.02</td>\n",
       "      <td>8.34</td>\n",
       "      <td>27.40</td>\n",
       "      <td>12.47</td>\n",
       "      <td>70.10</td>\n",
       "      <td>4.89</td>\n",
       "      <td>188.01</td>\n",
       "      <td>11.00</td>\n",
       "      <td>15.55</td>\n",
       "      <td>16.58</td>\n",
       "      <td>9.07</td>\n",
       "      <td>54.59</td>\n",
       "      <td>7.62</td>\n",
       "      <td>20.13</td>\n",
       "      <td>13.39</td>\n",
       "      <td>6.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.01</td>\n",
       "      <td>13.04</td>\n",
       "      <td>2.68</td>\n",
       "      <td>34.73</td>\n",
       "      <td>4.31</td>\n",
       "      <td>19.73</td>\n",
       "      <td>17.28</td>\n",
       "      <td>12.26</td>\n",
       "      <td>2.93</td>\n",
       "      <td>7.79</td>\n",
       "      <td>10.03</td>\n",
       "      <td>24.41</td>\n",
       "      <td>3.93</td>\n",
       "      <td>4.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-10</th>\n",
       "      <td>4.54</td>\n",
       "      <td>7.79</td>\n",
       "      <td>10.12</td>\n",
       "      <td>13.31</td>\n",
       "      <td>12.56</td>\n",
       "      <td>10.35</td>\n",
       "      <td>15.25</td>\n",
       "      <td>40.39</td>\n",
       "      <td>8.66</td>\n",
       "      <td>27.75</td>\n",
       "      <td>13.21</td>\n",
       "      <td>72.00</td>\n",
       "      <td>5.10</td>\n",
       "      <td>194.48</td>\n",
       "      <td>11.34</td>\n",
       "      <td>16.59</td>\n",
       "      <td>17.02</td>\n",
       "      <td>9.42</td>\n",
       "      <td>57.00</td>\n",
       "      <td>7.93</td>\n",
       "      <td>20.58</td>\n",
       "      <td>13.79</td>\n",
       "      <td>6.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.76</td>\n",
       "      <td>13.15</td>\n",
       "      <td>2.69</td>\n",
       "      <td>36.29</td>\n",
       "      <td>4.35</td>\n",
       "      <td>20.40</td>\n",
       "      <td>18.23</td>\n",
       "      <td>12.46</td>\n",
       "      <td>3.08</td>\n",
       "      <td>8.13</td>\n",
       "      <td>10.12</td>\n",
       "      <td>25.60</td>\n",
       "      <td>4.12</td>\n",
       "      <td>4.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-11</th>\n",
       "      <td>4.79</td>\n",
       "      <td>7.70</td>\n",
       "      <td>10.08</td>\n",
       "      <td>13.13</td>\n",
       "      <td>12.49</td>\n",
       "      <td>10.31</td>\n",
       "      <td>15.10</td>\n",
       "      <td>42.63</td>\n",
       "      <td>8.63</td>\n",
       "      <td>27.70</td>\n",
       "      <td>13.25</td>\n",
       "      <td>72.85</td>\n",
       "      <td>5.06</td>\n",
       "      <td>189.68</td>\n",
       "      <td>11.25</td>\n",
       "      <td>16.38</td>\n",
       "      <td>17.79</td>\n",
       "      <td>9.26</td>\n",
       "      <td>57.67</td>\n",
       "      <td>7.85</td>\n",
       "      <td>20.61</td>\n",
       "      <td>13.72</td>\n",
       "      <td>6.38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.49</td>\n",
       "      <td>13.02</td>\n",
       "      <td>2.67</td>\n",
       "      <td>35.83</td>\n",
       "      <td>4.35</td>\n",
       "      <td>20.20</td>\n",
       "      <td>18.22</td>\n",
       "      <td>12.41</td>\n",
       "      <td>3.04</td>\n",
       "      <td>8.00</td>\n",
       "      <td>10.04</td>\n",
       "      <td>25.95</td>\n",
       "      <td>4.16</td>\n",
       "      <td>4.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-12</th>\n",
       "      <td>4.77</td>\n",
       "      <td>7.66</td>\n",
       "      <td>10.03</td>\n",
       "      <td>13.22</td>\n",
       "      <td>12.62</td>\n",
       "      <td>10.39</td>\n",
       "      <td>15.29</td>\n",
       "      <td>43.46</td>\n",
       "      <td>8.58</td>\n",
       "      <td>27.37</td>\n",
       "      <td>13.31</td>\n",
       "      <td>73.99</td>\n",
       "      <td>5.03</td>\n",
       "      <td>190.35</td>\n",
       "      <td>11.05</td>\n",
       "      <td>16.51</td>\n",
       "      <td>17.14</td>\n",
       "      <td>9.23</td>\n",
       "      <td>55.89</td>\n",
       "      <td>7.85</td>\n",
       "      <td>20.50</td>\n",
       "      <td>14.10</td>\n",
       "      <td>6.41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.49</td>\n",
       "      <td>13.30</td>\n",
       "      <td>2.65</td>\n",
       "      <td>36.37</td>\n",
       "      <td>4.33</td>\n",
       "      <td>20.03</td>\n",
       "      <td>18.30</td>\n",
       "      <td>12.65</td>\n",
       "      <td>3.04</td>\n",
       "      <td>7.93</td>\n",
       "      <td>10.06</td>\n",
       "      <td>25.47</td>\n",
       "      <td>4.15</td>\n",
       "      <td>4.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-13</th>\n",
       "      <td>4.69</td>\n",
       "      <td>7.62</td>\n",
       "      <td>9.80</td>\n",
       "      <td>12.92</td>\n",
       "      <td>12.49</td>\n",
       "      <td>10.28</td>\n",
       "      <td>14.69</td>\n",
       "      <td>44.96</td>\n",
       "      <td>8.31</td>\n",
       "      <td>26.80</td>\n",
       "      <td>12.83</td>\n",
       "      <td>71.73</td>\n",
       "      <td>4.87</td>\n",
       "      <td>188.69</td>\n",
       "      <td>10.49</td>\n",
       "      <td>15.75</td>\n",
       "      <td>16.51</td>\n",
       "      <td>8.83</td>\n",
       "      <td>53.98</td>\n",
       "      <td>7.71</td>\n",
       "      <td>20.22</td>\n",
       "      <td>13.26</td>\n",
       "      <td>6.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.33</td>\n",
       "      <td>13.28</td>\n",
       "      <td>2.65</td>\n",
       "      <td>36.03</td>\n",
       "      <td>4.34</td>\n",
       "      <td>19.95</td>\n",
       "      <td>17.89</td>\n",
       "      <td>12.26</td>\n",
       "      <td>3.01</td>\n",
       "      <td>7.87</td>\n",
       "      <td>10.20</td>\n",
       "      <td>24.93</td>\n",
       "      <td>4.06</td>\n",
       "      <td>4.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-16</th>\n",
       "      <td>4.32</td>\n",
       "      <td>7.54</td>\n",
       "      <td>9.83</td>\n",
       "      <td>13.06</td>\n",
       "      <td>12.39</td>\n",
       "      <td>9.93</td>\n",
       "      <td>14.39</td>\n",
       "      <td>41.08</td>\n",
       "      <td>8.17</td>\n",
       "      <td>26.00</td>\n",
       "      <td>12.50</td>\n",
       "      <td>69.15</td>\n",
       "      <td>4.76</td>\n",
       "      <td>177.41</td>\n",
       "      <td>10.30</td>\n",
       "      <td>15.28</td>\n",
       "      <td>16.03</td>\n",
       "      <td>8.70</td>\n",
       "      <td>50.77</td>\n",
       "      <td>7.64</td>\n",
       "      <td>19.01</td>\n",
       "      <td>12.89</td>\n",
       "      <td>6.36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.02</td>\n",
       "      <td>13.32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.59</td>\n",
       "      <td>4.31</td>\n",
       "      <td>19.85</td>\n",
       "      <td>17.81</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.98</td>\n",
       "      <td>7.73</td>\n",
       "      <td>10.09</td>\n",
       "      <td>23.59</td>\n",
       "      <td>3.96</td>\n",
       "      <td>4.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-17</th>\n",
       "      <td>4.75</td>\n",
       "      <td>7.74</td>\n",
       "      <td>10.51</td>\n",
       "      <td>13.77</td>\n",
       "      <td>12.78</td>\n",
       "      <td>10.35</td>\n",
       "      <td>15.33</td>\n",
       "      <td>45.19</td>\n",
       "      <td>8.61</td>\n",
       "      <td>26.02</td>\n",
       "      <td>13.39</td>\n",
       "      <td>70.90</td>\n",
       "      <td>5.03</td>\n",
       "      <td>180.44</td>\n",
       "      <td>10.60</td>\n",
       "      <td>16.43</td>\n",
       "      <td>16.73</td>\n",
       "      <td>9.29</td>\n",
       "      <td>52.66</td>\n",
       "      <td>8.15</td>\n",
       "      <td>19.87</td>\n",
       "      <td>13.55</td>\n",
       "      <td>6.53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.38</td>\n",
       "      <td>13.60</td>\n",
       "      <td>2.69</td>\n",
       "      <td>37.82</td>\n",
       "      <td>4.36</td>\n",
       "      <td>20.68</td>\n",
       "      <td>18.78</td>\n",
       "      <td>12.99</td>\n",
       "      <td>3.10</td>\n",
       "      <td>8.19</td>\n",
       "      <td>10.32</td>\n",
       "      <td>24.72</td>\n",
       "      <td>4.36</td>\n",
       "      <td>4.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-18</th>\n",
       "      <td>4.73</td>\n",
       "      <td>7.58</td>\n",
       "      <td>10.47</td>\n",
       "      <td>13.69</td>\n",
       "      <td>12.52</td>\n",
       "      <td>10.12</td>\n",
       "      <td>15.21</td>\n",
       "      <td>45.46</td>\n",
       "      <td>8.47</td>\n",
       "      <td>24.66</td>\n",
       "      <td>13.26</td>\n",
       "      <td>63.81</td>\n",
       "      <td>4.93</td>\n",
       "      <td>177.38</td>\n",
       "      <td>10.48</td>\n",
       "      <td>16.82</td>\n",
       "      <td>16.49</td>\n",
       "      <td>9.08</td>\n",
       "      <td>51.61</td>\n",
       "      <td>8.07</td>\n",
       "      <td>19.14</td>\n",
       "      <td>13.32</td>\n",
       "      <td>6.48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.88</td>\n",
       "      <td>13.43</td>\n",
       "      <td>2.69</td>\n",
       "      <td>37.45</td>\n",
       "      <td>4.31</td>\n",
       "      <td>20.50</td>\n",
       "      <td>18.45</td>\n",
       "      <td>12.77</td>\n",
       "      <td>3.05</td>\n",
       "      <td>8.22</td>\n",
       "      <td>10.22</td>\n",
       "      <td>24.01</td>\n",
       "      <td>4.29</td>\n",
       "      <td>5.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-19</th>\n",
       "      <td>4.78</td>\n",
       "      <td>7.66</td>\n",
       "      <td>10.84</td>\n",
       "      <td>13.81</td>\n",
       "      <td>12.70</td>\n",
       "      <td>10.67</td>\n",
       "      <td>15.46</td>\n",
       "      <td>46.58</td>\n",
       "      <td>8.62</td>\n",
       "      <td>25.20</td>\n",
       "      <td>13.76</td>\n",
       "      <td>64.29</td>\n",
       "      <td>5.01</td>\n",
       "      <td>180.70</td>\n",
       "      <td>10.33</td>\n",
       "      <td>17.15</td>\n",
       "      <td>16.19</td>\n",
       "      <td>9.40</td>\n",
       "      <td>52.84</td>\n",
       "      <td>8.38</td>\n",
       "      <td>19.98</td>\n",
       "      <td>13.20</td>\n",
       "      <td>6.56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.10</td>\n",
       "      <td>13.78</td>\n",
       "      <td>2.70</td>\n",
       "      <td>38.51</td>\n",
       "      <td>4.36</td>\n",
       "      <td>21.22</td>\n",
       "      <td>19.00</td>\n",
       "      <td>12.88</td>\n",
       "      <td>3.09</td>\n",
       "      <td>8.48</td>\n",
       "      <td>10.26</td>\n",
       "      <td>24.41</td>\n",
       "      <td>4.48</td>\n",
       "      <td>5.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-20</th>\n",
       "      <td>4.77</td>\n",
       "      <td>7.74</td>\n",
       "      <td>11.01</td>\n",
       "      <td>13.99</td>\n",
       "      <td>13.00</td>\n",
       "      <td>10.94</td>\n",
       "      <td>15.52</td>\n",
       "      <td>45.62</td>\n",
       "      <td>8.80</td>\n",
       "      <td>26.68</td>\n",
       "      <td>14.09</td>\n",
       "      <td>65.74</td>\n",
       "      <td>5.10</td>\n",
       "      <td>185.97</td>\n",
       "      <td>10.41</td>\n",
       "      <td>17.79</td>\n",
       "      <td>16.48</td>\n",
       "      <td>9.51</td>\n",
       "      <td>54.34</td>\n",
       "      <td>8.60</td>\n",
       "      <td>20.54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.48</td>\n",
       "      <td>14.05</td>\n",
       "      <td>2.72</td>\n",
       "      <td>39.10</td>\n",
       "      <td>4.36</td>\n",
       "      <td>21.84</td>\n",
       "      <td>19.33</td>\n",
       "      <td>12.99</td>\n",
       "      <td>3.14</td>\n",
       "      <td>8.50</td>\n",
       "      <td>10.26</td>\n",
       "      <td>25.01</td>\n",
       "      <td>4.47</td>\n",
       "      <td>5.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-30</th>\n",
       "      <td>4.75</td>\n",
       "      <td>7.70</td>\n",
       "      <td>10.68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.70</td>\n",
       "      <td>10.43</td>\n",
       "      <td>15.48</td>\n",
       "      <td>46.06</td>\n",
       "      <td>8.63</td>\n",
       "      <td>26.19</td>\n",
       "      <td>13.67</td>\n",
       "      <td>64.87</td>\n",
       "      <td>5.04</td>\n",
       "      <td>183.80</td>\n",
       "      <td>10.37</td>\n",
       "      <td>17.38</td>\n",
       "      <td>16.23</td>\n",
       "      <td>9.24</td>\n",
       "      <td>53.30</td>\n",
       "      <td>8.36</td>\n",
       "      <td>20.33</td>\n",
       "      <td>13.49</td>\n",
       "      <td>6.45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.68</td>\n",
       "      <td>13.83</td>\n",
       "      <td>2.68</td>\n",
       "      <td>38.60</td>\n",
       "      <td>4.27</td>\n",
       "      <td>21.11</td>\n",
       "      <td>18.90</td>\n",
       "      <td>12.73</td>\n",
       "      <td>3.07</td>\n",
       "      <td>8.20</td>\n",
       "      <td>10.13</td>\n",
       "      <td>25.10</td>\n",
       "      <td>4.49</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-31</th>\n",
       "      <td>4.87</td>\n",
       "      <td>7.76</td>\n",
       "      <td>10.69</td>\n",
       "      <td>14.21</td>\n",
       "      <td>12.65</td>\n",
       "      <td>10.50</td>\n",
       "      <td>15.09</td>\n",
       "      <td>46.56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.93</td>\n",
       "      <td>5.08</td>\n",
       "      <td>186.41</td>\n",
       "      <td>10.39</td>\n",
       "      <td>17.37</td>\n",
       "      <td>16.45</td>\n",
       "      <td>9.21</td>\n",
       "      <td>54.97</td>\n",
       "      <td>8.36</td>\n",
       "      <td>20.44</td>\n",
       "      <td>13.48</td>\n",
       "      <td>6.49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.85</td>\n",
       "      <td>13.86</td>\n",
       "      <td>2.70</td>\n",
       "      <td>38.34</td>\n",
       "      <td>4.30</td>\n",
       "      <td>21.01</td>\n",
       "      <td>18.78</td>\n",
       "      <td>12.57</td>\n",
       "      <td>3.07</td>\n",
       "      <td>8.33</td>\n",
       "      <td>10.21</td>\n",
       "      <td>24.73</td>\n",
       "      <td>4.44</td>\n",
       "      <td>5.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-01</th>\n",
       "      <td>4.73</td>\n",
       "      <td>7.79</td>\n",
       "      <td>10.47</td>\n",
       "      <td>13.80</td>\n",
       "      <td>12.47</td>\n",
       "      <td>10.31</td>\n",
       "      <td>14.93</td>\n",
       "      <td>44.73</td>\n",
       "      <td>8.51</td>\n",
       "      <td>25.86</td>\n",
       "      <td>13.78</td>\n",
       "      <td>66.52</td>\n",
       "      <td>5.05</td>\n",
       "      <td>186.15</td>\n",
       "      <td>10.64</td>\n",
       "      <td>16.54</td>\n",
       "      <td>16.68</td>\n",
       "      <td>9.10</td>\n",
       "      <td>54.98</td>\n",
       "      <td>8.10</td>\n",
       "      <td>20.60</td>\n",
       "      <td>13.12</td>\n",
       "      <td>6.44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.57</td>\n",
       "      <td>13.56</td>\n",
       "      <td>2.68</td>\n",
       "      <td>37.41</td>\n",
       "      <td>4.28</td>\n",
       "      <td>20.65</td>\n",
       "      <td>18.34</td>\n",
       "      <td>12.40</td>\n",
       "      <td>3.04</td>\n",
       "      <td>8.16</td>\n",
       "      <td>10.18</td>\n",
       "      <td>24.71</td>\n",
       "      <td>4.37</td>\n",
       "      <td>5.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-02</th>\n",
       "      <td>4.83</td>\n",
       "      <td>7.86</td>\n",
       "      <td>10.80</td>\n",
       "      <td>14.06</td>\n",
       "      <td>12.87</td>\n",
       "      <td>10.56</td>\n",
       "      <td>15.22</td>\n",
       "      <td>45.57</td>\n",
       "      <td>8.64</td>\n",
       "      <td>26.24</td>\n",
       "      <td>14.05</td>\n",
       "      <td>66.67</td>\n",
       "      <td>5.25</td>\n",
       "      <td>186.43</td>\n",
       "      <td>10.77</td>\n",
       "      <td>16.90</td>\n",
       "      <td>17.14</td>\n",
       "      <td>9.19</td>\n",
       "      <td>55.72</td>\n",
       "      <td>8.53</td>\n",
       "      <td>20.92</td>\n",
       "      <td>13.31</td>\n",
       "      <td>6.48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.24</td>\n",
       "      <td>14.15</td>\n",
       "      <td>2.73</td>\n",
       "      <td>39.64</td>\n",
       "      <td>4.38</td>\n",
       "      <td>21.41</td>\n",
       "      <td>19.07</td>\n",
       "      <td>12.65</td>\n",
       "      <td>3.10</td>\n",
       "      <td>8.36</td>\n",
       "      <td>10.21</td>\n",
       "      <td>25.10</td>\n",
       "      <td>4.46</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-03</th>\n",
       "      <td>4.83</td>\n",
       "      <td>7.81</td>\n",
       "      <td>10.90</td>\n",
       "      <td>13.94</td>\n",
       "      <td>12.98</td>\n",
       "      <td>10.68</td>\n",
       "      <td>15.40</td>\n",
       "      <td>45.61</td>\n",
       "      <td>8.76</td>\n",
       "      <td>26.39</td>\n",
       "      <td>14.42</td>\n",
       "      <td>66.89</td>\n",
       "      <td>5.25</td>\n",
       "      <td>186.48</td>\n",
       "      <td>11.00</td>\n",
       "      <td>16.72</td>\n",
       "      <td>17.70</td>\n",
       "      <td>9.17</td>\n",
       "      <td>57.00</td>\n",
       "      <td>8.47</td>\n",
       "      <td>20.90</td>\n",
       "      <td>13.79</td>\n",
       "      <td>6.52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.35</td>\n",
       "      <td>14.18</td>\n",
       "      <td>2.75</td>\n",
       "      <td>40.15</td>\n",
       "      <td>4.41</td>\n",
       "      <td>21.86</td>\n",
       "      <td>19.30</td>\n",
       "      <td>12.54</td>\n",
       "      <td>3.10</td>\n",
       "      <td>8.35</td>\n",
       "      <td>10.22</td>\n",
       "      <td>24.89</td>\n",
       "      <td>4.50</td>\n",
       "      <td>5.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-06</th>\n",
       "      <td>4.82</td>\n",
       "      <td>7.78</td>\n",
       "      <td>10.84</td>\n",
       "      <td>13.89</td>\n",
       "      <td>12.86</td>\n",
       "      <td>10.45</td>\n",
       "      <td>15.25</td>\n",
       "      <td>45.61</td>\n",
       "      <td>8.79</td>\n",
       "      <td>27.05</td>\n",
       "      <td>14.59</td>\n",
       "      <td>68.41</td>\n",
       "      <td>5.27</td>\n",
       "      <td>188.54</td>\n",
       "      <td>11.00</td>\n",
       "      <td>17.07</td>\n",
       "      <td>17.93</td>\n",
       "      <td>9.27</td>\n",
       "      <td>58.59</td>\n",
       "      <td>8.45</td>\n",
       "      <td>21.56</td>\n",
       "      <td>13.68</td>\n",
       "      <td>6.47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.35</td>\n",
       "      <td>14.17</td>\n",
       "      <td>2.75</td>\n",
       "      <td>39.62</td>\n",
       "      <td>4.41</td>\n",
       "      <td>21.36</td>\n",
       "      <td>18.92</td>\n",
       "      <td>12.73</td>\n",
       "      <td>3.07</td>\n",
       "      <td>8.26</td>\n",
       "      <td>10.23</td>\n",
       "      <td>25.01</td>\n",
       "      <td>4.45</td>\n",
       "      <td>5.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-07</th>\n",
       "      <td>4.69</td>\n",
       "      <td>7.65</td>\n",
       "      <td>10.52</td>\n",
       "      <td>13.54</td>\n",
       "      <td>12.73</td>\n",
       "      <td>10.13</td>\n",
       "      <td>15.22</td>\n",
       "      <td>44.55</td>\n",
       "      <td>8.60</td>\n",
       "      <td>26.53</td>\n",
       "      <td>14.26</td>\n",
       "      <td>68.22</td>\n",
       "      <td>5.09</td>\n",
       "      <td>185.86</td>\n",
       "      <td>10.75</td>\n",
       "      <td>16.52</td>\n",
       "      <td>17.46</td>\n",
       "      <td>9.07</td>\n",
       "      <td>57.61</td>\n",
       "      <td>8.21</td>\n",
       "      <td>21.50</td>\n",
       "      <td>14.74</td>\n",
       "      <td>6.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.89</td>\n",
       "      <td>14.02</td>\n",
       "      <td>2.72</td>\n",
       "      <td>38.91</td>\n",
       "      <td>4.33</td>\n",
       "      <td>20.79</td>\n",
       "      <td>18.50</td>\n",
       "      <td>12.65</td>\n",
       "      <td>3.01</td>\n",
       "      <td>8.05</td>\n",
       "      <td>10.09</td>\n",
       "      <td>25.42</td>\n",
       "      <td>4.35</td>\n",
       "      <td>5.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-08</th>\n",
       "      <td>4.90</td>\n",
       "      <td>7.78</td>\n",
       "      <td>10.95</td>\n",
       "      <td>13.88</td>\n",
       "      <td>12.99</td>\n",
       "      <td>10.42</td>\n",
       "      <td>15.59</td>\n",
       "      <td>48.51</td>\n",
       "      <td>8.79</td>\n",
       "      <td>26.59</td>\n",
       "      <td>14.81</td>\n",
       "      <td>68.80</td>\n",
       "      <td>5.20</td>\n",
       "      <td>188.29</td>\n",
       "      <td>11.04</td>\n",
       "      <td>17.15</td>\n",
       "      <td>17.90</td>\n",
       "      <td>9.28</td>\n",
       "      <td>59.17</td>\n",
       "      <td>8.67</td>\n",
       "      <td>21.80</td>\n",
       "      <td>15.24</td>\n",
       "      <td>6.47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.63</td>\n",
       "      <td>14.43</td>\n",
       "      <td>2.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.41</td>\n",
       "      <td>21.75</td>\n",
       "      <td>19.24</td>\n",
       "      <td>12.98</td>\n",
       "      <td>3.09</td>\n",
       "      <td>8.36</td>\n",
       "      <td>10.26</td>\n",
       "      <td>25.87</td>\n",
       "      <td>4.53</td>\n",
       "      <td>5.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-09</th>\n",
       "      <td>4.88</td>\n",
       "      <td>7.69</td>\n",
       "      <td>10.87</td>\n",
       "      <td>13.77</td>\n",
       "      <td>12.99</td>\n",
       "      <td>10.56</td>\n",
       "      <td>15.49</td>\n",
       "      <td>47.57</td>\n",
       "      <td>8.87</td>\n",
       "      <td>26.93</td>\n",
       "      <td>14.91</td>\n",
       "      <td>68.77</td>\n",
       "      <td>5.26</td>\n",
       "      <td>190.75</td>\n",
       "      <td>11.11</td>\n",
       "      <td>17.40</td>\n",
       "      <td>17.98</td>\n",
       "      <td>9.33</td>\n",
       "      <td>59.40</td>\n",
       "      <td>8.57</td>\n",
       "      <td>21.32</td>\n",
       "      <td>15.13</td>\n",
       "      <td>6.41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.53</td>\n",
       "      <td>14.42</td>\n",
       "      <td>2.73</td>\n",
       "      <td>39.88</td>\n",
       "      <td>4.42</td>\n",
       "      <td>21.26</td>\n",
       "      <td>19.07</td>\n",
       "      <td>12.98</td>\n",
       "      <td>3.08</td>\n",
       "      <td>8.27</td>\n",
       "      <td>10.29</td>\n",
       "      <td>25.77</td>\n",
       "      <td>4.50</td>\n",
       "      <td>5.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-10</th>\n",
       "      <td>5.08</td>\n",
       "      <td>7.67</td>\n",
       "      <td>10.97</td>\n",
       "      <td>13.88</td>\n",
       "      <td>12.89</td>\n",
       "      <td>10.91</td>\n",
       "      <td>15.45</td>\n",
       "      <td>47.50</td>\n",
       "      <td>8.90</td>\n",
       "      <td>26.63</td>\n",
       "      <td>14.66</td>\n",
       "      <td>68.61</td>\n",
       "      <td>5.32</td>\n",
       "      <td>190.51</td>\n",
       "      <td>11.06</td>\n",
       "      <td>17.51</td>\n",
       "      <td>17.70</td>\n",
       "      <td>9.33</td>\n",
       "      <td>59.00</td>\n",
       "      <td>8.65</td>\n",
       "      <td>21.76</td>\n",
       "      <td>15.29</td>\n",
       "      <td>6.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.45</td>\n",
       "      <td>14.24</td>\n",
       "      <td>2.72</td>\n",
       "      <td>40.09</td>\n",
       "      <td>4.39</td>\n",
       "      <td>21.61</td>\n",
       "      <td>18.93</td>\n",
       "      <td>13.03</td>\n",
       "      <td>3.21</td>\n",
       "      <td>8.32</td>\n",
       "      <td>10.31</td>\n",
       "      <td>25.91</td>\n",
       "      <td>4.50</td>\n",
       "      <td>5.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-13</th>\n",
       "      <td>5.04</td>\n",
       "      <td>7.65</td>\n",
       "      <td>10.95</td>\n",
       "      <td>13.84</td>\n",
       "      <td>12.69</td>\n",
       "      <td>10.57</td>\n",
       "      <td>15.76</td>\n",
       "      <td>47.65</td>\n",
       "      <td>8.84</td>\n",
       "      <td>26.99</td>\n",
       "      <td>14.58</td>\n",
       "      <td>68.67</td>\n",
       "      <td>5.37</td>\n",
       "      <td>193.42</td>\n",
       "      <td>11.21</td>\n",
       "      <td>17.25</td>\n",
       "      <td>18.36</td>\n",
       "      <td>9.28</td>\n",
       "      <td>59.85</td>\n",
       "      <td>8.55</td>\n",
       "      <td>22.11</td>\n",
       "      <td>15.57</td>\n",
       "      <td>6.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.14</td>\n",
       "      <td>14.13</td>\n",
       "      <td>2.71</td>\n",
       "      <td>40.28</td>\n",
       "      <td>4.37</td>\n",
       "      <td>21.41</td>\n",
       "      <td>18.64</td>\n",
       "      <td>13.41</td>\n",
       "      <td>3.16</td>\n",
       "      <td>8.37</td>\n",
       "      <td>10.26</td>\n",
       "      <td>26.08</td>\n",
       "      <td>4.53</td>\n",
       "      <td>5.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-14</th>\n",
       "      <td>5.01</td>\n",
       "      <td>7.66</td>\n",
       "      <td>10.87</td>\n",
       "      <td>13.69</td>\n",
       "      <td>12.66</td>\n",
       "      <td>10.62</td>\n",
       "      <td>15.52</td>\n",
       "      <td>47.50</td>\n",
       "      <td>8.89</td>\n",
       "      <td>26.87</td>\n",
       "      <td>14.31</td>\n",
       "      <td>69.29</td>\n",
       "      <td>5.38</td>\n",
       "      <td>193.82</td>\n",
       "      <td>11.27</td>\n",
       "      <td>17.10</td>\n",
       "      <td>18.06</td>\n",
       "      <td>9.24</td>\n",
       "      <td>60.71</td>\n",
       "      <td>8.49</td>\n",
       "      <td>22.09</td>\n",
       "      <td>15.42</td>\n",
       "      <td>6.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.14</td>\n",
       "      <td>14.08</td>\n",
       "      <td>2.70</td>\n",
       "      <td>39.58</td>\n",
       "      <td>4.35</td>\n",
       "      <td>20.83</td>\n",
       "      <td>18.39</td>\n",
       "      <td>13.38</td>\n",
       "      <td>3.16</td>\n",
       "      <td>8.37</td>\n",
       "      <td>10.24</td>\n",
       "      <td>26.03</td>\n",
       "      <td>4.48</td>\n",
       "      <td>5.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-26</th>\n",
       "      <td>2.09</td>\n",
       "      <td>4.25</td>\n",
       "      <td>19.40</td>\n",
       "      <td>15.52</td>\n",
       "      <td>33.70</td>\n",
       "      <td>16.68</td>\n",
       "      <td>15.88</td>\n",
       "      <td>30.84</td>\n",
       "      <td>40.93</td>\n",
       "      <td>34.77</td>\n",
       "      <td>88.67</td>\n",
       "      <td>294.00</td>\n",
       "      <td>56.43</td>\n",
       "      <td>1898.00</td>\n",
       "      <td>32.44</td>\n",
       "      <td>31.81</td>\n",
       "      <td>20.00</td>\n",
       "      <td>24.33</td>\n",
       "      <td>286.93</td>\n",
       "      <td>9.51</td>\n",
       "      <td>36.19</td>\n",
       "      <td>48.17</td>\n",
       "      <td>23.39</td>\n",
       "      <td>53.06</td>\n",
       "      <td>31.26</td>\n",
       "      <td>17.88</td>\n",
       "      <td>2.82</td>\n",
       "      <td>43.12</td>\n",
       "      <td>4.35</td>\n",
       "      <td>20.29</td>\n",
       "      <td>29.44</td>\n",
       "      <td>35.35</td>\n",
       "      <td>5.01</td>\n",
       "      <td>13.13</td>\n",
       "      <td>5.44</td>\n",
       "      <td>192.41</td>\n",
       "      <td>9.15</td>\n",
       "      <td>13.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-29</th>\n",
       "      <td>2.07</td>\n",
       "      <td>4.26</td>\n",
       "      <td>19.37</td>\n",
       "      <td>15.56</td>\n",
       "      <td>33.28</td>\n",
       "      <td>16.61</td>\n",
       "      <td>15.50</td>\n",
       "      <td>30.59</td>\n",
       "      <td>40.61</td>\n",
       "      <td>34.23</td>\n",
       "      <td>87.80</td>\n",
       "      <td>291.09</td>\n",
       "      <td>56.78</td>\n",
       "      <td>1878.82</td>\n",
       "      <td>32.70</td>\n",
       "      <td>31.42</td>\n",
       "      <td>19.29</td>\n",
       "      <td>24.57</td>\n",
       "      <td>285.30</td>\n",
       "      <td>9.45</td>\n",
       "      <td>35.95</td>\n",
       "      <td>49.91</td>\n",
       "      <td>23.30</td>\n",
       "      <td>53.41</td>\n",
       "      <td>31.88</td>\n",
       "      <td>16.93</td>\n",
       "      <td>2.82</td>\n",
       "      <td>43.07</td>\n",
       "      <td>4.33</td>\n",
       "      <td>20.17</td>\n",
       "      <td>29.02</td>\n",
       "      <td>33.96</td>\n",
       "      <td>5.04</td>\n",
       "      <td>13.02</td>\n",
       "      <td>5.48</td>\n",
       "      <td>192.25</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-30</th>\n",
       "      <td>2.04</td>\n",
       "      <td>4.29</td>\n",
       "      <td>19.25</td>\n",
       "      <td>15.58</td>\n",
       "      <td>33.79</td>\n",
       "      <td>16.95</td>\n",
       "      <td>15.48</td>\n",
       "      <td>30.37</td>\n",
       "      <td>40.08</td>\n",
       "      <td>33.67</td>\n",
       "      <td>88.45</td>\n",
       "      <td>288.36</td>\n",
       "      <td>55.56</td>\n",
       "      <td>1870.00</td>\n",
       "      <td>33.33</td>\n",
       "      <td>30.99</td>\n",
       "      <td>20.07</td>\n",
       "      <td>25.40</td>\n",
       "      <td>284.09</td>\n",
       "      <td>9.41</td>\n",
       "      <td>36.13</td>\n",
       "      <td>47.88</td>\n",
       "      <td>23.28</td>\n",
       "      <td>52.80</td>\n",
       "      <td>30.52</td>\n",
       "      <td>16.82</td>\n",
       "      <td>2.82</td>\n",
       "      <td>42.89</td>\n",
       "      <td>4.36</td>\n",
       "      <td>20.47</td>\n",
       "      <td>29.50</td>\n",
       "      <td>34.20</td>\n",
       "      <td>5.07</td>\n",
       "      <td>13.11</td>\n",
       "      <td>5.47</td>\n",
       "      <td>190.40</td>\n",
       "      <td>8.90</td>\n",
       "      <td>14.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-31</th>\n",
       "      <td>2.01</td>\n",
       "      <td>4.27</td>\n",
       "      <td>19.52</td>\n",
       "      <td>15.75</td>\n",
       "      <td>35.05</td>\n",
       "      <td>17.30</td>\n",
       "      <td>15.47</td>\n",
       "      <td>30.14</td>\n",
       "      <td>40.36</td>\n",
       "      <td>34.66</td>\n",
       "      <td>88.57</td>\n",
       "      <td>300.99</td>\n",
       "      <td>52.88</td>\n",
       "      <td>1924.00</td>\n",
       "      <td>33.64</td>\n",
       "      <td>31.92</td>\n",
       "      <td>20.09</td>\n",
       "      <td>25.87</td>\n",
       "      <td>293.00</td>\n",
       "      <td>9.48</td>\n",
       "      <td>35.74</td>\n",
       "      <td>45.97</td>\n",
       "      <td>23.98</td>\n",
       "      <td>51.20</td>\n",
       "      <td>30.34</td>\n",
       "      <td>17.11</td>\n",
       "      <td>2.85</td>\n",
       "      <td>43.84</td>\n",
       "      <td>4.38</td>\n",
       "      <td>20.97</td>\n",
       "      <td>30.70</td>\n",
       "      <td>33.46</td>\n",
       "      <td>5.14</td>\n",
       "      <td>13.14</td>\n",
       "      <td>5.34</td>\n",
       "      <td>195.50</td>\n",
       "      <td>8.80</td>\n",
       "      <td>14.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-01</th>\n",
       "      <td>2.00</td>\n",
       "      <td>4.23</td>\n",
       "      <td>19.30</td>\n",
       "      <td>15.85</td>\n",
       "      <td>34.50</td>\n",
       "      <td>17.31</td>\n",
       "      <td>15.30</td>\n",
       "      <td>30.09</td>\n",
       "      <td>40.90</td>\n",
       "      <td>34.34</td>\n",
       "      <td>88.11</td>\n",
       "      <td>298.30</td>\n",
       "      <td>52.82</td>\n",
       "      <td>1880.89</td>\n",
       "      <td>34.50</td>\n",
       "      <td>31.60</td>\n",
       "      <td>20.37</td>\n",
       "      <td>26.21</td>\n",
       "      <td>292.58</td>\n",
       "      <td>9.39</td>\n",
       "      <td>34.55</td>\n",
       "      <td>45.88</td>\n",
       "      <td>23.91</td>\n",
       "      <td>51.65</td>\n",
       "      <td>31.11</td>\n",
       "      <td>17.11</td>\n",
       "      <td>2.83</td>\n",
       "      <td>43.65</td>\n",
       "      <td>4.36</td>\n",
       "      <td>20.82</td>\n",
       "      <td>30.45</td>\n",
       "      <td>32.25</td>\n",
       "      <td>5.15</td>\n",
       "      <td>13.00</td>\n",
       "      <td>5.36</td>\n",
       "      <td>186.80</td>\n",
       "      <td>8.65</td>\n",
       "      <td>13.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-02</th>\n",
       "      <td>2.00</td>\n",
       "      <td>4.26</td>\n",
       "      <td>19.24</td>\n",
       "      <td>15.61</td>\n",
       "      <td>34.32</td>\n",
       "      <td>17.02</td>\n",
       "      <td>15.26</td>\n",
       "      <td>30.16</td>\n",
       "      <td>40.21</td>\n",
       "      <td>33.90</td>\n",
       "      <td>86.95</td>\n",
       "      <td>296.11</td>\n",
       "      <td>52.21</td>\n",
       "      <td>1875.00</td>\n",
       "      <td>34.37</td>\n",
       "      <td>31.17</td>\n",
       "      <td>20.15</td>\n",
       "      <td>25.63</td>\n",
       "      <td>288.53</td>\n",
       "      <td>9.32</td>\n",
       "      <td>33.90</td>\n",
       "      <td>45.22</td>\n",
       "      <td>23.82</td>\n",
       "      <td>50.95</td>\n",
       "      <td>30.66</td>\n",
       "      <td>17.03</td>\n",
       "      <td>2.83</td>\n",
       "      <td>43.70</td>\n",
       "      <td>4.35</td>\n",
       "      <td>20.75</td>\n",
       "      <td>29.70</td>\n",
       "      <td>31.65</td>\n",
       "      <td>5.11</td>\n",
       "      <td>12.92</td>\n",
       "      <td>5.42</td>\n",
       "      <td>180.31</td>\n",
       "      <td>8.52</td>\n",
       "      <td>13.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-05</th>\n",
       "      <td>2.03</td>\n",
       "      <td>4.34</td>\n",
       "      <td>19.27</td>\n",
       "      <td>15.45</td>\n",
       "      <td>34.23</td>\n",
       "      <td>17.22</td>\n",
       "      <td>15.21</td>\n",
       "      <td>30.08</td>\n",
       "      <td>36.19</td>\n",
       "      <td>33.73</td>\n",
       "      <td>88.65</td>\n",
       "      <td>294.00</td>\n",
       "      <td>52.45</td>\n",
       "      <td>1835.00</td>\n",
       "      <td>33.73</td>\n",
       "      <td>31.01</td>\n",
       "      <td>19.79</td>\n",
       "      <td>25.58</td>\n",
       "      <td>282.78</td>\n",
       "      <td>9.40</td>\n",
       "      <td>33.37</td>\n",
       "      <td>45.77</td>\n",
       "      <td>23.82</td>\n",
       "      <td>50.49</td>\n",
       "      <td>32.56</td>\n",
       "      <td>17.08</td>\n",
       "      <td>2.84</td>\n",
       "      <td>43.80</td>\n",
       "      <td>4.36</td>\n",
       "      <td>20.90</td>\n",
       "      <td>29.86</td>\n",
       "      <td>31.19</td>\n",
       "      <td>5.17</td>\n",
       "      <td>13.05</td>\n",
       "      <td>5.56</td>\n",
       "      <td>180.10</td>\n",
       "      <td>8.59</td>\n",
       "      <td>13.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-06</th>\n",
       "      <td>2.05</td>\n",
       "      <td>4.41</td>\n",
       "      <td>19.48</td>\n",
       "      <td>15.73</td>\n",
       "      <td>33.62</td>\n",
       "      <td>17.63</td>\n",
       "      <td>15.42</td>\n",
       "      <td>30.85</td>\n",
       "      <td>35.42</td>\n",
       "      <td>33.88</td>\n",
       "      <td>91.50</td>\n",
       "      <td>294.02</td>\n",
       "      <td>56.87</td>\n",
       "      <td>1845.00</td>\n",
       "      <td>33.66</td>\n",
       "      <td>31.00</td>\n",
       "      <td>19.71</td>\n",
       "      <td>25.69</td>\n",
       "      <td>286.02</td>\n",
       "      <td>9.46</td>\n",
       "      <td>33.63</td>\n",
       "      <td>47.14</td>\n",
       "      <td>23.75</td>\n",
       "      <td>53.16</td>\n",
       "      <td>32.88</td>\n",
       "      <td>17.06</td>\n",
       "      <td>2.84</td>\n",
       "      <td>43.90</td>\n",
       "      <td>4.36</td>\n",
       "      <td>21.08</td>\n",
       "      <td>30.34</td>\n",
       "      <td>31.84</td>\n",
       "      <td>5.24</td>\n",
       "      <td>13.18</td>\n",
       "      <td>5.61</td>\n",
       "      <td>182.72</td>\n",
       "      <td>8.84</td>\n",
       "      <td>13.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-07</th>\n",
       "      <td>2.06</td>\n",
       "      <td>4.41</td>\n",
       "      <td>19.37</td>\n",
       "      <td>15.60</td>\n",
       "      <td>33.38</td>\n",
       "      <td>17.55</td>\n",
       "      <td>15.40</td>\n",
       "      <td>30.79</td>\n",
       "      <td>35.55</td>\n",
       "      <td>33.43</td>\n",
       "      <td>90.52</td>\n",
       "      <td>291.48</td>\n",
       "      <td>56.69</td>\n",
       "      <td>1818.01</td>\n",
       "      <td>33.59</td>\n",
       "      <td>30.41</td>\n",
       "      <td>19.62</td>\n",
       "      <td>25.80</td>\n",
       "      <td>278.12</td>\n",
       "      <td>9.47</td>\n",
       "      <td>33.22</td>\n",
       "      <td>47.24</td>\n",
       "      <td>23.57</td>\n",
       "      <td>53.46</td>\n",
       "      <td>32.61</td>\n",
       "      <td>17.09</td>\n",
       "      <td>2.83</td>\n",
       "      <td>43.60</td>\n",
       "      <td>4.35</td>\n",
       "      <td>20.98</td>\n",
       "      <td>30.25</td>\n",
       "      <td>32.09</td>\n",
       "      <td>5.23</td>\n",
       "      <td>13.14</td>\n",
       "      <td>5.58</td>\n",
       "      <td>183.95</td>\n",
       "      <td>8.94</td>\n",
       "      <td>13.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-08</th>\n",
       "      <td>2.04</td>\n",
       "      <td>4.41</td>\n",
       "      <td>19.31</td>\n",
       "      <td>15.75</td>\n",
       "      <td>33.30</td>\n",
       "      <td>17.58</td>\n",
       "      <td>15.35</td>\n",
       "      <td>30.29</td>\n",
       "      <td>33.96</td>\n",
       "      <td>33.73</td>\n",
       "      <td>92.01</td>\n",
       "      <td>293.75</td>\n",
       "      <td>56.50</td>\n",
       "      <td>1815.00</td>\n",
       "      <td>33.99</td>\n",
       "      <td>30.20</td>\n",
       "      <td>19.33</td>\n",
       "      <td>25.88</td>\n",
       "      <td>285.59</td>\n",
       "      <td>9.44</td>\n",
       "      <td>33.27</td>\n",
       "      <td>47.76</td>\n",
       "      <td>23.65</td>\n",
       "      <td>53.39</td>\n",
       "      <td>32.30</td>\n",
       "      <td>17.01</td>\n",
       "      <td>2.83</td>\n",
       "      <td>43.84</td>\n",
       "      <td>4.35</td>\n",
       "      <td>20.95</td>\n",
       "      <td>30.76</td>\n",
       "      <td>30.98</td>\n",
       "      <td>5.23</td>\n",
       "      <td>13.14</td>\n",
       "      <td>5.53</td>\n",
       "      <td>186.00</td>\n",
       "      <td>9.06</td>\n",
       "      <td>13.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-09</th>\n",
       "      <td>2.06</td>\n",
       "      <td>4.45</td>\n",
       "      <td>19.78</td>\n",
       "      <td>16.26</td>\n",
       "      <td>34.50</td>\n",
       "      <td>18.47</td>\n",
       "      <td>15.48</td>\n",
       "      <td>30.68</td>\n",
       "      <td>35.00</td>\n",
       "      <td>34.78</td>\n",
       "      <td>95.61</td>\n",
       "      <td>298.11</td>\n",
       "      <td>54.56</td>\n",
       "      <td>1844.79</td>\n",
       "      <td>35.30</td>\n",
       "      <td>31.37</td>\n",
       "      <td>19.54</td>\n",
       "      <td>26.50</td>\n",
       "      <td>291.21</td>\n",
       "      <td>9.54</td>\n",
       "      <td>33.70</td>\n",
       "      <td>48.03</td>\n",
       "      <td>23.91</td>\n",
       "      <td>53.18</td>\n",
       "      <td>32.73</td>\n",
       "      <td>17.38</td>\n",
       "      <td>2.84</td>\n",
       "      <td>44.69</td>\n",
       "      <td>4.36</td>\n",
       "      <td>21.47</td>\n",
       "      <td>31.50</td>\n",
       "      <td>31.31</td>\n",
       "      <td>5.36</td>\n",
       "      <td>13.28</td>\n",
       "      <td>5.59</td>\n",
       "      <td>191.09</td>\n",
       "      <td>9.19</td>\n",
       "      <td>13.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-13</th>\n",
       "      <td>2.05</td>\n",
       "      <td>4.43</td>\n",
       "      <td>19.83</td>\n",
       "      <td>16.30</td>\n",
       "      <td>35.35</td>\n",
       "      <td>18.09</td>\n",
       "      <td>15.65</td>\n",
       "      <td>31.47</td>\n",
       "      <td>34.44</td>\n",
       "      <td>35.52</td>\n",
       "      <td>93.00</td>\n",
       "      <td>302.00</td>\n",
       "      <td>54.99</td>\n",
       "      <td>1879.00</td>\n",
       "      <td>36.15</td>\n",
       "      <td>31.96</td>\n",
       "      <td>19.58</td>\n",
       "      <td>26.48</td>\n",
       "      <td>293.00</td>\n",
       "      <td>9.52</td>\n",
       "      <td>33.74</td>\n",
       "      <td>49.00</td>\n",
       "      <td>23.79</td>\n",
       "      <td>53.27</td>\n",
       "      <td>32.45</td>\n",
       "      <td>17.59</td>\n",
       "      <td>2.85</td>\n",
       "      <td>45.06</td>\n",
       "      <td>4.38</td>\n",
       "      <td>21.52</td>\n",
       "      <td>31.46</td>\n",
       "      <td>32.00</td>\n",
       "      <td>5.32</td>\n",
       "      <td>13.24</td>\n",
       "      <td>5.55</td>\n",
       "      <td>192.47</td>\n",
       "      <td>9.29</td>\n",
       "      <td>13.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-14</th>\n",
       "      <td>2.02</td>\n",
       "      <td>4.38</td>\n",
       "      <td>19.58</td>\n",
       "      <td>16.15</td>\n",
       "      <td>34.86</td>\n",
       "      <td>18.14</td>\n",
       "      <td>15.44</td>\n",
       "      <td>30.70</td>\n",
       "      <td>33.76</td>\n",
       "      <td>35.68</td>\n",
       "      <td>91.36</td>\n",
       "      <td>300.29</td>\n",
       "      <td>53.73</td>\n",
       "      <td>1869.00</td>\n",
       "      <td>36.30</td>\n",
       "      <td>31.59</td>\n",
       "      <td>19.71</td>\n",
       "      <td>26.49</td>\n",
       "      <td>292.30</td>\n",
       "      <td>9.46</td>\n",
       "      <td>33.60</td>\n",
       "      <td>49.23</td>\n",
       "      <td>23.70</td>\n",
       "      <td>52.55</td>\n",
       "      <td>32.35</td>\n",
       "      <td>17.38</td>\n",
       "      <td>2.85</td>\n",
       "      <td>44.65</td>\n",
       "      <td>4.36</td>\n",
       "      <td>21.26</td>\n",
       "      <td>31.63</td>\n",
       "      <td>31.74</td>\n",
       "      <td>5.26</td>\n",
       "      <td>13.11</td>\n",
       "      <td>5.52</td>\n",
       "      <td>191.55</td>\n",
       "      <td>9.00</td>\n",
       "      <td>13.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-15</th>\n",
       "      <td>2.00</td>\n",
       "      <td>4.40</td>\n",
       "      <td>19.53</td>\n",
       "      <td>16.20</td>\n",
       "      <td>36.01</td>\n",
       "      <td>18.85</td>\n",
       "      <td>15.34</td>\n",
       "      <td>30.01</td>\n",
       "      <td>33.04</td>\n",
       "      <td>35.49</td>\n",
       "      <td>91.50</td>\n",
       "      <td>298.56</td>\n",
       "      <td>51.30</td>\n",
       "      <td>1880.00</td>\n",
       "      <td>35.71</td>\n",
       "      <td>32.23</td>\n",
       "      <td>19.45</td>\n",
       "      <td>26.88</td>\n",
       "      <td>296.00</td>\n",
       "      <td>9.46</td>\n",
       "      <td>33.69</td>\n",
       "      <td>47.20</td>\n",
       "      <td>23.72</td>\n",
       "      <td>48.66</td>\n",
       "      <td>32.39</td>\n",
       "      <td>17.69</td>\n",
       "      <td>2.87</td>\n",
       "      <td>45.09</td>\n",
       "      <td>4.39</td>\n",
       "      <td>21.31</td>\n",
       "      <td>31.74</td>\n",
       "      <td>30.57</td>\n",
       "      <td>5.37</td>\n",
       "      <td>13.08</td>\n",
       "      <td>5.54</td>\n",
       "      <td>191.35</td>\n",
       "      <td>8.95</td>\n",
       "      <td>12.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-16</th>\n",
       "      <td>1.96</td>\n",
       "      <td>4.30</td>\n",
       "      <td>18.42</td>\n",
       "      <td>15.60</td>\n",
       "      <td>34.95</td>\n",
       "      <td>18.05</td>\n",
       "      <td>15.02</td>\n",
       "      <td>28.80</td>\n",
       "      <td>32.17</td>\n",
       "      <td>34.83</td>\n",
       "      <td>90.38</td>\n",
       "      <td>293.20</td>\n",
       "      <td>49.52</td>\n",
       "      <td>1859.00</td>\n",
       "      <td>33.99</td>\n",
       "      <td>31.19</td>\n",
       "      <td>19.53</td>\n",
       "      <td>26.06</td>\n",
       "      <td>289.50</td>\n",
       "      <td>9.05</td>\n",
       "      <td>32.88</td>\n",
       "      <td>46.88</td>\n",
       "      <td>23.46</td>\n",
       "      <td>48.30</td>\n",
       "      <td>30.96</td>\n",
       "      <td>17.22</td>\n",
       "      <td>2.85</td>\n",
       "      <td>43.93</td>\n",
       "      <td>4.36</td>\n",
       "      <td>20.88</td>\n",
       "      <td>31.06</td>\n",
       "      <td>28.88</td>\n",
       "      <td>5.15</td>\n",
       "      <td>12.41</td>\n",
       "      <td>5.37</td>\n",
       "      <td>188.51</td>\n",
       "      <td>8.68</td>\n",
       "      <td>12.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-19</th>\n",
       "      <td>1.91</td>\n",
       "      <td>4.18</td>\n",
       "      <td>18.42</td>\n",
       "      <td>14.97</td>\n",
       "      <td>35.09</td>\n",
       "      <td>18.44</td>\n",
       "      <td>15.01</td>\n",
       "      <td>28.34</td>\n",
       "      <td>32.19</td>\n",
       "      <td>34.69</td>\n",
       "      <td>91.36</td>\n",
       "      <td>289.50</td>\n",
       "      <td>49.87</td>\n",
       "      <td>1871.64</td>\n",
       "      <td>33.69</td>\n",
       "      <td>30.45</td>\n",
       "      <td>18.03</td>\n",
       "      <td>26.16</td>\n",
       "      <td>293.75</td>\n",
       "      <td>9.06</td>\n",
       "      <td>32.90</td>\n",
       "      <td>46.01</td>\n",
       "      <td>23.48</td>\n",
       "      <td>48.12</td>\n",
       "      <td>31.50</td>\n",
       "      <td>17.34</td>\n",
       "      <td>2.87</td>\n",
       "      <td>43.93</td>\n",
       "      <td>4.38</td>\n",
       "      <td>20.42</td>\n",
       "      <td>30.86</td>\n",
       "      <td>29.98</td>\n",
       "      <td>5.24</td>\n",
       "      <td>12.35</td>\n",
       "      <td>5.35</td>\n",
       "      <td>188.45</td>\n",
       "      <td>8.62</td>\n",
       "      <td>12.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-20</th>\n",
       "      <td>1.95</td>\n",
       "      <td>4.22</td>\n",
       "      <td>18.42</td>\n",
       "      <td>14.96</td>\n",
       "      <td>34.54</td>\n",
       "      <td>17.64</td>\n",
       "      <td>14.89</td>\n",
       "      <td>29.01</td>\n",
       "      <td>32.27</td>\n",
       "      <td>34.13</td>\n",
       "      <td>89.55</td>\n",
       "      <td>289.35</td>\n",
       "      <td>50.30</td>\n",
       "      <td>1878.00</td>\n",
       "      <td>32.77</td>\n",
       "      <td>29.58</td>\n",
       "      <td>18.19</td>\n",
       "      <td>25.87</td>\n",
       "      <td>296.09</td>\n",
       "      <td>9.09</td>\n",
       "      <td>32.66</td>\n",
       "      <td>45.75</td>\n",
       "      <td>23.42</td>\n",
       "      <td>50.04</td>\n",
       "      <td>31.35</td>\n",
       "      <td>17.08</td>\n",
       "      <td>2.84</td>\n",
       "      <td>43.24</td>\n",
       "      <td>4.37</td>\n",
       "      <td>20.10</td>\n",
       "      <td>29.84</td>\n",
       "      <td>29.83</td>\n",
       "      <td>5.11</td>\n",
       "      <td>12.33</td>\n",
       "      <td>5.16</td>\n",
       "      <td>194.23</td>\n",
       "      <td>8.70</td>\n",
       "      <td>12.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-21</th>\n",
       "      <td>1.98</td>\n",
       "      <td>4.25</td>\n",
       "      <td>18.43</td>\n",
       "      <td>15.06</td>\n",
       "      <td>34.41</td>\n",
       "      <td>17.83</td>\n",
       "      <td>14.92</td>\n",
       "      <td>30.48</td>\n",
       "      <td>31.70</td>\n",
       "      <td>33.43</td>\n",
       "      <td>87.94</td>\n",
       "      <td>281.08</td>\n",
       "      <td>50.09</td>\n",
       "      <td>1848.00</td>\n",
       "      <td>32.74</td>\n",
       "      <td>29.18</td>\n",
       "      <td>18.29</td>\n",
       "      <td>25.19</td>\n",
       "      <td>292.15</td>\n",
       "      <td>9.07</td>\n",
       "      <td>32.48</td>\n",
       "      <td>44.80</td>\n",
       "      <td>23.43</td>\n",
       "      <td>49.19</td>\n",
       "      <td>31.18</td>\n",
       "      <td>17.15</td>\n",
       "      <td>2.86</td>\n",
       "      <td>43.15</td>\n",
       "      <td>4.37</td>\n",
       "      <td>20.25</td>\n",
       "      <td>29.82</td>\n",
       "      <td>29.44</td>\n",
       "      <td>5.15</td>\n",
       "      <td>12.33</td>\n",
       "      <td>5.23</td>\n",
       "      <td>185.54</td>\n",
       "      <td>8.71</td>\n",
       "      <td>12.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-22</th>\n",
       "      <td>1.96</td>\n",
       "      <td>4.39</td>\n",
       "      <td>18.39</td>\n",
       "      <td>14.69</td>\n",
       "      <td>34.17</td>\n",
       "      <td>17.52</td>\n",
       "      <td>14.81</td>\n",
       "      <td>29.39</td>\n",
       "      <td>30.99</td>\n",
       "      <td>32.64</td>\n",
       "      <td>88.05</td>\n",
       "      <td>260.85</td>\n",
       "      <td>49.12</td>\n",
       "      <td>1820.81</td>\n",
       "      <td>32.80</td>\n",
       "      <td>28.73</td>\n",
       "      <td>18.49</td>\n",
       "      <td>24.56</td>\n",
       "      <td>292.44</td>\n",
       "      <td>9.12</td>\n",
       "      <td>32.00</td>\n",
       "      <td>46.60</td>\n",
       "      <td>23.42</td>\n",
       "      <td>49.18</td>\n",
       "      <td>31.99</td>\n",
       "      <td>17.05</td>\n",
       "      <td>2.86</td>\n",
       "      <td>42.48</td>\n",
       "      <td>4.39</td>\n",
       "      <td>20.26</td>\n",
       "      <td>29.91</td>\n",
       "      <td>28.63</td>\n",
       "      <td>5.12</td>\n",
       "      <td>12.33</td>\n",
       "      <td>5.34</td>\n",
       "      <td>187.10</td>\n",
       "      <td>8.65</td>\n",
       "      <td>12.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-23</th>\n",
       "      <td>1.96</td>\n",
       "      <td>4.47</td>\n",
       "      <td>18.36</td>\n",
       "      <td>14.42</td>\n",
       "      <td>34.36</td>\n",
       "      <td>17.55</td>\n",
       "      <td>14.77</td>\n",
       "      <td>28.73</td>\n",
       "      <td>30.48</td>\n",
       "      <td>32.93</td>\n",
       "      <td>87.76</td>\n",
       "      <td>252.69</td>\n",
       "      <td>49.30</td>\n",
       "      <td>1834.43</td>\n",
       "      <td>32.52</td>\n",
       "      <td>28.66</td>\n",
       "      <td>18.05</td>\n",
       "      <td>24.50</td>\n",
       "      <td>291.89</td>\n",
       "      <td>9.12</td>\n",
       "      <td>32.45</td>\n",
       "      <td>46.74</td>\n",
       "      <td>23.33</td>\n",
       "      <td>48.54</td>\n",
       "      <td>31.18</td>\n",
       "      <td>17.10</td>\n",
       "      <td>2.88</td>\n",
       "      <td>43.02</td>\n",
       "      <td>4.40</td>\n",
       "      <td>20.39</td>\n",
       "      <td>30.88</td>\n",
       "      <td>28.49</td>\n",
       "      <td>5.22</td>\n",
       "      <td>12.44</td>\n",
       "      <td>5.44</td>\n",
       "      <td>185.41</td>\n",
       "      <td>8.53</td>\n",
       "      <td>11.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-26</th>\n",
       "      <td>1.91</td>\n",
       "      <td>4.27</td>\n",
       "      <td>18.02</td>\n",
       "      <td>14.05</td>\n",
       "      <td>33.95</td>\n",
       "      <td>17.69</td>\n",
       "      <td>14.55</td>\n",
       "      <td>28.10</td>\n",
       "      <td>30.09</td>\n",
       "      <td>31.90</td>\n",
       "      <td>87.28</td>\n",
       "      <td>246.79</td>\n",
       "      <td>48.68</td>\n",
       "      <td>1863.00</td>\n",
       "      <td>32.04</td>\n",
       "      <td>28.33</td>\n",
       "      <td>17.76</td>\n",
       "      <td>24.95</td>\n",
       "      <td>299.65</td>\n",
       "      <td>8.97</td>\n",
       "      <td>32.36</td>\n",
       "      <td>45.29</td>\n",
       "      <td>23.05</td>\n",
       "      <td>48.80</td>\n",
       "      <td>30.36</td>\n",
       "      <td>16.75</td>\n",
       "      <td>2.85</td>\n",
       "      <td>42.49</td>\n",
       "      <td>4.35</td>\n",
       "      <td>19.90</td>\n",
       "      <td>30.82</td>\n",
       "      <td>28.70</td>\n",
       "      <td>5.15</td>\n",
       "      <td>12.21</td>\n",
       "      <td>5.11</td>\n",
       "      <td>194.51</td>\n",
       "      <td>7.82</td>\n",
       "      <td>11.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-27</th>\n",
       "      <td>1.91</td>\n",
       "      <td>4.28</td>\n",
       "      <td>18.07</td>\n",
       "      <td>14.37</td>\n",
       "      <td>33.90</td>\n",
       "      <td>17.67</td>\n",
       "      <td>14.65</td>\n",
       "      <td>28.30</td>\n",
       "      <td>30.45</td>\n",
       "      <td>33.65</td>\n",
       "      <td>87.66</td>\n",
       "      <td>264.07</td>\n",
       "      <td>49.32</td>\n",
       "      <td>1888.00</td>\n",
       "      <td>33.67</td>\n",
       "      <td>28.61</td>\n",
       "      <td>18.11</td>\n",
       "      <td>25.60</td>\n",
       "      <td>308.18</td>\n",
       "      <td>8.98</td>\n",
       "      <td>33.22</td>\n",
       "      <td>46.47</td>\n",
       "      <td>22.70</td>\n",
       "      <td>48.99</td>\n",
       "      <td>30.40</td>\n",
       "      <td>16.81</td>\n",
       "      <td>2.83</td>\n",
       "      <td>42.44</td>\n",
       "      <td>4.34</td>\n",
       "      <td>20.03</td>\n",
       "      <td>31.10</td>\n",
       "      <td>29.39</td>\n",
       "      <td>5.15</td>\n",
       "      <td>12.35</td>\n",
       "      <td>5.10</td>\n",
       "      <td>202.45</td>\n",
       "      <td>7.85</td>\n",
       "      <td>11.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-28</th>\n",
       "      <td>1.84</td>\n",
       "      <td>4.25</td>\n",
       "      <td>17.72</td>\n",
       "      <td>14.09</td>\n",
       "      <td>33.67</td>\n",
       "      <td>17.52</td>\n",
       "      <td>14.49</td>\n",
       "      <td>27.01</td>\n",
       "      <td>29.56</td>\n",
       "      <td>33.47</td>\n",
       "      <td>87.08</td>\n",
       "      <td>261.50</td>\n",
       "      <td>46.90</td>\n",
       "      <td>1883.00</td>\n",
       "      <td>33.51</td>\n",
       "      <td>28.30</td>\n",
       "      <td>17.84</td>\n",
       "      <td>25.30</td>\n",
       "      <td>306.85</td>\n",
       "      <td>8.82</td>\n",
       "      <td>33.26</td>\n",
       "      <td>43.98</td>\n",
       "      <td>22.46</td>\n",
       "      <td>47.90</td>\n",
       "      <td>30.64</td>\n",
       "      <td>16.84</td>\n",
       "      <td>2.85</td>\n",
       "      <td>41.89</td>\n",
       "      <td>4.35</td>\n",
       "      <td>20.08</td>\n",
       "      <td>31.48</td>\n",
       "      <td>28.11</td>\n",
       "      <td>5.10</td>\n",
       "      <td>12.26</td>\n",
       "      <td>5.07</td>\n",
       "      <td>202.48</td>\n",
       "      <td>7.48</td>\n",
       "      <td>11.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-29</th>\n",
       "      <td>1.84</td>\n",
       "      <td>4.26</td>\n",
       "      <td>17.40</td>\n",
       "      <td>13.85</td>\n",
       "      <td>33.15</td>\n",
       "      <td>17.28</td>\n",
       "      <td>14.27</td>\n",
       "      <td>26.97</td>\n",
       "      <td>29.61</td>\n",
       "      <td>34.97</td>\n",
       "      <td>89.49</td>\n",
       "      <td>266.10</td>\n",
       "      <td>47.98</td>\n",
       "      <td>1880.35</td>\n",
       "      <td>33.52</td>\n",
       "      <td>28.11</td>\n",
       "      <td>17.80</td>\n",
       "      <td>24.94</td>\n",
       "      <td>304.28</td>\n",
       "      <td>8.58</td>\n",
       "      <td>33.30</td>\n",
       "      <td>43.38</td>\n",
       "      <td>22.40</td>\n",
       "      <td>50.08</td>\n",
       "      <td>31.41</td>\n",
       "      <td>16.54</td>\n",
       "      <td>2.82</td>\n",
       "      <td>41.32</td>\n",
       "      <td>4.33</td>\n",
       "      <td>19.81</td>\n",
       "      <td>31.77</td>\n",
       "      <td>28.10</td>\n",
       "      <td>5.01</td>\n",
       "      <td>12.18</td>\n",
       "      <td>5.11</td>\n",
       "      <td>197.25</td>\n",
       "      <td>7.70</td>\n",
       "      <td>11.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-30</th>\n",
       "      <td>1.84</td>\n",
       "      <td>4.29</td>\n",
       "      <td>17.42</td>\n",
       "      <td>13.88</td>\n",
       "      <td>33.65</td>\n",
       "      <td>18.00</td>\n",
       "      <td>14.30</td>\n",
       "      <td>26.56</td>\n",
       "      <td>29.56</td>\n",
       "      <td>35.10</td>\n",
       "      <td>92.10</td>\n",
       "      <td>266.80</td>\n",
       "      <td>46.96</td>\n",
       "      <td>1872.50</td>\n",
       "      <td>33.89</td>\n",
       "      <td>28.81</td>\n",
       "      <td>17.60</td>\n",
       "      <td>24.77</td>\n",
       "      <td>302.89</td>\n",
       "      <td>8.66</td>\n",
       "      <td>32.98</td>\n",
       "      <td>41.95</td>\n",
       "      <td>22.74</td>\n",
       "      <td>47.91</td>\n",
       "      <td>31.64</td>\n",
       "      <td>16.65</td>\n",
       "      <td>2.86</td>\n",
       "      <td>41.58</td>\n",
       "      <td>4.35</td>\n",
       "      <td>20.33</td>\n",
       "      <td>31.63</td>\n",
       "      <td>27.80</td>\n",
       "      <td>5.15</td>\n",
       "      <td>12.12</td>\n",
       "      <td>5.13</td>\n",
       "      <td>198.25</td>\n",
       "      <td>7.84</td>\n",
       "      <td>11.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2613 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "tic         600010.SH  600028.SH  600030.SH  600031.SH  600036.SH  600048.SH  \\\n",
       "date                                                                           \n",
       "2012-01-04       4.15       7.36       9.56      12.09      11.67      10.05   \n",
       "2012-01-05       4.10       7.42       9.29      12.06      11.91       9.80   \n",
       "2012-01-06       4.34       7.48       9.39      12.06      11.99       9.71   \n",
       "2012-01-09       4.48       7.75       9.75      12.55      12.38      10.17   \n",
       "2012-01-10       4.54       7.79      10.12      13.31      12.56      10.35   \n",
       "2012-01-11       4.79       7.70      10.08      13.13      12.49      10.31   \n",
       "2012-01-12       4.77       7.66      10.03      13.22      12.62      10.39   \n",
       "2012-01-13       4.69       7.62       9.80      12.92      12.49      10.28   \n",
       "2012-01-16       4.32       7.54       9.83      13.06      12.39       9.93   \n",
       "2012-01-17       4.75       7.74      10.51      13.77      12.78      10.35   \n",
       "2012-01-18       4.73       7.58      10.47      13.69      12.52      10.12   \n",
       "2012-01-19       4.78       7.66      10.84      13.81      12.70      10.67   \n",
       "2012-01-20       4.77       7.74      11.01      13.99      13.00      10.94   \n",
       "2012-01-30       4.75       7.70      10.68        NaN      12.70      10.43   \n",
       "2012-01-31       4.87       7.76      10.69      14.21      12.65      10.50   \n",
       "2012-02-01       4.73       7.79      10.47      13.80      12.47      10.31   \n",
       "2012-02-02       4.83       7.86      10.80      14.06      12.87      10.56   \n",
       "2012-02-03       4.83       7.81      10.90      13.94      12.98      10.68   \n",
       "2012-02-06       4.82       7.78      10.84      13.89      12.86      10.45   \n",
       "2012-02-07       4.69       7.65      10.52      13.54      12.73      10.13   \n",
       "2012-02-08       4.90       7.78      10.95      13.88      12.99      10.42   \n",
       "2012-02-09       4.88       7.69      10.87      13.77      12.99      10.56   \n",
       "2012-02-10       5.08       7.67      10.97      13.88      12.89      10.91   \n",
       "2012-02-13       5.04       7.65      10.95      13.84      12.69      10.57   \n",
       "2012-02-14       5.01       7.66      10.87      13.69      12.66      10.62   \n",
       "...               ...        ...        ...        ...        ...        ...   \n",
       "2022-08-26       2.09       4.25      19.40      15.52      33.70      16.68   \n",
       "2022-08-29       2.07       4.26      19.37      15.56      33.28      16.61   \n",
       "2022-08-30       2.04       4.29      19.25      15.58      33.79      16.95   \n",
       "2022-08-31       2.01       4.27      19.52      15.75      35.05      17.30   \n",
       "2022-09-01       2.00       4.23      19.30      15.85      34.50      17.31   \n",
       "2022-09-02       2.00       4.26      19.24      15.61      34.32      17.02   \n",
       "2022-09-05       2.03       4.34      19.27      15.45      34.23      17.22   \n",
       "2022-09-06       2.05       4.41      19.48      15.73      33.62      17.63   \n",
       "2022-09-07       2.06       4.41      19.37      15.60      33.38      17.55   \n",
       "2022-09-08       2.04       4.41      19.31      15.75      33.30      17.58   \n",
       "2022-09-09       2.06       4.45      19.78      16.26      34.50      18.47   \n",
       "2022-09-13       2.05       4.43      19.83      16.30      35.35      18.09   \n",
       "2022-09-14       2.02       4.38      19.58      16.15      34.86      18.14   \n",
       "2022-09-15       2.00       4.40      19.53      16.20      36.01      18.85   \n",
       "2022-09-16       1.96       4.30      18.42      15.60      34.95      18.05   \n",
       "2022-09-19       1.91       4.18      18.42      14.97      35.09      18.44   \n",
       "2022-09-20       1.95       4.22      18.42      14.96      34.54      17.64   \n",
       "2022-09-21       1.98       4.25      18.43      15.06      34.41      17.83   \n",
       "2022-09-22       1.96       4.39      18.39      14.69      34.17      17.52   \n",
       "2022-09-23       1.96       4.47      18.36      14.42      34.36      17.55   \n",
       "2022-09-26       1.91       4.27      18.02      14.05      33.95      17.69   \n",
       "2022-09-27       1.91       4.28      18.07      14.37      33.90      17.67   \n",
       "2022-09-28       1.84       4.25      17.72      14.09      33.67      17.52   \n",
       "2022-09-29       1.84       4.26      17.40      13.85      33.15      17.28   \n",
       "2022-09-30       1.84       4.29      17.42      13.88      33.65      18.00   \n",
       "\n",
       "tic         600104.SH  600111.SH  600196.SH  600276.SH  600309.SH  600436.SH  \\\n",
       "date                                                                           \n",
       "2012-01-04      14.16      37.61       8.34      28.45      12.50      73.03   \n",
       "2012-01-05      14.39      35.64       8.25      27.00      12.10      70.50   \n",
       "2012-01-06      14.20      36.32       8.08      26.55      12.06      70.08   \n",
       "2012-01-09      14.90      39.02       8.34      27.40      12.47      70.10   \n",
       "2012-01-10      15.25      40.39       8.66      27.75      13.21      72.00   \n",
       "2012-01-11      15.10      42.63       8.63      27.70      13.25      72.85   \n",
       "2012-01-12      15.29      43.46       8.58      27.37      13.31      73.99   \n",
       "2012-01-13      14.69      44.96       8.31      26.80      12.83      71.73   \n",
       "2012-01-16      14.39      41.08       8.17      26.00      12.50      69.15   \n",
       "2012-01-17      15.33      45.19       8.61      26.02      13.39      70.90   \n",
       "2012-01-18      15.21      45.46       8.47      24.66      13.26      63.81   \n",
       "2012-01-19      15.46      46.58       8.62      25.20      13.76      64.29   \n",
       "2012-01-20      15.52      45.62       8.80      26.68      14.09      65.74   \n",
       "2012-01-30      15.48      46.06       8.63      26.19      13.67      64.87   \n",
       "2012-01-31      15.09      46.56        NaN      26.00        NaN      65.93   \n",
       "2012-02-01      14.93      44.73       8.51      25.86      13.78      66.52   \n",
       "2012-02-02      15.22      45.57       8.64      26.24      14.05      66.67   \n",
       "2012-02-03      15.40      45.61       8.76      26.39      14.42      66.89   \n",
       "2012-02-06      15.25      45.61       8.79      27.05      14.59      68.41   \n",
       "2012-02-07      15.22      44.55       8.60      26.53      14.26      68.22   \n",
       "2012-02-08      15.59      48.51       8.79      26.59      14.81      68.80   \n",
       "2012-02-09      15.49      47.57       8.87      26.93      14.91      68.77   \n",
       "2012-02-10      15.45      47.50       8.90      26.63      14.66      68.61   \n",
       "2012-02-13      15.76      47.65       8.84      26.99      14.58      68.67   \n",
       "2012-02-14      15.52      47.50       8.89      26.87      14.31      69.29   \n",
       "...               ...        ...        ...        ...        ...        ...   \n",
       "2022-08-26      15.88      30.84      40.93      34.77      88.67     294.00   \n",
       "2022-08-29      15.50      30.59      40.61      34.23      87.80     291.09   \n",
       "2022-08-30      15.48      30.37      40.08      33.67      88.45     288.36   \n",
       "2022-08-31      15.47      30.14      40.36      34.66      88.57     300.99   \n",
       "2022-09-01      15.30      30.09      40.90      34.34      88.11     298.30   \n",
       "2022-09-02      15.26      30.16      40.21      33.90      86.95     296.11   \n",
       "2022-09-05      15.21      30.08      36.19      33.73      88.65     294.00   \n",
       "2022-09-06      15.42      30.85      35.42      33.88      91.50     294.02   \n",
       "2022-09-07      15.40      30.79      35.55      33.43      90.52     291.48   \n",
       "2022-09-08      15.35      30.29      33.96      33.73      92.01     293.75   \n",
       "2022-09-09      15.48      30.68      35.00      34.78      95.61     298.11   \n",
       "2022-09-13      15.65      31.47      34.44      35.52      93.00     302.00   \n",
       "2022-09-14      15.44      30.70      33.76      35.68      91.36     300.29   \n",
       "2022-09-15      15.34      30.01      33.04      35.49      91.50     298.56   \n",
       "2022-09-16      15.02      28.80      32.17      34.83      90.38     293.20   \n",
       "2022-09-19      15.01      28.34      32.19      34.69      91.36     289.50   \n",
       "2022-09-20      14.89      29.01      32.27      34.13      89.55     289.35   \n",
       "2022-09-21      14.92      30.48      31.70      33.43      87.94     281.08   \n",
       "2022-09-22      14.81      29.39      30.99      32.64      88.05     260.85   \n",
       "2022-09-23      14.77      28.73      30.48      32.93      87.76     252.69   \n",
       "2022-09-26      14.55      28.10      30.09      31.90      87.28     246.79   \n",
       "2022-09-27      14.65      28.30      30.45      33.65      87.66     264.07   \n",
       "2022-09-28      14.49      27.01      29.56      33.47      87.08     261.50   \n",
       "2022-09-29      14.27      26.97      29.61      34.97      89.49     266.10   \n",
       "2022-09-30      14.30      26.56      29.56      35.10      92.10     266.80   \n",
       "\n",
       "tic         600438.SH  600519.SH  600570.SH  600585.SH  600588.SH  600690.SH  \\\n",
       "date                                                                           \n",
       "2012-01-04       4.85     185.27      11.50      15.28      16.90       8.78   \n",
       "2012-01-05       4.66     183.15      10.70      14.92      16.48       8.73   \n",
       "2012-01-06       4.72     186.64      10.67      14.72      16.23       8.79   \n",
       "2012-01-09       4.89     188.01      11.00      15.55      16.58       9.07   \n",
       "2012-01-10       5.10     194.48      11.34      16.59      17.02       9.42   \n",
       "2012-01-11       5.06     189.68      11.25      16.38      17.79       9.26   \n",
       "2012-01-12       5.03     190.35      11.05      16.51      17.14       9.23   \n",
       "2012-01-13       4.87     188.69      10.49      15.75      16.51       8.83   \n",
       "2012-01-16       4.76     177.41      10.30      15.28      16.03       8.70   \n",
       "2012-01-17       5.03     180.44      10.60      16.43      16.73       9.29   \n",
       "2012-01-18       4.93     177.38      10.48      16.82      16.49       9.08   \n",
       "2012-01-19       5.01     180.70      10.33      17.15      16.19       9.40   \n",
       "2012-01-20       5.10     185.97      10.41      17.79      16.48       9.51   \n",
       "2012-01-30       5.04     183.80      10.37      17.38      16.23       9.24   \n",
       "2012-01-31       5.08     186.41      10.39      17.37      16.45       9.21   \n",
       "2012-02-01       5.05     186.15      10.64      16.54      16.68       9.10   \n",
       "2012-02-02       5.25     186.43      10.77      16.90      17.14       9.19   \n",
       "2012-02-03       5.25     186.48      11.00      16.72      17.70       9.17   \n",
       "2012-02-06       5.27     188.54      11.00      17.07      17.93       9.27   \n",
       "2012-02-07       5.09     185.86      10.75      16.52      17.46       9.07   \n",
       "2012-02-08       5.20     188.29      11.04      17.15      17.90       9.28   \n",
       "2012-02-09       5.26     190.75      11.11      17.40      17.98       9.33   \n",
       "2012-02-10       5.32     190.51      11.06      17.51      17.70       9.33   \n",
       "2012-02-13       5.37     193.42      11.21      17.25      18.36       9.28   \n",
       "2012-02-14       5.38     193.82      11.27      17.10      18.06       9.24   \n",
       "...               ...        ...        ...        ...        ...        ...   \n",
       "2022-08-26      56.43    1898.00      32.44      31.81      20.00      24.33   \n",
       "2022-08-29      56.78    1878.82      32.70      31.42      19.29      24.57   \n",
       "2022-08-30      55.56    1870.00      33.33      30.99      20.07      25.40   \n",
       "2022-08-31      52.88    1924.00      33.64      31.92      20.09      25.87   \n",
       "2022-09-01      52.82    1880.89      34.50      31.60      20.37      26.21   \n",
       "2022-09-02      52.21    1875.00      34.37      31.17      20.15      25.63   \n",
       "2022-09-05      52.45    1835.00      33.73      31.01      19.79      25.58   \n",
       "2022-09-06      56.87    1845.00      33.66      31.00      19.71      25.69   \n",
       "2022-09-07      56.69    1818.01      33.59      30.41      19.62      25.80   \n",
       "2022-09-08      56.50    1815.00      33.99      30.20      19.33      25.88   \n",
       "2022-09-09      54.56    1844.79      35.30      31.37      19.54      26.50   \n",
       "2022-09-13      54.99    1879.00      36.15      31.96      19.58      26.48   \n",
       "2022-09-14      53.73    1869.00      36.30      31.59      19.71      26.49   \n",
       "2022-09-15      51.30    1880.00      35.71      32.23      19.45      26.88   \n",
       "2022-09-16      49.52    1859.00      33.99      31.19      19.53      26.06   \n",
       "2022-09-19      49.87    1871.64      33.69      30.45      18.03      26.16   \n",
       "2022-09-20      50.30    1878.00      32.77      29.58      18.19      25.87   \n",
       "2022-09-21      50.09    1848.00      32.74      29.18      18.29      25.19   \n",
       "2022-09-22      49.12    1820.81      32.80      28.73      18.49      24.56   \n",
       "2022-09-23      49.30    1834.43      32.52      28.66      18.05      24.50   \n",
       "2022-09-26      48.68    1863.00      32.04      28.33      17.76      24.95   \n",
       "2022-09-27      49.32    1888.00      33.67      28.61      18.11      25.60   \n",
       "2022-09-28      46.90    1883.00      33.51      28.30      17.84      25.30   \n",
       "2022-09-29      47.98    1880.35      33.52      28.11      17.80      24.94   \n",
       "2022-09-30      46.96    1872.50      33.89      28.81      17.60      24.77   \n",
       "\n",
       "tic         600809.SH  600837.SH  600887.SH  600893.SH  600900.SH  601012.SH  \\\n",
       "date                                                                           \n",
       "2012-01-04      57.79       7.12      19.73      13.29       6.29        NaN   \n",
       "2012-01-05      55.04       7.08      19.33      12.66       6.24        NaN   \n",
       "2012-01-06      53.69       7.30      19.66      12.95       6.22        NaN   \n",
       "2012-01-09      54.59       7.62      20.13      13.39       6.29        NaN   \n",
       "2012-01-10      57.00       7.93      20.58      13.79       6.40        NaN   \n",
       "2012-01-11      57.67       7.85      20.61      13.72       6.38        NaN   \n",
       "2012-01-12      55.89       7.85      20.50      14.10       6.41        NaN   \n",
       "2012-01-13      53.98       7.71      20.22      13.26       6.35        NaN   \n",
       "2012-01-16      50.77       7.64      19.01      12.89       6.36        NaN   \n",
       "2012-01-17      52.66       8.15      19.87      13.55       6.53        NaN   \n",
       "2012-01-18      51.61       8.07      19.14      13.32       6.48        NaN   \n",
       "2012-01-19      52.84       8.38      19.98      13.20       6.56        NaN   \n",
       "2012-01-20      54.34       8.60      20.54        NaN       6.57        NaN   \n",
       "2012-01-30      53.30       8.36      20.33      13.49       6.45        NaN   \n",
       "2012-01-31      54.97       8.36      20.44      13.48       6.49        NaN   \n",
       "2012-02-01      54.98       8.10      20.60      13.12       6.44        NaN   \n",
       "2012-02-02      55.72       8.53      20.92      13.31       6.48        NaN   \n",
       "2012-02-03      57.00       8.47      20.90      13.79       6.52        NaN   \n",
       "2012-02-06      58.59       8.45      21.56      13.68       6.47        NaN   \n",
       "2012-02-07      57.61       8.21      21.50      14.74       6.33        NaN   \n",
       "2012-02-08      59.17       8.67      21.80      15.24       6.47        NaN   \n",
       "2012-02-09      59.40       8.57      21.32      15.13       6.41        NaN   \n",
       "2012-02-10      59.00       8.65      21.76      15.29       6.40        NaN   \n",
       "2012-02-13      59.85       8.55      22.11      15.57       6.39        NaN   \n",
       "2012-02-14      60.71       8.49      22.09      15.42       6.40        NaN   \n",
       "...               ...        ...        ...        ...        ...        ...   \n",
       "2022-08-26     286.93       9.51      36.19      48.17      23.39      53.06   \n",
       "2022-08-29     285.30       9.45      35.95      49.91      23.30      53.41   \n",
       "2022-08-30     284.09       9.41      36.13      47.88      23.28      52.80   \n",
       "2022-08-31     293.00       9.48      35.74      45.97      23.98      51.20   \n",
       "2022-09-01     292.58       9.39      34.55      45.88      23.91      51.65   \n",
       "2022-09-02     288.53       9.32      33.90      45.22      23.82      50.95   \n",
       "2022-09-05     282.78       9.40      33.37      45.77      23.82      50.49   \n",
       "2022-09-06     286.02       9.46      33.63      47.14      23.75      53.16   \n",
       "2022-09-07     278.12       9.47      33.22      47.24      23.57      53.46   \n",
       "2022-09-08     285.59       9.44      33.27      47.76      23.65      53.39   \n",
       "2022-09-09     291.21       9.54      33.70      48.03      23.91      53.18   \n",
       "2022-09-13     293.00       9.52      33.74      49.00      23.79      53.27   \n",
       "2022-09-14     292.30       9.46      33.60      49.23      23.70      52.55   \n",
       "2022-09-15     296.00       9.46      33.69      47.20      23.72      48.66   \n",
       "2022-09-16     289.50       9.05      32.88      46.88      23.46      48.30   \n",
       "2022-09-19     293.75       9.06      32.90      46.01      23.48      48.12   \n",
       "2022-09-20     296.09       9.09      32.66      45.75      23.42      50.04   \n",
       "2022-09-21     292.15       9.07      32.48      44.80      23.43      49.19   \n",
       "2022-09-22     292.44       9.12      32.00      46.60      23.42      49.18   \n",
       "2022-09-23     291.89       9.12      32.45      46.74      23.33      48.54   \n",
       "2022-09-26     299.65       8.97      32.36      45.29      23.05      48.80   \n",
       "2022-09-27     308.18       8.98      33.22      46.47      22.70      48.99   \n",
       "2022-09-28     306.85       8.82      33.26      43.98      22.46      47.90   \n",
       "2022-09-29     304.28       8.58      33.30      43.38      22.40      50.08   \n",
       "2022-09-30     302.89       8.66      32.98      41.95      22.74      47.91   \n",
       "\n",
       "tic         601088.SH  601166.SH  601288.SH  601318.SH  601398.SH  601601.SH  \\\n",
       "date                                                                           \n",
       "2012-01-04      24.60      12.50       2.60      33.90       4.22      19.04   \n",
       "2012-01-05      24.29      12.71       2.65      33.93       4.25      19.12   \n",
       "2012-01-06      24.27      12.79       2.66      33.85       4.28      19.23   \n",
       "2012-01-09      26.01      13.04       2.68      34.73       4.31      19.73   \n",
       "2012-01-10      26.76      13.15       2.69      36.29       4.35      20.40   \n",
       "2012-01-11      26.49      13.02       2.67      35.83       4.35      20.20   \n",
       "2012-01-12      26.49      13.30       2.65      36.37       4.33      20.03   \n",
       "2012-01-13      26.33      13.28       2.65      36.03       4.34      19.95   \n",
       "2012-01-16      26.02      13.32        NaN      35.59       4.31      19.85   \n",
       "2012-01-17      27.38      13.60       2.69      37.82       4.36      20.68   \n",
       "2012-01-18      26.88      13.43       2.69      37.45       4.31      20.50   \n",
       "2012-01-19      27.10      13.78       2.70      38.51       4.36      21.22   \n",
       "2012-01-20      27.48      14.05       2.72      39.10       4.36      21.84   \n",
       "2012-01-30      26.68      13.83       2.68      38.60       4.27      21.11   \n",
       "2012-01-31      26.85      13.86       2.70      38.34       4.30      21.01   \n",
       "2012-02-01      26.57      13.56       2.68      37.41       4.28      20.65   \n",
       "2012-02-02      27.24      14.15       2.73      39.64       4.38      21.41   \n",
       "2012-02-03      27.35      14.18       2.75      40.15       4.41      21.86   \n",
       "2012-02-06      27.35      14.17       2.75      39.62       4.41      21.36   \n",
       "2012-02-07      26.89      14.02       2.72      38.91       4.33      20.79   \n",
       "2012-02-08      27.63      14.43       2.75        NaN       4.41      21.75   \n",
       "2012-02-09      27.53      14.42       2.73      39.88       4.42      21.26   \n",
       "2012-02-10      27.45      14.24       2.72      40.09       4.39      21.61   \n",
       "2012-02-13      27.14      14.13       2.71      40.28       4.37      21.41   \n",
       "2012-02-14      27.14      14.08       2.70      39.58       4.35      20.83   \n",
       "...               ...        ...        ...        ...        ...        ...   \n",
       "2022-08-26      31.26      17.88       2.82      43.12       4.35      20.29   \n",
       "2022-08-29      31.88      16.93       2.82      43.07       4.33      20.17   \n",
       "2022-08-30      30.52      16.82       2.82      42.89       4.36      20.47   \n",
       "2022-08-31      30.34      17.11       2.85      43.84       4.38      20.97   \n",
       "2022-09-01      31.11      17.11       2.83      43.65       4.36      20.82   \n",
       "2022-09-02      30.66      17.03       2.83      43.70       4.35      20.75   \n",
       "2022-09-05      32.56      17.08       2.84      43.80       4.36      20.90   \n",
       "2022-09-06      32.88      17.06       2.84      43.90       4.36      21.08   \n",
       "2022-09-07      32.61      17.09       2.83      43.60       4.35      20.98   \n",
       "2022-09-08      32.30      17.01       2.83      43.84       4.35      20.95   \n",
       "2022-09-09      32.73      17.38       2.84      44.69       4.36      21.47   \n",
       "2022-09-13      32.45      17.59       2.85      45.06       4.38      21.52   \n",
       "2022-09-14      32.35      17.38       2.85      44.65       4.36      21.26   \n",
       "2022-09-15      32.39      17.69       2.87      45.09       4.39      21.31   \n",
       "2022-09-16      30.96      17.22       2.85      43.93       4.36      20.88   \n",
       "2022-09-19      31.50      17.34       2.87      43.93       4.38      20.42   \n",
       "2022-09-20      31.35      17.08       2.84      43.24       4.37      20.10   \n",
       "2022-09-21      31.18      17.15       2.86      43.15       4.37      20.25   \n",
       "2022-09-22      31.99      17.05       2.86      42.48       4.39      20.26   \n",
       "2022-09-23      31.18      17.10       2.88      43.02       4.40      20.39   \n",
       "2022-09-26      30.36      16.75       2.85      42.49       4.35      19.90   \n",
       "2022-09-27      30.40      16.81       2.83      42.44       4.34      20.03   \n",
       "2022-09-28      30.64      16.84       2.85      41.89       4.35      20.08   \n",
       "2022-09-29      31.41      16.54       2.82      41.32       4.33      19.81   \n",
       "2022-09-30      31.64      16.65       2.86      41.58       4.35      20.33   \n",
       "\n",
       "tic         601628.SH  601633.SH  601668.SH  601688.SH  601857.SH  601888.SH  \\\n",
       "date                                                                           \n",
       "2012-01-04      17.46      11.87       2.86       7.62       9.75      25.59   \n",
       "2012-01-05      16.58      12.10       2.87       7.36       9.80      24.17   \n",
       "2012-01-06      16.73      11.81       2.87       7.49       9.96      23.61   \n",
       "2012-01-09      17.28      12.26       2.93       7.79      10.03      24.41   \n",
       "2012-01-10      18.23      12.46       3.08       8.13      10.12      25.60   \n",
       "2012-01-11      18.22      12.41       3.04       8.00      10.04      25.95   \n",
       "2012-01-12      18.30      12.65       3.04       7.93      10.06      25.47   \n",
       "2012-01-13      17.89      12.26       3.01       7.87      10.20      24.93   \n",
       "2012-01-16      17.81        NaN       2.98       7.73      10.09      23.59   \n",
       "2012-01-17      18.78      12.99       3.10       8.19      10.32      24.72   \n",
       "2012-01-18      18.45      12.77       3.05       8.22      10.22      24.01   \n",
       "2012-01-19      19.00      12.88       3.09       8.48      10.26      24.41   \n",
       "2012-01-20      19.33      12.99       3.14       8.50      10.26      25.01   \n",
       "2012-01-30      18.90      12.73       3.07       8.20      10.13      25.10   \n",
       "2012-01-31      18.78      12.57       3.07       8.33      10.21      24.73   \n",
       "2012-02-01      18.34      12.40       3.04       8.16      10.18      24.71   \n",
       "2012-02-02      19.07      12.65       3.10       8.36      10.21      25.10   \n",
       "2012-02-03      19.30      12.54       3.10       8.35      10.22      24.89   \n",
       "2012-02-06      18.92      12.73       3.07       8.26      10.23      25.01   \n",
       "2012-02-07      18.50      12.65       3.01       8.05      10.09      25.42   \n",
       "2012-02-08      19.24      12.98       3.09       8.36      10.26      25.87   \n",
       "2012-02-09      19.07      12.98       3.08       8.27      10.29      25.77   \n",
       "2012-02-10      18.93      13.03       3.21       8.32      10.31      25.91   \n",
       "2012-02-13      18.64      13.41       3.16       8.37      10.26      26.08   \n",
       "2012-02-14      18.39      13.38       3.16       8.37      10.24      26.03   \n",
       "...               ...        ...        ...        ...        ...        ...   \n",
       "2022-08-26      29.44      35.35       5.01      13.13       5.44     192.41   \n",
       "2022-08-29      29.02      33.96       5.04      13.02       5.48     192.25   \n",
       "2022-08-30      29.50      34.20       5.07      13.11       5.47     190.40   \n",
       "2022-08-31      30.70      33.46       5.14      13.14       5.34     195.50   \n",
       "2022-09-01      30.45      32.25       5.15      13.00       5.36     186.80   \n",
       "2022-09-02      29.70      31.65       5.11      12.92       5.42     180.31   \n",
       "2022-09-05      29.86      31.19       5.17      13.05       5.56     180.10   \n",
       "2022-09-06      30.34      31.84       5.24      13.18       5.61     182.72   \n",
       "2022-09-07      30.25      32.09       5.23      13.14       5.58     183.95   \n",
       "2022-09-08      30.76      30.98       5.23      13.14       5.53     186.00   \n",
       "2022-09-09      31.50      31.31       5.36      13.28       5.59     191.09   \n",
       "2022-09-13      31.46      32.00       5.32      13.24       5.55     192.47   \n",
       "2022-09-14      31.63      31.74       5.26      13.11       5.52     191.55   \n",
       "2022-09-15      31.74      30.57       5.37      13.08       5.54     191.35   \n",
       "2022-09-16      31.06      28.88       5.15      12.41       5.37     188.51   \n",
       "2022-09-19      30.86      29.98       5.24      12.35       5.35     188.45   \n",
       "2022-09-20      29.84      29.83       5.11      12.33       5.16     194.23   \n",
       "2022-09-21      29.82      29.44       5.15      12.33       5.23     185.54   \n",
       "2022-09-22      29.91      28.63       5.12      12.33       5.34     187.10   \n",
       "2022-09-23      30.88      28.49       5.22      12.44       5.44     185.41   \n",
       "2022-09-26      30.82      28.70       5.15      12.21       5.11     194.51   \n",
       "2022-09-27      31.10      29.39       5.15      12.35       5.10     202.45   \n",
       "2022-09-28      31.48      28.11       5.10      12.26       5.07     202.48   \n",
       "2022-09-29      31.77      28.10       5.01      12.18       5.11     197.25   \n",
       "2022-09-30      31.63      27.80       5.15      12.12       5.13     198.25   \n",
       "\n",
       "tic         601899.SH  601919.SH  \n",
       "date                              \n",
       "2012-01-04       3.81       4.50  \n",
       "2012-01-05       3.78       4.30  \n",
       "2012-01-06       3.80       4.32  \n",
       "2012-01-09       3.93       4.47  \n",
       "2012-01-10       4.12       4.68  \n",
       "2012-01-11       4.16       4.63  \n",
       "2012-01-12       4.15       4.69  \n",
       "2012-01-13       4.06       4.48  \n",
       "2012-01-16       3.96       4.38  \n",
       "2012-01-17       4.36       4.82  \n",
       "2012-01-18       4.29       5.10  \n",
       "2012-01-19       4.48       5.08  \n",
       "2012-01-20       4.47       5.05  \n",
       "2012-01-30       4.49       5.00  \n",
       "2012-01-31       4.44       5.08  \n",
       "2012-02-01       4.37       5.10  \n",
       "2012-02-02       4.46       5.33  \n",
       "2012-02-03       4.50       5.31  \n",
       "2012-02-06       4.45       5.30  \n",
       "2012-02-07       4.35       5.28  \n",
       "2012-02-08       4.53       5.37  \n",
       "2012-02-09       4.50       5.41  \n",
       "2012-02-10       4.50       5.47  \n",
       "2012-02-13       4.53       5.43  \n",
       "2012-02-14       4.48       5.39  \n",
       "...               ...        ...  \n",
       "2022-08-26       9.15      13.78  \n",
       "2022-08-29       9.02      13.60  \n",
       "2022-08-30       8.90      14.41  \n",
       "2022-08-31       8.80      14.20  \n",
       "2022-09-01       8.65      13.70  \n",
       "2022-09-02       8.52      13.33  \n",
       "2022-09-05       8.59      13.24  \n",
       "2022-09-06       8.84      13.39  \n",
       "2022-09-07       8.94      13.44  \n",
       "2022-09-08       9.06      13.26  \n",
       "2022-09-09       9.19      13.29  \n",
       "2022-09-13       9.29      13.26  \n",
       "2022-09-14       9.00      13.12  \n",
       "2022-09-15       8.95      12.93  \n",
       "2022-09-16       8.68      12.56  \n",
       "2022-09-19       8.62      12.13  \n",
       "2022-09-20       8.70      12.22  \n",
       "2022-09-21       8.71      12.41  \n",
       "2022-09-22       8.65      12.27  \n",
       "2022-09-23       8.53      11.97  \n",
       "2022-09-26       7.82      11.26  \n",
       "2022-09-27       7.85      11.34  \n",
       "2022-09-28       7.48      11.05  \n",
       "2022-09-29       7.70      11.08  \n",
       "2022-09-30       7.84      11.02  \n",
       "\n",
       "[2613 rows x 38 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_length = len(merged_closes)\n",
    "merged_closes.dropna(axis=1, thresh = int(0.9*data_length), inplace=True)\n",
    "merged_closes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8759700",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T02:27:10.255616Z",
     "start_time": "2022-10-12T02:27:10.210341Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tic</th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>600010.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>4.15</td>\n",
       "      <td>4.28</td>\n",
       "      <td>4.09</td>\n",
       "      <td>4.15</td>\n",
       "      <td>672559.53</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>600028.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>7.28</td>\n",
       "      <td>7.44</td>\n",
       "      <td>7.27</td>\n",
       "      <td>7.36</td>\n",
       "      <td>528181.38</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>600030.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>9.79</td>\n",
       "      <td>9.85</td>\n",
       "      <td>9.56</td>\n",
       "      <td>9.56</td>\n",
       "      <td>354005.33</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>600031.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>12.61</td>\n",
       "      <td>12.73</td>\n",
       "      <td>12.07</td>\n",
       "      <td>12.09</td>\n",
       "      <td>235312.56</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>600036.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>11.95</td>\n",
       "      <td>12.10</td>\n",
       "      <td>11.63</td>\n",
       "      <td>11.67</td>\n",
       "      <td>522606.17</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>600048.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>10.01</td>\n",
       "      <td>10.30</td>\n",
       "      <td>9.91</td>\n",
       "      <td>10.05</td>\n",
       "      <td>341555.93</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>600104.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>14.28</td>\n",
       "      <td>14.53</td>\n",
       "      <td>13.92</td>\n",
       "      <td>14.16</td>\n",
       "      <td>272418.21</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>600111.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>37.90</td>\n",
       "      <td>38.20</td>\n",
       "      <td>37.51</td>\n",
       "      <td>37.61</td>\n",
       "      <td>160533.19</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>600196.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>8.60</td>\n",
       "      <td>8.68</td>\n",
       "      <td>8.30</td>\n",
       "      <td>8.34</td>\n",
       "      <td>36465.88</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>600276.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>29.50</td>\n",
       "      <td>29.75</td>\n",
       "      <td>28.40</td>\n",
       "      <td>28.45</td>\n",
       "      <td>11847.13</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>600309.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>12.97</td>\n",
       "      <td>13.10</td>\n",
       "      <td>12.45</td>\n",
       "      <td>12.50</td>\n",
       "      <td>96092.38</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>600436.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>75.02</td>\n",
       "      <td>75.30</td>\n",
       "      <td>73.00</td>\n",
       "      <td>73.03</td>\n",
       "      <td>3099.31</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>600438.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>5.02</td>\n",
       "      <td>5.06</td>\n",
       "      <td>4.84</td>\n",
       "      <td>4.85</td>\n",
       "      <td>17962.70</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14</td>\n",
       "      <td>600519.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>191.50</td>\n",
       "      <td>192.77</td>\n",
       "      <td>185.00</td>\n",
       "      <td>185.27</td>\n",
       "      <td>33878.28</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>600570.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>12.24</td>\n",
       "      <td>12.25</td>\n",
       "      <td>11.46</td>\n",
       "      <td>11.50</td>\n",
       "      <td>18070.26</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>600585.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>15.81</td>\n",
       "      <td>15.90</td>\n",
       "      <td>15.27</td>\n",
       "      <td>15.28</td>\n",
       "      <td>207915.93</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>600588.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>18.00</td>\n",
       "      <td>18.19</td>\n",
       "      <td>16.88</td>\n",
       "      <td>16.90</td>\n",
       "      <td>25973.70</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>600690.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>9.00</td>\n",
       "      <td>9.17</td>\n",
       "      <td>8.78</td>\n",
       "      <td>8.78</td>\n",
       "      <td>142288.41</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>600809.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>63.00</td>\n",
       "      <td>63.03</td>\n",
       "      <td>57.36</td>\n",
       "      <td>57.79</td>\n",
       "      <td>28902.50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>600837.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>7.51</td>\n",
       "      <td>7.51</td>\n",
       "      <td>7.10</td>\n",
       "      <td>7.12</td>\n",
       "      <td>291690.79</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>600887.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>20.59</td>\n",
       "      <td>20.60</td>\n",
       "      <td>19.48</td>\n",
       "      <td>19.73</td>\n",
       "      <td>102000.09</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>600893.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>13.77</td>\n",
       "      <td>13.95</td>\n",
       "      <td>13.24</td>\n",
       "      <td>13.29</td>\n",
       "      <td>34955.58</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>600900.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>6.36</td>\n",
       "      <td>6.40</td>\n",
       "      <td>6.29</td>\n",
       "      <td>6.29</td>\n",
       "      <td>130363.57</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>601088.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>25.48</td>\n",
       "      <td>25.62</td>\n",
       "      <td>24.45</td>\n",
       "      <td>24.60</td>\n",
       "      <td>121256.25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "      <td>601166.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>12.65</td>\n",
       "      <td>12.68</td>\n",
       "      <td>12.48</td>\n",
       "      <td>12.50</td>\n",
       "      <td>405285.47</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>113624</td>\n",
       "      <td>600519.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>1898.62</td>\n",
       "      <td>1901.99</td>\n",
       "      <td>1866.00</td>\n",
       "      <td>1872.50</td>\n",
       "      <td>21289.08</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>113625</td>\n",
       "      <td>600570.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>33.79</td>\n",
       "      <td>34.74</td>\n",
       "      <td>33.60</td>\n",
       "      <td>33.89</td>\n",
       "      <td>101960.81</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>113626</td>\n",
       "      <td>600585.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>28.18</td>\n",
       "      <td>29.15</td>\n",
       "      <td>28.18</td>\n",
       "      <td>28.81</td>\n",
       "      <td>284870.69</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>113627</td>\n",
       "      <td>600588.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>17.71</td>\n",
       "      <td>17.93</td>\n",
       "      <td>17.60</td>\n",
       "      <td>17.60</td>\n",
       "      <td>124403.66</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>113628</td>\n",
       "      <td>600690.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>25.00</td>\n",
       "      <td>25.19</td>\n",
       "      <td>24.65</td>\n",
       "      <td>24.77</td>\n",
       "      <td>267702.88</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>113630</td>\n",
       "      <td>600809.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>309.00</td>\n",
       "      <td>309.80</td>\n",
       "      <td>300.12</td>\n",
       "      <td>302.89</td>\n",
       "      <td>32116.50</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>113631</td>\n",
       "      <td>600837.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>8.51</td>\n",
       "      <td>8.73</td>\n",
       "      <td>8.51</td>\n",
       "      <td>8.66</td>\n",
       "      <td>220874.32</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>113632</td>\n",
       "      <td>600887.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>33.29</td>\n",
       "      <td>33.47</td>\n",
       "      <td>32.93</td>\n",
       "      <td>32.98</td>\n",
       "      <td>264761.80</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>113633</td>\n",
       "      <td>600893.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>43.56</td>\n",
       "      <td>43.64</td>\n",
       "      <td>41.84</td>\n",
       "      <td>41.95</td>\n",
       "      <td>161512.07</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>113634</td>\n",
       "      <td>600900.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>22.40</td>\n",
       "      <td>22.85</td>\n",
       "      <td>22.28</td>\n",
       "      <td>22.74</td>\n",
       "      <td>423324.79</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>113636</td>\n",
       "      <td>601012.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>49.78</td>\n",
       "      <td>50.15</td>\n",
       "      <td>47.80</td>\n",
       "      <td>47.91</td>\n",
       "      <td>682745.27</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>113638</td>\n",
       "      <td>601088.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>31.60</td>\n",
       "      <td>31.92</td>\n",
       "      <td>31.10</td>\n",
       "      <td>31.64</td>\n",
       "      <td>219426.08</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>113639</td>\n",
       "      <td>601166.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>16.57</td>\n",
       "      <td>16.77</td>\n",
       "      <td>16.54</td>\n",
       "      <td>16.65</td>\n",
       "      <td>470496.19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>113641</td>\n",
       "      <td>601288.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2.83</td>\n",
       "      <td>2.86</td>\n",
       "      <td>2.83</td>\n",
       "      <td>2.86</td>\n",
       "      <td>2602100.09</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>113642</td>\n",
       "      <td>601318.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>41.35</td>\n",
       "      <td>41.98</td>\n",
       "      <td>41.35</td>\n",
       "      <td>41.58</td>\n",
       "      <td>331619.40</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>113643</td>\n",
       "      <td>601398.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.36</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.35</td>\n",
       "      <td>1578628.46</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>113644</td>\n",
       "      <td>601601.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>19.83</td>\n",
       "      <td>20.45</td>\n",
       "      <td>19.83</td>\n",
       "      <td>20.33</td>\n",
       "      <td>195189.41</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>113645</td>\n",
       "      <td>601628.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>31.76</td>\n",
       "      <td>32.00</td>\n",
       "      <td>31.16</td>\n",
       "      <td>31.63</td>\n",
       "      <td>111268.85</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>113646</td>\n",
       "      <td>601633.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>28.05</td>\n",
       "      <td>28.35</td>\n",
       "      <td>27.68</td>\n",
       "      <td>27.80</td>\n",
       "      <td>151081.85</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>113647</td>\n",
       "      <td>601668.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>5.03</td>\n",
       "      <td>5.19</td>\n",
       "      <td>5.03</td>\n",
       "      <td>5.15</td>\n",
       "      <td>2186913.38</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>113648</td>\n",
       "      <td>601688.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>12.19</td>\n",
       "      <td>12.29</td>\n",
       "      <td>12.10</td>\n",
       "      <td>12.12</td>\n",
       "      <td>229982.43</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>113650</td>\n",
       "      <td>601857.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>5.08</td>\n",
       "      <td>5.16</td>\n",
       "      <td>5.08</td>\n",
       "      <td>5.13</td>\n",
       "      <td>819572.30</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>113651</td>\n",
       "      <td>601888.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>198.24</td>\n",
       "      <td>200.50</td>\n",
       "      <td>195.71</td>\n",
       "      <td>198.25</td>\n",
       "      <td>80998.33</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>113652</td>\n",
       "      <td>601899.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>7.78</td>\n",
       "      <td>7.92</td>\n",
       "      <td>7.73</td>\n",
       "      <td>7.84</td>\n",
       "      <td>1988575.12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>113653</td>\n",
       "      <td>601919.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>11.00</td>\n",
       "      <td>11.14</td>\n",
       "      <td>10.92</td>\n",
       "      <td>11.02</td>\n",
       "      <td>625792.65</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97902 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0        tic        date     open     high      low    close  \\\n",
       "0              0  600010.SH  2012-01-04     4.15     4.28     4.09     4.15   \n",
       "0              1  600028.SH  2012-01-04     7.28     7.44     7.27     7.36   \n",
       "0              2  600030.SH  2012-01-04     9.79     9.85     9.56     9.56   \n",
       "0              3  600031.SH  2012-01-04    12.61    12.73    12.07    12.09   \n",
       "0              4  600036.SH  2012-01-04    11.95    12.10    11.63    11.67   \n",
       "0              5  600048.SH  2012-01-04    10.01    10.30     9.91    10.05   \n",
       "0              6  600104.SH  2012-01-04    14.28    14.53    13.92    14.16   \n",
       "0              7  600111.SH  2012-01-04    37.90    38.20    37.51    37.61   \n",
       "0              8  600196.SH  2012-01-04     8.60     8.68     8.30     8.34   \n",
       "0              9  600276.SH  2012-01-04    29.50    29.75    28.40    28.45   \n",
       "0             10  600309.SH  2012-01-04    12.97    13.10    12.45    12.50   \n",
       "0             12  600436.SH  2012-01-04    75.02    75.30    73.00    73.03   \n",
       "0             13  600438.SH  2012-01-04     5.02     5.06     4.84     4.85   \n",
       "0             14  600519.SH  2012-01-04   191.50   192.77   185.00   185.27   \n",
       "0             15  600570.SH  2012-01-04    12.24    12.25    11.46    11.50   \n",
       "0             16  600585.SH  2012-01-04    15.81    15.90    15.27    15.28   \n",
       "0             17  600588.SH  2012-01-04    18.00    18.19    16.88    16.90   \n",
       "0             18  600690.SH  2012-01-04     9.00     9.17     8.78     8.78   \n",
       "0             20  600809.SH  2012-01-04    63.00    63.03    57.36    57.79   \n",
       "0             21  600837.SH  2012-01-04     7.51     7.51     7.10     7.12   \n",
       "0             22  600887.SH  2012-01-04    20.59    20.60    19.48    19.73   \n",
       "0             23  600893.SH  2012-01-04    13.77    13.95    13.24    13.29   \n",
       "0             24  600900.SH  2012-01-04     6.36     6.40     6.29     6.29   \n",
       "0             25  601088.SH  2012-01-04    25.48    25.62    24.45    24.60   \n",
       "0             26  601166.SH  2012-01-04    12.65    12.68    12.48    12.50   \n",
       "...          ...        ...         ...      ...      ...      ...      ...   \n",
       "2612      113624  600519.SH  2022-09-30  1898.62  1901.99  1866.00  1872.50   \n",
       "2612      113625  600570.SH  2022-09-30    33.79    34.74    33.60    33.89   \n",
       "2612      113626  600585.SH  2022-09-30    28.18    29.15    28.18    28.81   \n",
       "2612      113627  600588.SH  2022-09-30    17.71    17.93    17.60    17.60   \n",
       "2612      113628  600690.SH  2022-09-30    25.00    25.19    24.65    24.77   \n",
       "2612      113630  600809.SH  2022-09-30   309.00   309.80   300.12   302.89   \n",
       "2612      113631  600837.SH  2022-09-30     8.51     8.73     8.51     8.66   \n",
       "2612      113632  600887.SH  2022-09-30    33.29    33.47    32.93    32.98   \n",
       "2612      113633  600893.SH  2022-09-30    43.56    43.64    41.84    41.95   \n",
       "2612      113634  600900.SH  2022-09-30    22.40    22.85    22.28    22.74   \n",
       "2612      113636  601012.SH  2022-09-30    49.78    50.15    47.80    47.91   \n",
       "2612      113638  601088.SH  2022-09-30    31.60    31.92    31.10    31.64   \n",
       "2612      113639  601166.SH  2022-09-30    16.57    16.77    16.54    16.65   \n",
       "2612      113641  601288.SH  2022-09-30     2.83     2.86     2.83     2.86   \n",
       "2612      113642  601318.SH  2022-09-30    41.35    41.98    41.35    41.58   \n",
       "2612      113643  601398.SH  2022-09-30     4.34     4.36     4.33     4.35   \n",
       "2612      113644  601601.SH  2022-09-30    19.83    20.45    19.83    20.33   \n",
       "2612      113645  601628.SH  2022-09-30    31.76    32.00    31.16    31.63   \n",
       "2612      113646  601633.SH  2022-09-30    28.05    28.35    27.68    27.80   \n",
       "2612      113647  601668.SH  2022-09-30     5.03     5.19     5.03     5.15   \n",
       "2612      113648  601688.SH  2022-09-30    12.19    12.29    12.10    12.12   \n",
       "2612      113650  601857.SH  2022-09-30     5.08     5.16     5.08     5.13   \n",
       "2612      113651  601888.SH  2022-09-30   198.24   200.50   195.71   198.25   \n",
       "2612      113652  601899.SH  2022-09-30     7.78     7.92     7.73     7.84   \n",
       "2612      113653  601919.SH  2022-09-30    11.00    11.14    10.92    11.02   \n",
       "\n",
       "          volume  day  \n",
       "0      672559.53    2  \n",
       "0      528181.38    2  \n",
       "0      354005.33    2  \n",
       "0      235312.56    2  \n",
       "0      522606.17    2  \n",
       "0      341555.93    2  \n",
       "0      272418.21    2  \n",
       "0      160533.19    2  \n",
       "0       36465.88    2  \n",
       "0       11847.13    2  \n",
       "0       96092.38    2  \n",
       "0        3099.31    2  \n",
       "0       17962.70    2  \n",
       "0       33878.28    2  \n",
       "0       18070.26    2  \n",
       "0      207915.93    2  \n",
       "0       25973.70    2  \n",
       "0      142288.41    2  \n",
       "0       28902.50    2  \n",
       "0      291690.79    2  \n",
       "0      102000.09    2  \n",
       "0       34955.58    2  \n",
       "0      130363.57    2  \n",
       "0      121256.25    2  \n",
       "0      405285.47    2  \n",
       "...          ...  ...  \n",
       "2612    21289.08    4  \n",
       "2612   101960.81    4  \n",
       "2612   284870.69    4  \n",
       "2612   124403.66    4  \n",
       "2612   267702.88    4  \n",
       "2612    32116.50    4  \n",
       "2612   220874.32    4  \n",
       "2612   264761.80    4  \n",
       "2612   161512.07    4  \n",
       "2612   423324.79    4  \n",
       "2612   682745.27    4  \n",
       "2612   219426.08    4  \n",
       "2612   470496.19    4  \n",
       "2612  2602100.09    4  \n",
       "2612   331619.40    4  \n",
       "2612  1578628.46    4  \n",
       "2612   195189.41    4  \n",
       "2612   111268.85    4  \n",
       "2612   151081.85    4  \n",
       "2612  2186913.38    4  \n",
       "2612   229982.43    4  \n",
       "2612   819572.30    4  \n",
       "2612    80998.33    4  \n",
       "2612  1988575.12    4  \n",
       "2612   625792.65    4  \n",
       "\n",
       "[97902 rows x 9 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select the stocks with missing data less than 10%\n",
    "tics = merged_closes.columns\n",
    "df = df[df.tic.isin(tics)]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd6f4938",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T02:27:15.803830Z",
     "start_time": "2022-10-12T02:27:15.716342Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tic</th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600010.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>4.15</td>\n",
       "      <td>4.28</td>\n",
       "      <td>4.09</td>\n",
       "      <td>4.15</td>\n",
       "      <td>672559.53</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600028.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>7.28</td>\n",
       "      <td>7.44</td>\n",
       "      <td>7.27</td>\n",
       "      <td>7.36</td>\n",
       "      <td>528181.38</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600030.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>9.79</td>\n",
       "      <td>9.85</td>\n",
       "      <td>9.56</td>\n",
       "      <td>9.56</td>\n",
       "      <td>354005.33</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600031.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>12.61</td>\n",
       "      <td>12.73</td>\n",
       "      <td>12.07</td>\n",
       "      <td>12.09</td>\n",
       "      <td>235312.56</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600036.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>11.95</td>\n",
       "      <td>12.10</td>\n",
       "      <td>11.63</td>\n",
       "      <td>11.67</td>\n",
       "      <td>522606.17</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600048.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>10.01</td>\n",
       "      <td>10.30</td>\n",
       "      <td>9.91</td>\n",
       "      <td>10.05</td>\n",
       "      <td>341555.93</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600104.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>14.28</td>\n",
       "      <td>14.53</td>\n",
       "      <td>13.92</td>\n",
       "      <td>14.16</td>\n",
       "      <td>272418.21</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600111.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>37.90</td>\n",
       "      <td>38.20</td>\n",
       "      <td>37.51</td>\n",
       "      <td>37.61</td>\n",
       "      <td>160533.19</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600196.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>8.60</td>\n",
       "      <td>8.68</td>\n",
       "      <td>8.30</td>\n",
       "      <td>8.34</td>\n",
       "      <td>36465.88</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600276.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>29.50</td>\n",
       "      <td>29.75</td>\n",
       "      <td>28.40</td>\n",
       "      <td>28.45</td>\n",
       "      <td>11847.13</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600309.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>12.97</td>\n",
       "      <td>13.10</td>\n",
       "      <td>12.45</td>\n",
       "      <td>12.50</td>\n",
       "      <td>96092.38</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600436.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>75.02</td>\n",
       "      <td>75.30</td>\n",
       "      <td>73.00</td>\n",
       "      <td>73.03</td>\n",
       "      <td>3099.31</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600438.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>5.02</td>\n",
       "      <td>5.06</td>\n",
       "      <td>4.84</td>\n",
       "      <td>4.85</td>\n",
       "      <td>17962.70</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600519.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>191.50</td>\n",
       "      <td>192.77</td>\n",
       "      <td>185.00</td>\n",
       "      <td>185.27</td>\n",
       "      <td>33878.28</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600570.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>12.24</td>\n",
       "      <td>12.25</td>\n",
       "      <td>11.46</td>\n",
       "      <td>11.50</td>\n",
       "      <td>18070.26</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600585.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>15.81</td>\n",
       "      <td>15.90</td>\n",
       "      <td>15.27</td>\n",
       "      <td>15.28</td>\n",
       "      <td>207915.93</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600588.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>18.00</td>\n",
       "      <td>18.19</td>\n",
       "      <td>16.88</td>\n",
       "      <td>16.90</td>\n",
       "      <td>25973.70</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600690.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>9.00</td>\n",
       "      <td>9.17</td>\n",
       "      <td>8.78</td>\n",
       "      <td>8.78</td>\n",
       "      <td>142288.41</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600809.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>63.00</td>\n",
       "      <td>63.03</td>\n",
       "      <td>57.36</td>\n",
       "      <td>57.79</td>\n",
       "      <td>28902.50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600837.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>7.51</td>\n",
       "      <td>7.51</td>\n",
       "      <td>7.10</td>\n",
       "      <td>7.12</td>\n",
       "      <td>291690.79</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600887.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>20.59</td>\n",
       "      <td>20.60</td>\n",
       "      <td>19.48</td>\n",
       "      <td>19.73</td>\n",
       "      <td>102000.09</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600893.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>13.77</td>\n",
       "      <td>13.95</td>\n",
       "      <td>13.24</td>\n",
       "      <td>13.29</td>\n",
       "      <td>34955.58</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600900.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>6.36</td>\n",
       "      <td>6.40</td>\n",
       "      <td>6.29</td>\n",
       "      <td>6.29</td>\n",
       "      <td>130363.57</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>601088.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>25.48</td>\n",
       "      <td>25.62</td>\n",
       "      <td>24.45</td>\n",
       "      <td>24.60</td>\n",
       "      <td>121256.25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>601166.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>12.65</td>\n",
       "      <td>12.68</td>\n",
       "      <td>12.48</td>\n",
       "      <td>12.50</td>\n",
       "      <td>405285.47</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>600519.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>1898.62</td>\n",
       "      <td>1901.99</td>\n",
       "      <td>1866.00</td>\n",
       "      <td>1872.50</td>\n",
       "      <td>21289.08</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>600570.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>33.79</td>\n",
       "      <td>34.74</td>\n",
       "      <td>33.60</td>\n",
       "      <td>33.89</td>\n",
       "      <td>101960.81</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>600585.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>28.18</td>\n",
       "      <td>29.15</td>\n",
       "      <td>28.18</td>\n",
       "      <td>28.81</td>\n",
       "      <td>284870.69</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>600588.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>17.71</td>\n",
       "      <td>17.93</td>\n",
       "      <td>17.60</td>\n",
       "      <td>17.60</td>\n",
       "      <td>124403.66</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>600690.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>25.00</td>\n",
       "      <td>25.19</td>\n",
       "      <td>24.65</td>\n",
       "      <td>24.77</td>\n",
       "      <td>267702.88</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>600809.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>309.00</td>\n",
       "      <td>309.80</td>\n",
       "      <td>300.12</td>\n",
       "      <td>302.89</td>\n",
       "      <td>32116.50</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>600837.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>8.51</td>\n",
       "      <td>8.73</td>\n",
       "      <td>8.51</td>\n",
       "      <td>8.66</td>\n",
       "      <td>220874.32</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>600887.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>33.29</td>\n",
       "      <td>33.47</td>\n",
       "      <td>32.93</td>\n",
       "      <td>32.98</td>\n",
       "      <td>264761.80</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>600893.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>43.56</td>\n",
       "      <td>43.64</td>\n",
       "      <td>41.84</td>\n",
       "      <td>41.95</td>\n",
       "      <td>161512.07</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>600900.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>22.40</td>\n",
       "      <td>22.85</td>\n",
       "      <td>22.28</td>\n",
       "      <td>22.74</td>\n",
       "      <td>423324.79</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>601012.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>49.78</td>\n",
       "      <td>50.15</td>\n",
       "      <td>47.80</td>\n",
       "      <td>47.91</td>\n",
       "      <td>682745.27</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>601088.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>31.60</td>\n",
       "      <td>31.92</td>\n",
       "      <td>31.10</td>\n",
       "      <td>31.64</td>\n",
       "      <td>219426.08</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>601166.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>16.57</td>\n",
       "      <td>16.77</td>\n",
       "      <td>16.54</td>\n",
       "      <td>16.65</td>\n",
       "      <td>470496.19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>601288.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2.83</td>\n",
       "      <td>2.86</td>\n",
       "      <td>2.83</td>\n",
       "      <td>2.86</td>\n",
       "      <td>2602100.09</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>601318.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>41.35</td>\n",
       "      <td>41.98</td>\n",
       "      <td>41.35</td>\n",
       "      <td>41.58</td>\n",
       "      <td>331619.40</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>601398.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.36</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.35</td>\n",
       "      <td>1578628.46</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>601601.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>19.83</td>\n",
       "      <td>20.45</td>\n",
       "      <td>19.83</td>\n",
       "      <td>20.33</td>\n",
       "      <td>195189.41</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>601628.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>31.76</td>\n",
       "      <td>32.00</td>\n",
       "      <td>31.16</td>\n",
       "      <td>31.63</td>\n",
       "      <td>111268.85</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>601633.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>28.05</td>\n",
       "      <td>28.35</td>\n",
       "      <td>27.68</td>\n",
       "      <td>27.80</td>\n",
       "      <td>151081.85</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>601668.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>5.03</td>\n",
       "      <td>5.19</td>\n",
       "      <td>5.03</td>\n",
       "      <td>5.15</td>\n",
       "      <td>2186913.38</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>601688.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>12.19</td>\n",
       "      <td>12.29</td>\n",
       "      <td>12.10</td>\n",
       "      <td>12.12</td>\n",
       "      <td>229982.43</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>601857.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>5.08</td>\n",
       "      <td>5.16</td>\n",
       "      <td>5.08</td>\n",
       "      <td>5.13</td>\n",
       "      <td>819572.30</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>601888.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>198.24</td>\n",
       "      <td>200.50</td>\n",
       "      <td>195.71</td>\n",
       "      <td>198.25</td>\n",
       "      <td>80998.33</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>601899.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>7.78</td>\n",
       "      <td>7.92</td>\n",
       "      <td>7.73</td>\n",
       "      <td>7.84</td>\n",
       "      <td>1988575.12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>601919.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>11.00</td>\n",
       "      <td>11.14</td>\n",
       "      <td>10.92</td>\n",
       "      <td>11.02</td>\n",
       "      <td>625792.65</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97902 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            tic        date     open     high      low    close      volume  \\\n",
       "0     600010.SH  2012-01-04     4.15     4.28     4.09     4.15   672559.53   \n",
       "0     600028.SH  2012-01-04     7.28     7.44     7.27     7.36   528181.38   \n",
       "0     600030.SH  2012-01-04     9.79     9.85     9.56     9.56   354005.33   \n",
       "0     600031.SH  2012-01-04    12.61    12.73    12.07    12.09   235312.56   \n",
       "0     600036.SH  2012-01-04    11.95    12.10    11.63    11.67   522606.17   \n",
       "0     600048.SH  2012-01-04    10.01    10.30     9.91    10.05   341555.93   \n",
       "0     600104.SH  2012-01-04    14.28    14.53    13.92    14.16   272418.21   \n",
       "0     600111.SH  2012-01-04    37.90    38.20    37.51    37.61   160533.19   \n",
       "0     600196.SH  2012-01-04     8.60     8.68     8.30     8.34    36465.88   \n",
       "0     600276.SH  2012-01-04    29.50    29.75    28.40    28.45    11847.13   \n",
       "0     600309.SH  2012-01-04    12.97    13.10    12.45    12.50    96092.38   \n",
       "0     600436.SH  2012-01-04    75.02    75.30    73.00    73.03     3099.31   \n",
       "0     600438.SH  2012-01-04     5.02     5.06     4.84     4.85    17962.70   \n",
       "0     600519.SH  2012-01-04   191.50   192.77   185.00   185.27    33878.28   \n",
       "0     600570.SH  2012-01-04    12.24    12.25    11.46    11.50    18070.26   \n",
       "0     600585.SH  2012-01-04    15.81    15.90    15.27    15.28   207915.93   \n",
       "0     600588.SH  2012-01-04    18.00    18.19    16.88    16.90    25973.70   \n",
       "0     600690.SH  2012-01-04     9.00     9.17     8.78     8.78   142288.41   \n",
       "0     600809.SH  2012-01-04    63.00    63.03    57.36    57.79    28902.50   \n",
       "0     600837.SH  2012-01-04     7.51     7.51     7.10     7.12   291690.79   \n",
       "0     600887.SH  2012-01-04    20.59    20.60    19.48    19.73   102000.09   \n",
       "0     600893.SH  2012-01-04    13.77    13.95    13.24    13.29    34955.58   \n",
       "0     600900.SH  2012-01-04     6.36     6.40     6.29     6.29   130363.57   \n",
       "0     601088.SH  2012-01-04    25.48    25.62    24.45    24.60   121256.25   \n",
       "0     601166.SH  2012-01-04    12.65    12.68    12.48    12.50   405285.47   \n",
       "...         ...         ...      ...      ...      ...      ...         ...   \n",
       "2612  600519.SH  2022-09-30  1898.62  1901.99  1866.00  1872.50    21289.08   \n",
       "2612  600570.SH  2022-09-30    33.79    34.74    33.60    33.89   101960.81   \n",
       "2612  600585.SH  2022-09-30    28.18    29.15    28.18    28.81   284870.69   \n",
       "2612  600588.SH  2022-09-30    17.71    17.93    17.60    17.60   124403.66   \n",
       "2612  600690.SH  2022-09-30    25.00    25.19    24.65    24.77   267702.88   \n",
       "2612  600809.SH  2022-09-30   309.00   309.80   300.12   302.89    32116.50   \n",
       "2612  600837.SH  2022-09-30     8.51     8.73     8.51     8.66   220874.32   \n",
       "2612  600887.SH  2022-09-30    33.29    33.47    32.93    32.98   264761.80   \n",
       "2612  600893.SH  2022-09-30    43.56    43.64    41.84    41.95   161512.07   \n",
       "2612  600900.SH  2022-09-30    22.40    22.85    22.28    22.74   423324.79   \n",
       "2612  601012.SH  2022-09-30    49.78    50.15    47.80    47.91   682745.27   \n",
       "2612  601088.SH  2022-09-30    31.60    31.92    31.10    31.64   219426.08   \n",
       "2612  601166.SH  2022-09-30    16.57    16.77    16.54    16.65   470496.19   \n",
       "2612  601288.SH  2022-09-30     2.83     2.86     2.83     2.86  2602100.09   \n",
       "2612  601318.SH  2022-09-30    41.35    41.98    41.35    41.58   331619.40   \n",
       "2612  601398.SH  2022-09-30     4.34     4.36     4.33     4.35  1578628.46   \n",
       "2612  601601.SH  2022-09-30    19.83    20.45    19.83    20.33   195189.41   \n",
       "2612  601628.SH  2022-09-30    31.76    32.00    31.16    31.63   111268.85   \n",
       "2612  601633.SH  2022-09-30    28.05    28.35    27.68    27.80   151081.85   \n",
       "2612  601668.SH  2022-09-30     5.03     5.19     5.03     5.15  2186913.38   \n",
       "2612  601688.SH  2022-09-30    12.19    12.29    12.10    12.12   229982.43   \n",
       "2612  601857.SH  2022-09-30     5.08     5.16     5.08     5.13   819572.30   \n",
       "2612  601888.SH  2022-09-30   198.24   200.50   195.71   198.25    80998.33   \n",
       "2612  601899.SH  2022-09-30     7.78     7.92     7.73     7.84  1988575.12   \n",
       "2612  601919.SH  2022-09-30    11.00    11.14    10.92    11.02   625792.65   \n",
       "\n",
       "      day  \n",
       "0       2  \n",
       "0       2  \n",
       "0       2  \n",
       "0       2  \n",
       "0       2  \n",
       "0       2  \n",
       "0       2  \n",
       "0       2  \n",
       "0       2  \n",
       "0       2  \n",
       "0       2  \n",
       "0       2  \n",
       "0       2  \n",
       "0       2  \n",
       "0       2  \n",
       "0       2  \n",
       "0       2  \n",
       "0       2  \n",
       "0       2  \n",
       "0       2  \n",
       "0       2  \n",
       "0       2  \n",
       "0       2  \n",
       "0       2  \n",
       "0       2  \n",
       "...   ...  \n",
       "2612    4  \n",
       "2612    4  \n",
       "2612    4  \n",
       "2612    4  \n",
       "2612    4  \n",
       "2612    4  \n",
       "2612    4  \n",
       "2612    4  \n",
       "2612    4  \n",
       "2612    4  \n",
       "2612    4  \n",
       "2612    4  \n",
       "2612    4  \n",
       "2612    4  \n",
       "2612    4  \n",
       "2612    4  \n",
       "2612    4  \n",
       "2612    4  \n",
       "2612    4  \n",
       "2612    4  \n",
       "2612    4  \n",
       "2612    4  \n",
       "2612    4  \n",
       "2612    4  \n",
       "2612    4  \n",
       "\n",
       "[97902 rows x 8 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# back fill missing data then front fill\n",
    "df = df.fillna(method = 'bfill').fillna(method = 'ffill')\n",
    "df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e40b006",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T02:27:51.621838Z",
     "start_time": "2022-10-12T02:27:20.606731Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 615
    },
    "id": "3e40b006",
    "outputId": "86eb6231-2bfa-4f04-bd37-9296d88102d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tech_indicator_list:  ['macd', 'boll_ub', 'boll_lb', 'rsi_30', 'cci_30', 'dx_30', 'close_30_sma', 'close_60_sma']\n",
      "indicator:  macd\n",
      "indicator:  boll_ub\n",
      "indicator:  boll_lb\n",
      "indicator:  rsi_30\n",
      "indicator:  cci_30\n",
      "indicator:  dx_30\n",
      "indicator:  close_30_sma\n",
      "indicator:  close_60_sma\n",
      "Succesfully add technical indicators\n",
      "Shape of DataFrame:  (99142, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tic</th>\n",
       "      <th>date</th>\n",
       "      <th>index</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600010.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.31</td>\n",
       "      <td>4.49</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.48</td>\n",
       "      <td>787406.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014165</td>\n",
       "      <td>4.618261</td>\n",
       "      <td>3.916739</td>\n",
       "      <td>88.841714</td>\n",
       "      <td>110.724638</td>\n",
       "      <td>48.821799</td>\n",
       "      <td>4.267500</td>\n",
       "      <td>4.267500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>600028.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.50</td>\n",
       "      <td>7.80</td>\n",
       "      <td>7.41</td>\n",
       "      <td>7.75</td>\n",
       "      <td>743960.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014251</td>\n",
       "      <td>7.846738</td>\n",
       "      <td>7.158262</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>133.333333</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>7.502500</td>\n",
       "      <td>7.502500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>600030.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.36</td>\n",
       "      <td>9.79</td>\n",
       "      <td>9.26</td>\n",
       "      <td>9.75</td>\n",
       "      <td>623061.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009148</td>\n",
       "      <td>9.901274</td>\n",
       "      <td>9.093726</td>\n",
       "      <td>64.412995</td>\n",
       "      <td>53.333333</td>\n",
       "      <td>12.698092</td>\n",
       "      <td>9.497500</td>\n",
       "      <td>9.497500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>600031.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.11</td>\n",
       "      <td>12.58</td>\n",
       "      <td>11.94</td>\n",
       "      <td>12.55</td>\n",
       "      <td>245945.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016771</td>\n",
       "      <td>12.670833</td>\n",
       "      <td>11.709167</td>\n",
       "      <td>94.588508</td>\n",
       "      <td>80.380952</td>\n",
       "      <td>26.343026</td>\n",
       "      <td>12.190000</td>\n",
       "      <td>12.190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>600036.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.98</td>\n",
       "      <td>12.50</td>\n",
       "      <td>11.90</td>\n",
       "      <td>12.38</td>\n",
       "      <td>960020.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024994</td>\n",
       "      <td>12.577274</td>\n",
       "      <td>11.397726</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>133.333333</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>11.987500</td>\n",
       "      <td>11.987500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>600048.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.66</td>\n",
       "      <td>10.21</td>\n",
       "      <td>9.56</td>\n",
       "      <td>10.17</td>\n",
       "      <td>469341.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004945</td>\n",
       "      <td>10.360324</td>\n",
       "      <td>9.504676</td>\n",
       "      <td>58.928190</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>3.558436</td>\n",
       "      <td>9.932500</td>\n",
       "      <td>9.932500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>600104.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.21</td>\n",
       "      <td>14.95</td>\n",
       "      <td>14.06</td>\n",
       "      <td>14.90</td>\n",
       "      <td>356606.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023904</td>\n",
       "      <td>15.092770</td>\n",
       "      <td>13.732230</td>\n",
       "      <td>83.281583</td>\n",
       "      <td>131.360947</td>\n",
       "      <td>43.366115</td>\n",
       "      <td>14.412500</td>\n",
       "      <td>14.412500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>600111.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>36.33</td>\n",
       "      <td>39.40</td>\n",
       "      <td>35.78</td>\n",
       "      <td>39.02</td>\n",
       "      <td>263676.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.067193</td>\n",
       "      <td>40.131340</td>\n",
       "      <td>34.163660</td>\n",
       "      <td>64.586597</td>\n",
       "      <td>77.199282</td>\n",
       "      <td>7.583484</td>\n",
       "      <td>37.147500</td>\n",
       "      <td>37.147500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>600196.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.10</td>\n",
       "      <td>8.35</td>\n",
       "      <td>8.04</td>\n",
       "      <td>8.34</td>\n",
       "      <td>62208.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000915</td>\n",
       "      <td>8.497653</td>\n",
       "      <td>8.007347</td>\n",
       "      <td>51.137481</td>\n",
       "      <td>-14.245014</td>\n",
       "      <td>49.001351</td>\n",
       "      <td>8.252500</td>\n",
       "      <td>8.252500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>600276.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>26.65</td>\n",
       "      <td>27.50</td>\n",
       "      <td>25.60</td>\n",
       "      <td>27.40</td>\n",
       "      <td>43085.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.033764</td>\n",
       "      <td>28.972755</td>\n",
       "      <td>25.727245</td>\n",
       "      <td>32.197647</td>\n",
       "      <td>-56.144438</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.350000</td>\n",
       "      <td>27.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>600309.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.08</td>\n",
       "      <td>12.50</td>\n",
       "      <td>11.84</td>\n",
       "      <td>12.47</td>\n",
       "      <td>151864.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000755</td>\n",
       "      <td>12.751932</td>\n",
       "      <td>11.813068</td>\n",
       "      <td>49.851392</td>\n",
       "      <td>-10.122921</td>\n",
       "      <td>35.172834</td>\n",
       "      <td>12.282500</td>\n",
       "      <td>12.282500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>600436.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>70.08</td>\n",
       "      <td>70.60</td>\n",
       "      <td>68.89</td>\n",
       "      <td>70.10</td>\n",
       "      <td>10927.68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.095540</td>\n",
       "      <td>73.757406</td>\n",
       "      <td>68.097594</td>\n",
       "      <td>0.716809</td>\n",
       "      <td>-61.967145</td>\n",
       "      <td>95.185322</td>\n",
       "      <td>70.927500</td>\n",
       "      <td>70.927500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>600438.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.73</td>\n",
       "      <td>4.91</td>\n",
       "      <td>4.66</td>\n",
       "      <td>4.89</td>\n",
       "      <td>24346.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002969</td>\n",
       "      <td>4.996025</td>\n",
       "      <td>4.563975</td>\n",
       "      <td>56.220718</td>\n",
       "      <td>30.529595</td>\n",
       "      <td>11.732573</td>\n",
       "      <td>4.780000</td>\n",
       "      <td>4.780000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>600519.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>186.00</td>\n",
       "      <td>188.09</td>\n",
       "      <td>181.77</td>\n",
       "      <td>188.01</td>\n",
       "      <td>26160.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.139206</td>\n",
       "      <td>189.913000</td>\n",
       "      <td>181.622000</td>\n",
       "      <td>70.541058</td>\n",
       "      <td>16.931217</td>\n",
       "      <td>7.889720</td>\n",
       "      <td>185.767500</td>\n",
       "      <td>185.767500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>600570.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.72</td>\n",
       "      <td>11.03</td>\n",
       "      <td>10.66</td>\n",
       "      <td>11.00</td>\n",
       "      <td>15365.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.013964</td>\n",
       "      <td>11.737500</td>\n",
       "      <td>10.197500</td>\n",
       "      <td>29.822271</td>\n",
       "      <td>-24.598512</td>\n",
       "      <td>57.180821</td>\n",
       "      <td>10.967500</td>\n",
       "      <td>10.967500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>600585.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.82</td>\n",
       "      <td>15.60</td>\n",
       "      <td>14.56</td>\n",
       "      <td>15.55</td>\n",
       "      <td>311506.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010049</td>\n",
       "      <td>15.857297</td>\n",
       "      <td>14.377703</td>\n",
       "      <td>61.041381</td>\n",
       "      <td>33.106576</td>\n",
       "      <td>15.199647</td>\n",
       "      <td>15.117500</td>\n",
       "      <td>15.117500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>600588.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.23</td>\n",
       "      <td>16.62</td>\n",
       "      <td>15.66</td>\n",
       "      <td>16.58</td>\n",
       "      <td>48522.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.011340</td>\n",
       "      <td>17.102087</td>\n",
       "      <td>15.992913</td>\n",
       "      <td>35.564287</td>\n",
       "      <td>-32.037222</td>\n",
       "      <td>66.698547</td>\n",
       "      <td>16.547500</td>\n",
       "      <td>16.547500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>600690.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.88</td>\n",
       "      <td>9.10</td>\n",
       "      <td>8.68</td>\n",
       "      <td>9.07</td>\n",
       "      <td>160606.42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011236</td>\n",
       "      <td>9.150342</td>\n",
       "      <td>8.534658</td>\n",
       "      <td>87.855596</td>\n",
       "      <td>80.341880</td>\n",
       "      <td>9.531850</td>\n",
       "      <td>8.842500</td>\n",
       "      <td>8.842500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>600809.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>53.70</td>\n",
       "      <td>54.60</td>\n",
       "      <td>52.78</td>\n",
       "      <td>54.59</td>\n",
       "      <td>28933.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.111768</td>\n",
       "      <td>58.810558</td>\n",
       "      <td>51.744442</td>\n",
       "      <td>18.849264</td>\n",
       "      <td>-62.041431</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>55.277500</td>\n",
       "      <td>55.277500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>600837.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.30</td>\n",
       "      <td>7.64</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.62</td>\n",
       "      <td>642922.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020084</td>\n",
       "      <td>7.772070</td>\n",
       "      <td>6.787930</td>\n",
       "      <td>93.443006</td>\n",
       "      <td>133.333333</td>\n",
       "      <td>79.566052</td>\n",
       "      <td>7.280000</td>\n",
       "      <td>7.280000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>600887.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19.67</td>\n",
       "      <td>20.20</td>\n",
       "      <td>19.08</td>\n",
       "      <td>20.13</td>\n",
       "      <td>118868.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019332</td>\n",
       "      <td>20.369437</td>\n",
       "      <td>19.055563</td>\n",
       "      <td>67.854754</td>\n",
       "      <td>46.840149</td>\n",
       "      <td>6.659267</td>\n",
       "      <td>19.712500</td>\n",
       "      <td>19.712500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>600893.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.92</td>\n",
       "      <td>13.46</td>\n",
       "      <td>12.74</td>\n",
       "      <td>13.39</td>\n",
       "      <td>43936.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009417</td>\n",
       "      <td>13.739108</td>\n",
       "      <td>12.405892</td>\n",
       "      <td>55.027883</td>\n",
       "      <td>26.845638</td>\n",
       "      <td>27.847554</td>\n",
       "      <td>13.072500</td>\n",
       "      <td>13.072500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>600900.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.22</td>\n",
       "      <td>6.30</td>\n",
       "      <td>6.17</td>\n",
       "      <td>6.29</td>\n",
       "      <td>203893.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>6.331181</td>\n",
       "      <td>6.188819</td>\n",
       "      <td>51.449571</td>\n",
       "      <td>-31.924883</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>6.260000</td>\n",
       "      <td>6.260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>601012.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>63.0</td>\n",
       "      <td>19.30</td>\n",
       "      <td>19.60</td>\n",
       "      <td>19.15</td>\n",
       "      <td>19.47</td>\n",
       "      <td>83715.18</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.006282</td>\n",
       "      <td>20.005980</td>\n",
       "      <td>19.214020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>19.610000</td>\n",
       "      <td>19.610000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>601088.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24.29</td>\n",
       "      <td>26.06</td>\n",
       "      <td>24.12</td>\n",
       "      <td>26.01</td>\n",
       "      <td>304669.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052423</td>\n",
       "      <td>26.443712</td>\n",
       "      <td>23.141288</td>\n",
       "      <td>84.919012</td>\n",
       "      <td>109.787234</td>\n",
       "      <td>66.693781</td>\n",
       "      <td>24.792500</td>\n",
       "      <td>24.792500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99117</th>\n",
       "      <td>600519.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>1898.62</td>\n",
       "      <td>1901.99</td>\n",
       "      <td>1866.00</td>\n",
       "      <td>1872.50</td>\n",
       "      <td>21289.08</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-3.205584</td>\n",
       "      <td>1905.084788</td>\n",
       "      <td>1810.868212</td>\n",
       "      <td>49.210286</td>\n",
       "      <td>43.354556</td>\n",
       "      <td>4.610511</td>\n",
       "      <td>1866.981333</td>\n",
       "      <td>1896.708500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99118</th>\n",
       "      <td>600570.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>33.79</td>\n",
       "      <td>34.74</td>\n",
       "      <td>33.60</td>\n",
       "      <td>33.89</td>\n",
       "      <td>101960.81</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.768929</td>\n",
       "      <td>36.239658</td>\n",
       "      <td>31.554342</td>\n",
       "      <td>44.196982</td>\n",
       "      <td>45.034429</td>\n",
       "      <td>8.461160</td>\n",
       "      <td>33.301667</td>\n",
       "      <td>37.428833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99119</th>\n",
       "      <td>600585.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>28.18</td>\n",
       "      <td>29.15</td>\n",
       "      <td>28.18</td>\n",
       "      <td>28.81</td>\n",
       "      <td>284870.69</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.951232</td>\n",
       "      <td>32.768742</td>\n",
       "      <td>27.320258</td>\n",
       "      <td>39.227171</td>\n",
       "      <td>-112.192998</td>\n",
       "      <td>23.395967</td>\n",
       "      <td>30.577000</td>\n",
       "      <td>31.911167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99120</th>\n",
       "      <td>600588.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>17.71</td>\n",
       "      <td>17.93</td>\n",
       "      <td>17.60</td>\n",
       "      <td>17.60</td>\n",
       "      <td>124403.66</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.686902</td>\n",
       "      <td>20.564209</td>\n",
       "      <td>17.092791</td>\n",
       "      <td>39.883637</td>\n",
       "      <td>-127.830776</td>\n",
       "      <td>23.497526</td>\n",
       "      <td>19.364000</td>\n",
       "      <td>20.070667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99121</th>\n",
       "      <td>600690.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>25.00</td>\n",
       "      <td>25.19</td>\n",
       "      <td>24.65</td>\n",
       "      <td>24.77</td>\n",
       "      <td>267702.88</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.032207</td>\n",
       "      <td>27.002850</td>\n",
       "      <td>24.280150</td>\n",
       "      <td>47.955669</td>\n",
       "      <td>-46.280992</td>\n",
       "      <td>8.286352</td>\n",
       "      <td>25.364667</td>\n",
       "      <td>24.991000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99122</th>\n",
       "      <td>600809.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>309.00</td>\n",
       "      <td>309.80</td>\n",
       "      <td>300.12</td>\n",
       "      <td>302.89</td>\n",
       "      <td>32116.50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.770177</td>\n",
       "      <td>309.269051</td>\n",
       "      <td>277.852949</td>\n",
       "      <td>56.490877</td>\n",
       "      <td>118.397397</td>\n",
       "      <td>35.043245</td>\n",
       "      <td>288.141333</td>\n",
       "      <td>285.021333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99123</th>\n",
       "      <td>600837.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>8.51</td>\n",
       "      <td>8.73</td>\n",
       "      <td>8.51</td>\n",
       "      <td>8.66</td>\n",
       "      <td>220874.32</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.182558</td>\n",
       "      <td>9.760406</td>\n",
       "      <td>8.598594</td>\n",
       "      <td>36.582080</td>\n",
       "      <td>-194.604245</td>\n",
       "      <td>55.336652</td>\n",
       "      <td>9.272333</td>\n",
       "      <td>9.353333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99124</th>\n",
       "      <td>600887.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>33.29</td>\n",
       "      <td>33.47</td>\n",
       "      <td>32.93</td>\n",
       "      <td>32.98</td>\n",
       "      <td>264761.80</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.588198</td>\n",
       "      <td>34.189506</td>\n",
       "      <td>32.071494</td>\n",
       "      <td>40.677415</td>\n",
       "      <td>-51.402939</td>\n",
       "      <td>12.827832</td>\n",
       "      <td>33.973667</td>\n",
       "      <td>35.066833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99125</th>\n",
       "      <td>600893.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>43.56</td>\n",
       "      <td>43.64</td>\n",
       "      <td>41.84</td>\n",
       "      <td>41.95</td>\n",
       "      <td>161512.07</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.371672</td>\n",
       "      <td>49.830794</td>\n",
       "      <td>42.613206</td>\n",
       "      <td>40.822531</td>\n",
       "      <td>-203.113753</td>\n",
       "      <td>31.939610</td>\n",
       "      <td>46.967333</td>\n",
       "      <td>49.416500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99126</th>\n",
       "      <td>600900.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>22.40</td>\n",
       "      <td>22.85</td>\n",
       "      <td>22.28</td>\n",
       "      <td>22.74</td>\n",
       "      <td>423324.79</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.283151</td>\n",
       "      <td>24.311465</td>\n",
       "      <td>22.450535</td>\n",
       "      <td>42.647592</td>\n",
       "      <td>-185.556412</td>\n",
       "      <td>34.433872</td>\n",
       "      <td>23.417667</td>\n",
       "      <td>23.789333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99127</th>\n",
       "      <td>601012.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>49.78</td>\n",
       "      <td>50.15</td>\n",
       "      <td>47.80</td>\n",
       "      <td>47.91</td>\n",
       "      <td>682745.27</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.728189</td>\n",
       "      <td>54.486358</td>\n",
       "      <td>46.129642</td>\n",
       "      <td>38.786281</td>\n",
       "      <td>-94.845268</td>\n",
       "      <td>35.806177</td>\n",
       "      <td>51.251333</td>\n",
       "      <td>55.487333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99128</th>\n",
       "      <td>601088.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>31.60</td>\n",
       "      <td>31.92</td>\n",
       "      <td>31.10</td>\n",
       "      <td>31.64</td>\n",
       "      <td>219426.08</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.096078</td>\n",
       "      <td>33.327838</td>\n",
       "      <td>30.026162</td>\n",
       "      <td>52.556566</td>\n",
       "      <td>16.859864</td>\n",
       "      <td>10.223676</td>\n",
       "      <td>31.409333</td>\n",
       "      <td>30.179500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99129</th>\n",
       "      <td>601166.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>16.57</td>\n",
       "      <td>16.77</td>\n",
       "      <td>16.54</td>\n",
       "      <td>16.65</td>\n",
       "      <td>470496.19</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.215111</td>\n",
       "      <td>17.677171</td>\n",
       "      <td>16.506829</td>\n",
       "      <td>41.092287</td>\n",
       "      <td>-130.421549</td>\n",
       "      <td>21.408923</td>\n",
       "      <td>17.211333</td>\n",
       "      <td>17.523000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99130</th>\n",
       "      <td>601288.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>2.83</td>\n",
       "      <td>2.86</td>\n",
       "      <td>2.83</td>\n",
       "      <td>2.86</td>\n",
       "      <td>2602100.09</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>2.879206</td>\n",
       "      <td>2.815794</td>\n",
       "      <td>49.061725</td>\n",
       "      <td>44.937429</td>\n",
       "      <td>19.468989</td>\n",
       "      <td>2.840333</td>\n",
       "      <td>2.852167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99131</th>\n",
       "      <td>601318.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>41.35</td>\n",
       "      <td>41.98</td>\n",
       "      <td>41.35</td>\n",
       "      <td>41.58</td>\n",
       "      <td>331619.40</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.306936</td>\n",
       "      <td>45.584692</td>\n",
       "      <td>41.195308</td>\n",
       "      <td>43.493820</td>\n",
       "      <td>-103.476775</td>\n",
       "      <td>14.614106</td>\n",
       "      <td>43.064000</td>\n",
       "      <td>42.768500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99132</th>\n",
       "      <td>601398.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.36</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.35</td>\n",
       "      <td>1578628.46</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.006202</td>\n",
       "      <td>4.398556</td>\n",
       "      <td>4.326444</td>\n",
       "      <td>44.834511</td>\n",
       "      <td>-39.017341</td>\n",
       "      <td>4.027457</td>\n",
       "      <td>4.355667</td>\n",
       "      <td>4.379167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99133</th>\n",
       "      <td>601601.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>19.83</td>\n",
       "      <td>20.45</td>\n",
       "      <td>19.83</td>\n",
       "      <td>20.33</td>\n",
       "      <td>195189.41</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.136296</td>\n",
       "      <td>21.714986</td>\n",
       "      <td>19.552014</td>\n",
       "      <td>47.205933</td>\n",
       "      <td>-43.289347</td>\n",
       "      <td>3.763124</td>\n",
       "      <td>20.489333</td>\n",
       "      <td>20.457833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99134</th>\n",
       "      <td>601628.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>31.76</td>\n",
       "      <td>32.00</td>\n",
       "      <td>31.16</td>\n",
       "      <td>31.63</td>\n",
       "      <td>111268.85</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.620124</td>\n",
       "      <td>32.273866</td>\n",
       "      <td>29.367134</td>\n",
       "      <td>59.040332</td>\n",
       "      <td>94.651333</td>\n",
       "      <td>30.245425</td>\n",
       "      <td>30.140667</td>\n",
       "      <td>28.998000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99135</th>\n",
       "      <td>601633.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>28.05</td>\n",
       "      <td>28.35</td>\n",
       "      <td>27.68</td>\n",
       "      <td>27.80</td>\n",
       "      <td>151081.85</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.220938</td>\n",
       "      <td>33.000132</td>\n",
       "      <td>27.071868</td>\n",
       "      <td>40.762729</td>\n",
       "      <td>-126.327626</td>\n",
       "      <td>38.764325</td>\n",
       "      <td>31.231667</td>\n",
       "      <td>32.385000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99136</th>\n",
       "      <td>601668.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>5.03</td>\n",
       "      <td>5.19</td>\n",
       "      <td>5.03</td>\n",
       "      <td>5.15</td>\n",
       "      <td>2186913.38</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.000079</td>\n",
       "      <td>5.374797</td>\n",
       "      <td>5.009203</td>\n",
       "      <td>49.362609</td>\n",
       "      <td>-8.448348</td>\n",
       "      <td>0.267188</td>\n",
       "      <td>5.138000</td>\n",
       "      <td>5.123167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99137</th>\n",
       "      <td>601688.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>12.19</td>\n",
       "      <td>12.29</td>\n",
       "      <td>12.10</td>\n",
       "      <td>12.12</td>\n",
       "      <td>229982.43</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.249653</td>\n",
       "      <td>13.538437</td>\n",
       "      <td>11.806563</td>\n",
       "      <td>36.813250</td>\n",
       "      <td>-122.198506</td>\n",
       "      <td>44.061683</td>\n",
       "      <td>12.812000</td>\n",
       "      <td>13.004333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99138</th>\n",
       "      <td>601857.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>5.08</td>\n",
       "      <td>5.16</td>\n",
       "      <td>5.08</td>\n",
       "      <td>5.13</td>\n",
       "      <td>819572.30</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.062860</td>\n",
       "      <td>5.755721</td>\n",
       "      <td>4.975279</td>\n",
       "      <td>45.564208</td>\n",
       "      <td>-113.679847</td>\n",
       "      <td>11.212406</td>\n",
       "      <td>5.364333</td>\n",
       "      <td>5.258000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99139</th>\n",
       "      <td>601888.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>198.24</td>\n",
       "      <td>200.50</td>\n",
       "      <td>195.71</td>\n",
       "      <td>198.25</td>\n",
       "      <td>80998.33</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.330810</td>\n",
       "      <td>203.420184</td>\n",
       "      <td>176.951816</td>\n",
       "      <td>51.954585</td>\n",
       "      <td>129.238562</td>\n",
       "      <td>17.738487</td>\n",
       "      <td>190.593667</td>\n",
       "      <td>197.692000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99140</th>\n",
       "      <td>601899.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>7.78</td>\n",
       "      <td>7.92</td>\n",
       "      <td>7.73</td>\n",
       "      <td>7.84</td>\n",
       "      <td>1988575.12</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.303164</td>\n",
       "      <td>9.603624</td>\n",
       "      <td>7.492376</td>\n",
       "      <td>38.868903</td>\n",
       "      <td>-169.989876</td>\n",
       "      <td>41.678620</td>\n",
       "      <td>8.679333</td>\n",
       "      <td>8.751333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99141</th>\n",
       "      <td>601919.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>11.00</td>\n",
       "      <td>11.14</td>\n",
       "      <td>10.92</td>\n",
       "      <td>11.02</td>\n",
       "      <td>625792.65</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.651301</td>\n",
       "      <td>14.200318</td>\n",
       "      <td>10.656682</td>\n",
       "      <td>32.953801</td>\n",
       "      <td>-154.242342</td>\n",
       "      <td>49.177082</td>\n",
       "      <td>12.898333</td>\n",
       "      <td>13.367333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99142 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             tic        date   index     open     high      low    close  \\\n",
       "0      600010.SH  2012-01-09     3.0     4.31     4.49     4.23     4.48   \n",
       "1      600028.SH  2012-01-09     3.0     7.50     7.80     7.41     7.75   \n",
       "2      600030.SH  2012-01-09     3.0     9.36     9.79     9.26     9.75   \n",
       "3      600031.SH  2012-01-09     3.0    12.11    12.58    11.94    12.55   \n",
       "4      600036.SH  2012-01-09     3.0    11.98    12.50    11.90    12.38   \n",
       "5      600048.SH  2012-01-09     3.0     9.66    10.21     9.56    10.17   \n",
       "6      600104.SH  2012-01-09     3.0    14.21    14.95    14.06    14.90   \n",
       "7      600111.SH  2012-01-09     3.0    36.33    39.40    35.78    39.02   \n",
       "8      600196.SH  2012-01-09     3.0     8.10     8.35     8.04     8.34   \n",
       "9      600276.SH  2012-01-09     3.0    26.65    27.50    25.60    27.40   \n",
       "10     600309.SH  2012-01-09     3.0    12.08    12.50    11.84    12.47   \n",
       "11     600436.SH  2012-01-09     3.0    70.08    70.60    68.89    70.10   \n",
       "12     600438.SH  2012-01-09     3.0     4.73     4.91     4.66     4.89   \n",
       "13     600519.SH  2012-01-09     3.0   186.00   188.09   181.77   188.01   \n",
       "14     600570.SH  2012-01-09     3.0    10.72    11.03    10.66    11.00   \n",
       "15     600585.SH  2012-01-09     3.0    14.82    15.60    14.56    15.55   \n",
       "16     600588.SH  2012-01-09     3.0    16.23    16.62    15.66    16.58   \n",
       "17     600690.SH  2012-01-09     3.0     8.88     9.10     8.68     9.07   \n",
       "18     600809.SH  2012-01-09     3.0    53.70    54.60    52.78    54.59   \n",
       "19     600837.SH  2012-01-09     3.0     7.30     7.64     7.24     7.62   \n",
       "20     600887.SH  2012-01-09     3.0    19.67    20.20    19.08    20.13   \n",
       "21     600893.SH  2012-01-09     3.0    12.92    13.46    12.74    13.39   \n",
       "22     600900.SH  2012-01-09     3.0     6.22     6.30     6.17     6.29   \n",
       "23     601012.SH  2012-01-09    63.0    19.30    19.60    19.15    19.47   \n",
       "24     601088.SH  2012-01-09     3.0    24.29    26.06    24.12    26.01   \n",
       "...          ...         ...     ...      ...      ...      ...      ...   \n",
       "99117  600519.SH  2022-09-30  2612.0  1898.62  1901.99  1866.00  1872.50   \n",
       "99118  600570.SH  2022-09-30  2612.0    33.79    34.74    33.60    33.89   \n",
       "99119  600585.SH  2022-09-30  2612.0    28.18    29.15    28.18    28.81   \n",
       "99120  600588.SH  2022-09-30  2612.0    17.71    17.93    17.60    17.60   \n",
       "99121  600690.SH  2022-09-30  2612.0    25.00    25.19    24.65    24.77   \n",
       "99122  600809.SH  2022-09-30  2612.0   309.00   309.80   300.12   302.89   \n",
       "99123  600837.SH  2022-09-30  2612.0     8.51     8.73     8.51     8.66   \n",
       "99124  600887.SH  2022-09-30  2612.0    33.29    33.47    32.93    32.98   \n",
       "99125  600893.SH  2022-09-30  2612.0    43.56    43.64    41.84    41.95   \n",
       "99126  600900.SH  2022-09-30  2612.0    22.40    22.85    22.28    22.74   \n",
       "99127  601012.SH  2022-09-30  2612.0    49.78    50.15    47.80    47.91   \n",
       "99128  601088.SH  2022-09-30  2612.0    31.60    31.92    31.10    31.64   \n",
       "99129  601166.SH  2022-09-30  2612.0    16.57    16.77    16.54    16.65   \n",
       "99130  601288.SH  2022-09-30  2612.0     2.83     2.86     2.83     2.86   \n",
       "99131  601318.SH  2022-09-30  2612.0    41.35    41.98    41.35    41.58   \n",
       "99132  601398.SH  2022-09-30  2612.0     4.34     4.36     4.33     4.35   \n",
       "99133  601601.SH  2022-09-30  2612.0    19.83    20.45    19.83    20.33   \n",
       "99134  601628.SH  2022-09-30  2612.0    31.76    32.00    31.16    31.63   \n",
       "99135  601633.SH  2022-09-30  2612.0    28.05    28.35    27.68    27.80   \n",
       "99136  601668.SH  2022-09-30  2612.0     5.03     5.19     5.03     5.15   \n",
       "99137  601688.SH  2022-09-30  2612.0    12.19    12.29    12.10    12.12   \n",
       "99138  601857.SH  2022-09-30  2612.0     5.08     5.16     5.08     5.13   \n",
       "99139  601888.SH  2022-09-30  2612.0   198.24   200.50   195.71   198.25   \n",
       "99140  601899.SH  2022-09-30  2612.0     7.78     7.92     7.73     7.84   \n",
       "99141  601919.SH  2022-09-30  2612.0    11.00    11.14    10.92    11.02   \n",
       "\n",
       "           volume  day      macd      boll_ub      boll_lb      rsi_30  \\\n",
       "0       787406.46  0.0  0.014165     4.618261     3.916739   88.841714   \n",
       "1       743960.15  0.0  0.014251     7.846738     7.158262  100.000000   \n",
       "2       623061.16  0.0  0.009148     9.901274     9.093726   64.412995   \n",
       "3       245945.25  0.0  0.016771    12.670833    11.709167   94.588508   \n",
       "4       960020.09  0.0  0.024994    12.577274    11.397726  100.000000   \n",
       "5       469341.00  0.0  0.004945    10.360324     9.504676   58.928190   \n",
       "6       356606.32  0.0  0.023904    15.092770    13.732230   83.281583   \n",
       "7       263676.19  0.0  0.067193    40.131340    34.163660   64.586597   \n",
       "8        62208.12  0.0 -0.000915     8.497653     8.007347   51.137481   \n",
       "9        43085.35  0.0 -0.033764    28.972755    25.727245   32.197647   \n",
       "10      151864.28  0.0  0.000755    12.751932    11.813068   49.851392   \n",
       "11       10927.68  0.0 -0.095540    73.757406    68.097594    0.716809   \n",
       "12       24346.27  0.0  0.002969     4.996025     4.563975   56.220718   \n",
       "13       26160.16  0.0  0.139206   189.913000   181.622000   70.541058   \n",
       "14       15365.29  0.0 -0.013964    11.737500    10.197500   29.822271   \n",
       "15      311506.05  0.0  0.010049    15.857297    14.377703   61.041381   \n",
       "16       48522.89  0.0 -0.011340    17.102087    15.992913   35.564287   \n",
       "17      160606.42  0.0  0.011236     9.150342     8.534658   87.855596   \n",
       "18       28933.49  0.0 -0.111768    58.810558    51.744442   18.849264   \n",
       "19      642922.60  0.0  0.020084     7.772070     6.787930   93.443006   \n",
       "20      118868.14  0.0  0.019332    20.369437    19.055563   67.854754   \n",
       "21       43936.61  0.0  0.009417    13.739108    12.405892   55.027883   \n",
       "22      203893.30  0.0  0.000106     6.331181     6.188819   51.449571   \n",
       "23       83715.18  3.0 -0.006282    20.005980    19.214020    0.000000   \n",
       "24      304669.62  0.0  0.052423    26.443712    23.141288   84.919012   \n",
       "...           ...  ...       ...          ...          ...         ...   \n",
       "99117    21289.08  4.0 -3.205584  1905.084788  1810.868212   49.210286   \n",
       "99118   101960.81  4.0 -0.768929    36.239658    31.554342   44.196982   \n",
       "99119   284870.69  4.0 -0.951232    32.768742    27.320258   39.227171   \n",
       "99120   124403.66  4.0 -0.686902    20.564209    17.092791   39.883637   \n",
       "99121   267702.88  4.0 -0.032207    27.002850    24.280150   47.955669   \n",
       "99122    32116.50  4.0  5.770177   309.269051   277.852949   56.490877   \n",
       "99123   220874.32  4.0 -0.182558     9.760406     8.598594   36.582080   \n",
       "99124   264761.80  4.0 -0.588198    34.189506    32.071494   40.677415   \n",
       "99125   161512.07  4.0 -1.371672    49.830794    42.613206   40.822531   \n",
       "99126   423324.79  4.0 -0.283151    24.311465    22.450535   42.647592   \n",
       "99127   682745.27  4.0 -1.728189    54.486358    46.129642   38.786281   \n",
       "99128   219426.08  4.0  0.096078    33.327838    30.026162   52.556566   \n",
       "99129   470496.19  4.0 -0.215111    17.677171    16.506829   41.092287   \n",
       "99130  2602100.09  4.0  0.000538     2.879206     2.815794   49.061725   \n",
       "99131   331619.40  4.0 -0.306936    45.584692    41.195308   43.493820   \n",
       "99132  1578628.46  4.0 -0.006202     4.398556     4.326444   44.834511   \n",
       "99133   195189.41  4.0 -0.136296    21.714986    19.552014   47.205933   \n",
       "99134   111268.85  4.0  0.620124    32.273866    29.367134   59.040332   \n",
       "99135   151081.85  4.0 -1.220938    33.000132    27.071868   40.762729   \n",
       "99136  2186913.38  4.0 -0.000079     5.374797     5.009203   49.362609   \n",
       "99137   229982.43  4.0 -0.249653    13.538437    11.806563   36.813250   \n",
       "99138   819572.30  4.0 -0.062860     5.755721     4.975279   45.564208   \n",
       "99139    80998.33  4.0  1.330810   203.420184   176.951816   51.954585   \n",
       "99140  1988575.12  4.0 -0.303164     9.603624     7.492376   38.868903   \n",
       "99141   625792.65  4.0 -0.651301    14.200318    10.656682   32.953801   \n",
       "\n",
       "           cci_30       dx_30  close_30_sma  close_60_sma  \n",
       "0      110.724638   48.821799      4.267500      4.267500  \n",
       "1      133.333333  100.000000      7.502500      7.502500  \n",
       "2       53.333333   12.698092      9.497500      9.497500  \n",
       "3       80.380952   26.343026     12.190000     12.190000  \n",
       "4      133.333333  100.000000     11.987500     11.987500  \n",
       "5       40.000000    3.558436      9.932500      9.932500  \n",
       "6      131.360947   43.366115     14.412500     14.412500  \n",
       "7       77.199282    7.583484     37.147500     37.147500  \n",
       "8      -14.245014   49.001351      8.252500      8.252500  \n",
       "9      -56.144438  100.000000     27.350000     27.350000  \n",
       "10     -10.122921   35.172834     12.282500     12.282500  \n",
       "11     -61.967145   95.185322     70.927500     70.927500  \n",
       "12      30.529595   11.732573      4.780000      4.780000  \n",
       "13      16.931217    7.889720    185.767500    185.767500  \n",
       "14     -24.598512   57.180821     10.967500     10.967500  \n",
       "15      33.106576   15.199647     15.117500     15.117500  \n",
       "16     -32.037222   66.698547     16.547500     16.547500  \n",
       "17      80.341880    9.531850      8.842500      8.842500  \n",
       "18     -62.041431  100.000000     55.277500     55.277500  \n",
       "19     133.333333   79.566052      7.280000      7.280000  \n",
       "20      46.840149    6.659267     19.712500     19.712500  \n",
       "21      26.845638   27.847554     13.072500     13.072500  \n",
       "22     -31.924883  100.000000      6.260000      6.260000  \n",
       "23     -66.666667  100.000000     19.610000     19.610000  \n",
       "24     109.787234   66.693781     24.792500     24.792500  \n",
       "...           ...         ...           ...           ...  \n",
       "99117   43.354556    4.610511   1866.981333   1896.708500  \n",
       "99118   45.034429    8.461160     33.301667     37.428833  \n",
       "99119 -112.192998   23.395967     30.577000     31.911167  \n",
       "99120 -127.830776   23.497526     19.364000     20.070667  \n",
       "99121  -46.280992    8.286352     25.364667     24.991000  \n",
       "99122  118.397397   35.043245    288.141333    285.021333  \n",
       "99123 -194.604245   55.336652      9.272333      9.353333  \n",
       "99124  -51.402939   12.827832     33.973667     35.066833  \n",
       "99125 -203.113753   31.939610     46.967333     49.416500  \n",
       "99126 -185.556412   34.433872     23.417667     23.789333  \n",
       "99127  -94.845268   35.806177     51.251333     55.487333  \n",
       "99128   16.859864   10.223676     31.409333     30.179500  \n",
       "99129 -130.421549   21.408923     17.211333     17.523000  \n",
       "99130   44.937429   19.468989      2.840333      2.852167  \n",
       "99131 -103.476775   14.614106     43.064000     42.768500  \n",
       "99132  -39.017341    4.027457      4.355667      4.379167  \n",
       "99133  -43.289347    3.763124     20.489333     20.457833  \n",
       "99134   94.651333   30.245425     30.140667     28.998000  \n",
       "99135 -126.327626   38.764325     31.231667     32.385000  \n",
       "99136   -8.448348    0.267188      5.138000      5.123167  \n",
       "99137 -122.198506   44.061683     12.812000     13.004333  \n",
       "99138 -113.679847   11.212406      5.364333      5.258000  \n",
       "99139  129.238562   17.738487    190.593667    197.692000  \n",
       "99140 -169.989876   41.678620      8.679333      8.751333  \n",
       "99141 -154.242342   49.177082     12.898333     13.367333  \n",
       "\n",
       "[99142 rows x 17 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add_technical_indicator\n",
    "ts_processor.dataframe = df\n",
    "ts_processor.add_technical_indicator(config.INDICATORS)\n",
    "ts_processor.clean_data()\n",
    "ts_processor.dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb3de6e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T02:28:12.795734Z",
     "start_time": "2022-10-12T02:28:11.420578Z"
    }
   },
   "outputs": [],
   "source": [
    "ts_processor.dataframe.to_csv('./datasets/A_stock_processed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fc2e45",
   "metadata": {
    "id": "25fc2e45"
   },
   "source": [
    "### Split traning dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bd83756",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T10:28:51.378464Z",
     "start_time": "2022-10-12T10:28:51.122396Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tic</th>\n",
       "      <th>date</th>\n",
       "      <th>index</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600010.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.31</td>\n",
       "      <td>4.49</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.48</td>\n",
       "      <td>787406.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014165</td>\n",
       "      <td>4.618261</td>\n",
       "      <td>3.916739</td>\n",
       "      <td>88.841714</td>\n",
       "      <td>110.724638</td>\n",
       "      <td>48.821799</td>\n",
       "      <td>4.267500</td>\n",
       "      <td>4.267500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>600028.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.50</td>\n",
       "      <td>7.80</td>\n",
       "      <td>7.41</td>\n",
       "      <td>7.75</td>\n",
       "      <td>743960.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014251</td>\n",
       "      <td>7.846738</td>\n",
       "      <td>7.158262</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>133.333333</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>7.502500</td>\n",
       "      <td>7.502500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>600030.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.36</td>\n",
       "      <td>9.79</td>\n",
       "      <td>9.26</td>\n",
       "      <td>9.75</td>\n",
       "      <td>623061.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009148</td>\n",
       "      <td>9.901274</td>\n",
       "      <td>9.093726</td>\n",
       "      <td>64.412995</td>\n",
       "      <td>53.333333</td>\n",
       "      <td>12.698092</td>\n",
       "      <td>9.497500</td>\n",
       "      <td>9.497500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>600031.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.11</td>\n",
       "      <td>12.58</td>\n",
       "      <td>11.94</td>\n",
       "      <td>12.55</td>\n",
       "      <td>245945.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016771</td>\n",
       "      <td>12.670833</td>\n",
       "      <td>11.709167</td>\n",
       "      <td>94.588508</td>\n",
       "      <td>80.380952</td>\n",
       "      <td>26.343026</td>\n",
       "      <td>12.190000</td>\n",
       "      <td>12.190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>600036.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.98</td>\n",
       "      <td>12.50</td>\n",
       "      <td>11.90</td>\n",
       "      <td>12.38</td>\n",
       "      <td>960020.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024994</td>\n",
       "      <td>12.577274</td>\n",
       "      <td>11.397726</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>133.333333</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>11.987500</td>\n",
       "      <td>11.987500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>600048.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.66</td>\n",
       "      <td>10.21</td>\n",
       "      <td>9.56</td>\n",
       "      <td>10.17</td>\n",
       "      <td>469341.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004945</td>\n",
       "      <td>10.360324</td>\n",
       "      <td>9.504676</td>\n",
       "      <td>58.928190</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>3.558436</td>\n",
       "      <td>9.932500</td>\n",
       "      <td>9.932500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>600104.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.21</td>\n",
       "      <td>14.95</td>\n",
       "      <td>14.06</td>\n",
       "      <td>14.90</td>\n",
       "      <td>356606.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023904</td>\n",
       "      <td>15.092770</td>\n",
       "      <td>13.732230</td>\n",
       "      <td>83.281583</td>\n",
       "      <td>131.360947</td>\n",
       "      <td>43.366115</td>\n",
       "      <td>14.412500</td>\n",
       "      <td>14.412500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>600111.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>36.33</td>\n",
       "      <td>39.40</td>\n",
       "      <td>35.78</td>\n",
       "      <td>39.02</td>\n",
       "      <td>263676.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.067193</td>\n",
       "      <td>40.131340</td>\n",
       "      <td>34.163660</td>\n",
       "      <td>64.586597</td>\n",
       "      <td>77.199282</td>\n",
       "      <td>7.583484</td>\n",
       "      <td>37.147500</td>\n",
       "      <td>37.147500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>600196.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.10</td>\n",
       "      <td>8.35</td>\n",
       "      <td>8.04</td>\n",
       "      <td>8.34</td>\n",
       "      <td>62208.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000915</td>\n",
       "      <td>8.497653</td>\n",
       "      <td>8.007347</td>\n",
       "      <td>51.137481</td>\n",
       "      <td>-14.245014</td>\n",
       "      <td>49.001351</td>\n",
       "      <td>8.252500</td>\n",
       "      <td>8.252500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>600276.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>26.65</td>\n",
       "      <td>27.50</td>\n",
       "      <td>25.60</td>\n",
       "      <td>27.40</td>\n",
       "      <td>43085.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.033764</td>\n",
       "      <td>28.972755</td>\n",
       "      <td>25.727245</td>\n",
       "      <td>32.197647</td>\n",
       "      <td>-56.144438</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.350000</td>\n",
       "      <td>27.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>600309.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.08</td>\n",
       "      <td>12.50</td>\n",
       "      <td>11.84</td>\n",
       "      <td>12.47</td>\n",
       "      <td>151864.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000755</td>\n",
       "      <td>12.751932</td>\n",
       "      <td>11.813068</td>\n",
       "      <td>49.851392</td>\n",
       "      <td>-10.122921</td>\n",
       "      <td>35.172834</td>\n",
       "      <td>12.282500</td>\n",
       "      <td>12.282500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>600436.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>70.08</td>\n",
       "      <td>70.60</td>\n",
       "      <td>68.89</td>\n",
       "      <td>70.10</td>\n",
       "      <td>10927.68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.095540</td>\n",
       "      <td>73.757406</td>\n",
       "      <td>68.097594</td>\n",
       "      <td>0.716809</td>\n",
       "      <td>-61.967145</td>\n",
       "      <td>95.185322</td>\n",
       "      <td>70.927500</td>\n",
       "      <td>70.927500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>600438.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.73</td>\n",
       "      <td>4.91</td>\n",
       "      <td>4.66</td>\n",
       "      <td>4.89</td>\n",
       "      <td>24346.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002969</td>\n",
       "      <td>4.996025</td>\n",
       "      <td>4.563975</td>\n",
       "      <td>56.220718</td>\n",
       "      <td>30.529595</td>\n",
       "      <td>11.732573</td>\n",
       "      <td>4.780000</td>\n",
       "      <td>4.780000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>600519.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>186.00</td>\n",
       "      <td>188.09</td>\n",
       "      <td>181.77</td>\n",
       "      <td>188.01</td>\n",
       "      <td>26160.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.139206</td>\n",
       "      <td>189.913000</td>\n",
       "      <td>181.622000</td>\n",
       "      <td>70.541058</td>\n",
       "      <td>16.931217</td>\n",
       "      <td>7.889720</td>\n",
       "      <td>185.767500</td>\n",
       "      <td>185.767500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>600570.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.72</td>\n",
       "      <td>11.03</td>\n",
       "      <td>10.66</td>\n",
       "      <td>11.00</td>\n",
       "      <td>15365.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.013964</td>\n",
       "      <td>11.737500</td>\n",
       "      <td>10.197500</td>\n",
       "      <td>29.822271</td>\n",
       "      <td>-24.598512</td>\n",
       "      <td>57.180821</td>\n",
       "      <td>10.967500</td>\n",
       "      <td>10.967500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>600585.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.82</td>\n",
       "      <td>15.60</td>\n",
       "      <td>14.56</td>\n",
       "      <td>15.55</td>\n",
       "      <td>311506.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010049</td>\n",
       "      <td>15.857297</td>\n",
       "      <td>14.377703</td>\n",
       "      <td>61.041381</td>\n",
       "      <td>33.106576</td>\n",
       "      <td>15.199647</td>\n",
       "      <td>15.117500</td>\n",
       "      <td>15.117500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>600588.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.23</td>\n",
       "      <td>16.62</td>\n",
       "      <td>15.66</td>\n",
       "      <td>16.58</td>\n",
       "      <td>48522.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.011340</td>\n",
       "      <td>17.102087</td>\n",
       "      <td>15.992913</td>\n",
       "      <td>35.564287</td>\n",
       "      <td>-32.037222</td>\n",
       "      <td>66.698547</td>\n",
       "      <td>16.547500</td>\n",
       "      <td>16.547500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>600690.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.88</td>\n",
       "      <td>9.10</td>\n",
       "      <td>8.68</td>\n",
       "      <td>9.07</td>\n",
       "      <td>160606.42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011236</td>\n",
       "      <td>9.150342</td>\n",
       "      <td>8.534658</td>\n",
       "      <td>87.855596</td>\n",
       "      <td>80.341880</td>\n",
       "      <td>9.531850</td>\n",
       "      <td>8.842500</td>\n",
       "      <td>8.842500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>600809.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>53.70</td>\n",
       "      <td>54.60</td>\n",
       "      <td>52.78</td>\n",
       "      <td>54.59</td>\n",
       "      <td>28933.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.111768</td>\n",
       "      <td>58.810558</td>\n",
       "      <td>51.744442</td>\n",
       "      <td>18.849264</td>\n",
       "      <td>-62.041431</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>55.277500</td>\n",
       "      <td>55.277500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>600837.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.30</td>\n",
       "      <td>7.64</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.62</td>\n",
       "      <td>642922.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020084</td>\n",
       "      <td>7.772070</td>\n",
       "      <td>6.787930</td>\n",
       "      <td>93.443006</td>\n",
       "      <td>133.333333</td>\n",
       "      <td>79.566052</td>\n",
       "      <td>7.280000</td>\n",
       "      <td>7.280000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>600887.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19.67</td>\n",
       "      <td>20.20</td>\n",
       "      <td>19.08</td>\n",
       "      <td>20.13</td>\n",
       "      <td>118868.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019332</td>\n",
       "      <td>20.369437</td>\n",
       "      <td>19.055563</td>\n",
       "      <td>67.854754</td>\n",
       "      <td>46.840149</td>\n",
       "      <td>6.659267</td>\n",
       "      <td>19.712500</td>\n",
       "      <td>19.712500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>600893.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.92</td>\n",
       "      <td>13.46</td>\n",
       "      <td>12.74</td>\n",
       "      <td>13.39</td>\n",
       "      <td>43936.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009417</td>\n",
       "      <td>13.739108</td>\n",
       "      <td>12.405892</td>\n",
       "      <td>55.027883</td>\n",
       "      <td>26.845638</td>\n",
       "      <td>27.847554</td>\n",
       "      <td>13.072500</td>\n",
       "      <td>13.072500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>600900.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.22</td>\n",
       "      <td>6.30</td>\n",
       "      <td>6.17</td>\n",
       "      <td>6.29</td>\n",
       "      <td>203893.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>6.331181</td>\n",
       "      <td>6.188819</td>\n",
       "      <td>51.449571</td>\n",
       "      <td>-31.924883</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>6.260000</td>\n",
       "      <td>6.260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>601012.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>63.0</td>\n",
       "      <td>19.30</td>\n",
       "      <td>19.60</td>\n",
       "      <td>19.15</td>\n",
       "      <td>19.47</td>\n",
       "      <td>83715.18</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.006282</td>\n",
       "      <td>20.005980</td>\n",
       "      <td>19.214020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>19.610000</td>\n",
       "      <td>19.610000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>601088.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24.29</td>\n",
       "      <td>26.06</td>\n",
       "      <td>24.12</td>\n",
       "      <td>26.01</td>\n",
       "      <td>304669.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052423</td>\n",
       "      <td>26.443712</td>\n",
       "      <td>23.141288</td>\n",
       "      <td>84.919012</td>\n",
       "      <td>109.787234</td>\n",
       "      <td>66.693781</td>\n",
       "      <td>24.792500</td>\n",
       "      <td>24.792500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99117</th>\n",
       "      <td>600519.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>1898.62</td>\n",
       "      <td>1901.99</td>\n",
       "      <td>1866.00</td>\n",
       "      <td>1872.50</td>\n",
       "      <td>21289.08</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-3.205584</td>\n",
       "      <td>1905.084788</td>\n",
       "      <td>1810.868212</td>\n",
       "      <td>49.210286</td>\n",
       "      <td>43.354556</td>\n",
       "      <td>4.610511</td>\n",
       "      <td>1866.981333</td>\n",
       "      <td>1896.708500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99118</th>\n",
       "      <td>600570.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>33.79</td>\n",
       "      <td>34.74</td>\n",
       "      <td>33.60</td>\n",
       "      <td>33.89</td>\n",
       "      <td>101960.81</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.768929</td>\n",
       "      <td>36.239658</td>\n",
       "      <td>31.554342</td>\n",
       "      <td>44.196982</td>\n",
       "      <td>45.034429</td>\n",
       "      <td>8.461160</td>\n",
       "      <td>33.301667</td>\n",
       "      <td>37.428833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99119</th>\n",
       "      <td>600585.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>28.18</td>\n",
       "      <td>29.15</td>\n",
       "      <td>28.18</td>\n",
       "      <td>28.81</td>\n",
       "      <td>284870.69</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.951232</td>\n",
       "      <td>32.768742</td>\n",
       "      <td>27.320258</td>\n",
       "      <td>39.227171</td>\n",
       "      <td>-112.192998</td>\n",
       "      <td>23.395967</td>\n",
       "      <td>30.577000</td>\n",
       "      <td>31.911167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99120</th>\n",
       "      <td>600588.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>17.71</td>\n",
       "      <td>17.93</td>\n",
       "      <td>17.60</td>\n",
       "      <td>17.60</td>\n",
       "      <td>124403.66</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.686902</td>\n",
       "      <td>20.564209</td>\n",
       "      <td>17.092791</td>\n",
       "      <td>39.883637</td>\n",
       "      <td>-127.830776</td>\n",
       "      <td>23.497526</td>\n",
       "      <td>19.364000</td>\n",
       "      <td>20.070667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99121</th>\n",
       "      <td>600690.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>25.00</td>\n",
       "      <td>25.19</td>\n",
       "      <td>24.65</td>\n",
       "      <td>24.77</td>\n",
       "      <td>267702.88</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.032207</td>\n",
       "      <td>27.002850</td>\n",
       "      <td>24.280150</td>\n",
       "      <td>47.955669</td>\n",
       "      <td>-46.280992</td>\n",
       "      <td>8.286352</td>\n",
       "      <td>25.364667</td>\n",
       "      <td>24.991000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99122</th>\n",
       "      <td>600809.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>309.00</td>\n",
       "      <td>309.80</td>\n",
       "      <td>300.12</td>\n",
       "      <td>302.89</td>\n",
       "      <td>32116.50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.770177</td>\n",
       "      <td>309.269051</td>\n",
       "      <td>277.852949</td>\n",
       "      <td>56.490877</td>\n",
       "      <td>118.397397</td>\n",
       "      <td>35.043245</td>\n",
       "      <td>288.141333</td>\n",
       "      <td>285.021333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99123</th>\n",
       "      <td>600837.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>8.51</td>\n",
       "      <td>8.73</td>\n",
       "      <td>8.51</td>\n",
       "      <td>8.66</td>\n",
       "      <td>220874.32</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.182558</td>\n",
       "      <td>9.760406</td>\n",
       "      <td>8.598594</td>\n",
       "      <td>36.582080</td>\n",
       "      <td>-194.604245</td>\n",
       "      <td>55.336652</td>\n",
       "      <td>9.272333</td>\n",
       "      <td>9.353333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99124</th>\n",
       "      <td>600887.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>33.29</td>\n",
       "      <td>33.47</td>\n",
       "      <td>32.93</td>\n",
       "      <td>32.98</td>\n",
       "      <td>264761.80</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.588198</td>\n",
       "      <td>34.189506</td>\n",
       "      <td>32.071494</td>\n",
       "      <td>40.677415</td>\n",
       "      <td>-51.402939</td>\n",
       "      <td>12.827832</td>\n",
       "      <td>33.973667</td>\n",
       "      <td>35.066833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99125</th>\n",
       "      <td>600893.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>43.56</td>\n",
       "      <td>43.64</td>\n",
       "      <td>41.84</td>\n",
       "      <td>41.95</td>\n",
       "      <td>161512.07</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.371672</td>\n",
       "      <td>49.830794</td>\n",
       "      <td>42.613206</td>\n",
       "      <td>40.822531</td>\n",
       "      <td>-203.113753</td>\n",
       "      <td>31.939610</td>\n",
       "      <td>46.967333</td>\n",
       "      <td>49.416500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99126</th>\n",
       "      <td>600900.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>22.40</td>\n",
       "      <td>22.85</td>\n",
       "      <td>22.28</td>\n",
       "      <td>22.74</td>\n",
       "      <td>423324.79</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.283151</td>\n",
       "      <td>24.311465</td>\n",
       "      <td>22.450535</td>\n",
       "      <td>42.647592</td>\n",
       "      <td>-185.556412</td>\n",
       "      <td>34.433872</td>\n",
       "      <td>23.417667</td>\n",
       "      <td>23.789333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99127</th>\n",
       "      <td>601012.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>49.78</td>\n",
       "      <td>50.15</td>\n",
       "      <td>47.80</td>\n",
       "      <td>47.91</td>\n",
       "      <td>682745.27</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.728189</td>\n",
       "      <td>54.486358</td>\n",
       "      <td>46.129642</td>\n",
       "      <td>38.786281</td>\n",
       "      <td>-94.845268</td>\n",
       "      <td>35.806177</td>\n",
       "      <td>51.251333</td>\n",
       "      <td>55.487333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99128</th>\n",
       "      <td>601088.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>31.60</td>\n",
       "      <td>31.92</td>\n",
       "      <td>31.10</td>\n",
       "      <td>31.64</td>\n",
       "      <td>219426.08</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.096078</td>\n",
       "      <td>33.327838</td>\n",
       "      <td>30.026162</td>\n",
       "      <td>52.556566</td>\n",
       "      <td>16.859864</td>\n",
       "      <td>10.223676</td>\n",
       "      <td>31.409333</td>\n",
       "      <td>30.179500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99129</th>\n",
       "      <td>601166.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>16.57</td>\n",
       "      <td>16.77</td>\n",
       "      <td>16.54</td>\n",
       "      <td>16.65</td>\n",
       "      <td>470496.19</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.215111</td>\n",
       "      <td>17.677171</td>\n",
       "      <td>16.506829</td>\n",
       "      <td>41.092287</td>\n",
       "      <td>-130.421549</td>\n",
       "      <td>21.408923</td>\n",
       "      <td>17.211333</td>\n",
       "      <td>17.523000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99130</th>\n",
       "      <td>601288.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>2.83</td>\n",
       "      <td>2.86</td>\n",
       "      <td>2.83</td>\n",
       "      <td>2.86</td>\n",
       "      <td>2602100.09</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>2.879206</td>\n",
       "      <td>2.815794</td>\n",
       "      <td>49.061725</td>\n",
       "      <td>44.937429</td>\n",
       "      <td>19.468989</td>\n",
       "      <td>2.840333</td>\n",
       "      <td>2.852167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99131</th>\n",
       "      <td>601318.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>41.35</td>\n",
       "      <td>41.98</td>\n",
       "      <td>41.35</td>\n",
       "      <td>41.58</td>\n",
       "      <td>331619.40</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.306936</td>\n",
       "      <td>45.584692</td>\n",
       "      <td>41.195308</td>\n",
       "      <td>43.493820</td>\n",
       "      <td>-103.476775</td>\n",
       "      <td>14.614106</td>\n",
       "      <td>43.064000</td>\n",
       "      <td>42.768500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99132</th>\n",
       "      <td>601398.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.36</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.35</td>\n",
       "      <td>1578628.46</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.006202</td>\n",
       "      <td>4.398556</td>\n",
       "      <td>4.326444</td>\n",
       "      <td>44.834511</td>\n",
       "      <td>-39.017341</td>\n",
       "      <td>4.027457</td>\n",
       "      <td>4.355667</td>\n",
       "      <td>4.379167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99133</th>\n",
       "      <td>601601.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>19.83</td>\n",
       "      <td>20.45</td>\n",
       "      <td>19.83</td>\n",
       "      <td>20.33</td>\n",
       "      <td>195189.41</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.136296</td>\n",
       "      <td>21.714986</td>\n",
       "      <td>19.552014</td>\n",
       "      <td>47.205933</td>\n",
       "      <td>-43.289347</td>\n",
       "      <td>3.763124</td>\n",
       "      <td>20.489333</td>\n",
       "      <td>20.457833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99134</th>\n",
       "      <td>601628.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>31.76</td>\n",
       "      <td>32.00</td>\n",
       "      <td>31.16</td>\n",
       "      <td>31.63</td>\n",
       "      <td>111268.85</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.620124</td>\n",
       "      <td>32.273866</td>\n",
       "      <td>29.367134</td>\n",
       "      <td>59.040332</td>\n",
       "      <td>94.651333</td>\n",
       "      <td>30.245425</td>\n",
       "      <td>30.140667</td>\n",
       "      <td>28.998000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99135</th>\n",
       "      <td>601633.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>28.05</td>\n",
       "      <td>28.35</td>\n",
       "      <td>27.68</td>\n",
       "      <td>27.80</td>\n",
       "      <td>151081.85</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.220938</td>\n",
       "      <td>33.000132</td>\n",
       "      <td>27.071868</td>\n",
       "      <td>40.762729</td>\n",
       "      <td>-126.327626</td>\n",
       "      <td>38.764325</td>\n",
       "      <td>31.231667</td>\n",
       "      <td>32.385000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99136</th>\n",
       "      <td>601668.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>5.03</td>\n",
       "      <td>5.19</td>\n",
       "      <td>5.03</td>\n",
       "      <td>5.15</td>\n",
       "      <td>2186913.38</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.000079</td>\n",
       "      <td>5.374797</td>\n",
       "      <td>5.009203</td>\n",
       "      <td>49.362609</td>\n",
       "      <td>-8.448348</td>\n",
       "      <td>0.267188</td>\n",
       "      <td>5.138000</td>\n",
       "      <td>5.123167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99137</th>\n",
       "      <td>601688.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>12.19</td>\n",
       "      <td>12.29</td>\n",
       "      <td>12.10</td>\n",
       "      <td>12.12</td>\n",
       "      <td>229982.43</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.249653</td>\n",
       "      <td>13.538437</td>\n",
       "      <td>11.806563</td>\n",
       "      <td>36.813250</td>\n",
       "      <td>-122.198506</td>\n",
       "      <td>44.061683</td>\n",
       "      <td>12.812000</td>\n",
       "      <td>13.004333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99138</th>\n",
       "      <td>601857.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>5.08</td>\n",
       "      <td>5.16</td>\n",
       "      <td>5.08</td>\n",
       "      <td>5.13</td>\n",
       "      <td>819572.30</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.062860</td>\n",
       "      <td>5.755721</td>\n",
       "      <td>4.975279</td>\n",
       "      <td>45.564208</td>\n",
       "      <td>-113.679847</td>\n",
       "      <td>11.212406</td>\n",
       "      <td>5.364333</td>\n",
       "      <td>5.258000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99139</th>\n",
       "      <td>601888.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>198.24</td>\n",
       "      <td>200.50</td>\n",
       "      <td>195.71</td>\n",
       "      <td>198.25</td>\n",
       "      <td>80998.33</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.330810</td>\n",
       "      <td>203.420184</td>\n",
       "      <td>176.951816</td>\n",
       "      <td>51.954585</td>\n",
       "      <td>129.238562</td>\n",
       "      <td>17.738487</td>\n",
       "      <td>190.593667</td>\n",
       "      <td>197.692000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99140</th>\n",
       "      <td>601899.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>7.78</td>\n",
       "      <td>7.92</td>\n",
       "      <td>7.73</td>\n",
       "      <td>7.84</td>\n",
       "      <td>1988575.12</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.303164</td>\n",
       "      <td>9.603624</td>\n",
       "      <td>7.492376</td>\n",
       "      <td>38.868903</td>\n",
       "      <td>-169.989876</td>\n",
       "      <td>41.678620</td>\n",
       "      <td>8.679333</td>\n",
       "      <td>8.751333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99141</th>\n",
       "      <td>601919.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>11.00</td>\n",
       "      <td>11.14</td>\n",
       "      <td>10.92</td>\n",
       "      <td>11.02</td>\n",
       "      <td>625792.65</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.651301</td>\n",
       "      <td>14.200318</td>\n",
       "      <td>10.656682</td>\n",
       "      <td>32.953801</td>\n",
       "      <td>-154.242342</td>\n",
       "      <td>49.177082</td>\n",
       "      <td>12.898333</td>\n",
       "      <td>13.367333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99142 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             tic        date   index     open     high      low    close  \\\n",
       "0      600010.SH  2012-01-09     3.0     4.31     4.49     4.23     4.48   \n",
       "1      600028.SH  2012-01-09     3.0     7.50     7.80     7.41     7.75   \n",
       "2      600030.SH  2012-01-09     3.0     9.36     9.79     9.26     9.75   \n",
       "3      600031.SH  2012-01-09     3.0    12.11    12.58    11.94    12.55   \n",
       "4      600036.SH  2012-01-09     3.0    11.98    12.50    11.90    12.38   \n",
       "5      600048.SH  2012-01-09     3.0     9.66    10.21     9.56    10.17   \n",
       "6      600104.SH  2012-01-09     3.0    14.21    14.95    14.06    14.90   \n",
       "7      600111.SH  2012-01-09     3.0    36.33    39.40    35.78    39.02   \n",
       "8      600196.SH  2012-01-09     3.0     8.10     8.35     8.04     8.34   \n",
       "9      600276.SH  2012-01-09     3.0    26.65    27.50    25.60    27.40   \n",
       "10     600309.SH  2012-01-09     3.0    12.08    12.50    11.84    12.47   \n",
       "11     600436.SH  2012-01-09     3.0    70.08    70.60    68.89    70.10   \n",
       "12     600438.SH  2012-01-09     3.0     4.73     4.91     4.66     4.89   \n",
       "13     600519.SH  2012-01-09     3.0   186.00   188.09   181.77   188.01   \n",
       "14     600570.SH  2012-01-09     3.0    10.72    11.03    10.66    11.00   \n",
       "15     600585.SH  2012-01-09     3.0    14.82    15.60    14.56    15.55   \n",
       "16     600588.SH  2012-01-09     3.0    16.23    16.62    15.66    16.58   \n",
       "17     600690.SH  2012-01-09     3.0     8.88     9.10     8.68     9.07   \n",
       "18     600809.SH  2012-01-09     3.0    53.70    54.60    52.78    54.59   \n",
       "19     600837.SH  2012-01-09     3.0     7.30     7.64     7.24     7.62   \n",
       "20     600887.SH  2012-01-09     3.0    19.67    20.20    19.08    20.13   \n",
       "21     600893.SH  2012-01-09     3.0    12.92    13.46    12.74    13.39   \n",
       "22     600900.SH  2012-01-09     3.0     6.22     6.30     6.17     6.29   \n",
       "23     601012.SH  2012-01-09    63.0    19.30    19.60    19.15    19.47   \n",
       "24     601088.SH  2012-01-09     3.0    24.29    26.06    24.12    26.01   \n",
       "...          ...         ...     ...      ...      ...      ...      ...   \n",
       "99117  600519.SH  2022-09-30  2612.0  1898.62  1901.99  1866.00  1872.50   \n",
       "99118  600570.SH  2022-09-30  2612.0    33.79    34.74    33.60    33.89   \n",
       "99119  600585.SH  2022-09-30  2612.0    28.18    29.15    28.18    28.81   \n",
       "99120  600588.SH  2022-09-30  2612.0    17.71    17.93    17.60    17.60   \n",
       "99121  600690.SH  2022-09-30  2612.0    25.00    25.19    24.65    24.77   \n",
       "99122  600809.SH  2022-09-30  2612.0   309.00   309.80   300.12   302.89   \n",
       "99123  600837.SH  2022-09-30  2612.0     8.51     8.73     8.51     8.66   \n",
       "99124  600887.SH  2022-09-30  2612.0    33.29    33.47    32.93    32.98   \n",
       "99125  600893.SH  2022-09-30  2612.0    43.56    43.64    41.84    41.95   \n",
       "99126  600900.SH  2022-09-30  2612.0    22.40    22.85    22.28    22.74   \n",
       "99127  601012.SH  2022-09-30  2612.0    49.78    50.15    47.80    47.91   \n",
       "99128  601088.SH  2022-09-30  2612.0    31.60    31.92    31.10    31.64   \n",
       "99129  601166.SH  2022-09-30  2612.0    16.57    16.77    16.54    16.65   \n",
       "99130  601288.SH  2022-09-30  2612.0     2.83     2.86     2.83     2.86   \n",
       "99131  601318.SH  2022-09-30  2612.0    41.35    41.98    41.35    41.58   \n",
       "99132  601398.SH  2022-09-30  2612.0     4.34     4.36     4.33     4.35   \n",
       "99133  601601.SH  2022-09-30  2612.0    19.83    20.45    19.83    20.33   \n",
       "99134  601628.SH  2022-09-30  2612.0    31.76    32.00    31.16    31.63   \n",
       "99135  601633.SH  2022-09-30  2612.0    28.05    28.35    27.68    27.80   \n",
       "99136  601668.SH  2022-09-30  2612.0     5.03     5.19     5.03     5.15   \n",
       "99137  601688.SH  2022-09-30  2612.0    12.19    12.29    12.10    12.12   \n",
       "99138  601857.SH  2022-09-30  2612.0     5.08     5.16     5.08     5.13   \n",
       "99139  601888.SH  2022-09-30  2612.0   198.24   200.50   195.71   198.25   \n",
       "99140  601899.SH  2022-09-30  2612.0     7.78     7.92     7.73     7.84   \n",
       "99141  601919.SH  2022-09-30  2612.0    11.00    11.14    10.92    11.02   \n",
       "\n",
       "           volume  day      macd      boll_ub      boll_lb      rsi_30  \\\n",
       "0       787406.46  0.0  0.014165     4.618261     3.916739   88.841714   \n",
       "1       743960.15  0.0  0.014251     7.846738     7.158262  100.000000   \n",
       "2       623061.16  0.0  0.009148     9.901274     9.093726   64.412995   \n",
       "3       245945.25  0.0  0.016771    12.670833    11.709167   94.588508   \n",
       "4       960020.09  0.0  0.024994    12.577274    11.397726  100.000000   \n",
       "5       469341.00  0.0  0.004945    10.360324     9.504676   58.928190   \n",
       "6       356606.32  0.0  0.023904    15.092770    13.732230   83.281583   \n",
       "7       263676.19  0.0  0.067193    40.131340    34.163660   64.586597   \n",
       "8        62208.12  0.0 -0.000915     8.497653     8.007347   51.137481   \n",
       "9        43085.35  0.0 -0.033764    28.972755    25.727245   32.197647   \n",
       "10      151864.28  0.0  0.000755    12.751932    11.813068   49.851392   \n",
       "11       10927.68  0.0 -0.095540    73.757406    68.097594    0.716809   \n",
       "12       24346.27  0.0  0.002969     4.996025     4.563975   56.220718   \n",
       "13       26160.16  0.0  0.139206   189.913000   181.622000   70.541058   \n",
       "14       15365.29  0.0 -0.013964    11.737500    10.197500   29.822271   \n",
       "15      311506.05  0.0  0.010049    15.857297    14.377703   61.041381   \n",
       "16       48522.89  0.0 -0.011340    17.102087    15.992913   35.564287   \n",
       "17      160606.42  0.0  0.011236     9.150342     8.534658   87.855596   \n",
       "18       28933.49  0.0 -0.111768    58.810558    51.744442   18.849264   \n",
       "19      642922.60  0.0  0.020084     7.772070     6.787930   93.443006   \n",
       "20      118868.14  0.0  0.019332    20.369437    19.055563   67.854754   \n",
       "21       43936.61  0.0  0.009417    13.739108    12.405892   55.027883   \n",
       "22      203893.30  0.0  0.000106     6.331181     6.188819   51.449571   \n",
       "23       83715.18  3.0 -0.006282    20.005980    19.214020    0.000000   \n",
       "24      304669.62  0.0  0.052423    26.443712    23.141288   84.919012   \n",
       "...           ...  ...       ...          ...          ...         ...   \n",
       "99117    21289.08  4.0 -3.205584  1905.084788  1810.868212   49.210286   \n",
       "99118   101960.81  4.0 -0.768929    36.239658    31.554342   44.196982   \n",
       "99119   284870.69  4.0 -0.951232    32.768742    27.320258   39.227171   \n",
       "99120   124403.66  4.0 -0.686902    20.564209    17.092791   39.883637   \n",
       "99121   267702.88  4.0 -0.032207    27.002850    24.280150   47.955669   \n",
       "99122    32116.50  4.0  5.770177   309.269051   277.852949   56.490877   \n",
       "99123   220874.32  4.0 -0.182558     9.760406     8.598594   36.582080   \n",
       "99124   264761.80  4.0 -0.588198    34.189506    32.071494   40.677415   \n",
       "99125   161512.07  4.0 -1.371672    49.830794    42.613206   40.822531   \n",
       "99126   423324.79  4.0 -0.283151    24.311465    22.450535   42.647592   \n",
       "99127   682745.27  4.0 -1.728189    54.486358    46.129642   38.786281   \n",
       "99128   219426.08  4.0  0.096078    33.327838    30.026162   52.556566   \n",
       "99129   470496.19  4.0 -0.215111    17.677171    16.506829   41.092287   \n",
       "99130  2602100.09  4.0  0.000538     2.879206     2.815794   49.061725   \n",
       "99131   331619.40  4.0 -0.306936    45.584692    41.195308   43.493820   \n",
       "99132  1578628.46  4.0 -0.006202     4.398556     4.326444   44.834511   \n",
       "99133   195189.41  4.0 -0.136296    21.714986    19.552014   47.205933   \n",
       "99134   111268.85  4.0  0.620124    32.273866    29.367134   59.040332   \n",
       "99135   151081.85  4.0 -1.220938    33.000132    27.071868   40.762729   \n",
       "99136  2186913.38  4.0 -0.000079     5.374797     5.009203   49.362609   \n",
       "99137   229982.43  4.0 -0.249653    13.538437    11.806563   36.813250   \n",
       "99138   819572.30  4.0 -0.062860     5.755721     4.975279   45.564208   \n",
       "99139    80998.33  4.0  1.330810   203.420184   176.951816   51.954585   \n",
       "99140  1988575.12  4.0 -0.303164     9.603624     7.492376   38.868903   \n",
       "99141   625792.65  4.0 -0.651301    14.200318    10.656682   32.953801   \n",
       "\n",
       "           cci_30       dx_30  close_30_sma  close_60_sma  \n",
       "0      110.724638   48.821799      4.267500      4.267500  \n",
       "1      133.333333  100.000000      7.502500      7.502500  \n",
       "2       53.333333   12.698092      9.497500      9.497500  \n",
       "3       80.380952   26.343026     12.190000     12.190000  \n",
       "4      133.333333  100.000000     11.987500     11.987500  \n",
       "5       40.000000    3.558436      9.932500      9.932500  \n",
       "6      131.360947   43.366115     14.412500     14.412500  \n",
       "7       77.199282    7.583484     37.147500     37.147500  \n",
       "8      -14.245014   49.001351      8.252500      8.252500  \n",
       "9      -56.144438  100.000000     27.350000     27.350000  \n",
       "10     -10.122921   35.172834     12.282500     12.282500  \n",
       "11     -61.967145   95.185322     70.927500     70.927500  \n",
       "12      30.529595   11.732573      4.780000      4.780000  \n",
       "13      16.931217    7.889720    185.767500    185.767500  \n",
       "14     -24.598512   57.180821     10.967500     10.967500  \n",
       "15      33.106576   15.199647     15.117500     15.117500  \n",
       "16     -32.037222   66.698547     16.547500     16.547500  \n",
       "17      80.341880    9.531850      8.842500      8.842500  \n",
       "18     -62.041431  100.000000     55.277500     55.277500  \n",
       "19     133.333333   79.566052      7.280000      7.280000  \n",
       "20      46.840149    6.659267     19.712500     19.712500  \n",
       "21      26.845638   27.847554     13.072500     13.072500  \n",
       "22     -31.924883  100.000000      6.260000      6.260000  \n",
       "23     -66.666667  100.000000     19.610000     19.610000  \n",
       "24     109.787234   66.693781     24.792500     24.792500  \n",
       "...           ...         ...           ...           ...  \n",
       "99117   43.354556    4.610511   1866.981333   1896.708500  \n",
       "99118   45.034429    8.461160     33.301667     37.428833  \n",
       "99119 -112.192998   23.395967     30.577000     31.911167  \n",
       "99120 -127.830776   23.497526     19.364000     20.070667  \n",
       "99121  -46.280992    8.286352     25.364667     24.991000  \n",
       "99122  118.397397   35.043245    288.141333    285.021333  \n",
       "99123 -194.604245   55.336652      9.272333      9.353333  \n",
       "99124  -51.402939   12.827832     33.973667     35.066833  \n",
       "99125 -203.113753   31.939610     46.967333     49.416500  \n",
       "99126 -185.556412   34.433872     23.417667     23.789333  \n",
       "99127  -94.845268   35.806177     51.251333     55.487333  \n",
       "99128   16.859864   10.223676     31.409333     30.179500  \n",
       "99129 -130.421549   21.408923     17.211333     17.523000  \n",
       "99130   44.937429   19.468989      2.840333      2.852167  \n",
       "99131 -103.476775   14.614106     43.064000     42.768500  \n",
       "99132  -39.017341    4.027457      4.355667      4.379167  \n",
       "99133  -43.289347    3.763124     20.489333     20.457833  \n",
       "99134   94.651333   30.245425     30.140667     28.998000  \n",
       "99135 -126.327626   38.764325     31.231667     32.385000  \n",
       "99136   -8.448348    0.267188      5.138000      5.123167  \n",
       "99137 -122.198506   44.061683     12.812000     13.004333  \n",
       "99138 -113.679847   11.212406      5.364333      5.258000  \n",
       "99139  129.238562   17.738487    190.593667    197.692000  \n",
       "99140 -169.989876   41.678620      8.679333      8.751333  \n",
       "99141 -154.242342   49.177082     12.898333     13.367333  \n",
       "\n",
       "[99142 rows x 17 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_processor.dataframe = pd.read_csv('./datasets/A_stock_processed.csv', index_col=[0])\n",
    "ts_processor.dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "pending-mother",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T10:28:53.420867Z",
     "start_time": "2022-10-12T10:28:53.350720Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pending-mother",
    "outputId": "87fb4ed5-6c51-4da4-b208-7a350a170c02"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train =ts_processor.data_split(ts_processor.dataframe, train_start_date, train_stop_date)       \n",
    "len(train.tic.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "signal-rochester",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T10:28:53.687120Z",
     "start_time": "2022-10-12T10:28:53.671813Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "signal-rochester",
    "outputId": "68104252-5064-4e12-c674-b27b75061fae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['600010.SH', '600028.SH', '600030.SH', '600031.SH', '600036.SH',\n",
       "       '600048.SH', '600104.SH', '600111.SH', '600196.SH', '600276.SH',\n",
       "       '600309.SH', '600436.SH', '600438.SH', '600519.SH', '600570.SH',\n",
       "       '600585.SH', '600588.SH', '600690.SH', '600809.SH', '600837.SH',\n",
       "       '600887.SH', '600893.SH', '600900.SH', '601012.SH', '601088.SH',\n",
       "       '601166.SH', '601288.SH', '601318.SH', '601398.SH', '601601.SH',\n",
       "       '601628.SH', '601633.SH', '601668.SH', '601688.SH', '601857.SH',\n",
       "       '601888.SH', '601899.SH', '601919.SH'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tic.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "future-while",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T10:28:54.163155Z",
     "start_time": "2022-10-12T10:28:54.133668Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "future-while",
    "outputId": "20d6734c-3206-4e18-bab9-ed340dd70151"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tic</th>\n",
       "      <th>date</th>\n",
       "      <th>index</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600010.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.31</td>\n",
       "      <td>4.49</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.48</td>\n",
       "      <td>787406.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014165</td>\n",
       "      <td>4.618261</td>\n",
       "      <td>3.916739</td>\n",
       "      <td>88.841714</td>\n",
       "      <td>110.724638</td>\n",
       "      <td>48.821799</td>\n",
       "      <td>4.2675</td>\n",
       "      <td>4.2675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600028.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.50</td>\n",
       "      <td>7.80</td>\n",
       "      <td>7.41</td>\n",
       "      <td>7.75</td>\n",
       "      <td>743960.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014251</td>\n",
       "      <td>7.846738</td>\n",
       "      <td>7.158262</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>133.333333</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>7.5025</td>\n",
       "      <td>7.5025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600030.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.36</td>\n",
       "      <td>9.79</td>\n",
       "      <td>9.26</td>\n",
       "      <td>9.75</td>\n",
       "      <td>623061.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009148</td>\n",
       "      <td>9.901274</td>\n",
       "      <td>9.093726</td>\n",
       "      <td>64.412995</td>\n",
       "      <td>53.333333</td>\n",
       "      <td>12.698092</td>\n",
       "      <td>9.4975</td>\n",
       "      <td>9.4975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600031.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.11</td>\n",
       "      <td>12.58</td>\n",
       "      <td>11.94</td>\n",
       "      <td>12.55</td>\n",
       "      <td>245945.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016771</td>\n",
       "      <td>12.670833</td>\n",
       "      <td>11.709167</td>\n",
       "      <td>94.588508</td>\n",
       "      <td>80.380952</td>\n",
       "      <td>26.343026</td>\n",
       "      <td>12.1900</td>\n",
       "      <td>12.1900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600036.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.98</td>\n",
       "      <td>12.50</td>\n",
       "      <td>11.90</td>\n",
       "      <td>12.38</td>\n",
       "      <td>960020.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024994</td>\n",
       "      <td>12.577274</td>\n",
       "      <td>11.397726</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>133.333333</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>11.9875</td>\n",
       "      <td>11.9875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         tic        date  index   open   high    low  close     volume  day  \\\n",
       "0  600010.SH  2012-01-09    3.0   4.31   4.49   4.23   4.48  787406.46  0.0   \n",
       "0  600028.SH  2012-01-09    3.0   7.50   7.80   7.41   7.75  743960.15  0.0   \n",
       "0  600030.SH  2012-01-09    3.0   9.36   9.79   9.26   9.75  623061.16  0.0   \n",
       "0  600031.SH  2012-01-09    3.0  12.11  12.58  11.94  12.55  245945.25  0.0   \n",
       "0  600036.SH  2012-01-09    3.0  11.98  12.50  11.90  12.38  960020.09  0.0   \n",
       "\n",
       "       macd    boll_ub    boll_lb      rsi_30      cci_30       dx_30  \\\n",
       "0  0.014165   4.618261   3.916739   88.841714  110.724638   48.821799   \n",
       "0  0.014251   7.846738   7.158262  100.000000  133.333333  100.000000   \n",
       "0  0.009148   9.901274   9.093726   64.412995   53.333333   12.698092   \n",
       "0  0.016771  12.670833  11.709167   94.588508   80.380952   26.343026   \n",
       "0  0.024994  12.577274  11.397726  100.000000  133.333333  100.000000   \n",
       "\n",
       "   close_30_sma  close_60_sma  \n",
       "0        4.2675        4.2675  \n",
       "0        7.5025        7.5025  \n",
       "0        9.4975        9.4975  \n",
       "0       12.1900       12.1900  \n",
       "0       11.9875       11.9875  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72e9bcc2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T10:28:54.660144Z",
     "start_time": "2022-10-12T10:28:54.652903Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "72e9bcc2",
    "outputId": "2e7dbf8d-4792-4bea-d26d-0fab001dab7b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73758, 17)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "provincial-wichita",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T10:28:55.430002Z",
     "start_time": "2022-10-12T10:28:55.414986Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "provincial-wichita",
    "outputId": "81a0dbd5-02d8-4f6a-cfee-62490004bfa9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 38, State Space: 381\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(train.tic.unique())\n",
    "state_space = stock_dimension*(len(config.INDICATORS)+2)+1 # (indicators + close_price + shares) * num_stock + cash\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90bbf93",
   "metadata": {
    "id": "e90bbf93"
   },
   "source": [
    "# 构建金融仿真环境\n",
    "FinRL中为我们构建了一个和OpenAI Gym-style类似的金融仿真环境，通过agent和该环境互动，包括监测股价的变动，动作的采取和奖励的计算，agent最终可以学习到一个交易策略以期最大化收益。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "dcb153fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T11:25:14.185428Z",
     "start_time": "2022-10-12T11:25:14.161450Z"
    },
    "id": "dcb153fc"
   },
   "outputs": [],
   "source": [
    "env_kwargs = {\n",
    "    \"stock_dim\": stock_dimension,\n",
    "    \"hmax\": 1000, \n",
    "    \"initial_amount\": 1e7, \n",
    "    \"buy_cost_pct\":6.87e-5,\n",
    "    \"sell_cost_pct\":2e-4,\n",
    "    \"reward_scaling\": 1e-4,\n",
    "    \"state_space\": state_space, \n",
    "    \"action_space\": stock_dimension,\n",
    "    \"tech_indicator_list\": config.INDICATORS, \n",
    "    \"print_verbosity\": 1,\n",
    "    \"initial_buy\":True,\n",
    "    \"hundred_each_trade\":True,\n",
    "    \"model_name\":'ppo_agents',\n",
    "    \"mode\":'train',\n",
    "}\n",
    "\n",
    "e_train_gym = StockTradingEnv(df = train, **env_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oyat-FppWzZ_",
   "metadata": {
    "id": "oyat-FppWzZ_"
   },
   "source": [
    "## Train DRL Agents\n",
    "FinRL为我们提供了多种强化学习算法：DDPG，A2C，PPO，SAC，TD3，我们将比较不同的强化学习算法在量化金融中的表现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "loaded-modem",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T11:25:15.288936Z",
     "start_time": "2022-10-12T11:25:15.267689Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "loaded-modem",
    "outputId": "f6fab15a-ecff-46f1-bcb0-f3750cc751fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
     ]
    }
   ],
   "source": [
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "print(type(env_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "thick-blackjack",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T11:25:15.932791Z",
     "start_time": "2022-10-12T11:25:15.882629Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "thick-blackjack",
    "outputId": "d20ac9f8-f707-4fea-ac04-956270a8bd9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 256, 'buffer_size': 100000, 'learning_rate': 0.0005, 'action_noise': NormalActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1])}\n",
      "Using cpu device\n",
      "{'batch_size': 128, 'buffer_size': 100000, 'learning_rate': 0.0001, 'learning_starts': 30, 'ent_coef': 'auto_0.1'}\n",
      "Using cpu device\n",
      "{'n_steps': 20}\n",
      "Using cpu device\n",
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to ./results/ppo\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "DDPG_PARAMS = {\n",
    "                \"batch_size\": 256, \n",
    "               \"buffer_size\": 100000, \n",
    "               \"learning_rate\": 0.0005,\n",
    "               \"action_noise\":\"normal\",\n",
    "                }\n",
    "\n",
    "SAC_PARAMS = {\n",
    "    \"batch_size\": 128,\n",
    "    \"buffer_size\": 100000,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"learning_starts\": 30,\n",
    "    \"ent_coef\": \"auto_0.1\",\n",
    "}\n",
    "\n",
    "PPO_PARAMS = {\n",
    "    \"n_steps\": 2048,\n",
    "    \"ent_coef\": 0.01,\n",
    "    \"learning_rate\": 0.00025,\n",
    "    \"batch_size\": 128,\n",
    "}\n",
    "\n",
    "A2C_PARAMS = {\n",
    "    \"n_steps\": 20,\n",
    "}\n",
    "\n",
    "POLICY_KWARGS = dict(net_arch=dict(pi=[64, 64], qf=[400, 300]))\n",
    "\n",
    "model_ddpg = agent.get_model(\"ddpg\", model_kwargs=DDPG_PARAMS, policy_kwargs=POLICY_KWARGS)\n",
    "model_sac = agent.get_model(\"sac\", model_kwargs=SAC_PARAMS, policy_kwargs=POLICY_KWARGS)\n",
    "model_a2c = agent.get_model('a2c', model_kwargs=A2C_PARAMS)\n",
    "model_ppo = agent.get_model('ppo', model_kwargs=PPO_PARAMS)\n",
    "\n",
    "# set up logger\n",
    "tmp_path = './results/ppo'\n",
    "new_logger = configure(tmp_path, [\"stdout\", \"csv\"])\n",
    "# Set new logger\n",
    "# model_ddpg.set_logger(new_logger)\n",
    "# model_sac.set_logger(new_logger)\n",
    "# model_a2c.set_logger(new_logger)\n",
    "model_ppo.set_logger(new_logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "97d691db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T18:47:40.722780Z",
     "start_time": "2022-10-12T11:25:18.122949Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "growing-supplier",
    "outputId": "7eb00fa2-31d0-4217-8515-fc80db1ebbe9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 2\n",
      "day: 1940, episode: 2\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 15268627.36\n",
      "total_reward: 5268627.36\n",
      "total_cost: 163708.74\n",
      "total_trades: 73656\n",
      "Sharpe: 0.349\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    fps             | 258       |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 7         |\n",
      "|    total_timesteps | 2048      |\n",
      "| train/             |           |\n",
      "|    reward          | -8.524504 |\n",
      "----------------------------------\n",
      "Episode: 3\n",
      "day: 1940, episode: 3\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 16173047.66\n",
      "total_reward: 6173047.66\n",
      "total_cost: 169825.34\n",
      "total_trades: 73654\n",
      "Sharpe: 0.386\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018989038 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.9       |\n",
      "|    explained_variance   | -0.00124    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.1e+03     |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0244     |\n",
      "|    reward               | -3.7176287  |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 3.02e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 4\n",
      "day: 1940, episode: 4\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9205385.94\n",
      "total_reward: -794614.06\n",
      "total_cost: 150230.06\n",
      "total_trades: 73660\n",
      "Sharpe: 0.115\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 232         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017111788 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54         |\n",
      "|    explained_variance   | -0.000513   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.14e+03    |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0223     |\n",
      "|    reward               | -11.854167  |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 2.3e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 5\n",
      "day: 1940, episode: 5\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12604789.44\n",
      "total_reward: 2604789.44\n",
      "total_cost: 149962.56\n",
      "total_trades: 73674\n",
      "Sharpe: 0.250\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 232         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 35          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017889049 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.1       |\n",
      "|    explained_variance   | 0.00447     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 718         |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0272     |\n",
      "|    reward               | -8.819344   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 1.08e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 6\n",
      "day: 1940, episode: 6\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12849968.02\n",
      "total_reward: 2849968.02\n",
      "total_cost: 151604.98\n",
      "total_trades: 73662\n",
      "Sharpe: 0.269\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 231         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 44          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021583462 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.2       |\n",
      "|    explained_variance   | -0.0101     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 659         |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0267     |\n",
      "|    reward               | 8.849718    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 1.57e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 7\n",
      "day: 1940, episode: 7\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13074340.62\n",
      "total_reward: 3074340.62\n",
      "total_cost: 147679.38\n",
      "total_trades: 73667\n",
      "Sharpe: 0.270\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 231         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024609892 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.3       |\n",
      "|    explained_variance   | -0.00365    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 692         |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.029      |\n",
      "|    reward               | 3.9369333   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 1.66e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 8\n",
      "day: 1940, episode: 8\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12530824.95\n",
      "total_reward: 2530824.95\n",
      "total_cost: 154031.05\n",
      "total_trades: 73639\n",
      "Sharpe: 0.247\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 232         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 61          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025299633 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.4       |\n",
      "|    explained_variance   | -0.000654   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.28e+03    |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0271     |\n",
      "|    reward               | 15.6959715  |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 2.29e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 9\n",
      "day: 1940, episode: 9\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11173807.18\n",
      "total_reward: 1173807.18\n",
      "total_cost: 137105.82\n",
      "total_trades: 73652\n",
      "Sharpe: 0.202\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 230         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 71          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026392294 |\n",
      "|    clip_fraction        | 0.305       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.5       |\n",
      "|    explained_variance   | -0.000777   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.41e+03    |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0249     |\n",
      "|    reward               | -11.285718  |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 2.93e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 10\n",
      "day: 1940, episode: 10\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12266530.39\n",
      "total_reward: 2266530.39\n",
      "total_cost: 145973.61\n",
      "total_trades: 73665\n",
      "Sharpe: 0.237\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 230         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 80          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021284057 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.5       |\n",
      "|    explained_variance   | -0.000435   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.26e+03    |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0331     |\n",
      "|    reward               | 3.9849346   |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 2.16e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 11\n",
      "day: 1940, episode: 11\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 16457738.10\n",
      "total_reward: 6457738.10\n",
      "total_cost: 155881.90\n",
      "total_trades: 73670\n",
      "Sharpe: 0.392\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 230         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 88          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032366104 |\n",
      "|    clip_fraction        | 0.327       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.6       |\n",
      "|    explained_variance   | -0.00163    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 693         |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0271     |\n",
      "|    reward               | 0.13367374  |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 1.99e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 12\n",
      "day: 1940, episode: 12\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13689511.52\n",
      "total_reward: 3689511.52\n",
      "total_cost: 144810.48\n",
      "total_trades: 73669\n",
      "Sharpe: 0.295\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 230         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 97          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045898095 |\n",
      "|    clip_fraction        | 0.331       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.7       |\n",
      "|    explained_variance   | -0.00105    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 966         |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0185     |\n",
      "|    reward               | 0.010574052 |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 2.15e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 13\n",
      "day: 1940, episode: 13\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13087527.20\n",
      "total_reward: 3087527.20\n",
      "total_cost: 141667.80\n",
      "total_trades: 73658\n",
      "Sharpe: 0.270\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 230         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 106         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037432216 |\n",
      "|    clip_fraction        | 0.353       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.8       |\n",
      "|    explained_variance   | 8.58e-05    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.18e+03    |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0218     |\n",
      "|    reward               | -8.00219    |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 2.2e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 14\n",
      "day: 1940, episode: 14\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9756999.23\n",
      "total_reward: -243000.77\n",
      "total_cost: 131143.77\n",
      "total_trades: 73673\n",
      "Sharpe: 0.158\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 230         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 115         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032159768 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.9       |\n",
      "|    explained_variance   | -0.00228    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 588         |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0258     |\n",
      "|    reward               | -0.27307907 |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 1.52e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 15\n",
      "day: 1940, episode: 15\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10397849.66\n",
      "total_reward: 397849.66\n",
      "total_cost: 127569.34\n",
      "total_trades: 73665\n",
      "Sharpe: 0.164\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 229        |\n",
      "|    iterations           | 14         |\n",
      "|    time_elapsed         | 124        |\n",
      "|    total_timesteps      | 28672      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03331959 |\n",
      "|    clip_fraction        | 0.349      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -55        |\n",
      "|    explained_variance   | 0.001      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 639        |\n",
      "|    n_updates            | 130        |\n",
      "|    policy_gradient_loss | -0.0234    |\n",
      "|    reward               | 5.2231154  |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 1.45e+03   |\n",
      "----------------------------------------\n",
      "Episode: 16\n",
      "day: 1940, episode: 16\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9891386.01\n",
      "total_reward: -108613.99\n",
      "total_cost: 130747.99\n",
      "total_trades: 73671\n",
      "Sharpe: 0.120\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 229        |\n",
      "|    iterations           | 15         |\n",
      "|    time_elapsed         | 133        |\n",
      "|    total_timesteps      | 30720      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0269477  |\n",
      "|    clip_fraction        | 0.261      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -55.1      |\n",
      "|    explained_variance   | -0.00191   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 786        |\n",
      "|    n_updates            | 140        |\n",
      "|    policy_gradient_loss | -0.0166    |\n",
      "|    reward               | -33.331825 |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 1.87e+03   |\n",
      "----------------------------------------\n",
      "Episode: 17\n",
      "day: 1940, episode: 17\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14202194.17\n",
      "total_reward: 4202194.17\n",
      "total_cost: 146418.83\n",
      "total_trades: 73665\n",
      "Sharpe: 0.319\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 229       |\n",
      "|    iterations           | 16        |\n",
      "|    time_elapsed         | 143       |\n",
      "|    total_timesteps      | 32768     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0352526 |\n",
      "|    clip_fraction        | 0.361     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -55.1     |\n",
      "|    explained_variance   | -0.000345 |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 882       |\n",
      "|    n_updates            | 150       |\n",
      "|    policy_gradient_loss | -0.0216   |\n",
      "|    reward               | 3.2483292 |\n",
      "|    std                  | 1.03      |\n",
      "|    value_loss           | 1.6e+03   |\n",
      "---------------------------------------\n",
      "Episode: 18\n",
      "day: 1940, episode: 18\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11822961.86\n",
      "total_reward: 1822961.86\n",
      "total_cost: 144959.14\n",
      "total_trades: 73669\n",
      "Sharpe: 0.213\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 229        |\n",
      "|    iterations           | 17         |\n",
      "|    time_elapsed         | 151        |\n",
      "|    total_timesteps      | 34816      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03417223 |\n",
      "|    clip_fraction        | 0.312      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -55.2      |\n",
      "|    explained_variance   | 0.00208    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.23e+03   |\n",
      "|    n_updates            | 160        |\n",
      "|    policy_gradient_loss | -0.0194    |\n",
      "|    reward               | 7.3508015  |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 2.08e+03   |\n",
      "----------------------------------------\n",
      "Episode: 19\n",
      "day: 1940, episode: 19\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11113196.21\n",
      "total_reward: 1113196.21\n",
      "total_cost: 135994.79\n",
      "total_trades: 73645\n",
      "Sharpe: 0.209\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 229         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 160         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.04306218  |\n",
      "|    clip_fraction        | 0.384       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.3       |\n",
      "|    explained_variance   | 0.00171     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 695         |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0248     |\n",
      "|    reward               | -0.18945894 |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 1.22e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 20\n",
      "day: 1940, episode: 20\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13648746.44\n",
      "total_reward: 3648746.44\n",
      "total_cost: 137399.56\n",
      "total_trades: 73659\n",
      "Sharpe: 0.293\n",
      "=================================\n",
      "Episode: 21\n",
      "day: 1940, episode: 21\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13816436.03\n",
      "total_reward: 3816436.03\n",
      "total_cost: 130883.97\n",
      "total_trades: 73658\n",
      "Sharpe: 0.299\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 229         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 169         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026176454 |\n",
      "|    clip_fraction        | 0.294       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.4       |\n",
      "|    explained_variance   | 0.00142     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 789         |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0341     |\n",
      "|    reward               | -2.4056697  |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 2e+03       |\n",
      "-----------------------------------------\n",
      "Episode: 22\n",
      "day: 1940, episode: 22\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9031412.45\n",
      "total_reward: -968587.55\n",
      "total_cost: 136668.55\n",
      "total_trades: 73658\n",
      "Sharpe: 0.094\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 228         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 179         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038468167 |\n",
      "|    clip_fraction        | 0.376       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.6       |\n",
      "|    explained_variance   | 0.0125      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.01e+03    |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    reward               | 3.612962    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 1.49e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 23\n",
      "day: 1940, episode: 23\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13875147.38\n",
      "total_reward: 3875147.38\n",
      "total_cost: 138156.62\n",
      "total_trades: 73663\n",
      "Sharpe: 0.305\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 228         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 188         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026292134 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.6       |\n",
      "|    explained_variance   | 0.00823     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.06e+03    |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0254     |\n",
      "|    reward               | -3.1701312  |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 1.42e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 24\n",
      "day: 1940, episode: 24\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10527454.26\n",
      "total_reward: 527454.26\n",
      "total_cost: 130833.74\n",
      "total_trades: 73664\n",
      "Sharpe: 0.185\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 228         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 197         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033302203 |\n",
      "|    clip_fraction        | 0.301       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.7       |\n",
      "|    explained_variance   | 0.00102     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 789         |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0293     |\n",
      "|    reward               | -5.637415   |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 1.68e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 25\n",
      "day: 1940, episode: 25\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14078032.96\n",
      "total_reward: 4078032.96\n",
      "total_cost: 130718.04\n",
      "total_trades: 73667\n",
      "Sharpe: 0.311\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 228         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 206         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034392253 |\n",
      "|    clip_fraction        | 0.319       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.8       |\n",
      "|    explained_variance   | 0.00966     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 515         |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.025      |\n",
      "|    reward               | 5.688355    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 1.31e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 26\n",
      "day: 1940, episode: 26\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12524515.80\n",
      "total_reward: 2524515.80\n",
      "total_cost: 130754.20\n",
      "total_trades: 73672\n",
      "Sharpe: 0.249\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 228        |\n",
      "|    iterations           | 24         |\n",
      "|    time_elapsed         | 215        |\n",
      "|    total_timesteps      | 49152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0377974  |\n",
      "|    clip_fraction        | 0.317      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -55.9      |\n",
      "|    explained_variance   | 0.0119     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 824        |\n",
      "|    n_updates            | 230        |\n",
      "|    policy_gradient_loss | -0.0263    |\n",
      "|    reward               | -2.0912633 |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 1.92e+03   |\n",
      "----------------------------------------\n",
      "Episode: 27\n",
      "day: 1940, episode: 27\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14829754.64\n",
      "total_reward: 4829754.64\n",
      "total_cost: 133521.36\n",
      "total_trades: 73668\n",
      "Sharpe: 0.347\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 228        |\n",
      "|    iterations           | 25         |\n",
      "|    time_elapsed         | 223        |\n",
      "|    total_timesteps      | 51200      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04948041 |\n",
      "|    clip_fraction        | 0.428      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -56        |\n",
      "|    explained_variance   | 0.0216     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 567        |\n",
      "|    n_updates            | 240        |\n",
      "|    policy_gradient_loss | -0.0125    |\n",
      "|    reward               | 34.46914   |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 1.36e+03   |\n",
      "----------------------------------------\n",
      "Episode: 28\n",
      "day: 1940, episode: 28\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11974528.27\n",
      "total_reward: 1974528.27\n",
      "total_cost: 140201.73\n",
      "total_trades: 73661\n",
      "Sharpe: 0.222\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 228         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 232         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031213388 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.1       |\n",
      "|    explained_variance   | 0.0177      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.26e+03    |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0279     |\n",
      "|    reward               | -40.5174    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 2.2e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 29\n",
      "day: 1940, episode: 29\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9981275.87\n",
      "total_reward: -18724.13\n",
      "total_cost: 132209.13\n",
      "total_trades: 73651\n",
      "Sharpe: 0.115\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 228         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 242         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035155162 |\n",
      "|    clip_fraction        | 0.305       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.2       |\n",
      "|    explained_variance   | 0.0281      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.01e+03    |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0228     |\n",
      "|    reward               | -10.841137  |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 2.07e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 30\n",
      "day: 1940, episode: 30\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12261016.53\n",
      "total_reward: 2261016.53\n",
      "total_cost: 128185.47\n",
      "total_trades: 73687\n",
      "Sharpe: 0.240\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 228        |\n",
      "|    iterations           | 28         |\n",
      "|    time_elapsed         | 251        |\n",
      "|    total_timesteps      | 57344      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0273897  |\n",
      "|    clip_fraction        | 0.279      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -56.3      |\n",
      "|    explained_variance   | 0.0334     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.43e+03   |\n",
      "|    n_updates            | 270        |\n",
      "|    policy_gradient_loss | -0.0295    |\n",
      "|    reward               | -2.4022036 |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 1.94e+03   |\n",
      "----------------------------------------\n",
      "Episode: 31\n",
      "day: 1940, episode: 31\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11374243.45\n",
      "total_reward: 1374243.45\n",
      "total_cost: 131989.55\n",
      "total_trades: 73667\n",
      "Sharpe: 0.208\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 228         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 260         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032655388 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.4       |\n",
      "|    explained_variance   | 0.00805     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.39e+03    |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0227     |\n",
      "|    reward               | -4.0755997  |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 2.13e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 32\n",
      "day: 1940, episode: 32\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11426128.23\n",
      "total_reward: 1426128.23\n",
      "total_cost: 119338.77\n",
      "total_trades: 73661\n",
      "Sharpe: 0.218\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 227         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 269         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042265423 |\n",
      "|    clip_fraction        | 0.352       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.5       |\n",
      "|    explained_variance   | 0.0167      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 795         |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0192     |\n",
      "|    reward               | 2.625296    |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 2.26e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 33\n",
      "day: 1940, episode: 33\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12035026.74\n",
      "total_reward: 2035026.74\n",
      "total_cost: 118572.26\n",
      "total_trades: 73671\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 227         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 278         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030906161 |\n",
      "|    clip_fraction        | 0.318       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.6       |\n",
      "|    explained_variance   | 0.0499      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 843         |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0196     |\n",
      "|    reward               | -3.5460973  |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 1.87e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 34\n",
      "day: 1940, episode: 34\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11693392.70\n",
      "total_reward: 1693392.70\n",
      "total_cost: 121233.30\n",
      "total_trades: 73654\n",
      "Sharpe: 0.222\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 227         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 287         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029107666 |\n",
      "|    clip_fraction        | 0.257       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.6       |\n",
      "|    explained_variance   | 0.0443      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.54e+03    |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0222     |\n",
      "|    reward               | -1.7545301  |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 1.86e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 35\n",
      "day: 1940, episode: 35\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 15496987.40\n",
      "total_reward: 5496987.40\n",
      "total_cost: 129253.60\n",
      "total_trades: 73664\n",
      "Sharpe: 0.367\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 227         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 296         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023161381 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.6       |\n",
      "|    explained_variance   | 0.056       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.28e+03    |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0266     |\n",
      "|    reward               | -2.5897903  |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 2.79e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 36\n",
      "day: 1940, episode: 36\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14701015.56\n",
      "total_reward: 4701015.56\n",
      "total_cost: 131757.44\n",
      "total_trades: 73676\n",
      "Sharpe: 0.336\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 227         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 305         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027689986 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.7       |\n",
      "|    explained_variance   | 0.0507      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 757         |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0247     |\n",
      "|    reward               | -13.14142   |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 2.5e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 37\n",
      "day: 1940, episode: 37\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11770882.58\n",
      "total_reward: 1770882.58\n",
      "total_cost: 122260.42\n",
      "total_trades: 73651\n",
      "Sharpe: 0.233\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 228         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 314         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020523027 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.8       |\n",
      "|    explained_variance   | 0.0554      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 850         |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0259     |\n",
      "|    reward               | -15.009219  |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 1.9e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 38\n",
      "day: 1940, episode: 38\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14361408.87\n",
      "total_reward: 4361408.87\n",
      "total_cost: 123559.13\n",
      "total_trades: 73656\n",
      "Sharpe: 0.324\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 227        |\n",
      "|    iterations           | 36         |\n",
      "|    time_elapsed         | 323        |\n",
      "|    total_timesteps      | 73728      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02443922 |\n",
      "|    clip_fraction        | 0.244      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -56.8      |\n",
      "|    explained_variance   | 0.0494     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.09e+03   |\n",
      "|    n_updates            | 350        |\n",
      "|    policy_gradient_loss | -0.0275    |\n",
      "|    reward               | -11.978147 |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 2.27e+03   |\n",
      "----------------------------------------\n",
      "Episode: 39\n",
      "day: 1940, episode: 39\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14134991.15\n",
      "total_reward: 4134991.15\n",
      "total_cost: 133708.85\n",
      "total_trades: 73669\n",
      "Sharpe: 0.315\n",
      "=================================\n",
      "Episode: 40\n",
      "day: 1940, episode: 40\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 15717003.02\n",
      "total_reward: 5717003.02\n",
      "total_cost: 136625.98\n",
      "total_trades: 73657\n",
      "Sharpe: 0.371\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 227         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 332         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025680745 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.9       |\n",
      "|    explained_variance   | 0.0462      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.01e+03    |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0211     |\n",
      "|    reward               | 0.5252837   |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 2.26e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 41\n",
      "day: 1940, episode: 41\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14861380.24\n",
      "total_reward: 4861380.24\n",
      "total_cost: 131510.76\n",
      "total_trades: 73673\n",
      "Sharpe: 0.345\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 227         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 342         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024506643 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57         |\n",
      "|    explained_variance   | 0.0337      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2e+03       |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0229     |\n",
      "|    reward               | 0.015207669 |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 3.17e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 42\n",
      "day: 1940, episode: 42\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 16421006.67\n",
      "total_reward: 6421006.67\n",
      "total_cost: 128131.33\n",
      "total_trades: 73658\n",
      "Sharpe: 0.401\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 227         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 350         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029715225 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.1       |\n",
      "|    explained_variance   | 0.052       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.02e+03    |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0245     |\n",
      "|    reward               | -4.757452   |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 2.71e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 43\n",
      "day: 1940, episode: 43\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14503447.67\n",
      "total_reward: 4503447.67\n",
      "total_cost: 130317.33\n",
      "total_trades: 73672\n",
      "Sharpe: 0.329\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 227         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 359         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026530677 |\n",
      "|    clip_fraction        | 0.28        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.2       |\n",
      "|    explained_variance   | 0.0273      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 863         |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0285     |\n",
      "|    reward               | 11.609581   |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 2.48e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 44\n",
      "day: 1940, episode: 44\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 15347669.27\n",
      "total_reward: 5347669.27\n",
      "total_cost: 130376.73\n",
      "total_trades: 73656\n",
      "Sharpe: 0.366\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 228         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 367         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025066897 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.2       |\n",
      "|    explained_variance   | 0.0417      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.24e+03    |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0256     |\n",
      "|    reward               | -13.590822  |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 2.55e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 45\n",
      "day: 1940, episode: 45\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14047696.66\n",
      "total_reward: 4047696.66\n",
      "total_cost: 126693.34\n",
      "total_trades: 73675\n",
      "Sharpe: 0.314\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 228        |\n",
      "|    iterations           | 42         |\n",
      "|    time_elapsed         | 375        |\n",
      "|    total_timesteps      | 86016      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02265548 |\n",
      "|    clip_fraction        | 0.247      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -57.4      |\n",
      "|    explained_variance   | 0.0437     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.33e+03   |\n",
      "|    n_updates            | 410        |\n",
      "|    policy_gradient_loss | -0.0254    |\n",
      "|    reward               | 7.4518027  |\n",
      "|    std                  | 1.1        |\n",
      "|    value_loss           | 2.55e+03   |\n",
      "----------------------------------------\n",
      "Episode: 46\n",
      "day: 1940, episode: 46\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 15041251.90\n",
      "total_reward: 5041251.90\n",
      "total_cost: 131560.10\n",
      "total_trades: 73670\n",
      "Sharpe: 0.351\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 229        |\n",
      "|    iterations           | 43         |\n",
      "|    time_elapsed         | 383        |\n",
      "|    total_timesteps      | 88064      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02516643 |\n",
      "|    clip_fraction        | 0.264      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -57.4      |\n",
      "|    explained_variance   | 0.0434     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 820        |\n",
      "|    n_updates            | 420        |\n",
      "|    policy_gradient_loss | -0.0252    |\n",
      "|    reward               | 11.413863  |\n",
      "|    std                  | 1.1        |\n",
      "|    value_loss           | 2.08e+03   |\n",
      "----------------------------------------\n",
      "Episode: 47\n",
      "day: 1940, episode: 47\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11256916.87\n",
      "total_reward: 1256916.87\n",
      "total_cost: 118099.13\n",
      "total_trades: 73674\n",
      "Sharpe: 0.209\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 229         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 391         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023646493 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.5       |\n",
      "|    explained_variance   | -0.0126     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.07e+03    |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0233     |\n",
      "|    reward               | -2.141923   |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 2.6e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 48\n",
      "day: 1940, episode: 48\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13521404.78\n",
      "total_reward: 3521404.78\n",
      "total_cost: 120384.22\n",
      "total_trades: 73661\n",
      "Sharpe: 0.288\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 230         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 399         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029127773 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.6       |\n",
      "|    explained_variance   | 0.0308      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 711         |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0243     |\n",
      "|    reward               | 6.6233816   |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 1.91e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 49\n",
      "day: 1940, episode: 49\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13084218.20\n",
      "total_reward: 3084218.20\n",
      "total_cost: 125621.80\n",
      "total_trades: 73657\n",
      "Sharpe: 0.268\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 230         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 407         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022952542 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.6       |\n",
      "|    explained_variance   | 0.0307      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.09e+03    |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0245     |\n",
      "|    reward               | -2.7012737  |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 3.84e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 50\n",
      "day: 1940, episode: 50\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9944402.97\n",
      "total_reward: -55597.03\n",
      "total_cost: 114557.03\n",
      "total_trades: 73670\n",
      "Sharpe: 0.125\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 231         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 415         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036515594 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.7       |\n",
      "|    explained_variance   | 0.0628      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.15e+03    |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.02       |\n",
      "|    reward               | -3.4280286  |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 2.06e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 51\n",
      "day: 1940, episode: 51\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 16004681.17\n",
      "total_reward: 6004681.17\n",
      "total_cost: 124711.83\n",
      "total_trades: 73669\n",
      "Sharpe: 0.385\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 231         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 425         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020224692 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.7       |\n",
      "|    explained_variance   | 0.0972      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 866         |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0285     |\n",
      "|    reward               | 8.3249035   |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 2.56e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 52\n",
      "day: 1940, episode: 52\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 15255738.49\n",
      "total_reward: 5255738.49\n",
      "total_cost: 123400.51\n",
      "total_trades: 73661\n",
      "Sharpe: 0.360\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 231         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 433         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028837828 |\n",
      "|    clip_fraction        | 0.288       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.8       |\n",
      "|    explained_variance   | 0.0288      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.89e+03    |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0287     |\n",
      "|    reward               | -11.84638   |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 2.29e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 53\n",
      "day: 1940, episode: 53\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 15423634.79\n",
      "total_reward: 5423634.79\n",
      "total_cost: 132615.21\n",
      "total_trades: 73680\n",
      "Sharpe: 0.361\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 232         |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 441         |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023262434 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.8       |\n",
      "|    explained_variance   | 0.0421      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.48e+03    |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.0272     |\n",
      "|    reward               | 5.383512    |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 2.47e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 54\n",
      "day: 1940, episode: 54\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12005630.16\n",
      "total_reward: 2005630.16\n",
      "total_cost: 115937.84\n",
      "total_trades: 73673\n",
      "Sharpe: 0.230\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 232         |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 449         |\n",
      "|    total_timesteps      | 104448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039887093 |\n",
      "|    clip_fraction        | 0.347       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.9       |\n",
      "|    explained_variance   | -0.000329   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.03e+03    |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.0181     |\n",
      "|    reward               | 0.7921661   |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 1.95e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 55\n",
      "day: 1940, episode: 55\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12049021.71\n",
      "total_reward: 2049021.71\n",
      "total_cost: 121744.29\n",
      "total_trades: 73663\n",
      "Sharpe: 0.229\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 232        |\n",
      "|    iterations           | 52         |\n",
      "|    time_elapsed         | 457        |\n",
      "|    total_timesteps      | 106496     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02488356 |\n",
      "|    clip_fraction        | 0.244      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -58        |\n",
      "|    explained_variance   | 0.0235     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.14e+03   |\n",
      "|    n_updates            | 510        |\n",
      "|    policy_gradient_loss | -0.0215    |\n",
      "|    reward               | -4.2640285 |\n",
      "|    std                  | 1.12       |\n",
      "|    value_loss           | 1.93e+03   |\n",
      "----------------------------------------\n",
      "Episode: 56\n",
      "day: 1940, episode: 56\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10806862.01\n",
      "total_reward: 806862.01\n",
      "total_cost: 126993.99\n",
      "total_trades: 73672\n",
      "Sharpe: 0.184\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 465         |\n",
      "|    total_timesteps      | 108544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031748287 |\n",
      "|    clip_fraction        | 0.308       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.1       |\n",
      "|    explained_variance   | 0.0326      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 541         |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.0265     |\n",
      "|    reward               | -9.424259   |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 1.41e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 57\n",
      "day: 1940, episode: 57\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14315839.53\n",
      "total_reward: 4315839.53\n",
      "total_cost: 115892.47\n",
      "total_trades: 73674\n",
      "Sharpe: 0.328\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 233        |\n",
      "|    iterations           | 54         |\n",
      "|    time_elapsed         | 473        |\n",
      "|    total_timesteps      | 110592     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03242917 |\n",
      "|    clip_fraction        | 0.316      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -58.2      |\n",
      "|    explained_variance   | 0.0271     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 633        |\n",
      "|    n_updates            | 530        |\n",
      "|    policy_gradient_loss | -0.023     |\n",
      "|    reward               | 4.727483   |\n",
      "|    std                  | 1.12       |\n",
      "|    value_loss           | 1.37e+03   |\n",
      "----------------------------------------\n",
      "Episode: 58\n",
      "day: 1940, episode: 58\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14430299.30\n",
      "total_reward: 4430299.30\n",
      "total_cost: 126073.70\n",
      "total_trades: 73651\n",
      "Sharpe: 0.330\n",
      "=================================\n",
      "Episode: 59\n",
      "day: 1940, episode: 59\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 15282345.86\n",
      "total_reward: 5282345.86\n",
      "total_cost: 124435.14\n",
      "total_trades: 73673\n",
      "Sharpe: 0.365\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 482         |\n",
      "|    total_timesteps      | 112640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029045453 |\n",
      "|    clip_fraction        | 0.324       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.3       |\n",
      "|    explained_variance   | 0.0266      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 727         |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.0209     |\n",
      "|    reward               | -5.9284577  |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 1.82e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 60\n",
      "day: 1940, episode: 60\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12111707.61\n",
      "total_reward: 2111707.61\n",
      "total_cost: 123132.39\n",
      "total_trades: 73673\n",
      "Sharpe: 0.242\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 490         |\n",
      "|    total_timesteps      | 114688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025577765 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.4       |\n",
      "|    explained_variance   | 0.017       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.21e+03    |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | -0.0271     |\n",
      "|    reward               | -4.3472095  |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 2.22e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 61\n",
      "day: 1940, episode: 61\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14953416.65\n",
      "total_reward: 4953416.65\n",
      "total_cost: 122884.35\n",
      "total_trades: 73672\n",
      "Sharpe: 0.350\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 498         |\n",
      "|    total_timesteps      | 116736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025613159 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.5       |\n",
      "|    explained_variance   | 0.0184      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 467         |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.02       |\n",
      "|    reward               | 17.492094   |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 1.52e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 62\n",
      "day: 1940, episode: 62\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11322157.92\n",
      "total_reward: 1322157.92\n",
      "total_cost: 115781.08\n",
      "total_trades: 73655\n",
      "Sharpe: 0.213\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 507         |\n",
      "|    total_timesteps      | 118784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042520896 |\n",
      "|    clip_fraction        | 0.375       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.6       |\n",
      "|    explained_variance   | 0.0116      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.11e+03    |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    reward               | -3.6639147  |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 2.03e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 63\n",
      "day: 1940, episode: 63\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13444000.06\n",
      "total_reward: 3444000.06\n",
      "total_cost: 122595.94\n",
      "total_trades: 73666\n",
      "Sharpe: 0.285\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 234        |\n",
      "|    iterations           | 59         |\n",
      "|    time_elapsed         | 515        |\n",
      "|    total_timesteps      | 120832     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02983668 |\n",
      "|    clip_fraction        | 0.286      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -58.7      |\n",
      "|    explained_variance   | 0.0178     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 796        |\n",
      "|    n_updates            | 580        |\n",
      "|    policy_gradient_loss | -0.021     |\n",
      "|    reward               | 7.2159476  |\n",
      "|    std                  | 1.14       |\n",
      "|    value_loss           | 1.95e+03   |\n",
      "----------------------------------------\n",
      "Episode: 64\n",
      "day: 1940, episode: 64\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12288118.31\n",
      "total_reward: 2288118.31\n",
      "total_cost: 119561.69\n",
      "total_trades: 73669\n",
      "Sharpe: 0.235\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 523         |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025115507 |\n",
      "|    clip_fraction        | 0.304       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.8       |\n",
      "|    explained_variance   | 0.0486      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.34e+03    |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.0223     |\n",
      "|    reward               | 1.6549548   |\n",
      "|    std                  | 1.14        |\n",
      "|    value_loss           | 2.9e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 65\n",
      "day: 1940, episode: 65\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14065563.83\n",
      "total_reward: 4065563.83\n",
      "total_cost: 121269.17\n",
      "total_trades: 73682\n",
      "Sharpe: 0.312\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 531         |\n",
      "|    total_timesteps      | 124928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020860402 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.8       |\n",
      "|    explained_variance   | 0.0759      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.06e+03    |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.0257     |\n",
      "|    reward               | 32.857105   |\n",
      "|    std                  | 1.14        |\n",
      "|    value_loss           | 2.48e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 66\n",
      "day: 1940, episode: 66\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10630957.68\n",
      "total_reward: 630957.68\n",
      "total_cost: 114893.32\n",
      "total_trades: 73659\n",
      "Sharpe: 0.162\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 540         |\n",
      "|    total_timesteps      | 126976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025138684 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.9       |\n",
      "|    explained_variance   | 0.0179      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.36e+03    |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | -0.0241     |\n",
      "|    reward               | 48.365574   |\n",
      "|    std                  | 1.14        |\n",
      "|    value_loss           | 2.83e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 67\n",
      "day: 1940, episode: 67\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13966835.24\n",
      "total_reward: 3966835.24\n",
      "total_cost: 129203.76\n",
      "total_trades: 73666\n",
      "Sharpe: 0.310\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 549         |\n",
      "|    total_timesteps      | 129024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024153378 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59         |\n",
      "|    explained_variance   | 0.0742      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.36e+03    |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.0266     |\n",
      "|    reward               | -5.640754   |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 2.34e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 68\n",
      "day: 1940, episode: 68\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10647643.89\n",
      "total_reward: 647643.89\n",
      "total_cost: 117154.11\n",
      "total_trades: 73675\n",
      "Sharpe: 0.171\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 557         |\n",
      "|    total_timesteps      | 131072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028144635 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.1       |\n",
      "|    explained_variance   | 0.0247      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 985         |\n",
      "|    n_updates            | 630         |\n",
      "|    policy_gradient_loss | -0.0269     |\n",
      "|    reward               | 2.3912752   |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 2.37e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 69\n",
      "day: 1940, episode: 69\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11669782.12\n",
      "total_reward: 1669782.12\n",
      "total_cost: 125236.88\n",
      "total_trades: 73672\n",
      "Sharpe: 0.210\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 565         |\n",
      "|    total_timesteps      | 133120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030949827 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.1       |\n",
      "|    explained_variance   | 0.00987     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 551         |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.0291     |\n",
      "|    reward               | -5.552121   |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 1.44e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 70\n",
      "day: 1940, episode: 70\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11849658.28\n",
      "total_reward: 1849658.28\n",
      "total_cost: 126653.72\n",
      "total_trades: 73668\n",
      "Sharpe: 0.228\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 573         |\n",
      "|    total_timesteps      | 135168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035862535 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.2       |\n",
      "|    explained_variance   | 0.0368      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 677         |\n",
      "|    n_updates            | 650         |\n",
      "|    policy_gradient_loss | -0.035      |\n",
      "|    reward               | 13.165623   |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 1.88e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 71\n",
      "day: 1940, episode: 71\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 15247879.29\n",
      "total_reward: 5247879.29\n",
      "total_cost: 132679.71\n",
      "total_trades: 73676\n",
      "Sharpe: 0.361\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 581         |\n",
      "|    total_timesteps      | 137216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043597892 |\n",
      "|    clip_fraction        | 0.34        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.3       |\n",
      "|    explained_variance   | 0.0143      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.3e+03     |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.00564    |\n",
      "|    reward               | 5.606277    |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 2.41e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 72\n",
      "day: 1940, episode: 72\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14954041.53\n",
      "total_reward: 4954041.53\n",
      "total_cost: 123510.47\n",
      "total_trades: 73649\n",
      "Sharpe: 0.350\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 589         |\n",
      "|    total_timesteps      | 139264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038890876 |\n",
      "|    clip_fraction        | 0.386       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.4       |\n",
      "|    explained_variance   | 0.0283      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 748         |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    reward               | -5.1794953  |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 2.22e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 73\n",
      "day: 1940, episode: 73\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13860749.51\n",
      "total_reward: 3860749.51\n",
      "total_cost: 131060.49\n",
      "total_trades: 73668\n",
      "Sharpe: 0.305\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 598         |\n",
      "|    total_timesteps      | 141312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019965276 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.5       |\n",
      "|    explained_variance   | 0.0368      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.7e+03     |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.0286     |\n",
      "|    reward               | 5.6048565   |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 2.43e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 74\n",
      "day: 1940, episode: 74\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11345955.18\n",
      "total_reward: 1345955.18\n",
      "total_cost: 122209.82\n",
      "total_trades: 73663\n",
      "Sharpe: 0.197\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 607         |\n",
      "|    total_timesteps      | 143360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022642266 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.6       |\n",
      "|    explained_variance   | 0.000623    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.13e+03    |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.0265     |\n",
      "|    reward               | 5.843803    |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 2.13e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 75\n",
      "day: 1940, episode: 75\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9852735.13\n",
      "total_reward: -147264.87\n",
      "total_cost: 115954.87\n",
      "total_trades: 73674\n",
      "Sharpe: 0.133\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 615         |\n",
      "|    total_timesteps      | 145408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034167513 |\n",
      "|    clip_fraction        | 0.343       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.6       |\n",
      "|    explained_variance   | 0.0624      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 976         |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | -0.0211     |\n",
      "|    reward               | 6.702913    |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 1.89e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 76\n",
      "day: 1940, episode: 76\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 16131320.95\n",
      "total_reward: 6131320.95\n",
      "total_cost: 120202.05\n",
      "total_trades: 73673\n",
      "Sharpe: 0.386\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 624         |\n",
      "|    total_timesteps      | 147456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030421518 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.7       |\n",
      "|    explained_variance   | 0.0273      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 990         |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | -0.0265     |\n",
      "|    reward               | -3.6466732  |\n",
      "|    std                  | 1.17        |\n",
      "|    value_loss           | 2.48e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 77\n",
      "day: 1940, episode: 77\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 15116385.97\n",
      "total_reward: 5116385.97\n",
      "total_cost: 120746.03\n",
      "total_trades: 73660\n",
      "Sharpe: 0.359\n",
      "=================================\n",
      "Episode: 78\n",
      "day: 1940, episode: 78\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10371949.85\n",
      "total_reward: 371949.85\n",
      "total_cost: 113935.15\n",
      "total_trades: 73669\n",
      "Sharpe: 0.147\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 632         |\n",
      "|    total_timesteps      | 149504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031492524 |\n",
      "|    clip_fraction        | 0.3         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.8       |\n",
      "|    explained_variance   | 0.0299      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.51e+03    |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | -0.0254     |\n",
      "|    reward               | -1.0468191  |\n",
      "|    std                  | 1.17        |\n",
      "|    value_loss           | 2.35e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 79\n",
      "day: 1940, episode: 79\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12028183.20\n",
      "total_reward: 2028183.20\n",
      "total_cost: 117782.80\n",
      "total_trades: 73667\n",
      "Sharpe: 0.223\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 640         |\n",
      "|    total_timesteps      | 151552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035780095 |\n",
      "|    clip_fraction        | 0.325       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.9       |\n",
      "|    explained_variance   | 0.109       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 743         |\n",
      "|    n_updates            | 730         |\n",
      "|    policy_gradient_loss | -0.0218     |\n",
      "|    reward               | 1.4985706   |\n",
      "|    std                  | 1.17        |\n",
      "|    value_loss           | 1.41e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 80\n",
      "day: 1940, episode: 80\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10753771.02\n",
      "total_reward: 753771.02\n",
      "total_cost: 122765.98\n",
      "total_trades: 73672\n",
      "Sharpe: 0.172\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 236        |\n",
      "|    iterations           | 75         |\n",
      "|    time_elapsed         | 648        |\n",
      "|    total_timesteps      | 153600     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03944653 |\n",
      "|    clip_fraction        | 0.365      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -60        |\n",
      "|    explained_variance   | 0.0894     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 669        |\n",
      "|    n_updates            | 740        |\n",
      "|    policy_gradient_loss | -0.016     |\n",
      "|    reward               | 0.5127313  |\n",
      "|    std                  | 1.18       |\n",
      "|    value_loss           | 1.9e+03    |\n",
      "----------------------------------------\n",
      "Episode: 81\n",
      "day: 1940, episode: 81\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11801880.82\n",
      "total_reward: 1801880.82\n",
      "total_cost: 115243.18\n",
      "total_trades: 73673\n",
      "Sharpe: 0.215\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 656         |\n",
      "|    total_timesteps      | 155648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022183886 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.1       |\n",
      "|    explained_variance   | 0.0763      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 685         |\n",
      "|    n_updates            | 750         |\n",
      "|    policy_gradient_loss | -0.0299     |\n",
      "|    reward               | 14.002259   |\n",
      "|    std                  | 1.18        |\n",
      "|    value_loss           | 1.64e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 82\n",
      "day: 1940, episode: 82\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11883470.82\n",
      "total_reward: 1883470.82\n",
      "total_cost: 124009.18\n",
      "total_trades: 73666\n",
      "Sharpe: 0.217\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 666         |\n",
      "|    total_timesteps      | 157696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020039879 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.2       |\n",
      "|    explained_variance   | 0.14        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.24e+03    |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -0.0263     |\n",
      "|    reward               | -5.3472633  |\n",
      "|    std                  | 1.18        |\n",
      "|    value_loss           | 1.92e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 83\n",
      "day: 1940, episode: 83\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10359190.82\n",
      "total_reward: 359190.82\n",
      "total_cost: 128033.18\n",
      "total_trades: 73679\n",
      "Sharpe: 0.169\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 674         |\n",
      "|    total_timesteps      | 159744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027710365 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.3       |\n",
      "|    explained_variance   | -0.015      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 675         |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | -0.0211     |\n",
      "|    reward               | 1.8443505   |\n",
      "|    std                  | 1.18        |\n",
      "|    value_loss           | 1.79e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 84\n",
      "day: 1940, episode: 84\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10289953.38\n",
      "total_reward: 289953.38\n",
      "total_cost: 121718.62\n",
      "total_trades: 73674\n",
      "Sharpe: 0.142\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 79          |\n",
      "|    time_elapsed         | 682         |\n",
      "|    total_timesteps      | 161792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032969836 |\n",
      "|    clip_fraction        | 0.288       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.4       |\n",
      "|    explained_variance   | 0.0229      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 635         |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.0263     |\n",
      "|    reward               | -8.112898   |\n",
      "|    std                  | 1.19        |\n",
      "|    value_loss           | 1.51e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 85\n",
      "day: 1940, episode: 85\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12764110.85\n",
      "total_reward: 2764110.85\n",
      "total_cost: 120873.15\n",
      "total_trades: 73671\n",
      "Sharpe: 0.258\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 690         |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040021993 |\n",
      "|    clip_fraction        | 0.362       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.4       |\n",
      "|    explained_variance   | 0.0499      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 722         |\n",
      "|    n_updates            | 790         |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    reward               | 34.902428   |\n",
      "|    std                  | 1.19        |\n",
      "|    value_loss           | 1.87e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 86\n",
      "day: 1940, episode: 86\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11145676.16\n",
      "total_reward: 1145676.16\n",
      "total_cost: 123613.84\n",
      "total_trades: 73660\n",
      "Sharpe: 0.188\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 237        |\n",
      "|    iterations           | 81         |\n",
      "|    time_elapsed         | 698        |\n",
      "|    total_timesteps      | 165888     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03715772 |\n",
      "|    clip_fraction        | 0.374      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -60.5      |\n",
      "|    explained_variance   | 0.0463     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.01e+03   |\n",
      "|    n_updates            | 800        |\n",
      "|    policy_gradient_loss | -0.0191    |\n",
      "|    reward               | -9.607943  |\n",
      "|    std                  | 1.19       |\n",
      "|    value_loss           | 2.51e+03   |\n",
      "----------------------------------------\n",
      "Episode: 87\n",
      "day: 1940, episode: 87\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11767334.65\n",
      "total_reward: 1767334.65\n",
      "total_cost: 131620.35\n",
      "total_trades: 73668\n",
      "Sharpe: 0.210\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 237        |\n",
      "|    iterations           | 82         |\n",
      "|    time_elapsed         | 706        |\n",
      "|    total_timesteps      | 167936     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02961162 |\n",
      "|    clip_fraction        | 0.267      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -60.6      |\n",
      "|    explained_variance   | 0.0339     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.37e+03   |\n",
      "|    n_updates            | 810        |\n",
      "|    policy_gradient_loss | -0.0263    |\n",
      "|    reward               | 9.787343   |\n",
      "|    std                  | 1.2        |\n",
      "|    value_loss           | 2.33e+03   |\n",
      "----------------------------------------\n",
      "Episode: 88\n",
      "day: 1940, episode: 88\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14136360.76\n",
      "total_reward: 4136360.76\n",
      "total_cost: 135925.24\n",
      "total_trades: 73674\n",
      "Sharpe: 0.318\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 714         |\n",
      "|    total_timesteps      | 169984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037682615 |\n",
      "|    clip_fraction        | 0.335       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.7       |\n",
      "|    explained_variance   | 0.0121      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 940         |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -0.0259     |\n",
      "|    reward               | 14.824418   |\n",
      "|    std                  | 1.2         |\n",
      "|    value_loss           | 2.12e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 89\n",
      "day: 1940, episode: 89\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13522146.26\n",
      "total_reward: 3522146.26\n",
      "total_cost: 143318.74\n",
      "total_trades: 73667\n",
      "Sharpe: 0.295\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 724         |\n",
      "|    total_timesteps      | 172032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027020939 |\n",
      "|    clip_fraction        | 0.28        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.9       |\n",
      "|    explained_variance   | 0.0197      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 877         |\n",
      "|    n_updates            | 830         |\n",
      "|    policy_gradient_loss | -0.0275     |\n",
      "|    reward               | 2.5223877   |\n",
      "|    std                  | 1.2         |\n",
      "|    value_loss           | 1.87e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 90\n",
      "day: 1940, episode: 90\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11781280.07\n",
      "total_reward: 1781280.07\n",
      "total_cost: 133678.93\n",
      "total_trades: 73674\n",
      "Sharpe: 0.216\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 732         |\n",
      "|    total_timesteps      | 174080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027638566 |\n",
      "|    clip_fraction        | 0.319       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61         |\n",
      "|    explained_variance   | 0.00455     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.01e+03    |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | -0.0237     |\n",
      "|    reward               | 0.0439573   |\n",
      "|    std                  | 1.21        |\n",
      "|    value_loss           | 1.87e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 91\n",
      "day: 1940, episode: 91\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14718136.83\n",
      "total_reward: 4718136.83\n",
      "total_cost: 138915.17\n",
      "total_trades: 73666\n",
      "Sharpe: 0.339\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 86          |\n",
      "|    time_elapsed         | 741         |\n",
      "|    total_timesteps      | 176128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033473104 |\n",
      "|    clip_fraction        | 0.334       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.1       |\n",
      "|    explained_variance   | 0.0244      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 816         |\n",
      "|    n_updates            | 850         |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    reward               | 1.6404483   |\n",
      "|    std                  | 1.21        |\n",
      "|    value_loss           | 1.84e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 92\n",
      "day: 1940, episode: 92\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11934131.48\n",
      "total_reward: 1934131.48\n",
      "total_cost: 131765.52\n",
      "total_trades: 73686\n",
      "Sharpe: 0.220\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 749         |\n",
      "|    total_timesteps      | 178176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022911822 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.2       |\n",
      "|    explained_variance   | 0.00222     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.28e+03    |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.0326     |\n",
      "|    reward               | -6.307958   |\n",
      "|    std                  | 1.22        |\n",
      "|    value_loss           | 2.47e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 93\n",
      "day: 1940, episode: 93\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12616109.95\n",
      "total_reward: 2616109.95\n",
      "total_cost: 139689.05\n",
      "total_trades: 73673\n",
      "Sharpe: 0.257\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 88          |\n",
      "|    time_elapsed         | 757         |\n",
      "|    total_timesteps      | 180224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029378157 |\n",
      "|    clip_fraction        | 0.309       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.3       |\n",
      "|    explained_variance   | -0.00723    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 855         |\n",
      "|    n_updates            | 870         |\n",
      "|    policy_gradient_loss | -0.0229     |\n",
      "|    reward               | -37.290768  |\n",
      "|    std                  | 1.22        |\n",
      "|    value_loss           | 1.5e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 94\n",
      "day: 1940, episode: 94\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12775101.83\n",
      "total_reward: 2775101.83\n",
      "total_cost: 136101.17\n",
      "total_trades: 73667\n",
      "Sharpe: 0.269\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 238        |\n",
      "|    iterations           | 89         |\n",
      "|    time_elapsed         | 765        |\n",
      "|    total_timesteps      | 182272     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02889029 |\n",
      "|    clip_fraction        | 0.281      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -61.4      |\n",
      "|    explained_variance   | -0.00367   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 745        |\n",
      "|    n_updates            | 880        |\n",
      "|    policy_gradient_loss | -0.0279    |\n",
      "|    reward               | 6.132735   |\n",
      "|    std                  | 1.22       |\n",
      "|    value_loss           | 1.57e+03   |\n",
      "----------------------------------------\n",
      "Episode: 95\n",
      "day: 1940, episode: 95\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 15731145.92\n",
      "total_reward: 5731145.92\n",
      "total_cost: 137529.08\n",
      "total_trades: 73665\n",
      "Sharpe: 0.383\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 773         |\n",
      "|    total_timesteps      | 184320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018708883 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.4       |\n",
      "|    explained_variance   | -0.00667    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 944         |\n",
      "|    n_updates            | 890         |\n",
      "|    policy_gradient_loss | -0.0321     |\n",
      "|    reward               | -0.27285382 |\n",
      "|    std                  | 1.22        |\n",
      "|    value_loss           | 1.88e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 96\n",
      "day: 1940, episode: 96\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 17322708.13\n",
      "total_reward: 7322708.13\n",
      "total_cost: 134117.87\n",
      "total_trades: 73679\n",
      "Sharpe: 0.423\n",
      "=================================\n",
      "Episode: 97\n",
      "day: 1940, episode: 97\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 16107628.87\n",
      "total_reward: 6107628.87\n",
      "total_cost: 134483.13\n",
      "total_trades: 73677\n",
      "Sharpe: 0.395\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 782         |\n",
      "|    total_timesteps      | 186368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037476704 |\n",
      "|    clip_fraction        | 0.32        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.5       |\n",
      "|    explained_variance   | 0.00137     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 714         |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    reward               | -0.65032506 |\n",
      "|    std                  | 1.22        |\n",
      "|    value_loss           | 2.26e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 98\n",
      "day: 1940, episode: 98\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 15802791.58\n",
      "total_reward: 5802791.58\n",
      "total_cost: 140654.42\n",
      "total_trades: 73681\n",
      "Sharpe: 0.380\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 791         |\n",
      "|    total_timesteps      | 188416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021162007 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.6       |\n",
      "|    explained_variance   | 0.0157      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 740         |\n",
      "|    n_updates            | 910         |\n",
      "|    policy_gradient_loss | -0.0307     |\n",
      "|    reward               | -5.6720214  |\n",
      "|    std                  | 1.23        |\n",
      "|    value_loss           | 2.13e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 99\n",
      "day: 1940, episode: 99\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 17337961.27\n",
      "total_reward: 7337961.27\n",
      "total_cost: 141355.73\n",
      "total_trades: 73675\n",
      "Sharpe: 0.436\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 799         |\n",
      "|    total_timesteps      | 190464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043233648 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.7       |\n",
      "|    explained_variance   | -0.017      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 608         |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | -0.0202     |\n",
      "|    reward               | 1.6144227   |\n",
      "|    std                  | 1.23        |\n",
      "|    value_loss           | 1.95e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 100\n",
      "day: 1940, episode: 100\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14134812.59\n",
      "total_reward: 4134812.59\n",
      "total_cost: 134304.41\n",
      "total_trades: 73680\n",
      "Sharpe: 0.322\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 238        |\n",
      "|    iterations           | 94         |\n",
      "|    time_elapsed         | 807        |\n",
      "|    total_timesteps      | 192512     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01874049 |\n",
      "|    clip_fraction        | 0.202      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -61.7      |\n",
      "|    explained_variance   | 0.00573    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 978        |\n",
      "|    n_updates            | 930        |\n",
      "|    policy_gradient_loss | -0.0269    |\n",
      "|    reward               | 15.413993  |\n",
      "|    std                  | 1.23       |\n",
      "|    value_loss           | 2.48e+03   |\n",
      "----------------------------------------\n",
      "Episode: 101\n",
      "day: 1940, episode: 101\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14665080.51\n",
      "total_reward: 4665080.51\n",
      "total_cost: 138263.49\n",
      "total_trades: 73668\n",
      "Sharpe: 0.334\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 815         |\n",
      "|    total_timesteps      | 194560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044464827 |\n",
      "|    clip_fraction        | 0.327       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.8       |\n",
      "|    explained_variance   | -0.00912    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 815         |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    reward               | 1.6822908   |\n",
      "|    std                  | 1.23        |\n",
      "|    value_loss           | 1.54e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 102\n",
      "day: 1940, episode: 102\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 16128211.18\n",
      "total_reward: 6128211.18\n",
      "total_cost: 138525.82\n",
      "total_trades: 73692\n",
      "Sharpe: 0.390\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 823         |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027398532 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.9       |\n",
      "|    explained_variance   | 0.0112      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.28e+03    |\n",
      "|    n_updates            | 950         |\n",
      "|    policy_gradient_loss | -0.0279     |\n",
      "|    reward               | 3.4506867   |\n",
      "|    std                  | 1.24        |\n",
      "|    value_loss           | 2.39e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 103\n",
      "day: 1940, episode: 103\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 16996527.09\n",
      "total_reward: 6996527.09\n",
      "total_cost: 138342.91\n",
      "total_trades: 73668\n",
      "Sharpe: 0.410\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 831         |\n",
      "|    total_timesteps      | 198656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023813661 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62         |\n",
      "|    explained_variance   | -0.0233     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.07e+03    |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.0249     |\n",
      "|    reward               | -2.403937   |\n",
      "|    std                  | 1.24        |\n",
      "|    value_loss           | 1.93e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 104\n",
      "day: 1940, episode: 104\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12320357.79\n",
      "total_reward: 2320357.79\n",
      "total_cost: 128502.21\n",
      "total_trades: 73670\n",
      "Sharpe: 0.254\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 839         |\n",
      "|    total_timesteps      | 200704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034757964 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.1       |\n",
      "|    explained_variance   | 0.0089      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.19e+03    |\n",
      "|    n_updates            | 970         |\n",
      "|    policy_gradient_loss | -0.0187     |\n",
      "|    reward               | 15.416338   |\n",
      "|    std                  | 1.24        |\n",
      "|    value_loss           | 2.46e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 105\n",
      "day: 1940, episode: 105\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 18787239.43\n",
      "total_reward: 8787239.43\n",
      "total_cost: 138351.57\n",
      "total_trades: 73664\n",
      "Sharpe: 0.487\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 848         |\n",
      "|    total_timesteps      | 202752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025008913 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.2       |\n",
      "|    explained_variance   | 0.0206      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 945         |\n",
      "|    n_updates            | 980         |\n",
      "|    policy_gradient_loss | -0.0316     |\n",
      "|    reward               | 38.268547   |\n",
      "|    std                  | 1.25        |\n",
      "|    value_loss           | 2.09e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 106\n",
      "day: 1940, episode: 106\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 17557100.38\n",
      "total_reward: 7557100.38\n",
      "total_cost: 131984.62\n",
      "total_trades: 73675\n",
      "Sharpe: 0.440\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 100         |\n",
      "|    time_elapsed         | 856         |\n",
      "|    total_timesteps      | 204800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034969285 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.3       |\n",
      "|    explained_variance   | 0.0107      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.69e+03    |\n",
      "|    n_updates            | 990         |\n",
      "|    policy_gradient_loss | -0.0235     |\n",
      "|    reward               | 0.305922    |\n",
      "|    std                  | 1.25        |\n",
      "|    value_loss           | 2.89e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 107\n",
      "day: 1940, episode: 107\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13354060.84\n",
      "total_reward: 3354060.84\n",
      "total_cost: 133575.16\n",
      "total_trades: 73675\n",
      "Sharpe: 0.286\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 101         |\n",
      "|    time_elapsed         | 864         |\n",
      "|    total_timesteps      | 206848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047613814 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.4       |\n",
      "|    explained_variance   | 0.0227      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.03e+03    |\n",
      "|    n_updates            | 1000        |\n",
      "|    policy_gradient_loss | -0.0262     |\n",
      "|    reward               | 8.175851    |\n",
      "|    std                  | 1.26        |\n",
      "|    value_loss           | 2.11e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 108\n",
      "day: 1940, episode: 108\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 20380829.20\n",
      "total_reward: 10380829.20\n",
      "total_cost: 137844.80\n",
      "total_trades: 73680\n",
      "Sharpe: 0.516\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 239      |\n",
      "|    iterations           | 102      |\n",
      "|    time_elapsed         | 873      |\n",
      "|    total_timesteps      | 208896   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.033832 |\n",
      "|    clip_fraction        | 0.319    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -62.6    |\n",
      "|    explained_variance   | 0.00253  |\n",
      "|    learning_rate        | 0.00025  |\n",
      "|    loss                 | 892      |\n",
      "|    n_updates            | 1010     |\n",
      "|    policy_gradient_loss | -0.0209  |\n",
      "|    reward               | 5.297442 |\n",
      "|    std                  | 1.26     |\n",
      "|    value_loss           | 2.03e+03 |\n",
      "--------------------------------------\n",
      "Episode: 109\n",
      "day: 1940, episode: 109\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 15860750.17\n",
      "total_reward: 5860750.17\n",
      "total_cost: 136683.83\n",
      "total_trades: 73664\n",
      "Sharpe: 0.377\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 103         |\n",
      "|    time_elapsed         | 881         |\n",
      "|    total_timesteps      | 210944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026120262 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.7       |\n",
      "|    explained_variance   | 0.0111      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 996         |\n",
      "|    n_updates            | 1020        |\n",
      "|    policy_gradient_loss | -0.0243     |\n",
      "|    reward               | -22.150457  |\n",
      "|    std                  | 1.26        |\n",
      "|    value_loss           | 2.49e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 110\n",
      "day: 1940, episode: 110\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14416154.99\n",
      "total_reward: 4416154.99\n",
      "total_cost: 133493.01\n",
      "total_trades: 73677\n",
      "Sharpe: 0.330\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 104         |\n",
      "|    time_elapsed         | 889         |\n",
      "|    total_timesteps      | 212992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.049926937 |\n",
      "|    clip_fraction        | 0.357       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.8       |\n",
      "|    explained_variance   | -0.00404    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 743         |\n",
      "|    n_updates            | 1030        |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | -11.793726  |\n",
      "|    std                  | 1.27        |\n",
      "|    value_loss           | 1.75e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 111\n",
      "day: 1940, episode: 111\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 19369385.67\n",
      "total_reward: 9369385.67\n",
      "total_cost: 137041.33\n",
      "total_trades: 73677\n",
      "Sharpe: 0.488\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 105         |\n",
      "|    time_elapsed         | 897         |\n",
      "|    total_timesteps      | 215040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036096346 |\n",
      "|    clip_fraction        | 0.307       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.9       |\n",
      "|    explained_variance   | 6.56e-06    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 835         |\n",
      "|    n_updates            | 1040        |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    reward               | 3.9865348   |\n",
      "|    std                  | 1.27        |\n",
      "|    value_loss           | 2.2e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 112\n",
      "day: 1940, episode: 112\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13262476.70\n",
      "total_reward: 3262476.70\n",
      "total_cost: 126800.30\n",
      "total_trades: 73672\n",
      "Sharpe: 0.287\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 106         |\n",
      "|    time_elapsed         | 906         |\n",
      "|    total_timesteps      | 217088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030400671 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.1       |\n",
      "|    explained_variance   | 0.000428    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.47e+03    |\n",
      "|    n_updates            | 1050        |\n",
      "|    policy_gradient_loss | -0.0221     |\n",
      "|    reward               | -68.785805  |\n",
      "|    std                  | 1.28        |\n",
      "|    value_loss           | 2.01e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 113\n",
      "day: 1940, episode: 113\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 17139846.62\n",
      "total_reward: 7139846.62\n",
      "total_cost: 139552.38\n",
      "total_trades: 73661\n",
      "Sharpe: 0.416\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 107         |\n",
      "|    time_elapsed         | 914         |\n",
      "|    total_timesteps      | 219136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030470166 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.1       |\n",
      "|    explained_variance   | 0.00742     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.17e+03    |\n",
      "|    n_updates            | 1060        |\n",
      "|    policy_gradient_loss | -0.0216     |\n",
      "|    reward               | 28.733416   |\n",
      "|    std                  | 1.28        |\n",
      "|    value_loss           | 2.33e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 114\n",
      "day: 1940, episode: 114\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 17184491.46\n",
      "total_reward: 7184491.46\n",
      "total_cost: 139743.54\n",
      "total_trades: 73670\n",
      "Sharpe: 0.423\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 239        |\n",
      "|    iterations           | 108        |\n",
      "|    time_elapsed         | 922        |\n",
      "|    total_timesteps      | 221184     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06321371 |\n",
      "|    clip_fraction        | 0.325      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -63.2      |\n",
      "|    explained_variance   | 0.0108     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.02e+03   |\n",
      "|    n_updates            | 1070       |\n",
      "|    policy_gradient_loss | -0.00843   |\n",
      "|    reward               | -17.808722 |\n",
      "|    std                  | 1.28       |\n",
      "|    value_loss           | 2.53e+03   |\n",
      "----------------------------------------\n",
      "Episode: 115\n",
      "day: 1940, episode: 115\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13075929.76\n",
      "total_reward: 3075929.76\n",
      "total_cost: 136124.24\n",
      "total_trades: 73677\n",
      "Sharpe: 0.285\n",
      "=================================\n",
      "Episode: 116\n",
      "day: 1940, episode: 116\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14315651.03\n",
      "total_reward: 4315651.03\n",
      "total_cost: 137952.97\n",
      "total_trades: 73664\n",
      "Sharpe: 0.323\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 239        |\n",
      "|    iterations           | 109        |\n",
      "|    time_elapsed         | 930        |\n",
      "|    total_timesteps      | 223232     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03403171 |\n",
      "|    clip_fraction        | 0.312      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -63.2      |\n",
      "|    explained_variance   | 0.0312     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 485        |\n",
      "|    n_updates            | 1080       |\n",
      "|    policy_gradient_loss | -0.0299    |\n",
      "|    reward               | 3.6808362  |\n",
      "|    std                  | 1.28       |\n",
      "|    value_loss           | 1.26e+03   |\n",
      "----------------------------------------\n",
      "Episode: 117\n",
      "day: 1940, episode: 117\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 15900569.59\n",
      "total_reward: 5900569.59\n",
      "total_cost: 142903.41\n",
      "total_trades: 73673\n",
      "Sharpe: 0.386\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 239        |\n",
      "|    iterations           | 110        |\n",
      "|    time_elapsed         | 938        |\n",
      "|    total_timesteps      | 225280     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03699488 |\n",
      "|    clip_fraction        | 0.269      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -63.3      |\n",
      "|    explained_variance   | 0.000675   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.13e+03   |\n",
      "|    n_updates            | 1090       |\n",
      "|    policy_gradient_loss | -0.0205    |\n",
      "|    reward               | -13.866593 |\n",
      "|    std                  | 1.28       |\n",
      "|    value_loss           | 1.91e+03   |\n",
      "----------------------------------------\n",
      "Episode: 118\n",
      "day: 1940, episode: 118\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 15365072.02\n",
      "total_reward: 5365072.02\n",
      "total_cost: 146749.98\n",
      "total_trades: 73676\n",
      "Sharpe: 0.364\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 111         |\n",
      "|    time_elapsed         | 947         |\n",
      "|    total_timesteps      | 227328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.056270838 |\n",
      "|    clip_fraction        | 0.351       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.4       |\n",
      "|    explained_variance   | 0.0132      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 719         |\n",
      "|    n_updates            | 1100        |\n",
      "|    policy_gradient_loss | -0.00988    |\n",
      "|    reward               | -0.7858346  |\n",
      "|    std                  | 1.29        |\n",
      "|    value_loss           | 2.04e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 119\n",
      "day: 1940, episode: 119\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10389486.76\n",
      "total_reward: 389486.76\n",
      "total_cost: 135758.24\n",
      "total_trades: 73681\n",
      "Sharpe: 0.160\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 112         |\n",
      "|    time_elapsed         | 955         |\n",
      "|    total_timesteps      | 229376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037609234 |\n",
      "|    clip_fraction        | 0.293       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.5       |\n",
      "|    explained_variance   | 0.000112    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.24e+03    |\n",
      "|    n_updates            | 1110        |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    reward               | -2.457426   |\n",
      "|    std                  | 1.29        |\n",
      "|    value_loss           | 2.21e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 120\n",
      "day: 1940, episode: 120\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12300309.25\n",
      "total_reward: 2300309.25\n",
      "total_cost: 137695.75\n",
      "total_trades: 73680\n",
      "Sharpe: 0.239\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 113         |\n",
      "|    time_elapsed         | 964         |\n",
      "|    total_timesteps      | 231424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038979433 |\n",
      "|    clip_fraction        | 0.332       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.6       |\n",
      "|    explained_variance   | 0.0138      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 489         |\n",
      "|    n_updates            | 1120        |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    reward               | 43.553864   |\n",
      "|    std                  | 1.29        |\n",
      "|    value_loss           | 1.38e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 121\n",
      "day: 1940, episode: 121\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11102483.76\n",
      "total_reward: 1102483.76\n",
      "total_cost: 121149.24\n",
      "total_trades: 73685\n",
      "Sharpe: 0.187\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 114         |\n",
      "|    time_elapsed         | 972         |\n",
      "|    total_timesteps      | 233472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029497694 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.7       |\n",
      "|    explained_variance   | -0.00303    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 985         |\n",
      "|    n_updates            | 1130        |\n",
      "|    policy_gradient_loss | -0.0216     |\n",
      "|    reward               | -10.114688  |\n",
      "|    std                  | 1.3         |\n",
      "|    value_loss           | 1.97e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 122\n",
      "day: 1940, episode: 122\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13657309.23\n",
      "total_reward: 3657309.23\n",
      "total_cost: 141268.77\n",
      "total_trades: 73665\n",
      "Sharpe: 0.298\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 115         |\n",
      "|    time_elapsed         | 980         |\n",
      "|    total_timesteps      | 235520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030451223 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.8       |\n",
      "|    explained_variance   | 0.00297     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.15e+03    |\n",
      "|    n_updates            | 1140        |\n",
      "|    policy_gradient_loss | -0.027      |\n",
      "|    reward               | -17.312834  |\n",
      "|    std                  | 1.3         |\n",
      "|    value_loss           | 1.99e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 123\n",
      "day: 1940, episode: 123\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11854254.29\n",
      "total_reward: 1854254.29\n",
      "total_cost: 128859.71\n",
      "total_trades: 73681\n",
      "Sharpe: 0.216\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 240        |\n",
      "|    iterations           | 116        |\n",
      "|    time_elapsed         | 988        |\n",
      "|    total_timesteps      | 237568     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05177555 |\n",
      "|    clip_fraction        | 0.377      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -63.9      |\n",
      "|    explained_variance   | 0.0388     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.05e+03   |\n",
      "|    n_updates            | 1150       |\n",
      "|    policy_gradient_loss | -0.0108    |\n",
      "|    reward               | 10.934207  |\n",
      "|    std                  | 1.3        |\n",
      "|    value_loss           | 2.15e+03   |\n",
      "----------------------------------------\n",
      "Episode: 124\n",
      "day: 1940, episode: 124\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14011320.96\n",
      "total_reward: 4011320.96\n",
      "total_cost: 134592.04\n",
      "total_trades: 73677\n",
      "Sharpe: 0.312\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 117         |\n",
      "|    time_elapsed         | 996         |\n",
      "|    total_timesteps      | 239616      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036686733 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64         |\n",
      "|    explained_variance   | 0.024       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 692         |\n",
      "|    n_updates            | 1160        |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    reward               | -2.6740968  |\n",
      "|    std                  | 1.31        |\n",
      "|    value_loss           | 2.05e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 125\n",
      "day: 1940, episode: 125\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13894296.47\n",
      "total_reward: 3894296.47\n",
      "total_cost: 142745.53\n",
      "total_trades: 73669\n",
      "Sharpe: 0.311\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 118         |\n",
      "|    time_elapsed         | 1004        |\n",
      "|    total_timesteps      | 241664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.061309792 |\n",
      "|    clip_fraction        | 0.387       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64         |\n",
      "|    explained_variance   | 0.0154      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.15e+03    |\n",
      "|    n_updates            | 1170        |\n",
      "|    policy_gradient_loss | -0.00266    |\n",
      "|    reward               | 4.0928955   |\n",
      "|    std                  | 1.31        |\n",
      "|    value_loss           | 2.09e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 126\n",
      "day: 1940, episode: 126\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11500961.96\n",
      "total_reward: 1500961.96\n",
      "total_cost: 139671.04\n",
      "total_trades: 73674\n",
      "Sharpe: 0.211\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 119         |\n",
      "|    time_elapsed         | 1012        |\n",
      "|    total_timesteps      | 243712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024480969 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.2       |\n",
      "|    explained_variance   | -0.00142    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 832         |\n",
      "|    n_updates            | 1180        |\n",
      "|    policy_gradient_loss | -0.029      |\n",
      "|    reward               | 21.60492    |\n",
      "|    std                  | 1.31        |\n",
      "|    value_loss           | 1.44e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 127\n",
      "day: 1940, episode: 127\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11616861.89\n",
      "total_reward: 1616861.89\n",
      "total_cost: 136447.11\n",
      "total_trades: 73667\n",
      "Sharpe: 0.207\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 120         |\n",
      "|    time_elapsed         | 1022        |\n",
      "|    total_timesteps      | 245760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028170288 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.3       |\n",
      "|    explained_variance   | -0.00757    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 800         |\n",
      "|    n_updates            | 1190        |\n",
      "|    policy_gradient_loss | -0.0251     |\n",
      "|    reward               | 4.228345    |\n",
      "|    std                  | 1.32        |\n",
      "|    value_loss           | 1.93e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 128\n",
      "day: 1940, episode: 128\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12096336.18\n",
      "total_reward: 2096336.18\n",
      "total_cost: 134783.82\n",
      "total_trades: 73675\n",
      "Sharpe: 0.229\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 121         |\n",
      "|    time_elapsed         | 1031        |\n",
      "|    total_timesteps      | 247808      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026191859 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.4       |\n",
      "|    explained_variance   | -0.006      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.5e+03     |\n",
      "|    n_updates            | 1200        |\n",
      "|    policy_gradient_loss | -0.0252     |\n",
      "|    reward               | 2.1383634   |\n",
      "|    std                  | 1.32        |\n",
      "|    value_loss           | 2.18e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 129\n",
      "day: 1940, episode: 129\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12334329.94\n",
      "total_reward: 2334329.94\n",
      "total_cost: 137376.06\n",
      "total_trades: 73675\n",
      "Sharpe: 0.237\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 122         |\n",
      "|    time_elapsed         | 1039        |\n",
      "|    total_timesteps      | 249856      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026093913 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.5       |\n",
      "|    explained_variance   | -0.00895    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 962         |\n",
      "|    n_updates            | 1210        |\n",
      "|    policy_gradient_loss | -0.0302     |\n",
      "|    reward               | 1.8044772   |\n",
      "|    std                  | 1.32        |\n",
      "|    value_loss           | 2.28e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 130\n",
      "day: 1940, episode: 130\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10334410.03\n",
      "total_reward: 334410.03\n",
      "total_cost: 132803.97\n",
      "total_trades: 73677\n",
      "Sharpe: 0.167\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 123         |\n",
      "|    time_elapsed         | 1047        |\n",
      "|    total_timesteps      | 251904      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023271453 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.5       |\n",
      "|    explained_variance   | 0.00837     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 962         |\n",
      "|    n_updates            | 1220        |\n",
      "|    policy_gradient_loss | -0.0228     |\n",
      "|    reward               | -8.872314   |\n",
      "|    std                  | 1.33        |\n",
      "|    value_loss           | 1.6e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 131\n",
      "day: 1940, episode: 131\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9919488.95\n",
      "total_reward: -80511.05\n",
      "total_cost: 125596.05\n",
      "total_trades: 73678\n",
      "Sharpe: 0.157\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 124         |\n",
      "|    time_elapsed         | 1056        |\n",
      "|    total_timesteps      | 253952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045517996 |\n",
      "|    clip_fraction        | 0.358       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.6       |\n",
      "|    explained_variance   | -0.0125     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 713         |\n",
      "|    n_updates            | 1230        |\n",
      "|    policy_gradient_loss | -0.00939    |\n",
      "|    reward               | -10.404264  |\n",
      "|    std                  | 1.33        |\n",
      "|    value_loss           | 1.7e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 132\n",
      "day: 1940, episode: 132\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12285764.78\n",
      "total_reward: 2285764.78\n",
      "total_cost: 133478.22\n",
      "total_trades: 73686\n",
      "Sharpe: 0.237\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 240        |\n",
      "|    iterations           | 125        |\n",
      "|    time_elapsed         | 1064       |\n",
      "|    total_timesteps      | 256000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07876469 |\n",
      "|    clip_fraction        | 0.325      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -64.7      |\n",
      "|    explained_variance   | 0.03       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.4e+03    |\n",
      "|    n_updates            | 1240       |\n",
      "|    policy_gradient_loss | -0.0114    |\n",
      "|    reward               | 21.870882  |\n",
      "|    std                  | 1.33       |\n",
      "|    value_loss           | 2.36e+03   |\n",
      "----------------------------------------\n",
      "Episode: 133\n",
      "day: 1940, episode: 133\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10291383.87\n",
      "total_reward: 291383.87\n",
      "total_cost: 126294.13\n",
      "total_trades: 73672\n",
      "Sharpe: 0.166\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 240        |\n",
      "|    iterations           | 126        |\n",
      "|    time_elapsed         | 1072       |\n",
      "|    total_timesteps      | 258048     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02842504 |\n",
      "|    clip_fraction        | 0.291      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -64.8      |\n",
      "|    explained_variance   | -0.031     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 746        |\n",
      "|    n_updates            | 1250       |\n",
      "|    policy_gradient_loss | -0.0273    |\n",
      "|    reward               | -2.3475575 |\n",
      "|    std                  | 1.34       |\n",
      "|    value_loss           | 1.55e+03   |\n",
      "----------------------------------------\n",
      "Episode: 134\n",
      "day: 1940, episode: 134\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11573000.95\n",
      "total_reward: 1573000.95\n",
      "total_cost: 129571.05\n",
      "total_trades: 73679\n",
      "Sharpe: 0.209\n",
      "=================================\n",
      "Episode: 135\n",
      "day: 1940, episode: 135\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9697152.01\n",
      "total_reward: -302847.99\n",
      "total_cost: 123102.99\n",
      "total_trades: 73684\n",
      "Sharpe: 0.129\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 127         |\n",
      "|    time_elapsed         | 1081        |\n",
      "|    total_timesteps      | 260096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035546094 |\n",
      "|    clip_fraction        | 0.321       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.9       |\n",
      "|    explained_variance   | -0.00291    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 779         |\n",
      "|    n_updates            | 1260        |\n",
      "|    policy_gradient_loss | -0.0203     |\n",
      "|    reward               | -0.5097825  |\n",
      "|    std                  | 1.34        |\n",
      "|    value_loss           | 1.84e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 136\n",
      "day: 1940, episode: 136\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11439938.54\n",
      "total_reward: 1439938.54\n",
      "total_cost: 128516.46\n",
      "total_trades: 73663\n",
      "Sharpe: 0.202\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 128         |\n",
      "|    time_elapsed         | 1090        |\n",
      "|    total_timesteps      | 262144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033954825 |\n",
      "|    clip_fraction        | 0.35        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.1       |\n",
      "|    explained_variance   | -0.0001     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 706         |\n",
      "|    n_updates            | 1270        |\n",
      "|    policy_gradient_loss | -0.0257     |\n",
      "|    reward               | -3.3054028  |\n",
      "|    std                  | 1.35        |\n",
      "|    value_loss           | 1.41e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 137\n",
      "day: 1940, episode: 137\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13841559.48\n",
      "total_reward: 3841559.48\n",
      "total_cost: 141569.52\n",
      "total_trades: 73677\n",
      "Sharpe: 0.303\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 129         |\n",
      "|    time_elapsed         | 1098        |\n",
      "|    total_timesteps      | 264192      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032184407 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.2       |\n",
      "|    explained_variance   | 0.01        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.32e+03    |\n",
      "|    n_updates            | 1280        |\n",
      "|    policy_gradient_loss | -0.0275     |\n",
      "|    reward               | -2.5230446  |\n",
      "|    std                  | 1.35        |\n",
      "|    value_loss           | 1.78e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 138\n",
      "day: 1940, episode: 138\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11170870.19\n",
      "total_reward: 1170870.19\n",
      "total_cost: 135708.81\n",
      "total_trades: 73679\n",
      "Sharpe: 0.194\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 130         |\n",
      "|    time_elapsed         | 1106        |\n",
      "|    total_timesteps      | 266240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035060827 |\n",
      "|    clip_fraction        | 0.297       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.3       |\n",
      "|    explained_variance   | 0.0197      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 920         |\n",
      "|    n_updates            | 1290        |\n",
      "|    policy_gradient_loss | -0.0242     |\n",
      "|    reward               | 5.9529247   |\n",
      "|    std                  | 1.35        |\n",
      "|    value_loss           | 2.28e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 139\n",
      "day: 1940, episode: 139\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8290332.08\n",
      "total_reward: -1709667.92\n",
      "total_cost: 114664.92\n",
      "total_trades: 73676\n",
      "Sharpe: 0.075\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 131         |\n",
      "|    time_elapsed         | 1114        |\n",
      "|    total_timesteps      | 268288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039403778 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.3       |\n",
      "|    explained_variance   | -0.00493    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 896         |\n",
      "|    n_updates            | 1300        |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    reward               | 0.2859387   |\n",
      "|    std                  | 1.35        |\n",
      "|    value_loss           | 1.87e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 140\n",
      "day: 1940, episode: 140\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13280916.48\n",
      "total_reward: 3280916.48\n",
      "total_cost: 126150.52\n",
      "total_trades: 73678\n",
      "Sharpe: 0.279\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 132         |\n",
      "|    time_elapsed         | 1125        |\n",
      "|    total_timesteps      | 270336      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028385751 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.4       |\n",
      "|    explained_variance   | 0.0121      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 490         |\n",
      "|    n_updates            | 1310        |\n",
      "|    policy_gradient_loss | -0.0216     |\n",
      "|    reward               | -2.0182574  |\n",
      "|    std                  | 1.36        |\n",
      "|    value_loss           | 1.3e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 141\n",
      "day: 1940, episode: 141\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10565227.40\n",
      "total_reward: 565227.40\n",
      "total_cost: 118529.60\n",
      "total_trades: 73679\n",
      "Sharpe: 0.163\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 133         |\n",
      "|    time_elapsed         | 1133        |\n",
      "|    total_timesteps      | 272384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042953454 |\n",
      "|    clip_fraction        | 0.324       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.5       |\n",
      "|    explained_variance   | 0.00892     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 847         |\n",
      "|    n_updates            | 1320        |\n",
      "|    policy_gradient_loss | -0.0239     |\n",
      "|    reward               | 6.335924    |\n",
      "|    std                  | 1.36        |\n",
      "|    value_loss           | 1.94e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 142\n",
      "day: 1940, episode: 142\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12497564.38\n",
      "total_reward: 2497564.38\n",
      "total_cost: 137466.62\n",
      "total_trades: 73683\n",
      "Sharpe: 0.245\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 134         |\n",
      "|    time_elapsed         | 1142        |\n",
      "|    total_timesteps      | 274432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027647708 |\n",
      "|    clip_fraction        | 0.257       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.6       |\n",
      "|    explained_variance   | 0.00422     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 864         |\n",
      "|    n_updates            | 1330        |\n",
      "|    policy_gradient_loss | -0.0261     |\n",
      "|    reward               | 0.90679055  |\n",
      "|    std                  | 1.36        |\n",
      "|    value_loss           | 2.06e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 143\n",
      "day: 1940, episode: 143\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9557819.45\n",
      "total_reward: -442180.55\n",
      "total_cost: 122672.55\n",
      "total_trades: 73668\n",
      "Sharpe: 0.127\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 135         |\n",
      "|    time_elapsed         | 1151        |\n",
      "|    total_timesteps      | 276480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032849196 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.7       |\n",
      "|    explained_variance   | 0.000758    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.55e+03    |\n",
      "|    n_updates            | 1340        |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    reward               | -21.898327  |\n",
      "|    std                  | 1.37        |\n",
      "|    value_loss           | 2.29e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 144\n",
      "day: 1940, episode: 144\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11128563.33\n",
      "total_reward: 1128563.33\n",
      "total_cost: 136744.67\n",
      "total_trades: 73671\n",
      "Sharpe: 0.177\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 240        |\n",
      "|    iterations           | 136        |\n",
      "|    time_elapsed         | 1159       |\n",
      "|    total_timesteps      | 278528     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03461095 |\n",
      "|    clip_fraction        | 0.276      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -65.8      |\n",
      "|    explained_variance   | 0.019      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 922        |\n",
      "|    n_updates            | 1350       |\n",
      "|    policy_gradient_loss | -0.0267    |\n",
      "|    reward               | -8.053351  |\n",
      "|    std                  | 1.37       |\n",
      "|    value_loss           | 1.95e+03   |\n",
      "----------------------------------------\n",
      "Episode: 145\n",
      "day: 1940, episode: 145\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13014658.52\n",
      "total_reward: 3014658.52\n",
      "total_cost: 133983.48\n",
      "total_trades: 73679\n",
      "Sharpe: 0.268\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 240        |\n",
      "|    iterations           | 137        |\n",
      "|    time_elapsed         | 1167       |\n",
      "|    total_timesteps      | 280576     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03508777 |\n",
      "|    clip_fraction        | 0.324      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -65.9      |\n",
      "|    explained_variance   | 0.0062     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.14e+03   |\n",
      "|    n_updates            | 1360       |\n",
      "|    policy_gradient_loss | -0.0202    |\n",
      "|    reward               | -20.78739  |\n",
      "|    std                  | 1.38       |\n",
      "|    value_loss           | 2.05e+03   |\n",
      "----------------------------------------\n",
      "Episode: 146\n",
      "day: 1940, episode: 146\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14052677.98\n",
      "total_reward: 4052677.98\n",
      "total_cost: 139069.02\n",
      "total_trades: 73685\n",
      "Sharpe: 0.313\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 240        |\n",
      "|    iterations           | 138        |\n",
      "|    time_elapsed         | 1175       |\n",
      "|    total_timesteps      | 282624     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02345636 |\n",
      "|    clip_fraction        | 0.257      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -66        |\n",
      "|    explained_variance   | 0.00982    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.15e+03   |\n",
      "|    n_updates            | 1370       |\n",
      "|    policy_gradient_loss | -0.0221    |\n",
      "|    reward               | -3.1823194 |\n",
      "|    std                  | 1.38       |\n",
      "|    value_loss           | 2.37e+03   |\n",
      "----------------------------------------\n",
      "Episode: 147\n",
      "day: 1940, episode: 147\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11559589.29\n",
      "total_reward: 1559589.29\n",
      "total_cost: 142096.71\n",
      "total_trades: 73670\n",
      "Sharpe: 0.202\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 240        |\n",
      "|    iterations           | 139        |\n",
      "|    time_elapsed         | 1183       |\n",
      "|    total_timesteps      | 284672     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0310065  |\n",
      "|    clip_fraction        | 0.302      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -66.1      |\n",
      "|    explained_variance   | -0.0271    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 637        |\n",
      "|    n_updates            | 1380       |\n",
      "|    policy_gradient_loss | -0.0218    |\n",
      "|    reward               | -1.8543752 |\n",
      "|    std                  | 1.38       |\n",
      "|    value_loss           | 1.86e+03   |\n",
      "----------------------------------------\n",
      "Episode: 148\n",
      "day: 1940, episode: 148\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14033816.81\n",
      "total_reward: 4033816.81\n",
      "total_cost: 148169.19\n",
      "total_trades: 73682\n",
      "Sharpe: 0.312\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 140         |\n",
      "|    time_elapsed         | 1191        |\n",
      "|    total_timesteps      | 286720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029475303 |\n",
      "|    clip_fraction        | 0.284       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.2       |\n",
      "|    explained_variance   | -0.00647    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 906         |\n",
      "|    n_updates            | 1390        |\n",
      "|    policy_gradient_loss | -0.0192     |\n",
      "|    reward               | -3.8270767  |\n",
      "|    std                  | 1.39        |\n",
      "|    value_loss           | 1.63e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 149\n",
      "day: 1940, episode: 149\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11475442.71\n",
      "total_reward: 1475442.71\n",
      "total_cost: 145807.29\n",
      "total_trades: 73682\n",
      "Sharpe: 0.205\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 141         |\n",
      "|    time_elapsed         | 1199        |\n",
      "|    total_timesteps      | 288768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042242948 |\n",
      "|    clip_fraction        | 0.336       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.3       |\n",
      "|    explained_variance   | -0.00136    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 726         |\n",
      "|    n_updates            | 1400        |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    reward               | -12.309246  |\n",
      "|    std                  | 1.39        |\n",
      "|    value_loss           | 1.4e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 150\n",
      "day: 1940, episode: 150\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11322291.89\n",
      "total_reward: 1322291.89\n",
      "total_cost: 140849.11\n",
      "total_trades: 73694\n",
      "Sharpe: 0.193\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 142         |\n",
      "|    time_elapsed         | 1208        |\n",
      "|    total_timesteps      | 290816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024933763 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.4       |\n",
      "|    explained_variance   | 0.000728    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 684         |\n",
      "|    n_updates            | 1410        |\n",
      "|    policy_gradient_loss | -0.0282     |\n",
      "|    reward               | -5.927937   |\n",
      "|    std                  | 1.39        |\n",
      "|    value_loss           | 1.44e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 151\n",
      "day: 1940, episode: 151\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8922709.62\n",
      "total_reward: -1077290.38\n",
      "total_cost: 138105.38\n",
      "total_trades: 73690\n",
      "Sharpe: 0.069\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 143         |\n",
      "|    time_elapsed         | 1216        |\n",
      "|    total_timesteps      | 292864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026109718 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.4       |\n",
      "|    explained_variance   | 0.00447     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 565         |\n",
      "|    n_updates            | 1420        |\n",
      "|    policy_gradient_loss | -0.0245     |\n",
      "|    reward               | 3.4722698   |\n",
      "|    std                  | 1.39        |\n",
      "|    value_loss           | 1.7e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 152\n",
      "day: 1940, episode: 152\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10690431.65\n",
      "total_reward: 690431.65\n",
      "total_cost: 134512.35\n",
      "total_trades: 73673\n",
      "Sharpe: 0.188\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 240       |\n",
      "|    iterations           | 144       |\n",
      "|    time_elapsed         | 1224      |\n",
      "|    total_timesteps      | 294912    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0377035 |\n",
      "|    clip_fraction        | 0.321     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -66.5     |\n",
      "|    explained_variance   | -0.0151   |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 585       |\n",
      "|    n_updates            | 1430      |\n",
      "|    policy_gradient_loss | -0.0239   |\n",
      "|    reward               | -5.027184 |\n",
      "|    std                  | 1.4       |\n",
      "|    value_loss           | 1.08e+03  |\n",
      "---------------------------------------\n",
      "Episode: 153\n",
      "day: 1940, episode: 153\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14745940.75\n",
      "total_reward: 4745940.75\n",
      "total_cost: 139210.25\n",
      "total_trades: 73683\n",
      "Sharpe: 0.335\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 145         |\n",
      "|    time_elapsed         | 1232        |\n",
      "|    total_timesteps      | 296960      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022768203 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.5       |\n",
      "|    explained_variance   | -0.00338    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.15e+03    |\n",
      "|    n_updates            | 1440        |\n",
      "|    policy_gradient_loss | -0.0243     |\n",
      "|    reward               | 18.742111   |\n",
      "|    std                  | 1.4         |\n",
      "|    value_loss           | 2.33e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 154\n",
      "day: 1940, episode: 154\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13282652.87\n",
      "total_reward: 3282652.87\n",
      "total_cost: 131611.13\n",
      "total_trades: 73678\n",
      "Sharpe: 0.290\n",
      "=================================\n",
      "Episode: 155\n",
      "day: 1940, episode: 155\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11434219.24\n",
      "total_reward: 1434219.24\n",
      "total_cost: 137350.76\n",
      "total_trades: 73675\n",
      "Sharpe: 0.219\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 240        |\n",
      "|    iterations           | 146        |\n",
      "|    time_elapsed         | 1240       |\n",
      "|    total_timesteps      | 299008     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03241927 |\n",
      "|    clip_fraction        | 0.298      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -66.6      |\n",
      "|    explained_variance   | -0.00314   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.01e+03   |\n",
      "|    n_updates            | 1450       |\n",
      "|    policy_gradient_loss | -0.0153    |\n",
      "|    reward               | -13.398672 |\n",
      "|    std                  | 1.4        |\n",
      "|    value_loss           | 2.08e+03   |\n",
      "----------------------------------------\n",
      "Episode: 156\n",
      "day: 1940, episode: 156\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14084948.14\n",
      "total_reward: 4084948.14\n",
      "total_cost: 139678.86\n",
      "total_trades: 73685\n",
      "Sharpe: 0.311\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 147         |\n",
      "|    time_elapsed         | 1248        |\n",
      "|    total_timesteps      | 301056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037605897 |\n",
      "|    clip_fraction        | 0.32        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.7       |\n",
      "|    explained_variance   | -0.00417    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 956         |\n",
      "|    n_updates            | 1460        |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    reward               | -5.6413364  |\n",
      "|    std                  | 1.4         |\n",
      "|    value_loss           | 1.8e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 157\n",
      "day: 1940, episode: 157\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 16719187.77\n",
      "total_reward: 6719187.77\n",
      "total_cost: 138101.23\n",
      "total_trades: 73681\n",
      "Sharpe: 0.398\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 241        |\n",
      "|    iterations           | 148        |\n",
      "|    time_elapsed         | 1256       |\n",
      "|    total_timesteps      | 303104     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03881191 |\n",
      "|    clip_fraction        | 0.336      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -66.8      |\n",
      "|    explained_variance   | -0.00517   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 864        |\n",
      "|    n_updates            | 1470       |\n",
      "|    policy_gradient_loss | -0.0223    |\n",
      "|    reward               | 3.3261867  |\n",
      "|    std                  | 1.41       |\n",
      "|    value_loss           | 2.35e+03   |\n",
      "----------------------------------------\n",
      "Episode: 158\n",
      "day: 1940, episode: 158\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14358687.75\n",
      "total_reward: 4358687.75\n",
      "total_cost: 132775.25\n",
      "total_trades: 73688\n",
      "Sharpe: 0.319\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 149         |\n",
      "|    time_elapsed         | 1266        |\n",
      "|    total_timesteps      | 305152      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037557796 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.8       |\n",
      "|    explained_variance   | -0.00229    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.98e+03    |\n",
      "|    n_updates            | 1480        |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    reward               | 2.291036    |\n",
      "|    std                  | 1.41        |\n",
      "|    value_loss           | 3.36e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 159\n",
      "day: 1940, episode: 159\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11277736.02\n",
      "total_reward: 1277736.02\n",
      "total_cost: 136576.98\n",
      "total_trades: 73682\n",
      "Sharpe: 0.211\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 150         |\n",
      "|    time_elapsed         | 1274        |\n",
      "|    total_timesteps      | 307200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026102316 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.9       |\n",
      "|    explained_variance   | -0.00579    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.36e+03    |\n",
      "|    n_updates            | 1490        |\n",
      "|    policy_gradient_loss | -0.0195     |\n",
      "|    reward               | 10.701668   |\n",
      "|    std                  | 1.41        |\n",
      "|    value_loss           | 2.6e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 160\n",
      "day: 1940, episode: 160\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 16316711.30\n",
      "total_reward: 6316711.30\n",
      "total_cost: 143070.70\n",
      "total_trades: 73665\n",
      "Sharpe: 0.385\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 151         |\n",
      "|    time_elapsed         | 1282        |\n",
      "|    total_timesteps      | 309248      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040331185 |\n",
      "|    clip_fraction        | 0.344       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67         |\n",
      "|    explained_variance   | 0.00349     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.1e+03     |\n",
      "|    n_updates            | 1500        |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    reward               | 8.875708    |\n",
      "|    std                  | 1.42        |\n",
      "|    value_loss           | 1.85e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 161\n",
      "day: 1940, episode: 161\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12498261.09\n",
      "total_reward: 2498261.09\n",
      "total_cost: 134274.91\n",
      "total_trades: 73673\n",
      "Sharpe: 0.250\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 152         |\n",
      "|    time_elapsed         | 1290        |\n",
      "|    total_timesteps      | 311296      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022359729 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.1       |\n",
      "|    explained_variance   | 0.00433     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.06e+03    |\n",
      "|    n_updates            | 1510        |\n",
      "|    policy_gradient_loss | -0.0187     |\n",
      "|    reward               | 7.8780513   |\n",
      "|    std                  | 1.42        |\n",
      "|    value_loss           | 3.84e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 162\n",
      "day: 1940, episode: 162\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11145909.54\n",
      "total_reward: 1145909.54\n",
      "total_cost: 136092.46\n",
      "total_trades: 73685\n",
      "Sharpe: 0.209\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 153         |\n",
      "|    time_elapsed         | 1298        |\n",
      "|    total_timesteps      | 313344      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022234375 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.2       |\n",
      "|    explained_variance   | -0.000421   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.13e+03    |\n",
      "|    n_updates            | 1520        |\n",
      "|    policy_gradient_loss | -0.0241     |\n",
      "|    reward               | -23.546303  |\n",
      "|    std                  | 1.42        |\n",
      "|    value_loss           | 2.87e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 163\n",
      "day: 1940, episode: 163\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 17199577.02\n",
      "total_reward: 7199577.02\n",
      "total_cost: 138648.98\n",
      "total_trades: 73682\n",
      "Sharpe: 0.420\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 241        |\n",
      "|    iterations           | 154        |\n",
      "|    time_elapsed         | 1306       |\n",
      "|    total_timesteps      | 315392     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02325498 |\n",
      "|    clip_fraction        | 0.242      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -67.3      |\n",
      "|    explained_variance   | 0.029      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.63e+03   |\n",
      "|    n_updates            | 1530       |\n",
      "|    policy_gradient_loss | -0.0276    |\n",
      "|    reward               | -2.4809864 |\n",
      "|    std                  | 1.43       |\n",
      "|    value_loss           | 2.77e+03   |\n",
      "----------------------------------------\n",
      "Episode: 164\n",
      "day: 1940, episode: 164\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14366498.81\n",
      "total_reward: 4366498.81\n",
      "total_cost: 132638.19\n",
      "total_trades: 73685\n",
      "Sharpe: 0.319\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 155         |\n",
      "|    time_elapsed         | 1314        |\n",
      "|    total_timesteps      | 317440      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015427198 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.4       |\n",
      "|    explained_variance   | 0.0331      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.04e+03    |\n",
      "|    n_updates            | 1540        |\n",
      "|    policy_gradient_loss | -0.022      |\n",
      "|    reward               | -5.9977674  |\n",
      "|    std                  | 1.43        |\n",
      "|    value_loss           | 3.24e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 165\n",
      "day: 1940, episode: 165\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 18469260.10\n",
      "total_reward: 8469260.10\n",
      "total_cost: 142553.90\n",
      "total_trades: 73677\n",
      "Sharpe: 0.465\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 156         |\n",
      "|    time_elapsed         | 1323        |\n",
      "|    total_timesteps      | 319488      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033783033 |\n",
      "|    clip_fraction        | 0.305       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.4       |\n",
      "|    explained_variance   | 0.0212      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.84e+03    |\n",
      "|    n_updates            | 1550        |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    reward               | 2.1612163   |\n",
      "|    std                  | 1.43        |\n",
      "|    value_loss           | 3.62e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 166\n",
      "day: 1940, episode: 166\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 16072320.96\n",
      "total_reward: 6072320.96\n",
      "total_cost: 133477.04\n",
      "total_trades: 73681\n",
      "Sharpe: 0.371\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 157         |\n",
      "|    time_elapsed         | 1332        |\n",
      "|    total_timesteps      | 321536      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017269153 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.5       |\n",
      "|    explained_variance   | 0.052       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.78e+03    |\n",
      "|    n_updates            | 1560        |\n",
      "|    policy_gradient_loss | -0.0213     |\n",
      "|    reward               | -5.556538   |\n",
      "|    std                  | 1.43        |\n",
      "|    value_loss           | 3.45e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 167\n",
      "day: 1940, episode: 167\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12881119.11\n",
      "total_reward: 2881119.11\n",
      "total_cost: 123640.89\n",
      "total_trades: 73678\n",
      "Sharpe: 0.262\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 158         |\n",
      "|    time_elapsed         | 1340        |\n",
      "|    total_timesteps      | 323584      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038229503 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.5       |\n",
      "|    explained_variance   | 0.057       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.43e+03    |\n",
      "|    n_updates            | 1570        |\n",
      "|    policy_gradient_loss | -0.0218     |\n",
      "|    reward               | -2.780746   |\n",
      "|    std                  | 1.44        |\n",
      "|    value_loss           | 4.03e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 168\n",
      "day: 1940, episode: 168\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 21078484.37\n",
      "total_reward: 11078484.37\n",
      "total_cost: 133848.63\n",
      "total_trades: 73685\n",
      "Sharpe: 0.524\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 159         |\n",
      "|    time_elapsed         | 1348        |\n",
      "|    total_timesteps      | 325632      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019577239 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.6       |\n",
      "|    explained_variance   | 0.00056     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.54e+03    |\n",
      "|    n_updates            | 1580        |\n",
      "|    policy_gradient_loss | -0.0281     |\n",
      "|    reward               | 13.507069   |\n",
      "|    std                  | 1.44        |\n",
      "|    value_loss           | 3.44e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 169\n",
      "day: 1940, episode: 169\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 19433494.20\n",
      "total_reward: 9433494.20\n",
      "total_cost: 128948.80\n",
      "total_trades: 73672\n",
      "Sharpe: 0.469\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 160         |\n",
      "|    time_elapsed         | 1356        |\n",
      "|    total_timesteps      | 327680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029627616 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.7       |\n",
      "|    explained_variance   | 0.0164      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.89e+03    |\n",
      "|    n_updates            | 1590        |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    reward               | -3.7088954  |\n",
      "|    std                  | 1.44        |\n",
      "|    value_loss           | 3.93e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 170\n",
      "day: 1940, episode: 170\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14966267.65\n",
      "total_reward: 4966267.65\n",
      "total_cost: 135947.35\n",
      "total_trades: 73685\n",
      "Sharpe: 0.333\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 241        |\n",
      "|    iterations           | 161        |\n",
      "|    time_elapsed         | 1364       |\n",
      "|    total_timesteps      | 329728     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03141637 |\n",
      "|    clip_fraction        | 0.321      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -67.8      |\n",
      "|    explained_variance   | 0.0368     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.11e+03   |\n",
      "|    n_updates            | 1600       |\n",
      "|    policy_gradient_loss | -0.0202    |\n",
      "|    reward               | 3.9556913  |\n",
      "|    std                  | 1.44       |\n",
      "|    value_loss           | 4.29e+03   |\n",
      "----------------------------------------\n",
      "Episode: 171\n",
      "day: 1940, episode: 171\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 19886572.16\n",
      "total_reward: 9886572.16\n",
      "total_cost: 146372.84\n",
      "total_trades: 73688\n",
      "Sharpe: 0.492\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 162         |\n",
      "|    time_elapsed         | 1372        |\n",
      "|    total_timesteps      | 331776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039318483 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.8       |\n",
      "|    explained_variance   | -0.00862    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.55e+03    |\n",
      "|    n_updates            | 1610        |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    reward               | 3.6871839   |\n",
      "|    std                  | 1.44        |\n",
      "|    value_loss           | 3.47e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 172\n",
      "day: 1940, episode: 172\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 18927379.34\n",
      "total_reward: 8927379.34\n",
      "total_cost: 142048.66\n",
      "total_trades: 73684\n",
      "Sharpe: 0.480\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 241        |\n",
      "|    iterations           | 163        |\n",
      "|    time_elapsed         | 1380       |\n",
      "|    total_timesteps      | 333824     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02362107 |\n",
      "|    clip_fraction        | 0.246      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -67.9      |\n",
      "|    explained_variance   | -0.00673   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.54e+03   |\n",
      "|    n_updates            | 1620       |\n",
      "|    policy_gradient_loss | -0.0317    |\n",
      "|    reward               | 5.9779387  |\n",
      "|    std                  | 1.45       |\n",
      "|    value_loss           | 3.43e+03   |\n",
      "----------------------------------------\n",
      "Episode: 173\n",
      "day: 1940, episode: 173\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 20308849.61\n",
      "total_reward: 10308849.61\n",
      "total_cost: 142111.39\n",
      "total_trades: 73692\n",
      "Sharpe: 0.515\n",
      "=================================\n",
      "Episode: 174\n",
      "day: 1940, episode: 174\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 16234870.43\n",
      "total_reward: 6234870.43\n",
      "total_cost: 130530.57\n",
      "total_trades: 73687\n",
      "Sharpe: 0.387\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 241        |\n",
      "|    iterations           | 164        |\n",
      "|    time_elapsed         | 1389       |\n",
      "|    total_timesteps      | 335872     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03351852 |\n",
      "|    clip_fraction        | 0.284      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -68        |\n",
      "|    explained_variance   | -0.00678   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.69e+03   |\n",
      "|    n_updates            | 1630       |\n",
      "|    policy_gradient_loss | -0.0222    |\n",
      "|    reward               | -1.2252568 |\n",
      "|    std                  | 1.46       |\n",
      "|    value_loss           | 2.78e+03   |\n",
      "----------------------------------------\n",
      "Episode: 175\n",
      "day: 1940, episode: 175\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 18257471.53\n",
      "total_reward: 8257471.53\n",
      "total_cost: 131305.47\n",
      "total_trades: 73679\n",
      "Sharpe: 0.440\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 165         |\n",
      "|    time_elapsed         | 1397        |\n",
      "|    total_timesteps      | 337920      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039669074 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.1       |\n",
      "|    explained_variance   | 0.00184     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 890         |\n",
      "|    n_updates            | 1640        |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    reward               | 12.352745   |\n",
      "|    std                  | 1.46        |\n",
      "|    value_loss           | 2.02e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 176\n",
      "day: 1940, episode: 176\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 20411263.23\n",
      "total_reward: 10411263.23\n",
      "total_cost: 136553.77\n",
      "total_trades: 73677\n",
      "Sharpe: 0.508\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 166         |\n",
      "|    time_elapsed         | 1405        |\n",
      "|    total_timesteps      | 339968      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034289323 |\n",
      "|    clip_fraction        | 0.302       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.2       |\n",
      "|    explained_variance   | -0.00412    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.53e+03    |\n",
      "|    n_updates            | 1650        |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    reward               | -17.99028   |\n",
      "|    std                  | 1.46        |\n",
      "|    value_loss           | 3.3e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 177\n",
      "day: 1940, episode: 177\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 18187869.08\n",
      "total_reward: 8187869.08\n",
      "total_cost: 133874.92\n",
      "total_trades: 73687\n",
      "Sharpe: 0.445\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 241        |\n",
      "|    iterations           | 167        |\n",
      "|    time_elapsed         | 1413       |\n",
      "|    total_timesteps      | 342016     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03145398 |\n",
      "|    clip_fraction        | 0.314      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -68.4      |\n",
      "|    explained_variance   | -0.00416   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.29e+03   |\n",
      "|    n_updates            | 1660       |\n",
      "|    policy_gradient_loss | -0.0188    |\n",
      "|    reward               | -1.2259651 |\n",
      "|    std                  | 1.47       |\n",
      "|    value_loss           | 3.13e+03   |\n",
      "----------------------------------------\n",
      "Episode: 178\n",
      "day: 1940, episode: 178\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13507695.62\n",
      "total_reward: 3507695.62\n",
      "total_cost: 129078.38\n",
      "total_trades: 73681\n",
      "Sharpe: 0.287\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 168         |\n",
      "|    time_elapsed         | 1421        |\n",
      "|    total_timesteps      | 344064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.055569224 |\n",
      "|    clip_fraction        | 0.367       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.5       |\n",
      "|    explained_variance   | 0.00478     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.28e+03    |\n",
      "|    n_updates            | 1670        |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    reward               | -7.832815   |\n",
      "|    std                  | 1.47        |\n",
      "|    value_loss           | 3.36e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 179\n",
      "day: 1940, episode: 179\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 15298233.03\n",
      "total_reward: 5298233.03\n",
      "total_cost: 128293.97\n",
      "total_trades: 73690\n",
      "Sharpe: 0.351\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 242        |\n",
      "|    iterations           | 169        |\n",
      "|    time_elapsed         | 1429       |\n",
      "|    total_timesteps      | 346112     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03842951 |\n",
      "|    clip_fraction        | 0.321      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -68.6      |\n",
      "|    explained_variance   | -0.00346   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.86e+03   |\n",
      "|    n_updates            | 1680       |\n",
      "|    policy_gradient_loss | -0.0142    |\n",
      "|    reward               | 5.2513533  |\n",
      "|    std                  | 1.48       |\n",
      "|    value_loss           | 3.4e+03    |\n",
      "----------------------------------------\n",
      "Episode: 180\n",
      "day: 1940, episode: 180\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12944633.03\n",
      "total_reward: 2944633.03\n",
      "total_cost: 130306.97\n",
      "total_trades: 73695\n",
      "Sharpe: 0.275\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 170         |\n",
      "|    time_elapsed         | 1438        |\n",
      "|    total_timesteps      | 348160      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042292833 |\n",
      "|    clip_fraction        | 0.27        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.6       |\n",
      "|    explained_variance   | -0.00701    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.81e+03    |\n",
      "|    n_updates            | 1690        |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    reward               | 21.96533    |\n",
      "|    std                  | 1.48        |\n",
      "|    value_loss           | 3.32e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 181\n",
      "day: 1940, episode: 181\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 15833193.26\n",
      "total_reward: 5833193.26\n",
      "total_cost: 131740.74\n",
      "total_trades: 73686\n",
      "Sharpe: 0.373\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 241        |\n",
      "|    iterations           | 171        |\n",
      "|    time_elapsed         | 1447       |\n",
      "|    total_timesteps      | 350208     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03238335 |\n",
      "|    clip_fraction        | 0.267      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -68.7      |\n",
      "|    explained_variance   | 0.0173     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.81e+03   |\n",
      "|    n_updates            | 1700       |\n",
      "|    policy_gradient_loss | -0.0247    |\n",
      "|    reward               | -10.367532 |\n",
      "|    std                  | 1.48       |\n",
      "|    value_loss           | 3.06e+03   |\n",
      "----------------------------------------\n",
      "Episode: 182\n",
      "day: 1940, episode: 182\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12236430.54\n",
      "total_reward: 2236430.54\n",
      "total_cost: 121452.46\n",
      "total_trades: 73683\n",
      "Sharpe: 0.251\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 242        |\n",
      "|    iterations           | 172        |\n",
      "|    time_elapsed         | 1455       |\n",
      "|    total_timesteps      | 352256     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04780719 |\n",
      "|    clip_fraction        | 0.323      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -68.8      |\n",
      "|    explained_variance   | -0.00714   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 891        |\n",
      "|    n_updates            | 1710       |\n",
      "|    policy_gradient_loss | -0.0211    |\n",
      "|    reward               | 8.859017   |\n",
      "|    std                  | 1.48       |\n",
      "|    value_loss           | 2.82e+03   |\n",
      "----------------------------------------\n",
      "Episode: 183\n",
      "day: 1940, episode: 183\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10889624.94\n",
      "total_reward: 889624.94\n",
      "total_cost: 128640.06\n",
      "total_trades: 73681\n",
      "Sharpe: 0.189\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 173         |\n",
      "|    time_elapsed         | 1463        |\n",
      "|    total_timesteps      | 354304      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040766057 |\n",
      "|    clip_fraction        | 0.359       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.8       |\n",
      "|    explained_variance   | 0.026       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.1e+03     |\n",
      "|    n_updates            | 1720        |\n",
      "|    policy_gradient_loss | -0.0194     |\n",
      "|    reward               | -6.8024044  |\n",
      "|    std                  | 1.49        |\n",
      "|    value_loss           | 2.09e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 184\n",
      "day: 1940, episode: 184\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 17945123.29\n",
      "total_reward: 7945123.29\n",
      "total_cost: 139472.71\n",
      "total_trades: 73680\n",
      "Sharpe: 0.441\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 174         |\n",
      "|    time_elapsed         | 1471        |\n",
      "|    total_timesteps      | 356352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046745054 |\n",
      "|    clip_fraction        | 0.342       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.9       |\n",
      "|    explained_variance   | -0.00614    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.16e+03    |\n",
      "|    n_updates            | 1730        |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    reward               | -0.94968253 |\n",
      "|    std                  | 1.49        |\n",
      "|    value_loss           | 2.67e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 185\n",
      "day: 1940, episode: 185\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12151067.59\n",
      "total_reward: 2151067.59\n",
      "total_cost: 132258.41\n",
      "total_trades: 73678\n",
      "Sharpe: 0.245\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 242        |\n",
      "|    iterations           | 175        |\n",
      "|    time_elapsed         | 1479       |\n",
      "|    total_timesteps      | 358400     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02213818 |\n",
      "|    clip_fraction        | 0.27       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -69        |\n",
      "|    explained_variance   | 0.00208    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 685        |\n",
      "|    n_updates            | 1740       |\n",
      "|    policy_gradient_loss | -0.0203    |\n",
      "|    reward               | 3.450977   |\n",
      "|    std                  | 1.49       |\n",
      "|    value_loss           | 1.94e+03   |\n",
      "----------------------------------------\n",
      "Episode: 186\n",
      "day: 1940, episode: 186\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 15496724.95\n",
      "total_reward: 5496724.95\n",
      "total_cost: 134959.05\n",
      "total_trades: 73678\n",
      "Sharpe: 0.355\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 176         |\n",
      "|    time_elapsed         | 1487        |\n",
      "|    total_timesteps      | 360448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022937916 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69         |\n",
      "|    explained_variance   | 0.00674     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.71e+03    |\n",
      "|    n_updates            | 1750        |\n",
      "|    policy_gradient_loss | -0.0233     |\n",
      "|    reward               | -2.4584124  |\n",
      "|    std                  | 1.49        |\n",
      "|    value_loss           | 2.88e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 187\n",
      "day: 1940, episode: 187\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 15530045.62\n",
      "total_reward: 5530045.62\n",
      "total_cost: 133841.38\n",
      "total_trades: 73680\n",
      "Sharpe: 0.356\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 177         |\n",
      "|    time_elapsed         | 1495        |\n",
      "|    total_timesteps      | 362496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027409125 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.1       |\n",
      "|    explained_variance   | -0.0117     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.42e+03    |\n",
      "|    n_updates            | 1760        |\n",
      "|    policy_gradient_loss | -0.0265     |\n",
      "|    reward               | 27.934227   |\n",
      "|    std                  | 1.5         |\n",
      "|    value_loss           | 2.65e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 188\n",
      "day: 1940, episode: 188\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 15162410.82\n",
      "total_reward: 5162410.82\n",
      "total_cost: 135405.18\n",
      "total_trades: 73677\n",
      "Sharpe: 0.344\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 242      |\n",
      "|    iterations           | 178      |\n",
      "|    time_elapsed         | 1505     |\n",
      "|    total_timesteps      | 364544   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.037069 |\n",
      "|    clip_fraction        | 0.321    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -69.2    |\n",
      "|    explained_variance   | -0.00713 |\n",
      "|    learning_rate        | 0.00025  |\n",
      "|    loss                 | 1.48e+03 |\n",
      "|    n_updates            | 1770     |\n",
      "|    policy_gradient_loss | -0.0195  |\n",
      "|    reward               | 5.387788 |\n",
      "|    std                  | 1.5      |\n",
      "|    value_loss           | 2.87e+03 |\n",
      "--------------------------------------\n",
      "Episode: 189\n",
      "day: 1940, episode: 189\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11430267.98\n",
      "total_reward: 1430267.98\n",
      "total_cost: 130423.02\n",
      "total_trades: 73678\n",
      "Sharpe: 0.226\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 242        |\n",
      "|    iterations           | 179        |\n",
      "|    time_elapsed         | 1513       |\n",
      "|    total_timesteps      | 366592     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03132767 |\n",
      "|    clip_fraction        | 0.216      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -69.3      |\n",
      "|    explained_variance   | -0.00156   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.24e+03   |\n",
      "|    n_updates            | 1780       |\n",
      "|    policy_gradient_loss | -0.0181    |\n",
      "|    reward               | 3.762643   |\n",
      "|    std                  | 1.5        |\n",
      "|    value_loss           | 2.72e+03   |\n",
      "----------------------------------------\n",
      "Episode: 190\n",
      "day: 1940, episode: 190\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 15272499.37\n",
      "total_reward: 5272499.37\n",
      "total_cost: 125479.63\n",
      "total_trades: 73690\n",
      "Sharpe: 0.341\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 180         |\n",
      "|    time_elapsed         | 1521        |\n",
      "|    total_timesteps      | 368640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040080704 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.3       |\n",
      "|    explained_variance   | 0.00621     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.1e+03     |\n",
      "|    n_updates            | 1790        |\n",
      "|    policy_gradient_loss | -0.0201     |\n",
      "|    reward               | 8.684316    |\n",
      "|    std                  | 1.5         |\n",
      "|    value_loss           | 3.5e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 191\n",
      "day: 1940, episode: 191\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9938864.04\n",
      "total_reward: -61135.96\n",
      "total_cost: 108468.96\n",
      "total_trades: 73667\n",
      "Sharpe: 0.166\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 181         |\n",
      "|    time_elapsed         | 1529        |\n",
      "|    total_timesteps      | 370688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033574004 |\n",
      "|    clip_fraction        | 0.326       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.4       |\n",
      "|    explained_variance   | 0.0365      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.68e+03    |\n",
      "|    n_updates            | 1800        |\n",
      "|    policy_gradient_loss | -0.0231     |\n",
      "|    reward               | 39.552628   |\n",
      "|    std                  | 1.51        |\n",
      "|    value_loss           | 3.24e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 192\n",
      "day: 1940, episode: 192\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 17831209.41\n",
      "total_reward: 7831209.41\n",
      "total_cost: 125600.59\n",
      "total_trades: 73688\n",
      "Sharpe: 0.421\n",
      "=================================\n",
      "Episode: 193\n",
      "day: 1940, episode: 193\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13916296.71\n",
      "total_reward: 3916296.71\n",
      "total_cost: 131169.29\n",
      "total_trades: 73683\n",
      "Sharpe: 0.299\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 182         |\n",
      "|    time_elapsed         | 1537        |\n",
      "|    total_timesteps      | 372736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039259832 |\n",
      "|    clip_fraction        | 0.362       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.4       |\n",
      "|    explained_variance   | 0.0208      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.34e+03    |\n",
      "|    n_updates            | 1810        |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | -3.1622074  |\n",
      "|    std                  | 1.51        |\n",
      "|    value_loss           | 3.72e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 194\n",
      "day: 1940, episode: 194\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10778809.15\n",
      "total_reward: 778809.15\n",
      "total_cost: 114904.85\n",
      "total_trades: 73680\n",
      "Sharpe: 0.186\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 183         |\n",
      "|    time_elapsed         | 1545        |\n",
      "|    total_timesteps      | 374784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030297572 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.5       |\n",
      "|    explained_variance   | 0.0204      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.76e+03    |\n",
      "|    n_updates            | 1820        |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    reward               | -14.40503   |\n",
      "|    std                  | 1.51        |\n",
      "|    value_loss           | 3.19e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 195\n",
      "day: 1940, episode: 195\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10506555.77\n",
      "total_reward: 506555.77\n",
      "total_cost: 127057.23\n",
      "total_trades: 73684\n",
      "Sharpe: 0.182\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 184         |\n",
      "|    time_elapsed         | 1553        |\n",
      "|    total_timesteps      | 376832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047032643 |\n",
      "|    clip_fraction        | 0.381       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.7       |\n",
      "|    explained_variance   | 0.102       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.41e+03    |\n",
      "|    n_updates            | 1830        |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    reward               | -11.390429  |\n",
      "|    std                  | 1.52        |\n",
      "|    value_loss           | 2e+03       |\n",
      "-----------------------------------------\n",
      "Episode: 196\n",
      "day: 1940, episode: 196\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12414481.52\n",
      "total_reward: 2414481.52\n",
      "total_cost: 139896.48\n",
      "total_trades: 73678\n",
      "Sharpe: 0.249\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 242        |\n",
      "|    iterations           | 185        |\n",
      "|    time_elapsed         | 1562       |\n",
      "|    total_timesteps      | 378880     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04485544 |\n",
      "|    clip_fraction        | 0.355      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -69.7      |\n",
      "|    explained_variance   | 0.054      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.5e+03    |\n",
      "|    n_updates            | 1840       |\n",
      "|    policy_gradient_loss | -0.00913   |\n",
      "|    reward               | -12.705089 |\n",
      "|    std                  | 1.52       |\n",
      "|    value_loss           | 3.05e+03   |\n",
      "----------------------------------------\n",
      "Episode: 197\n",
      "day: 1940, episode: 197\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11355711.06\n",
      "total_reward: 1355711.06\n",
      "total_cost: 130615.94\n",
      "total_trades: 73670\n",
      "Sharpe: 0.220\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 186         |\n",
      "|    time_elapsed         | 1571        |\n",
      "|    total_timesteps      | 380928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030149575 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.8       |\n",
      "|    explained_variance   | 0.026       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.67e+03    |\n",
      "|    n_updates            | 1850        |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    reward               | -8.153701   |\n",
      "|    std                  | 1.52        |\n",
      "|    value_loss           | 3.38e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 198\n",
      "day: 1940, episode: 198\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14961673.75\n",
      "total_reward: 4961673.75\n",
      "total_cost: 126272.25\n",
      "total_trades: 73690\n",
      "Sharpe: 0.333\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 187         |\n",
      "|    time_elapsed         | 1579        |\n",
      "|    total_timesteps      | 382976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.071001545 |\n",
      "|    clip_fraction        | 0.381       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.8       |\n",
      "|    explained_variance   | 0.033       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.52e+03    |\n",
      "|    n_updates            | 1860        |\n",
      "|    policy_gradient_loss | -0.00464    |\n",
      "|    reward               | -0.23383474 |\n",
      "|    std                  | 1.52        |\n",
      "|    value_loss           | 3.25e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 199\n",
      "day: 1940, episode: 199\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14204782.01\n",
      "total_reward: 4204782.01\n",
      "total_cost: 128896.99\n",
      "total_trades: 73696\n",
      "Sharpe: 0.307\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 188         |\n",
      "|    time_elapsed         | 1587        |\n",
      "|    total_timesteps      | 385024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017253432 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.9       |\n",
      "|    explained_variance   | 0.018       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.36e+03    |\n",
      "|    n_updates            | 1870        |\n",
      "|    policy_gradient_loss | -0.0258     |\n",
      "|    reward               | 33.569042   |\n",
      "|    std                  | 1.53        |\n",
      "|    value_loss           | 3.74e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 200\n",
      "day: 1940, episode: 200\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 15450108.07\n",
      "total_reward: 5450108.07\n",
      "total_cost: 135473.93\n",
      "total_trades: 73692\n",
      "Sharpe: 0.349\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 189         |\n",
      "|    time_elapsed         | 1595        |\n",
      "|    total_timesteps      | 387072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023592968 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70         |\n",
      "|    explained_variance   | 0.0326      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.01e+03    |\n",
      "|    n_updates            | 1880        |\n",
      "|    policy_gradient_loss | -0.0262     |\n",
      "|    reward               | 15.596397   |\n",
      "|    std                  | 1.53        |\n",
      "|    value_loss           | 4.29e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 201\n",
      "day: 1940, episode: 201\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 15125679.65\n",
      "total_reward: 5125679.65\n",
      "total_cost: 143611.35\n",
      "total_trades: 73688\n",
      "Sharpe: 0.336\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 190         |\n",
      "|    time_elapsed         | 1603        |\n",
      "|    total_timesteps      | 389120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015802825 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70         |\n",
      "|    explained_variance   | -0.000101   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.23e+03    |\n",
      "|    n_updates            | 1890        |\n",
      "|    policy_gradient_loss | -0.0266     |\n",
      "|    reward               | -2.6057832  |\n",
      "|    std                  | 1.53        |\n",
      "|    value_loss           | 3.94e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 202\n",
      "day: 1940, episode: 202\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13414322.58\n",
      "total_reward: 3414322.58\n",
      "total_cost: 136055.42\n",
      "total_trades: 73685\n",
      "Sharpe: 0.282\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 191         |\n",
      "|    time_elapsed         | 1611        |\n",
      "|    total_timesteps      | 391168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029866282 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.1       |\n",
      "|    explained_variance   | 0.026       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.63e+03    |\n",
      "|    n_updates            | 1900        |\n",
      "|    policy_gradient_loss | -0.0202     |\n",
      "|    reward               | -7.7205033  |\n",
      "|    std                  | 1.54        |\n",
      "|    value_loss           | 4.86e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 203\n",
      "day: 1940, episode: 203\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10668976.43\n",
      "total_reward: 668976.43\n",
      "total_cost: 129803.57\n",
      "total_trades: 73698\n",
      "Sharpe: 0.185\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 192         |\n",
      "|    time_elapsed         | 1619        |\n",
      "|    total_timesteps      | 393216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029671181 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.2       |\n",
      "|    explained_variance   | -0.0393     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.87e+03    |\n",
      "|    n_updates            | 1910        |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    reward               | 0.06344734  |\n",
      "|    std                  | 1.54        |\n",
      "|    value_loss           | 3.16e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 204\n",
      "day: 1940, episode: 204\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12559442.62\n",
      "total_reward: 2559442.62\n",
      "total_cost: 137346.38\n",
      "total_trades: 73686\n",
      "Sharpe: 0.249\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 193         |\n",
      "|    time_elapsed         | 1628        |\n",
      "|    total_timesteps      | 395264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028973777 |\n",
      "|    clip_fraction        | 0.28        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.3       |\n",
      "|    explained_variance   | 0.0217      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.12e+03    |\n",
      "|    n_updates            | 1920        |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    reward               | 1.8227476   |\n",
      "|    std                  | 1.54        |\n",
      "|    value_loss           | 2.74e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 205\n",
      "day: 1940, episode: 205\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 15739109.64\n",
      "total_reward: 5739109.64\n",
      "total_cost: 140524.36\n",
      "total_trades: 73691\n",
      "Sharpe: 0.360\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 194         |\n",
      "|    time_elapsed         | 1636        |\n",
      "|    total_timesteps      | 397312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026677882 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.4       |\n",
      "|    explained_variance   | 0.00205     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.07e+03    |\n",
      "|    n_updates            | 1930        |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    reward               | 6.486326    |\n",
      "|    std                  | 1.55        |\n",
      "|    value_loss           | 3.91e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 206\n",
      "day: 1940, episode: 206\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12968010.13\n",
      "total_reward: 2968010.13\n",
      "total_cost: 131959.87\n",
      "total_trades: 73688\n",
      "Sharpe: 0.272\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 195         |\n",
      "|    time_elapsed         | 1645        |\n",
      "|    total_timesteps      | 399360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035868585 |\n",
      "|    clip_fraction        | 0.315       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.5       |\n",
      "|    explained_variance   | 0.0238      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.92e+03    |\n",
      "|    n_updates            | 1940        |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    reward               | 5.556707    |\n",
      "|    std                  | 1.55        |\n",
      "|    value_loss           | 3.28e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 207\n",
      "day: 1940, episode: 207\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 16145725.54\n",
      "total_reward: 6145725.54\n",
      "total_cost: 140742.46\n",
      "total_trades: 73683\n",
      "Sharpe: 0.373\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 196         |\n",
      "|    time_elapsed         | 1654        |\n",
      "|    total_timesteps      | 401408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043056354 |\n",
      "|    clip_fraction        | 0.37        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.6       |\n",
      "|    explained_variance   | 0.0196      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.16e+03    |\n",
      "|    n_updates            | 1950        |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    reward               | 0.72484654  |\n",
      "|    std                  | 1.56        |\n",
      "|    value_loss           | 3.66e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 208\n",
      "day: 1940, episode: 208\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 17026125.34\n",
      "total_reward: 7026125.34\n",
      "total_cost: 137232.66\n",
      "total_trades: 73685\n",
      "Sharpe: 0.393\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 242        |\n",
      "|    iterations           | 197        |\n",
      "|    time_elapsed         | 1662       |\n",
      "|    total_timesteps      | 403456     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03539615 |\n",
      "|    clip_fraction        | 0.287      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -70.8      |\n",
      "|    explained_variance   | 0.00374    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.6e+03    |\n",
      "|    n_updates            | 1960       |\n",
      "|    policy_gradient_loss | -0.0182    |\n",
      "|    reward               | -4.9213386 |\n",
      "|    std                  | 1.56       |\n",
      "|    value_loss           | 4.63e+03   |\n",
      "----------------------------------------\n",
      "Episode: 209\n",
      "day: 1940, episode: 209\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13762851.68\n",
      "total_reward: 3762851.68\n",
      "total_cost: 133497.32\n",
      "total_trades: 73677\n",
      "Sharpe: 0.295\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 198         |\n",
      "|    time_elapsed         | 1670        |\n",
      "|    total_timesteps      | 405504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.049201425 |\n",
      "|    clip_fraction        | 0.38        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.9       |\n",
      "|    explained_variance   | 0.0195      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.88e+03    |\n",
      "|    n_updates            | 1970        |\n",
      "|    policy_gradient_loss | -0.0095     |\n",
      "|    reward               | -103.84008  |\n",
      "|    std                  | 1.57        |\n",
      "|    value_loss           | 5.35e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 210\n",
      "day: 1940, episode: 210\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 16607943.75\n",
      "total_reward: 6607943.75\n",
      "total_cost: 122542.25\n",
      "total_trades: 73689\n",
      "Sharpe: 0.380\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 199         |\n",
      "|    time_elapsed         | 1680        |\n",
      "|    total_timesteps      | 407552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034181785 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71         |\n",
      "|    explained_variance   | 0.0314      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.16e+03    |\n",
      "|    n_updates            | 1980        |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    reward               | 15.611906   |\n",
      "|    std                  | 1.57        |\n",
      "|    value_loss           | 5.35e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 211\n",
      "day: 1940, episode: 211\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11775200.37\n",
      "total_reward: 1775200.37\n",
      "total_cost: 129329.63\n",
      "total_trades: 73686\n",
      "Sharpe: 0.237\n",
      "=================================\n",
      "Episode: 212\n",
      "day: 1940, episode: 212\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 15673123.96\n",
      "total_reward: 5673123.96\n",
      "total_cost: 130868.04\n",
      "total_trades: 73676\n",
      "Sharpe: 0.352\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 200         |\n",
      "|    time_elapsed         | 1690        |\n",
      "|    total_timesteps      | 409600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.053306174 |\n",
      "|    clip_fraction        | 0.396       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.1       |\n",
      "|    explained_variance   | 0.0265      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.08e+03    |\n",
      "|    n_updates            | 1990        |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | -4.422111   |\n",
      "|    std                  | 1.58        |\n",
      "|    value_loss           | 2.48e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 213\n",
      "day: 1940, episode: 213\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 15154196.60\n",
      "total_reward: 5154196.60\n",
      "total_cost: 136063.40\n",
      "total_trades: 73683\n",
      "Sharpe: 0.339\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 201         |\n",
      "|    time_elapsed         | 1699        |\n",
      "|    total_timesteps      | 411648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021564968 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.1       |\n",
      "|    explained_variance   | 0.0313      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.5e+03     |\n",
      "|    n_updates            | 2000        |\n",
      "|    policy_gradient_loss | -0.0228     |\n",
      "|    reward               | -0.4797644  |\n",
      "|    std                  | 1.58        |\n",
      "|    value_loss           | 5.19e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 214\n",
      "day: 1940, episode: 214\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14908597.01\n",
      "total_reward: 4908597.01\n",
      "total_cost: 139926.99\n",
      "total_trades: 73675\n",
      "Sharpe: 0.328\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 202         |\n",
      "|    time_elapsed         | 1708        |\n",
      "|    total_timesteps      | 413696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024817253 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.2       |\n",
      "|    explained_variance   | 0.0136      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.57e+03    |\n",
      "|    n_updates            | 2010        |\n",
      "|    policy_gradient_loss | -0.0185     |\n",
      "|    reward               | 2.5414495   |\n",
      "|    std                  | 1.59        |\n",
      "|    value_loss           | 4.2e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 215\n",
      "day: 1940, episode: 215\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 15239785.84\n",
      "total_reward: 5239785.84\n",
      "total_cost: 134265.16\n",
      "total_trades: 73688\n",
      "Sharpe: 0.338\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 203         |\n",
      "|    time_elapsed         | 1717        |\n",
      "|    total_timesteps      | 415744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024029171 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.3       |\n",
      "|    explained_variance   | 0.00604     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.71e+03    |\n",
      "|    n_updates            | 2020        |\n",
      "|    policy_gradient_loss | -0.0205     |\n",
      "|    reward               | -6.739492   |\n",
      "|    std                  | 1.59        |\n",
      "|    value_loss           | 5.05e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 216\n",
      "day: 1940, episode: 216\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13264747.21\n",
      "total_reward: 3264747.21\n",
      "total_cost: 126691.79\n",
      "total_trades: 73680\n",
      "Sharpe: 0.289\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 204         |\n",
      "|    time_elapsed         | 1726        |\n",
      "|    total_timesteps      | 417792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021365732 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.4       |\n",
      "|    explained_variance   | 0.0195      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.44e+03    |\n",
      "|    n_updates            | 2030        |\n",
      "|    policy_gradient_loss | -0.0223     |\n",
      "|    reward               | 6.7986307   |\n",
      "|    std                  | 1.59        |\n",
      "|    value_loss           | 5.32e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 217\n",
      "day: 1940, episode: 217\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14069331.57\n",
      "total_reward: 4069331.57\n",
      "total_cost: 135947.43\n",
      "total_trades: 73692\n",
      "Sharpe: 0.304\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 205         |\n",
      "|    time_elapsed         | 1735        |\n",
      "|    total_timesteps      | 419840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.050531812 |\n",
      "|    clip_fraction        | 0.369       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.5       |\n",
      "|    explained_variance   | 0.00328     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.94e+03    |\n",
      "|    n_updates            | 2040        |\n",
      "|    policy_gradient_loss | -0.00795    |\n",
      "|    reward               | 3.763989    |\n",
      "|    std                  | 1.59        |\n",
      "|    value_loss           | 4.28e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 218\n",
      "day: 1940, episode: 218\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 15352854.35\n",
      "total_reward: 5352854.35\n",
      "total_cost: 136763.65\n",
      "total_trades: 73678\n",
      "Sharpe: 0.342\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 206         |\n",
      "|    time_elapsed         | 1745        |\n",
      "|    total_timesteps      | 421888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030833786 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.6       |\n",
      "|    explained_variance   | 0.0364      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.3e+03     |\n",
      "|    n_updates            | 2050        |\n",
      "|    policy_gradient_loss | -0.00723    |\n",
      "|    reward               | -4.5414567  |\n",
      "|    std                  | 1.6         |\n",
      "|    value_loss           | 4e+03       |\n",
      "-----------------------------------------\n",
      "Episode: 219\n",
      "day: 1940, episode: 219\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12487262.19\n",
      "total_reward: 2487262.19\n",
      "total_cost: 127013.81\n",
      "total_trades: 73674\n",
      "Sharpe: 0.268\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 207         |\n",
      "|    time_elapsed         | 1754        |\n",
      "|    total_timesteps      | 423936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.057257283 |\n",
      "|    clip_fraction        | 0.356       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.7       |\n",
      "|    explained_variance   | 0.0351      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.97e+03    |\n",
      "|    n_updates            | 2060        |\n",
      "|    policy_gradient_loss | -0.00214    |\n",
      "|    reward               | 7.841256    |\n",
      "|    std                  | 1.6         |\n",
      "|    value_loss           | 4.72e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 220\n",
      "day: 1940, episode: 220\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12999696.37\n",
      "total_reward: 2999696.37\n",
      "total_cost: 128861.63\n",
      "total_trades: 73688\n",
      "Sharpe: 0.283\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 208         |\n",
      "|    time_elapsed         | 1763        |\n",
      "|    total_timesteps      | 425984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.051280707 |\n",
      "|    clip_fraction        | 0.297       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.7       |\n",
      "|    explained_variance   | 0.128       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3e+03       |\n",
      "|    n_updates            | 2070        |\n",
      "|    policy_gradient_loss | -0.00759    |\n",
      "|    reward               | 46.95352    |\n",
      "|    std                  | 1.6         |\n",
      "|    value_loss           | 4.25e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 221\n",
      "day: 1940, episode: 221\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 16215604.56\n",
      "total_reward: 6215604.56\n",
      "total_cost: 142171.44\n",
      "total_trades: 73683\n",
      "Sharpe: 0.369\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 241        |\n",
      "|    iterations           | 209        |\n",
      "|    time_elapsed         | 1773       |\n",
      "|    total_timesteps      | 428032     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02984067 |\n",
      "|    clip_fraction        | 0.267      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -71.8      |\n",
      "|    explained_variance   | -0.00317   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 3.26e+03   |\n",
      "|    n_updates            | 2080       |\n",
      "|    policy_gradient_loss | -0.0195    |\n",
      "|    reward               | 3.7278159  |\n",
      "|    std                  | 1.61       |\n",
      "|    value_loss           | 5.17e+03   |\n",
      "----------------------------------------\n",
      "Episode: 222\n",
      "day: 1940, episode: 222\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10964944.55\n",
      "total_reward: 964944.55\n",
      "total_cost: 126096.45\n",
      "total_trades: 73687\n",
      "Sharpe: 0.211\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 241        |\n",
      "|    iterations           | 210        |\n",
      "|    time_elapsed         | 1782       |\n",
      "|    total_timesteps      | 430080     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0509585  |\n",
      "|    clip_fraction        | 0.368      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -71.9      |\n",
      "|    explained_variance   | -0.015     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 3.1e+03    |\n",
      "|    n_updates            | 2090       |\n",
      "|    policy_gradient_loss | -0.00784   |\n",
      "|    reward               | -2.6025527 |\n",
      "|    std                  | 1.61       |\n",
      "|    value_loss           | 3.91e+03   |\n",
      "----------------------------------------\n",
      "Episode: 223\n",
      "day: 1940, episode: 223\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14780519.54\n",
      "total_reward: 4780519.54\n",
      "total_cost: 139547.46\n",
      "total_trades: 73686\n",
      "Sharpe: 0.330\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 211         |\n",
      "|    time_elapsed         | 1791        |\n",
      "|    total_timesteps      | 432128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021837614 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72         |\n",
      "|    explained_variance   | 0.0188      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.36e+03    |\n",
      "|    n_updates            | 2100        |\n",
      "|    policy_gradient_loss | -0.026      |\n",
      "|    reward               | -2.0461044  |\n",
      "|    std                  | 1.62        |\n",
      "|    value_loss           | 3.15e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 224\n",
      "day: 1940, episode: 224\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 17272937.64\n",
      "total_reward: 7272937.64\n",
      "total_cost: 141128.36\n",
      "total_trades: 73688\n",
      "Sharpe: 0.392\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 212         |\n",
      "|    time_elapsed         | 1800        |\n",
      "|    total_timesteps      | 434176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030492097 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.1       |\n",
      "|    explained_variance   | 0.0294      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.52e+03    |\n",
      "|    n_updates            | 2110        |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    reward               | -0.98487234 |\n",
      "|    std                  | 1.62        |\n",
      "|    value_loss           | 5.17e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 225\n",
      "day: 1940, episode: 225\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14344677.96\n",
      "total_reward: 4344677.96\n",
      "total_cost: 140240.04\n",
      "total_trades: 73693\n",
      "Sharpe: 0.310\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 213         |\n",
      "|    time_elapsed         | 1809        |\n",
      "|    total_timesteps      | 436224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030960929 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.2       |\n",
      "|    explained_variance   | 0.0232      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.44e+03    |\n",
      "|    n_updates            | 2120        |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    reward               | -13.64954   |\n",
      "|    std                  | 1.62        |\n",
      "|    value_loss           | 5.19e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 226\n",
      "day: 1940, episode: 226\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10486943.94\n",
      "total_reward: 486943.94\n",
      "total_cost: 127421.06\n",
      "total_trades: 73689\n",
      "Sharpe: 0.198\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 241        |\n",
      "|    iterations           | 214        |\n",
      "|    time_elapsed         | 1818       |\n",
      "|    total_timesteps      | 438272     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03830052 |\n",
      "|    clip_fraction        | 0.316      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -72.3      |\n",
      "|    explained_variance   | 0.0615     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.96e+03   |\n",
      "|    n_updates            | 2130       |\n",
      "|    policy_gradient_loss | -0.00841   |\n",
      "|    reward               | -13.470875 |\n",
      "|    std                  | 1.63       |\n",
      "|    value_loss           | 3.12e+03   |\n",
      "----------------------------------------\n",
      "Episode: 227\n",
      "day: 1940, episode: 227\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13284529.48\n",
      "total_reward: 3284529.48\n",
      "total_cost: 135522.52\n",
      "total_trades: 73688\n",
      "Sharpe: 0.288\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 240        |\n",
      "|    iterations           | 215        |\n",
      "|    time_elapsed         | 1827       |\n",
      "|    total_timesteps      | 440320     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03865353 |\n",
      "|    clip_fraction        | 0.317      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -72.3      |\n",
      "|    explained_variance   | 0.0646     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.84e+03   |\n",
      "|    n_updates            | 2140       |\n",
      "|    policy_gradient_loss | -0.0142    |\n",
      "|    reward               | 4.6342072  |\n",
      "|    std                  | 1.63       |\n",
      "|    value_loss           | 4.04e+03   |\n",
      "----------------------------------------\n",
      "Episode: 228\n",
      "day: 1940, episode: 228\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12259709.75\n",
      "total_reward: 2259709.75\n",
      "total_cost: 128012.25\n",
      "total_trades: 73692\n",
      "Sharpe: 0.247\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 216         |\n",
      "|    time_elapsed         | 1836        |\n",
      "|    total_timesteps      | 442368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026985295 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.4       |\n",
      "|    explained_variance   | 0.0935      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.64e+03    |\n",
      "|    n_updates            | 2150        |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    reward               | -13.961625  |\n",
      "|    std                  | 1.63        |\n",
      "|    value_loss           | 5.08e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 229\n",
      "day: 1940, episode: 229\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 16247709.73\n",
      "total_reward: 6247709.73\n",
      "total_cost: 131298.27\n",
      "total_trades: 73683\n",
      "Sharpe: 0.362\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 240        |\n",
      "|    iterations           | 217        |\n",
      "|    time_elapsed         | 1845       |\n",
      "|    total_timesteps      | 444416     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03638527 |\n",
      "|    clip_fraction        | 0.31       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -72.5      |\n",
      "|    explained_variance   | 0.0238     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 4.28e+03   |\n",
      "|    n_updates            | 2160       |\n",
      "|    policy_gradient_loss | -0.0147    |\n",
      "|    reward               | 15.221364  |\n",
      "|    std                  | 1.64       |\n",
      "|    value_loss           | 7.13e+03   |\n",
      "----------------------------------------\n",
      "Episode: 230\n",
      "day: 1940, episode: 230\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12688067.83\n",
      "total_reward: 2688067.83\n",
      "total_cost: 131483.17\n",
      "total_trades: 73686\n",
      "Sharpe: 0.267\n",
      "=================================\n",
      "Episode: 231\n",
      "day: 1940, episode: 231\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11892095.10\n",
      "total_reward: 1892095.10\n",
      "total_cost: 130824.90\n",
      "total_trades: 73681\n",
      "Sharpe: 0.250\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 218         |\n",
      "|    time_elapsed         | 1854        |\n",
      "|    total_timesteps      | 446464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042830423 |\n",
      "|    clip_fraction        | 0.287       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.5       |\n",
      "|    explained_variance   | 0.031       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.7e+03     |\n",
      "|    n_updates            | 2170        |\n",
      "|    policy_gradient_loss | -0.00494    |\n",
      "|    reward               | 4.9487476   |\n",
      "|    std                  | 1.64        |\n",
      "|    value_loss           | 4.97e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 232\n",
      "day: 1940, episode: 232\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14113198.78\n",
      "total_reward: 4113198.78\n",
      "total_cost: 137752.22\n",
      "total_trades: 73691\n",
      "Sharpe: 0.303\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 219         |\n",
      "|    time_elapsed         | 1863        |\n",
      "|    total_timesteps      | 448512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027986588 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.7       |\n",
      "|    explained_variance   | 0.0718      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.91e+03    |\n",
      "|    n_updates            | 2180        |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    reward               | 18.48064    |\n",
      "|    std                  | 1.64        |\n",
      "|    value_loss           | 3.98e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 233\n",
      "day: 1940, episode: 233\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14563149.35\n",
      "total_reward: 4563149.35\n",
      "total_cost: 142630.65\n",
      "total_trades: 73684\n",
      "Sharpe: 0.315\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 220         |\n",
      "|    time_elapsed         | 1872        |\n",
      "|    total_timesteps      | 450560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020428177 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.7       |\n",
      "|    explained_variance   | 0.0927      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.38e+03    |\n",
      "|    n_updates            | 2190        |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    reward               | -5.1850033  |\n",
      "|    std                  | 1.65        |\n",
      "|    value_loss           | 5.56e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 234\n",
      "day: 1940, episode: 234\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13278739.32\n",
      "total_reward: 3278739.32\n",
      "total_cost: 133478.68\n",
      "total_trades: 73684\n",
      "Sharpe: 0.291\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 240        |\n",
      "|    iterations           | 221        |\n",
      "|    time_elapsed         | 1880       |\n",
      "|    total_timesteps      | 452608     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02702837 |\n",
      "|    clip_fraction        | 0.239      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -72.8      |\n",
      "|    explained_variance   | 0.014      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.66e+03   |\n",
      "|    n_updates            | 2200       |\n",
      "|    policy_gradient_loss | -0.0135    |\n",
      "|    reward               | -8.413346  |\n",
      "|    std                  | 1.65       |\n",
      "|    value_loss           | 5.7e+03    |\n",
      "----------------------------------------\n",
      "Episode: 235\n",
      "day: 1940, episode: 235\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14496472.97\n",
      "total_reward: 4496472.97\n",
      "total_cost: 131924.03\n",
      "total_trades: 73684\n",
      "Sharpe: 0.314\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 240        |\n",
      "|    iterations           | 222        |\n",
      "|    time_elapsed         | 1889       |\n",
      "|    total_timesteps      | 454656     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01997086 |\n",
      "|    clip_fraction        | 0.19       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -72.8      |\n",
      "|    explained_variance   | 0.0514     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.21e+03   |\n",
      "|    n_updates            | 2210       |\n",
      "|    policy_gradient_loss | -0.0201    |\n",
      "|    reward               | -11.578082 |\n",
      "|    std                  | 1.65       |\n",
      "|    value_loss           | 3.97e+03   |\n",
      "----------------------------------------\n",
      "Episode: 236\n",
      "day: 1940, episode: 236\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13830093.19\n",
      "total_reward: 3830093.19\n",
      "total_cost: 135567.81\n",
      "total_trades: 73684\n",
      "Sharpe: 0.294\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 223         |\n",
      "|    time_elapsed         | 1898        |\n",
      "|    total_timesteps      | 456704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015461939 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.9       |\n",
      "|    explained_variance   | 0.0357      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.86e+03    |\n",
      "|    n_updates            | 2220        |\n",
      "|    policy_gradient_loss | -0.025      |\n",
      "|    reward               | -4.480404   |\n",
      "|    std                  | 1.66        |\n",
      "|    value_loss           | 5.94e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 237\n",
      "day: 1940, episode: 237\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 15650591.38\n",
      "total_reward: 5650591.38\n",
      "total_cost: 141418.62\n",
      "total_trades: 73701\n",
      "Sharpe: 0.350\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 224         |\n",
      "|    time_elapsed         | 1907        |\n",
      "|    total_timesteps      | 458752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037194043 |\n",
      "|    clip_fraction        | 0.257       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73         |\n",
      "|    explained_variance   | 0.108       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.51e+03    |\n",
      "|    n_updates            | 2230        |\n",
      "|    policy_gradient_loss | -0.0186     |\n",
      "|    reward               | 13.721171   |\n",
      "|    std                  | 1.66        |\n",
      "|    value_loss           | 4.31e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 238\n",
      "day: 1940, episode: 238\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 15404501.86\n",
      "total_reward: 5404501.86\n",
      "total_cost: 145509.14\n",
      "total_trades: 73682\n",
      "Sharpe: 0.345\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 225         |\n",
      "|    time_elapsed         | 1916        |\n",
      "|    total_timesteps      | 460800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027557105 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.1       |\n",
      "|    explained_variance   | 0.0871      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.18e+03    |\n",
      "|    n_updates            | 2240        |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    reward               | 15.029034   |\n",
      "|    std                  | 1.66        |\n",
      "|    value_loss           | 5.84e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 239\n",
      "day: 1940, episode: 239\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14404833.29\n",
      "total_reward: 4404833.29\n",
      "total_cost: 136070.71\n",
      "total_trades: 73685\n",
      "Sharpe: 0.312\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 240       |\n",
      "|    iterations           | 226       |\n",
      "|    time_elapsed         | 1925      |\n",
      "|    total_timesteps      | 462848    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0322998 |\n",
      "|    clip_fraction        | 0.244     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -73.2     |\n",
      "|    explained_variance   | 0.0756    |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 2.74e+03  |\n",
      "|    n_updates            | 2250      |\n",
      "|    policy_gradient_loss | -0.0109   |\n",
      "|    reward               | -21.38427 |\n",
      "|    std                  | 1.67      |\n",
      "|    value_loss           | 6.06e+03  |\n",
      "---------------------------------------\n",
      "Episode: 240\n",
      "day: 1940, episode: 240\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11370673.54\n",
      "total_reward: 1370673.54\n",
      "total_cost: 133330.46\n",
      "total_trades: 73687\n",
      "Sharpe: 0.211\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 227         |\n",
      "|    time_elapsed         | 1935        |\n",
      "|    total_timesteps      | 464896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026561216 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.2       |\n",
      "|    explained_variance   | -0.0408     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.42e+03    |\n",
      "|    n_updates            | 2260        |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    reward               | -12.2492285 |\n",
      "|    std                  | 1.67        |\n",
      "|    value_loss           | 5e+03       |\n",
      "-----------------------------------------\n",
      "Episode: 241\n",
      "day: 1940, episode: 241\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13651009.14\n",
      "total_reward: 3651009.14\n",
      "total_cost: 136188.86\n",
      "total_trades: 73681\n",
      "Sharpe: 0.289\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 228         |\n",
      "|    time_elapsed         | 1944        |\n",
      "|    total_timesteps      | 466944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.059224468 |\n",
      "|    clip_fraction        | 0.395       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.3       |\n",
      "|    explained_variance   | 0.0382      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.56e+03    |\n",
      "|    n_updates            | 2270        |\n",
      "|    policy_gradient_loss | -0.0044     |\n",
      "|    reward               | -6.0478263  |\n",
      "|    std                  | 1.68        |\n",
      "|    value_loss           | 4.07e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 242\n",
      "day: 1940, episode: 242\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13073487.11\n",
      "total_reward: 3073487.11\n",
      "total_cost: 144097.89\n",
      "total_trades: 73685\n",
      "Sharpe: 0.273\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 229         |\n",
      "|    time_elapsed         | 1954        |\n",
      "|    total_timesteps      | 468992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047714274 |\n",
      "|    clip_fraction        | 0.344       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.5       |\n",
      "|    explained_variance   | 0.0511      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.83e+03    |\n",
      "|    n_updates            | 2280        |\n",
      "|    policy_gradient_loss | -0.00603    |\n",
      "|    reward               | 2.54496     |\n",
      "|    std                  | 1.68        |\n",
      "|    value_loss           | 3.31e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 243\n",
      "day: 1940, episode: 243\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11991756.63\n",
      "total_reward: 1991756.63\n",
      "total_cost: 135846.37\n",
      "total_trades: 73684\n",
      "Sharpe: 0.241\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 239        |\n",
      "|    iterations           | 230        |\n",
      "|    time_elapsed         | 1963       |\n",
      "|    total_timesteps      | 471040     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01723647 |\n",
      "|    clip_fraction        | 0.217      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -73.6      |\n",
      "|    explained_variance   | 0.0492     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.65e+03   |\n",
      "|    n_updates            | 2290       |\n",
      "|    policy_gradient_loss | -0.0247    |\n",
      "|    reward               | 1.4124376  |\n",
      "|    std                  | 1.68       |\n",
      "|    value_loss           | 2.73e+03   |\n",
      "----------------------------------------\n",
      "Episode: 244\n",
      "day: 1940, episode: 244\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12911006.07\n",
      "total_reward: 2911006.07\n",
      "total_cost: 139760.93\n",
      "total_trades: 73685\n",
      "Sharpe: 0.276\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 231         |\n",
      "|    time_elapsed         | 1972        |\n",
      "|    total_timesteps      | 473088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037611436 |\n",
      "|    clip_fraction        | 0.267       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.6       |\n",
      "|    explained_variance   | 0.00357     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.31e+03    |\n",
      "|    n_updates            | 2300        |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    reward               | -9.453467   |\n",
      "|    std                  | 1.69        |\n",
      "|    value_loss           | 2.88e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 245\n",
      "day: 1940, episode: 245\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 16581909.61\n",
      "total_reward: 6581909.61\n",
      "total_cost: 134134.39\n",
      "total_trades: 73686\n",
      "Sharpe: 0.375\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 239        |\n",
      "|    iterations           | 232        |\n",
      "|    time_elapsed         | 1981       |\n",
      "|    total_timesteps      | 475136     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06590558 |\n",
      "|    clip_fraction        | 0.362      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -73.7      |\n",
      "|    explained_variance   | 0.0256     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 3.3e+03    |\n",
      "|    n_updates            | 2310       |\n",
      "|    policy_gradient_loss | 0.00304    |\n",
      "|    reward               | 7.3507366  |\n",
      "|    std                  | 1.69       |\n",
      "|    value_loss           | 5.27e+03   |\n",
      "----------------------------------------\n",
      "Episode: 246\n",
      "day: 1940, episode: 246\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11968312.59\n",
      "total_reward: 1968312.59\n",
      "total_cost: 138578.41\n",
      "total_trades: 73684\n",
      "Sharpe: 0.228\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 239        |\n",
      "|    iterations           | 233        |\n",
      "|    time_elapsed         | 1990       |\n",
      "|    total_timesteps      | 477184     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06098254 |\n",
      "|    clip_fraction        | 0.326      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -73.8      |\n",
      "|    explained_variance   | 0.021      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.38e+03   |\n",
      "|    n_updates            | 2320       |\n",
      "|    policy_gradient_loss | -0.00508   |\n",
      "|    reward               | -16.589024 |\n",
      "|    std                  | 1.7        |\n",
      "|    value_loss           | 4.79e+03   |\n",
      "----------------------------------------\n",
      "Episode: 247\n",
      "day: 1940, episode: 247\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 16011550.07\n",
      "total_reward: 6011550.07\n",
      "total_cost: 134480.93\n",
      "total_trades: 73694\n",
      "Sharpe: 0.363\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 239        |\n",
      "|    iterations           | 234        |\n",
      "|    time_elapsed         | 1999       |\n",
      "|    total_timesteps      | 479232     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03880787 |\n",
      "|    clip_fraction        | 0.298      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -73.9      |\n",
      "|    explained_variance   | 0.0847     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.06e+03   |\n",
      "|    n_updates            | 2330       |\n",
      "|    policy_gradient_loss | -0.00208   |\n",
      "|    reward               | 1.3166275  |\n",
      "|    std                  | 1.7        |\n",
      "|    value_loss           | 5.06e+03   |\n",
      "----------------------------------------\n",
      "Episode: 248\n",
      "day: 1940, episode: 248\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14414044.07\n",
      "total_reward: 4414044.07\n",
      "total_cost: 140602.93\n",
      "total_trades: 73691\n",
      "Sharpe: 0.319\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 235         |\n",
      "|    time_elapsed         | 2008        |\n",
      "|    total_timesteps      | 481280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023749921 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74         |\n",
      "|    explained_variance   | 0.0452      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.84e+03    |\n",
      "|    n_updates            | 2340        |\n",
      "|    policy_gradient_loss | -0.0181     |\n",
      "|    reward               | 8.203006    |\n",
      "|    std                  | 1.7         |\n",
      "|    value_loss           | 5.04e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 249\n",
      "day: 1940, episode: 249\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14062049.38\n",
      "total_reward: 4062049.38\n",
      "total_cost: 139565.62\n",
      "total_trades: 73691\n",
      "Sharpe: 0.302\n",
      "=================================\n",
      "Episode: 250\n",
      "day: 1940, episode: 250\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 15502577.26\n",
      "total_reward: 5502577.26\n",
      "total_cost: 131033.74\n",
      "total_trades: 73686\n",
      "Sharpe: 0.347\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 236         |\n",
      "|    time_elapsed         | 2017        |\n",
      "|    total_timesteps      | 483328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.052791025 |\n",
      "|    clip_fraction        | 0.319       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.1       |\n",
      "|    explained_variance   | 0.0544      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.51e+03    |\n",
      "|    n_updates            | 2350        |\n",
      "|    policy_gradient_loss | -0.00394    |\n",
      "|    reward               | 0.2088949   |\n",
      "|    std                  | 1.71        |\n",
      "|    value_loss           | 4.54e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 251\n",
      "day: 1940, episode: 251\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13470626.35\n",
      "total_reward: 3470626.35\n",
      "total_cost: 140213.65\n",
      "total_trades: 73685\n",
      "Sharpe: 0.283\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 237         |\n",
      "|    time_elapsed         | 2026        |\n",
      "|    total_timesteps      | 485376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029627979 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.2       |\n",
      "|    explained_variance   | 0.026       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.34e+03    |\n",
      "|    n_updates            | 2360        |\n",
      "|    policy_gradient_loss | -0.00815    |\n",
      "|    reward               | 8.710621    |\n",
      "|    std                  | 1.71        |\n",
      "|    value_loss           | 5.38e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 252\n",
      "day: 1940, episode: 252\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13429314.28\n",
      "total_reward: 3429314.28\n",
      "total_cost: 136597.72\n",
      "total_trades: 73697\n",
      "Sharpe: 0.289\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 238         |\n",
      "|    time_elapsed         | 2035        |\n",
      "|    total_timesteps      | 487424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027161505 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.2       |\n",
      "|    explained_variance   | 0.0116      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.33e+03    |\n",
      "|    n_updates            | 2370        |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    reward               | 14.655963   |\n",
      "|    std                  | 1.71        |\n",
      "|    value_loss           | 3.36e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 253\n",
      "day: 1940, episode: 253\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 15472090.64\n",
      "total_reward: 5472090.64\n",
      "total_cost: 128024.36\n",
      "total_trades: 73684\n",
      "Sharpe: 0.349\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 239         |\n",
      "|    time_elapsed         | 2044        |\n",
      "|    total_timesteps      | 489472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028297197 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.3       |\n",
      "|    explained_variance   | 0.0313      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.16e+03    |\n",
      "|    n_updates            | 2380        |\n",
      "|    policy_gradient_loss | -0.0191     |\n",
      "|    reward               | -20.03026   |\n",
      "|    std                  | 1.72        |\n",
      "|    value_loss           | 4.23e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 254\n",
      "day: 1940, episode: 254\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 15189869.03\n",
      "total_reward: 5189869.03\n",
      "total_cost: 134085.97\n",
      "total_trades: 73677\n",
      "Sharpe: 0.340\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 240         |\n",
      "|    time_elapsed         | 2052        |\n",
      "|    total_timesteps      | 491520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047133792 |\n",
      "|    clip_fraction        | 0.328       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.4       |\n",
      "|    explained_variance   | 0.0723      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.89e+03    |\n",
      "|    n_updates            | 2390        |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    reward               | 2.9710214   |\n",
      "|    std                  | 1.72        |\n",
      "|    value_loss           | 4.66e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 255\n",
      "day: 1940, episode: 255\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14403669.42\n",
      "total_reward: 4403669.42\n",
      "total_cost: 130118.58\n",
      "total_trades: 73685\n",
      "Sharpe: 0.315\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 241         |\n",
      "|    time_elapsed         | 2061        |\n",
      "|    total_timesteps      | 493568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031151757 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.5       |\n",
      "|    explained_variance   | 0.0882      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.34e+03    |\n",
      "|    n_updates            | 2400        |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    reward               | 5.0744653   |\n",
      "|    std                  | 1.73        |\n",
      "|    value_loss           | 4.75e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 256\n",
      "day: 1940, episode: 256\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 15138085.54\n",
      "total_reward: 5138085.54\n",
      "total_cost: 140251.46\n",
      "total_trades: 73696\n",
      "Sharpe: 0.336\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 239        |\n",
      "|    iterations           | 242        |\n",
      "|    time_elapsed         | 2070       |\n",
      "|    total_timesteps      | 495616     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04564213 |\n",
      "|    clip_fraction        | 0.311      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -74.6      |\n",
      "|    explained_variance   | 0.058      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.64e+03   |\n",
      "|    n_updates            | 2410       |\n",
      "|    policy_gradient_loss | -0.0151    |\n",
      "|    reward               | 14.377018  |\n",
      "|    std                  | 1.73       |\n",
      "|    value_loss           | 4.99e+03   |\n",
      "----------------------------------------\n",
      "Episode: 257\n",
      "day: 1940, episode: 257\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14210946.26\n",
      "total_reward: 4210946.26\n",
      "total_cost: 135113.74\n",
      "total_trades: 73698\n",
      "Sharpe: 0.308\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 243         |\n",
      "|    time_elapsed         | 2079        |\n",
      "|    total_timesteps      | 497664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020434307 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.7       |\n",
      "|    explained_variance   | 0.0413      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.01e+03    |\n",
      "|    n_updates            | 2420        |\n",
      "|    policy_gradient_loss | -0.0255     |\n",
      "|    reward               | 0.025646228 |\n",
      "|    std                  | 1.74        |\n",
      "|    value_loss           | 4.84e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 258\n",
      "day: 1940, episode: 258\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13869402.46\n",
      "total_reward: 3869402.46\n",
      "total_cost: 137312.54\n",
      "total_trades: 73688\n",
      "Sharpe: 0.295\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 244         |\n",
      "|    time_elapsed         | 2088        |\n",
      "|    total_timesteps      | 499712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032198478 |\n",
      "|    clip_fraction        | 0.257       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.8       |\n",
      "|    explained_variance   | 0.0382      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.98e+03    |\n",
      "|    n_updates            | 2430        |\n",
      "|    policy_gradient_loss | -0.00623    |\n",
      "|    reward               | -73.90452   |\n",
      "|    std                  | 1.74        |\n",
      "|    value_loss           | 4.51e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 259\n",
      "day: 1940, episode: 259\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12523814.66\n",
      "total_reward: 2523814.66\n",
      "total_cost: 135565.34\n",
      "total_trades: 73693\n",
      "Sharpe: 0.263\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 245         |\n",
      "|    time_elapsed         | 2098        |\n",
      "|    total_timesteps      | 501760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021364583 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.9       |\n",
      "|    explained_variance   | 0.023       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.86e+03    |\n",
      "|    n_updates            | 2440        |\n",
      "|    policy_gradient_loss | -0.027      |\n",
      "|    reward               | -74.84562   |\n",
      "|    std                  | 1.74        |\n",
      "|    value_loss           | 5.91e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 260\n",
      "day: 1940, episode: 260\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 15055878.27\n",
      "total_reward: 5055878.27\n",
      "total_cost: 141498.73\n",
      "total_trades: 73697\n",
      "Sharpe: 0.330\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 239        |\n",
      "|    iterations           | 246        |\n",
      "|    time_elapsed         | 2107       |\n",
      "|    total_timesteps      | 503808     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04210687 |\n",
      "|    clip_fraction        | 0.27       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -74.9      |\n",
      "|    explained_variance   | 0.041      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.5e+03    |\n",
      "|    n_updates            | 2450       |\n",
      "|    policy_gradient_loss | -0.011     |\n",
      "|    reward               | 6.835765   |\n",
      "|    std                  | 1.75       |\n",
      "|    value_loss           | 6.33e+03   |\n",
      "----------------------------------------\n",
      "Episode: 261\n",
      "day: 1940, episode: 261\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13693356.08\n",
      "total_reward: 3693356.08\n",
      "total_cost: 141196.92\n",
      "total_trades: 73701\n",
      "Sharpe: 0.291\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 247         |\n",
      "|    time_elapsed         | 2116        |\n",
      "|    total_timesteps      | 505856      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024028009 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75         |\n",
      "|    explained_variance   | 0.0549      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.56e+03    |\n",
      "|    n_updates            | 2460        |\n",
      "|    policy_gradient_loss | -0.0206     |\n",
      "|    reward               | -0.4344324  |\n",
      "|    std                  | 1.75        |\n",
      "|    value_loss           | 5.83e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 262\n",
      "day: 1940, episode: 262\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13549332.89\n",
      "total_reward: 3549332.89\n",
      "total_cost: 140483.11\n",
      "total_trades: 73690\n",
      "Sharpe: 0.290\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 238        |\n",
      "|    iterations           | 248        |\n",
      "|    time_elapsed         | 2125       |\n",
      "|    total_timesteps      | 507904     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04073961 |\n",
      "|    clip_fraction        | 0.287      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -75.1      |\n",
      "|    explained_variance   | 0.0108     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 3.01e+03   |\n",
      "|    n_updates            | 2470       |\n",
      "|    policy_gradient_loss | -0.0107    |\n",
      "|    reward               | -2.302672  |\n",
      "|    std                  | 1.76       |\n",
      "|    value_loss           | 4.81e+03   |\n",
      "----------------------------------------\n",
      "Episode: 263\n",
      "day: 1940, episode: 263\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14827470.78\n",
      "total_reward: 4827470.78\n",
      "total_cost: 144961.22\n",
      "total_trades: 73690\n",
      "Sharpe: 0.328\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 249         |\n",
      "|    time_elapsed         | 2134        |\n",
      "|    total_timesteps      | 509952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017399814 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.2       |\n",
      "|    explained_variance   | 0.0192      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.27e+03    |\n",
      "|    n_updates            | 2480        |\n",
      "|    policy_gradient_loss | -0.0313     |\n",
      "|    reward               | 3.2313557   |\n",
      "|    std                  | 1.76        |\n",
      "|    value_loss           | 4.76e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 264\n",
      "day: 1940, episode: 264\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 16048225.75\n",
      "total_reward: 6048225.75\n",
      "total_cost: 148348.25\n",
      "total_trades: 73689\n",
      "Sharpe: 0.364\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 250         |\n",
      "|    time_elapsed         | 2143        |\n",
      "|    total_timesteps      | 512000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040454812 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.3       |\n",
      "|    explained_variance   | 0.00856     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.78e+03    |\n",
      "|    n_updates            | 2490        |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    reward               | -1.484959   |\n",
      "|    std                  | 1.76        |\n",
      "|    value_loss           | 4.95e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 265\n",
      "day: 1940, episode: 265\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10634847.06\n",
      "total_reward: 634847.06\n",
      "total_cost: 140768.94\n",
      "total_trades: 73692\n",
      "Sharpe: 0.192\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 251         |\n",
      "|    time_elapsed         | 2152        |\n",
      "|    total_timesteps      | 514048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041357897 |\n",
      "|    clip_fraction        | 0.326       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.4       |\n",
      "|    explained_variance   | -0.00251    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.61e+03    |\n",
      "|    n_updates            | 2500        |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    reward               | 4.8607454   |\n",
      "|    std                  | 1.77        |\n",
      "|    value_loss           | 4.25e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 266\n",
      "day: 1940, episode: 266\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13109085.66\n",
      "total_reward: 3109085.66\n",
      "total_cost: 144720.34\n",
      "total_trades: 73689\n",
      "Sharpe: 0.277\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 252         |\n",
      "|    time_elapsed         | 2161        |\n",
      "|    total_timesteps      | 516096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020811286 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.6       |\n",
      "|    explained_variance   | 0.0122      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.15e+03    |\n",
      "|    n_updates            | 2510        |\n",
      "|    policy_gradient_loss | -0.0277     |\n",
      "|    reward               | -1.1004668  |\n",
      "|    std                  | 1.78        |\n",
      "|    value_loss           | 4.2e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 267\n",
      "day: 1940, episode: 267\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14232581.56\n",
      "total_reward: 4232581.56\n",
      "total_cost: 149953.44\n",
      "total_trades: 73686\n",
      "Sharpe: 0.320\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 253         |\n",
      "|    time_elapsed         | 2170        |\n",
      "|    total_timesteps      | 518144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021202568 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.7       |\n",
      "|    explained_variance   | -0.0121     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.57e+03    |\n",
      "|    n_updates            | 2520        |\n",
      "|    policy_gradient_loss | -0.0203     |\n",
      "|    reward               | -8.392966   |\n",
      "|    std                  | 1.78        |\n",
      "|    value_loss           | 4.11e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 268\n",
      "day: 1940, episode: 268\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14143257.45\n",
      "total_reward: 4143257.45\n",
      "total_cost: 147223.55\n",
      "total_trades: 73687\n",
      "Sharpe: 0.305\n",
      "=================================\n",
      "Episode: 269\n",
      "day: 1940, episode: 269\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12703859.18\n",
      "total_reward: 2703859.18\n",
      "total_cost: 145645.82\n",
      "total_trades: 73681\n",
      "Sharpe: 0.256\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 254         |\n",
      "|    time_elapsed         | 2179        |\n",
      "|    total_timesteps      | 520192      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040566288 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.8       |\n",
      "|    explained_variance   | 0.00247     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.65e+03    |\n",
      "|    n_updates            | 2530        |\n",
      "|    policy_gradient_loss | -0.0219     |\n",
      "|    reward               | -2.3587172  |\n",
      "|    std                  | 1.79        |\n",
      "|    value_loss           | 4.8e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 270\n",
      "day: 1940, episode: 270\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13124156.26\n",
      "total_reward: 3124156.26\n",
      "total_cost: 142497.74\n",
      "total_trades: 73678\n",
      "Sharpe: 0.269\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 255         |\n",
      "|    time_elapsed         | 2188        |\n",
      "|    total_timesteps      | 522240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031263866 |\n",
      "|    clip_fraction        | 0.27        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.9       |\n",
      "|    explained_variance   | 0.000305    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.7e+03     |\n",
      "|    n_updates            | 2540        |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    reward               | 3.5542839   |\n",
      "|    std                  | 1.79        |\n",
      "|    value_loss           | 4.04e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 271\n",
      "day: 1940, episode: 271\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14481178.64\n",
      "total_reward: 4481178.64\n",
      "total_cost: 148613.36\n",
      "total_trades: 73686\n",
      "Sharpe: 0.315\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 256         |\n",
      "|    time_elapsed         | 2196        |\n",
      "|    total_timesteps      | 524288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027685754 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.1       |\n",
      "|    explained_variance   | 0.00818     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.67e+03    |\n",
      "|    n_updates            | 2550        |\n",
      "|    policy_gradient_loss | -0.0219     |\n",
      "|    reward               | -10.327114  |\n",
      "|    std                  | 1.8         |\n",
      "|    value_loss           | 3.87e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 272\n",
      "day: 1940, episode: 272\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14932127.95\n",
      "total_reward: 4932127.95\n",
      "total_cost: 150818.05\n",
      "total_trades: 73691\n",
      "Sharpe: 0.332\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 238        |\n",
      "|    iterations           | 257        |\n",
      "|    time_elapsed         | 2206       |\n",
      "|    total_timesteps      | 526336     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04743278 |\n",
      "|    clip_fraction        | 0.389      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76.2      |\n",
      "|    explained_variance   | 0.017      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.66e+03   |\n",
      "|    n_updates            | 2560       |\n",
      "|    policy_gradient_loss | -0.00151   |\n",
      "|    reward               | 9.419792   |\n",
      "|    std                  | 1.81       |\n",
      "|    value_loss           | 4.5e+03    |\n",
      "----------------------------------------\n",
      "Episode: 273\n",
      "day: 1940, episode: 273\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 15071667.97\n",
      "total_reward: 5071667.97\n",
      "total_cost: 151585.03\n",
      "total_trades: 73692\n",
      "Sharpe: 0.333\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 258         |\n",
      "|    time_elapsed         | 2216        |\n",
      "|    total_timesteps      | 528384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024871826 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.2       |\n",
      "|    explained_variance   | 0.0116      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.62e+03    |\n",
      "|    n_updates            | 2570        |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    reward               | 9.520732    |\n",
      "|    std                  | 1.81        |\n",
      "|    value_loss           | 4.62e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 274\n",
      "day: 1940, episode: 274\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13628160.01\n",
      "total_reward: 3628160.01\n",
      "total_cost: 148277.99\n",
      "total_trades: 73700\n",
      "Sharpe: 0.292\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 259         |\n",
      "|    time_elapsed         | 2225        |\n",
      "|    total_timesteps      | 530432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040901855 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.3       |\n",
      "|    explained_variance   | -0.00319    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.4e+03     |\n",
      "|    n_updates            | 2580        |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    reward               | 26.482437   |\n",
      "|    std                  | 1.81        |\n",
      "|    value_loss           | 5.07e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 275\n",
      "day: 1940, episode: 275\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 16364699.52\n",
      "total_reward: 6364699.52\n",
      "total_cost: 152798.48\n",
      "total_trades: 73691\n",
      "Sharpe: 0.376\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 238        |\n",
      "|    iterations           | 260        |\n",
      "|    time_elapsed         | 2234       |\n",
      "|    total_timesteps      | 532480     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04394916 |\n",
      "|    clip_fraction        | 0.29       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76.4      |\n",
      "|    explained_variance   | 0.00398    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.93e+03   |\n",
      "|    n_updates            | 2590       |\n",
      "|    policy_gradient_loss | -0.0114    |\n",
      "|    reward               | -4.964664  |\n",
      "|    std                  | 1.82       |\n",
      "|    value_loss           | 3.96e+03   |\n",
      "----------------------------------------\n",
      "Episode: 276\n",
      "day: 1940, episode: 276\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14638585.15\n",
      "total_reward: 4638585.15\n",
      "total_cost: 152717.85\n",
      "total_trades: 73701\n",
      "Sharpe: 0.325\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 238        |\n",
      "|    iterations           | 261        |\n",
      "|    time_elapsed         | 2243       |\n",
      "|    total_timesteps      | 534528     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05270025 |\n",
      "|    clip_fraction        | 0.33       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76.5      |\n",
      "|    explained_variance   | -0.0133    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.47e+03   |\n",
      "|    n_updates            | 2600       |\n",
      "|    policy_gradient_loss | -0.00963   |\n",
      "|    reward               | -4.6113615 |\n",
      "|    std                  | 1.82       |\n",
      "|    value_loss           | 5.17e+03   |\n",
      "----------------------------------------\n",
      "Episode: 277\n",
      "day: 1940, episode: 277\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11998183.45\n",
      "total_reward: 1998183.45\n",
      "total_cost: 151492.55\n",
      "total_trades: 73694\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 262         |\n",
      "|    time_elapsed         | 2253        |\n",
      "|    total_timesteps      | 536576      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024746025 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.6       |\n",
      "|    explained_variance   | 0.0114      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.51e+03    |\n",
      "|    n_updates            | 2610        |\n",
      "|    policy_gradient_loss | -0.0212     |\n",
      "|    reward               | -45.48892   |\n",
      "|    std                  | 1.83        |\n",
      "|    value_loss           | 3.6e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 278\n",
      "day: 1940, episode: 278\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12831011.61\n",
      "total_reward: 2831011.61\n",
      "total_cost: 154304.39\n",
      "total_trades: 73691\n",
      "Sharpe: 0.268\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 238        |\n",
      "|    iterations           | 263        |\n",
      "|    time_elapsed         | 2262       |\n",
      "|    total_timesteps      | 538624     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03284634 |\n",
      "|    clip_fraction        | 0.229      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76.6      |\n",
      "|    explained_variance   | -0.00935   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.57e+03   |\n",
      "|    n_updates            | 2620       |\n",
      "|    policy_gradient_loss | -0.0213    |\n",
      "|    reward               | -5.880653  |\n",
      "|    std                  | 1.83       |\n",
      "|    value_loss           | 3.31e+03   |\n",
      "----------------------------------------\n",
      "Episode: 279\n",
      "day: 1940, episode: 279\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13360343.60\n",
      "total_reward: 3360343.60\n",
      "total_cost: 150981.40\n",
      "total_trades: 73682\n",
      "Sharpe: 0.294\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 264         |\n",
      "|    time_elapsed         | 2272        |\n",
      "|    total_timesteps      | 540672      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038820025 |\n",
      "|    clip_fraction        | 0.331       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.7       |\n",
      "|    explained_variance   | 0.0156      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.75e+03    |\n",
      "|    n_updates            | 2630        |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    reward               | 9.214878    |\n",
      "|    std                  | 1.83        |\n",
      "|    value_loss           | 3.62e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 280\n",
      "day: 1940, episode: 280\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 17292709.27\n",
      "total_reward: 7292709.27\n",
      "total_cost: 154865.73\n",
      "total_trades: 73685\n",
      "Sharpe: 0.405\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 237        |\n",
      "|    iterations           | 265        |\n",
      "|    time_elapsed         | 2281       |\n",
      "|    total_timesteps      | 542720     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04707316 |\n",
      "|    clip_fraction        | 0.333      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76.8      |\n",
      "|    explained_variance   | 0.00421    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 3.04e+03   |\n",
      "|    n_updates            | 2640       |\n",
      "|    policy_gradient_loss | -0.0159    |\n",
      "|    reward               | 4.2659607  |\n",
      "|    std                  | 1.84       |\n",
      "|    value_loss           | 4.62e+03   |\n",
      "----------------------------------------\n",
      "Episode: 281\n",
      "day: 1940, episode: 281\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13123825.72\n",
      "total_reward: 3123825.72\n",
      "total_cost: 151060.28\n",
      "total_trades: 73689\n",
      "Sharpe: 0.271\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 266         |\n",
      "|    time_elapsed         | 2290        |\n",
      "|    total_timesteps      | 544768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025530223 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.9       |\n",
      "|    explained_variance   | -0.0116     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.31e+03    |\n",
      "|    n_updates            | 2650        |\n",
      "|    policy_gradient_loss | -0.0218     |\n",
      "|    reward               | -0.9581441  |\n",
      "|    std                  | 1.84        |\n",
      "|    value_loss           | 3.05e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 282\n",
      "day: 1940, episode: 282\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12634089.86\n",
      "total_reward: 2634089.86\n",
      "total_cost: 152502.14\n",
      "total_trades: 73684\n",
      "Sharpe: 0.256\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 267         |\n",
      "|    time_elapsed         | 2299        |\n",
      "|    total_timesteps      | 546816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02469724  |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77         |\n",
      "|    explained_variance   | 0.00945     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 999         |\n",
      "|    n_updates            | 2660        |\n",
      "|    policy_gradient_loss | -0.0277     |\n",
      "|    reward               | -0.97829646 |\n",
      "|    std                  | 1.85        |\n",
      "|    value_loss           | 2.55e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 283\n",
      "day: 1940, episode: 283\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10199335.50\n",
      "total_reward: 199335.50\n",
      "total_cost: 149803.50\n",
      "total_trades: 73687\n",
      "Sharpe: 0.158\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 237        |\n",
      "|    iterations           | 268        |\n",
      "|    time_elapsed         | 2308       |\n",
      "|    total_timesteps      | 548864     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03389377 |\n",
      "|    clip_fraction        | 0.318      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -77.1      |\n",
      "|    explained_variance   | -0.00648   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 603        |\n",
      "|    n_updates            | 2670       |\n",
      "|    policy_gradient_loss | -0.0211    |\n",
      "|    reward               | -1.9240847 |\n",
      "|    std                  | 1.85       |\n",
      "|    value_loss           | 2.05e+03   |\n",
      "----------------------------------------\n",
      "Episode: 284\n",
      "day: 1940, episode: 284\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 15184660.35\n",
      "total_reward: 5184660.35\n",
      "total_cost: 158899.65\n",
      "total_trades: 73681\n",
      "Sharpe: 0.357\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 237        |\n",
      "|    iterations           | 269        |\n",
      "|    time_elapsed         | 2317       |\n",
      "|    total_timesteps      | 550912     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04658892 |\n",
      "|    clip_fraction        | 0.315      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -77.2      |\n",
      "|    explained_variance   | -0.0101    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.36e+03   |\n",
      "|    n_updates            | 2680       |\n",
      "|    policy_gradient_loss | -0.0117    |\n",
      "|    reward               | 0.97764254 |\n",
      "|    std                  | 1.86       |\n",
      "|    value_loss           | 2.2e+03    |\n",
      "----------------------------------------\n",
      "Episode: 285\n",
      "day: 1940, episode: 285\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12908491.96\n",
      "total_reward: 2908491.96\n",
      "total_cost: 152351.04\n",
      "total_trades: 73696\n",
      "Sharpe: 0.266\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 270         |\n",
      "|    time_elapsed         | 2326        |\n",
      "|    total_timesteps      | 552960      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012832006 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.3       |\n",
      "|    explained_variance   | -0.00273    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.17e+03    |\n",
      "|    n_updates            | 2690        |\n",
      "|    policy_gradient_loss | -0.0235     |\n",
      "|    reward               | 8.900426    |\n",
      "|    std                  | 1.86        |\n",
      "|    value_loss           | 3.05e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 286\n",
      "day: 1940, episode: 286\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 16288355.56\n",
      "total_reward: 6288355.56\n",
      "total_cost: 154403.44\n",
      "total_trades: 73689\n",
      "Sharpe: 0.376\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 271         |\n",
      "|    time_elapsed         | 2337        |\n",
      "|    total_timesteps      | 555008      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032066256 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.4       |\n",
      "|    explained_variance   | 0.00449     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.37e+03    |\n",
      "|    n_updates            | 2700        |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    reward               | 12.048145   |\n",
      "|    std                  | 1.87        |\n",
      "|    value_loss           | 4.56e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 287\n",
      "day: 1940, episode: 287\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 17287431.33\n",
      "total_reward: 7287431.33\n",
      "total_cost: 159002.67\n",
      "total_trades: 73691\n",
      "Sharpe: 0.408\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 272         |\n",
      "|    time_elapsed         | 2347        |\n",
      "|    total_timesteps      | 557056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014607644 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.5       |\n",
      "|    explained_variance   | -0.0107     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.13e+03    |\n",
      "|    n_updates            | 2710        |\n",
      "|    policy_gradient_loss | -0.0213     |\n",
      "|    reward               | -0.24649495 |\n",
      "|    std                  | 1.87        |\n",
      "|    value_loss           | 5.28e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 288\n",
      "day: 1940, episode: 288\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13017089.64\n",
      "total_reward: 3017089.64\n",
      "total_cost: 151560.36\n",
      "total_trades: 73689\n",
      "Sharpe: 0.275\n",
      "=================================\n",
      "Episode: 289\n",
      "day: 1940, episode: 289\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 18959403.94\n",
      "total_reward: 8959403.94\n",
      "total_cost: 157558.06\n",
      "total_trades: 73684\n",
      "Sharpe: 0.463\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 237        |\n",
      "|    iterations           | 273        |\n",
      "|    time_elapsed         | 2357       |\n",
      "|    total_timesteps      | 559104     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02643019 |\n",
      "|    clip_fraction        | 0.285      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -77.6      |\n",
      "|    explained_variance   | -0.00371   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.17e+03   |\n",
      "|    n_updates            | 2720       |\n",
      "|    policy_gradient_loss | -0.0131    |\n",
      "|    reward               | -2.4180765 |\n",
      "|    std                  | 1.88       |\n",
      "|    value_loss           | 3.78e+03   |\n",
      "----------------------------------------\n",
      "Episode: 290\n",
      "day: 1940, episode: 290\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 17997343.72\n",
      "total_reward: 7997343.72\n",
      "total_cost: 156832.28\n",
      "total_trades: 73691\n",
      "Sharpe: 0.425\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 274         |\n",
      "|    time_elapsed         | 2366        |\n",
      "|    total_timesteps      | 561152      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038141057 |\n",
      "|    clip_fraction        | 0.326       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.7       |\n",
      "|    explained_variance   | 0.00277     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.31e+03    |\n",
      "|    n_updates            | 2730        |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    reward               | -8.931008   |\n",
      "|    std                  | 1.88        |\n",
      "|    value_loss           | 3.24e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 291\n",
      "day: 1940, episode: 291\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 18746485.90\n",
      "total_reward: 8746485.90\n",
      "total_cost: 159503.10\n",
      "total_trades: 73689\n",
      "Sharpe: 0.452\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 275         |\n",
      "|    time_elapsed         | 2375        |\n",
      "|    total_timesteps      | 563200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020265514 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.8       |\n",
      "|    explained_variance   | -0.00586    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.12e+03    |\n",
      "|    n_updates            | 2740        |\n",
      "|    policy_gradient_loss | -0.0225     |\n",
      "|    reward               | 15.650648   |\n",
      "|    std                  | 1.89        |\n",
      "|    value_loss           | 4.39e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 292\n",
      "day: 1940, episode: 292\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10895657.85\n",
      "total_reward: 895657.85\n",
      "total_cost: 154455.15\n",
      "total_trades: 73689\n",
      "Sharpe: 0.192\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 276         |\n",
      "|    time_elapsed         | 2384        |\n",
      "|    total_timesteps      | 565248      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033911567 |\n",
      "|    clip_fraction        | 0.301       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.9       |\n",
      "|    explained_variance   | -0.0144     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.4e+03     |\n",
      "|    n_updates            | 2750        |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    reward               | -0.87508065 |\n",
      "|    std                  | 1.89        |\n",
      "|    value_loss           | 3.87e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 293\n",
      "day: 1940, episode: 293\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13583449.49\n",
      "total_reward: 3583449.49\n",
      "total_cost: 155338.51\n",
      "total_trades: 73698\n",
      "Sharpe: 0.300\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 236      |\n",
      "|    iterations           | 277      |\n",
      "|    time_elapsed         | 2393     |\n",
      "|    total_timesteps      | 567296   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.036074 |\n",
      "|    clip_fraction        | 0.29     |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -78.1    |\n",
      "|    explained_variance   | -0.00926 |\n",
      "|    learning_rate        | 0.00025  |\n",
      "|    loss                 | 1.04e+03 |\n",
      "|    n_updates            | 2760     |\n",
      "|    policy_gradient_loss | -0.0181  |\n",
      "|    reward               | 8.589046 |\n",
      "|    std                  | 1.9      |\n",
      "|    value_loss           | 2.6e+03  |\n",
      "--------------------------------------\n",
      "Episode: 294\n",
      "day: 1940, episode: 294\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 16862313.39\n",
      "total_reward: 6862313.39\n",
      "total_cost: 155857.61\n",
      "total_trades: 73688\n",
      "Sharpe: 0.401\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 236        |\n",
      "|    iterations           | 278        |\n",
      "|    time_elapsed         | 2403       |\n",
      "|    total_timesteps      | 569344     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0259703  |\n",
      "|    clip_fraction        | 0.276      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -78.2      |\n",
      "|    explained_variance   | 0.00251    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 719        |\n",
      "|    n_updates            | 2770       |\n",
      "|    policy_gradient_loss | -0.0242    |\n",
      "|    reward               | 0.44332495 |\n",
      "|    std                  | 1.91       |\n",
      "|    value_loss           | 1.77e+03   |\n",
      "----------------------------------------\n",
      "Episode: 295\n",
      "day: 1940, episode: 295\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12986462.38\n",
      "total_reward: 2986462.38\n",
      "total_cost: 160753.62\n",
      "total_trades: 73697\n",
      "Sharpe: 0.268\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 279         |\n",
      "|    time_elapsed         | 2412        |\n",
      "|    total_timesteps      | 571392      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036593117 |\n",
      "|    clip_fraction        | 0.309       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.3       |\n",
      "|    explained_variance   | 0.00281     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.67e+03    |\n",
      "|    n_updates            | 2780        |\n",
      "|    policy_gradient_loss | -0.0238     |\n",
      "|    reward               | -22.234308  |\n",
      "|    std                  | 1.91        |\n",
      "|    value_loss           | 3.96e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 296\n",
      "day: 1940, episode: 296\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 16461896.17\n",
      "total_reward: 6461896.17\n",
      "total_cost: 161076.83\n",
      "total_trades: 73697\n",
      "Sharpe: 0.391\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 236        |\n",
      "|    iterations           | 280        |\n",
      "|    time_elapsed         | 2421       |\n",
      "|    total_timesteps      | 573440     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03035839 |\n",
      "|    clip_fraction        | 0.232      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -78.5      |\n",
      "|    explained_variance   | 0.0034     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.12e+03   |\n",
      "|    n_updates            | 2790       |\n",
      "|    policy_gradient_loss | -0.0262    |\n",
      "|    reward               | 14.4115925 |\n",
      "|    std                  | 1.92       |\n",
      "|    value_loss           | 2.46e+03   |\n",
      "----------------------------------------\n",
      "Episode: 297\n",
      "day: 1940, episode: 297\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13815787.44\n",
      "total_reward: 3815787.44\n",
      "total_cost: 156447.56\n",
      "total_trades: 73692\n",
      "Sharpe: 0.306\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 281         |\n",
      "|    time_elapsed         | 2430        |\n",
      "|    total_timesteps      | 575488      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026498111 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.5       |\n",
      "|    explained_variance   | -0.0281     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 995         |\n",
      "|    n_updates            | 2800        |\n",
      "|    policy_gradient_loss | -0.0215     |\n",
      "|    reward               | 17.922773   |\n",
      "|    std                  | 1.92        |\n",
      "|    value_loss           | 3.63e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 298\n",
      "day: 1940, episode: 298\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14513235.95\n",
      "total_reward: 4513235.95\n",
      "total_cost: 159335.05\n",
      "total_trades: 73690\n",
      "Sharpe: 0.324\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 282         |\n",
      "|    time_elapsed         | 2439        |\n",
      "|    total_timesteps      | 577536      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041312262 |\n",
      "|    clip_fraction        | 0.295       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.6       |\n",
      "|    explained_variance   | -0.001      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.46e+03    |\n",
      "|    n_updates            | 2810        |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    reward               | 0.046158202 |\n",
      "|    std                  | 1.92        |\n",
      "|    value_loss           | 3.17e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 299\n",
      "day: 1940, episode: 299\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 15680621.68\n",
      "total_reward: 5680621.68\n",
      "total_cost: 161938.32\n",
      "total_trades: 73698\n",
      "Sharpe: 0.360\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 283         |\n",
      "|    time_elapsed         | 2448        |\n",
      "|    total_timesteps      | 579584      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038298775 |\n",
      "|    clip_fraction        | 0.288       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.7       |\n",
      "|    explained_variance   | -0.008      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.15e+03    |\n",
      "|    n_updates            | 2820        |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    reward               | 2.9086275   |\n",
      "|    std                  | 1.93        |\n",
      "|    value_loss           | 2.35e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 300\n",
      "day: 1940, episode: 300\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12095198.18\n",
      "total_reward: 2095198.18\n",
      "total_cost: 158689.82\n",
      "total_trades: 73692\n",
      "Sharpe: 0.254\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 236        |\n",
      "|    iterations           | 284        |\n",
      "|    time_elapsed         | 2458       |\n",
      "|    total_timesteps      | 581632     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05329577 |\n",
      "|    clip_fraction        | 0.322      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -78.8      |\n",
      "|    explained_variance   | 0.00594    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.03e+03   |\n",
      "|    n_updates            | 2830       |\n",
      "|    policy_gradient_loss | -0.0133    |\n",
      "|    reward               | 4.477644   |\n",
      "|    std                  | 1.94       |\n",
      "|    value_loss           | 2.43e+03   |\n",
      "----------------------------------------\n",
      "Episode: 301\n",
      "day: 1940, episode: 301\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 16712524.43\n",
      "total_reward: 6712524.43\n",
      "total_cost: 160219.57\n",
      "total_trades: 73686\n",
      "Sharpe: 0.394\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 236        |\n",
      "|    iterations           | 285        |\n",
      "|    time_elapsed         | 2467       |\n",
      "|    total_timesteps      | 583680     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04379109 |\n",
      "|    clip_fraction        | 0.32       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -78.9      |\n",
      "|    explained_variance   | 0.0155     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.45e+03   |\n",
      "|    n_updates            | 2840       |\n",
      "|    policy_gradient_loss | -0.0133    |\n",
      "|    reward               | 22.197264  |\n",
      "|    std                  | 1.94       |\n",
      "|    value_loss           | 2.56e+03   |\n",
      "----------------------------------------\n",
      "Episode: 302\n",
      "day: 1940, episode: 302\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 16205577.80\n",
      "total_reward: 6205577.80\n",
      "total_cost: 167303.20\n",
      "total_trades: 73691\n",
      "Sharpe: 0.374\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 286         |\n",
      "|    time_elapsed         | 2477        |\n",
      "|    total_timesteps      | 585728      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041422773 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79         |\n",
      "|    explained_variance   | -0.0166     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.68e+03    |\n",
      "|    n_updates            | 2850        |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    reward               | 3.9067008   |\n",
      "|    std                  | 1.95        |\n",
      "|    value_loss           | 3.05e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 303\n",
      "day: 1940, episode: 303\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 15201339.46\n",
      "total_reward: 5201339.46\n",
      "total_cost: 165653.54\n",
      "total_trades: 73690\n",
      "Sharpe: 0.343\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 287         |\n",
      "|    time_elapsed         | 2486        |\n",
      "|    total_timesteps      | 587776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017644424 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.1       |\n",
      "|    explained_variance   | -0.00245    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.31e+03    |\n",
      "|    n_updates            | 2860        |\n",
      "|    policy_gradient_loss | -0.0219     |\n",
      "|    reward               | -3.8519983  |\n",
      "|    std                  | 1.95        |\n",
      "|    value_loss           | 2.87e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 304\n",
      "day: 1940, episode: 304\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 15422503.52\n",
      "total_reward: 5422503.52\n",
      "total_cost: 166030.48\n",
      "total_trades: 73688\n",
      "Sharpe: 0.360\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 288         |\n",
      "|    time_elapsed         | 2495        |\n",
      "|    total_timesteps      | 589824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035947233 |\n",
      "|    clip_fraction        | 0.289       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.2       |\n",
      "|    explained_variance   | -0.0142     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.06e+03    |\n",
      "|    n_updates            | 2870        |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    reward               | -0.22113319 |\n",
      "|    std                  | 1.96        |\n",
      "|    value_loss           | 2.34e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 305\n",
      "day: 1940, episode: 305\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12762967.13\n",
      "total_reward: 2762967.13\n",
      "total_cost: 162654.87\n",
      "total_trades: 73684\n",
      "Sharpe: 0.262\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 289         |\n",
      "|    time_elapsed         | 2504        |\n",
      "|    total_timesteps      | 591872      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043580353 |\n",
      "|    clip_fraction        | 0.333       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.3       |\n",
      "|    explained_variance   | 0.0143      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.78e+03    |\n",
      "|    n_updates            | 2880        |\n",
      "|    policy_gradient_loss | -0.0061     |\n",
      "|    reward               | 40.17213    |\n",
      "|    std                  | 1.96        |\n",
      "|    value_loss           | 3.43e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 306\n",
      "day: 1940, episode: 306\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12602488.48\n",
      "total_reward: 2602488.48\n",
      "total_cost: 160783.52\n",
      "total_trades: 73694\n",
      "Sharpe: 0.255\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 290         |\n",
      "|    time_elapsed         | 2513        |\n",
      "|    total_timesteps      | 593920      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043372326 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.4       |\n",
      "|    explained_variance   | -0.018      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.08e+03    |\n",
      "|    n_updates            | 2890        |\n",
      "|    policy_gradient_loss | -0.0073     |\n",
      "|    reward               | 5.0554667   |\n",
      "|    std                  | 1.97        |\n",
      "|    value_loss           | 3.56e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 307\n",
      "day: 1940, episode: 307\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13377857.44\n",
      "total_reward: 3377857.44\n",
      "total_cost: 174396.56\n",
      "total_trades: 73690\n",
      "Sharpe: 0.286\n",
      "=================================\n",
      "Episode: 308\n",
      "day: 1940, episode: 308\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 15832624.70\n",
      "total_reward: 5832624.70\n",
      "total_cost: 169676.30\n",
      "total_trades: 73693\n",
      "Sharpe: 0.373\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 236       |\n",
      "|    iterations           | 291       |\n",
      "|    time_elapsed         | 2523      |\n",
      "|    total_timesteps      | 595968    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0316353 |\n",
      "|    clip_fraction        | 0.277     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -79.6     |\n",
      "|    explained_variance   | 0.000967  |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 1.47e+03  |\n",
      "|    n_updates            | 2900      |\n",
      "|    policy_gradient_loss | -0.0183   |\n",
      "|    reward               | -6.80301  |\n",
      "|    std                  | 1.98      |\n",
      "|    value_loss           | 2.97e+03  |\n",
      "---------------------------------------\n",
      "Episode: 309\n",
      "day: 1940, episode: 309\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9319453.72\n",
      "total_reward: -680546.28\n",
      "total_cost: 156432.28\n",
      "total_trades: 73703\n",
      "Sharpe: 0.135\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 236        |\n",
      "|    iterations           | 292        |\n",
      "|    time_elapsed         | 2533       |\n",
      "|    total_timesteps      | 598016     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04337232 |\n",
      "|    clip_fraction        | 0.349      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -79.7      |\n",
      "|    explained_variance   | 0.00772    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.32e+03   |\n",
      "|    n_updates            | 2910       |\n",
      "|    policy_gradient_loss | -0.0191    |\n",
      "|    reward               | 2.30791    |\n",
      "|    std                  | 1.99       |\n",
      "|    value_loss           | 2.61e+03   |\n",
      "----------------------------------------\n",
      "Episode: 310\n",
      "day: 1940, episode: 310\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 16284530.23\n",
      "total_reward: 6284530.23\n",
      "total_cost: 162659.77\n",
      "total_trades: 73690\n",
      "Sharpe: 0.383\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 293         |\n",
      "|    time_elapsed         | 2544        |\n",
      "|    total_timesteps      | 600064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029528968 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.9       |\n",
      "|    explained_variance   | -0.011      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 619         |\n",
      "|    n_updates            | 2920        |\n",
      "|    policy_gradient_loss | -0.0187     |\n",
      "|    reward               | -7.4763603  |\n",
      "|    std                  | 1.99        |\n",
      "|    value_loss           | 1.5e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 311\n",
      "day: 1940, episode: 311\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14536973.14\n",
      "total_reward: 4536973.14\n",
      "total_cost: 161217.86\n",
      "total_trades: 73695\n",
      "Sharpe: 0.327\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 294         |\n",
      "|    time_elapsed         | 2553        |\n",
      "|    total_timesteps      | 602112      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035956033 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80         |\n",
      "|    explained_variance   | -8.3e-05    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 975         |\n",
      "|    n_updates            | 2930        |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    reward               | 14.802544   |\n",
      "|    std                  | 2           |\n",
      "|    value_loss           | 3.04e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 312\n",
      "day: 1940, episode: 312\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11194747.70\n",
      "total_reward: 1194747.70\n",
      "total_cost: 169141.30\n",
      "total_trades: 73689\n",
      "Sharpe: 0.184\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 295         |\n",
      "|    time_elapsed         | 2563        |\n",
      "|    total_timesteps      | 604160      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029053107 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.1       |\n",
      "|    explained_variance   | -0.00664    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.24e+03    |\n",
      "|    n_updates            | 2940        |\n",
      "|    policy_gradient_loss | -0.0226     |\n",
      "|    reward               | -14.781682  |\n",
      "|    std                  | 2           |\n",
      "|    value_loss           | 2.91e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 313\n",
      "day: 1940, episode: 313\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11958168.81\n",
      "total_reward: 1958168.81\n",
      "total_cost: 162046.19\n",
      "total_trades: 73681\n",
      "Sharpe: 0.243\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 235        |\n",
      "|    iterations           | 296        |\n",
      "|    time_elapsed         | 2572       |\n",
      "|    total_timesteps      | 606208     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06486648 |\n",
      "|    clip_fraction        | 0.392      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -80.2      |\n",
      "|    explained_variance   | -0.00471   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 716        |\n",
      "|    n_updates            | 2950       |\n",
      "|    policy_gradient_loss | 0.00165    |\n",
      "|    reward               | -3.228969  |\n",
      "|    std                  | 2.01       |\n",
      "|    value_loss           | 1.42e+03   |\n",
      "----------------------------------------\n",
      "Episode: 314\n",
      "day: 1940, episode: 314\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11811993.28\n",
      "total_reward: 1811993.28\n",
      "total_cost: 168572.72\n",
      "total_trades: 73699\n",
      "Sharpe: 0.236\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 297         |\n",
      "|    time_elapsed         | 2581        |\n",
      "|    total_timesteps      | 608256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032600246 |\n",
      "|    clip_fraction        | 0.317       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.2       |\n",
      "|    explained_variance   | -0.0125     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 476         |\n",
      "|    n_updates            | 2960        |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    reward               | -13.114763  |\n",
      "|    std                  | 2.01        |\n",
      "|    value_loss           | 1.26e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 315\n",
      "day: 1940, episode: 315\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12115567.50\n",
      "total_reward: 2115567.50\n",
      "total_cost: 167732.50\n",
      "total_trades: 73696\n",
      "Sharpe: 0.230\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 298         |\n",
      "|    time_elapsed         | 2589        |\n",
      "|    total_timesteps      | 610304      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027481634 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.3       |\n",
      "|    explained_variance   | -0.00584    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 911         |\n",
      "|    n_updates            | 2970        |\n",
      "|    policy_gradient_loss | -0.0229     |\n",
      "|    reward               | -19.867634  |\n",
      "|    std                  | 2.02        |\n",
      "|    value_loss           | 1.76e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 316\n",
      "day: 1940, episode: 316\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7648129.36\n",
      "total_reward: -2351870.64\n",
      "total_cost: 161233.64\n",
      "total_trades: 73691\n",
      "Sharpe: 0.031\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 299         |\n",
      "|    time_elapsed         | 2597        |\n",
      "|    total_timesteps      | 612352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034440845 |\n",
      "|    clip_fraction        | 0.345       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.4       |\n",
      "|    explained_variance   | 0.00337     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 897         |\n",
      "|    n_updates            | 2980        |\n",
      "|    policy_gradient_loss | -0.00964    |\n",
      "|    reward               | -6.6199894  |\n",
      "|    std                  | 2.02        |\n",
      "|    value_loss           | 1.96e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 317\n",
      "day: 1940, episode: 317\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8814427.77\n",
      "total_reward: -1185572.23\n",
      "total_cost: 153954.23\n",
      "total_trades: 73692\n",
      "Sharpe: 0.093\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 300         |\n",
      "|    time_elapsed         | 2606        |\n",
      "|    total_timesteps      | 614400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027180754 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.4       |\n",
      "|    explained_variance   | -0.00705    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 564         |\n",
      "|    n_updates            | 2990        |\n",
      "|    policy_gradient_loss | -0.0198     |\n",
      "|    reward               | 0.041896258 |\n",
      "|    std                  | 2.02        |\n",
      "|    value_loss           | 1.64e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 318\n",
      "day: 1940, episode: 318\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12744007.22\n",
      "total_reward: 2744007.22\n",
      "total_cost: 159342.78\n",
      "total_trades: 73699\n",
      "Sharpe: 0.256\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 235        |\n",
      "|    iterations           | 301        |\n",
      "|    time_elapsed         | 2614       |\n",
      "|    total_timesteps      | 616448     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03932365 |\n",
      "|    clip_fraction        | 0.31       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -80.5      |\n",
      "|    explained_variance   | 0.00114    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 612        |\n",
      "|    n_updates            | 3000       |\n",
      "|    policy_gradient_loss | -0.01      |\n",
      "|    reward               | 1.7668662  |\n",
      "|    std                  | 2.03       |\n",
      "|    value_loss           | 1.87e+03   |\n",
      "----------------------------------------\n",
      "Episode: 319\n",
      "day: 1940, episode: 319\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 17556275.72\n",
      "total_reward: 7556275.72\n",
      "total_cost: 160007.28\n",
      "total_trades: 73688\n",
      "Sharpe: 0.429\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 302         |\n",
      "|    time_elapsed         | 2623        |\n",
      "|    total_timesteps      | 618496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022733549 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.6       |\n",
      "|    explained_variance   | -0.00594    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.13e+03    |\n",
      "|    n_updates            | 3010        |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    reward               | -4.067056   |\n",
      "|    std                  | 2.03        |\n",
      "|    value_loss           | 1.93e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 320\n",
      "day: 1940, episode: 320\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9983758.50\n",
      "total_reward: -16241.50\n",
      "total_cost: 164036.50\n",
      "total_trades: 73694\n",
      "Sharpe: 0.143\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 303         |\n",
      "|    time_elapsed         | 2632        |\n",
      "|    total_timesteps      | 620544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024422275 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.6       |\n",
      "|    explained_variance   | 0.00138     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 934         |\n",
      "|    n_updates            | 3020        |\n",
      "|    policy_gradient_loss | -0.0204     |\n",
      "|    reward               | 3.4329648   |\n",
      "|    std                  | 2.03        |\n",
      "|    value_loss           | 2.03e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 321\n",
      "day: 1940, episode: 321\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13426723.42\n",
      "total_reward: 3426723.42\n",
      "total_cost: 157068.58\n",
      "total_trades: 73694\n",
      "Sharpe: 0.285\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 304         |\n",
      "|    time_elapsed         | 2643        |\n",
      "|    total_timesteps      | 622592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024882447 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.7       |\n",
      "|    explained_variance   | 0.0122      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.62e+03    |\n",
      "|    n_updates            | 3030        |\n",
      "|    policy_gradient_loss | -0.021      |\n",
      "|    reward               | 5.590169    |\n",
      "|    std                  | 2.03        |\n",
      "|    value_loss           | 1.6e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 322\n",
      "day: 1940, episode: 322\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9623919.36\n",
      "total_reward: -376080.64\n",
      "total_cost: 161771.64\n",
      "total_trades: 73695\n",
      "Sharpe: 0.108\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 235        |\n",
      "|    iterations           | 305        |\n",
      "|    time_elapsed         | 2653       |\n",
      "|    total_timesteps      | 624640     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01959651 |\n",
      "|    clip_fraction        | 0.204      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -80.8      |\n",
      "|    explained_variance   | -0.00478   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 776        |\n",
      "|    n_updates            | 3040       |\n",
      "|    policy_gradient_loss | -0.0208    |\n",
      "|    reward               | 5.2249303  |\n",
      "|    std                  | 2.04       |\n",
      "|    value_loss           | 1.65e+03   |\n",
      "----------------------------------------\n",
      "Episode: 323\n",
      "day: 1940, episode: 323\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10800691.60\n",
      "total_reward: 800691.60\n",
      "total_cost: 160247.40\n",
      "total_trades: 73693\n",
      "Sharpe: 0.196\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 235        |\n",
      "|    iterations           | 306        |\n",
      "|    time_elapsed         | 2662       |\n",
      "|    total_timesteps      | 626688     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03597109 |\n",
      "|    clip_fraction        | 0.281      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -80.8      |\n",
      "|    explained_variance   | 0.00502    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 615        |\n",
      "|    n_updates            | 3050       |\n",
      "|    policy_gradient_loss | -0.0177    |\n",
      "|    reward               | -6.2952313 |\n",
      "|    std                  | 2.04       |\n",
      "|    value_loss           | 1.11e+03   |\n",
      "----------------------------------------\n",
      "Episode: 324\n",
      "day: 1940, episode: 324\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10511503.18\n",
      "total_reward: 511503.18\n",
      "total_cost: 152371.82\n",
      "total_trades: 73682\n",
      "Sharpe: 0.179\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 307         |\n",
      "|    time_elapsed         | 2671        |\n",
      "|    total_timesteps      | 628736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038018245 |\n",
      "|    clip_fraction        | 0.308       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81         |\n",
      "|    explained_variance   | 0.0241      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 247         |\n",
      "|    n_updates            | 3060        |\n",
      "|    policy_gradient_loss | -0.00693    |\n",
      "|    reward               | -0.77651846 |\n",
      "|    std                  | 2.05        |\n",
      "|    value_loss           | 766         |\n",
      "-----------------------------------------\n",
      "Episode: 325\n",
      "day: 1940, episode: 325\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12019987.41\n",
      "total_reward: 2019987.41\n",
      "total_cost: 158437.59\n",
      "total_trades: 73696\n",
      "Sharpe: 0.241\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 235        |\n",
      "|    iterations           | 308        |\n",
      "|    time_elapsed         | 2680       |\n",
      "|    total_timesteps      | 630784     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03711497 |\n",
      "|    clip_fraction        | 0.302      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -81.1      |\n",
      "|    explained_variance   | 0.0303     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 548        |\n",
      "|    n_updates            | 3070       |\n",
      "|    policy_gradient_loss | -0.014     |\n",
      "|    reward               | 0.18827888 |\n",
      "|    std                  | 2.06       |\n",
      "|    value_loss           | 1.02e+03   |\n",
      "----------------------------------------\n",
      "Episode: 326\n",
      "day: 1940, episode: 326\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13739757.52\n",
      "total_reward: 3739757.52\n",
      "total_cost: 151099.48\n",
      "total_trades: 73688\n",
      "Sharpe: 0.306\n",
      "=================================\n",
      "Episode: 327\n",
      "day: 1940, episode: 327\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12385084.33\n",
      "total_reward: 2385084.33\n",
      "total_cost: 158279.67\n",
      "total_trades: 73687\n",
      "Sharpe: 0.260\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 309         |\n",
      "|    time_elapsed         | 2689        |\n",
      "|    total_timesteps      | 632832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021692103 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.2       |\n",
      "|    explained_variance   | -0.0118     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 445         |\n",
      "|    n_updates            | 3080        |\n",
      "|    policy_gradient_loss | -0.0212     |\n",
      "|    reward               | -4.974222   |\n",
      "|    std                  | 2.06        |\n",
      "|    value_loss           | 1.09e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 328\n",
      "day: 1940, episode: 328\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13161605.99\n",
      "total_reward: 3161605.99\n",
      "total_cost: 159543.01\n",
      "total_trades: 73688\n",
      "Sharpe: 0.285\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 310         |\n",
      "|    time_elapsed         | 2698        |\n",
      "|    total_timesteps      | 634880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029184442 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.3       |\n",
      "|    explained_variance   | 0.0215      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.34e+03    |\n",
      "|    n_updates            | 3090        |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    reward               | 6.5469975   |\n",
      "|    std                  | 2.07        |\n",
      "|    value_loss           | 1.39e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 329\n",
      "day: 1940, episode: 329\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 18364147.05\n",
      "total_reward: 8364147.05\n",
      "total_cost: 154315.95\n",
      "total_trades: 73695\n",
      "Sharpe: 0.440\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 311         |\n",
      "|    time_elapsed         | 2708        |\n",
      "|    total_timesteps      | 636928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023365162 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.3       |\n",
      "|    explained_variance   | -0.00223    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 547         |\n",
      "|    n_updates            | 3100        |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    reward               | -8.185457   |\n",
      "|    std                  | 2.07        |\n",
      "|    value_loss           | 1.13e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 330\n",
      "day: 1940, episode: 330\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 18257832.05\n",
      "total_reward: 8257832.05\n",
      "total_cost: 148024.95\n",
      "total_trades: 73685\n",
      "Sharpe: 0.425\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 312         |\n",
      "|    time_elapsed         | 2717        |\n",
      "|    total_timesteps      | 638976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025065862 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.4       |\n",
      "|    explained_variance   | 0.0131      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 801         |\n",
      "|    n_updates            | 3110        |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    reward               | 10.741947   |\n",
      "|    std                  | 2.07        |\n",
      "|    value_loss           | 1.68e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 331\n",
      "day: 1940, episode: 331\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 16678088.26\n",
      "total_reward: 6678088.26\n",
      "total_cost: 155071.74\n",
      "total_trades: 73692\n",
      "Sharpe: 0.400\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 313         |\n",
      "|    time_elapsed         | 2726        |\n",
      "|    total_timesteps      | 641024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016482025 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.5       |\n",
      "|    explained_variance   | 0.0254      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 735         |\n",
      "|    n_updates            | 3120        |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    reward               | -21.748497  |\n",
      "|    std                  | 2.08        |\n",
      "|    value_loss           | 2e+03       |\n",
      "-----------------------------------------\n",
      "Episode: 332\n",
      "day: 1940, episode: 332\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 19486127.73\n",
      "total_reward: 9486127.73\n",
      "total_cost: 146939.27\n",
      "total_trades: 73692\n",
      "Sharpe: 0.458\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 314         |\n",
      "|    time_elapsed         | 2735        |\n",
      "|    total_timesteps      | 643072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014303388 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.6       |\n",
      "|    explained_variance   | 0.0295      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 824         |\n",
      "|    n_updates            | 3130        |\n",
      "|    policy_gradient_loss | -0.0228     |\n",
      "|    reward               | -1.5087525  |\n",
      "|    std                  | 2.08        |\n",
      "|    value_loss           | 1.37e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 333\n",
      "day: 1940, episode: 333\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 17482018.75\n",
      "total_reward: 7482018.75\n",
      "total_cost: 155735.25\n",
      "total_trades: 73689\n",
      "Sharpe: 0.425\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 315         |\n",
      "|    time_elapsed         | 2744        |\n",
      "|    total_timesteps      | 645120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030763408 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.7       |\n",
      "|    explained_variance   | 0.0493      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 941         |\n",
      "|    n_updates            | 3140        |\n",
      "|    policy_gradient_loss | -0.0194     |\n",
      "|    reward               | -0.45328224 |\n",
      "|    std                  | 2.09        |\n",
      "|    value_loss           | 2.57e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 334\n",
      "day: 1940, episode: 334\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 17718122.25\n",
      "total_reward: 7718122.25\n",
      "total_cost: 152373.75\n",
      "total_trades: 73691\n",
      "Sharpe: 0.420\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 316         |\n",
      "|    time_elapsed         | 2753        |\n",
      "|    total_timesteps      | 647168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016199049 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.7       |\n",
      "|    explained_variance   | 0.0702      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.01e+03    |\n",
      "|    n_updates            | 3150        |\n",
      "|    policy_gradient_loss | -0.0203     |\n",
      "|    reward               | 25.946417   |\n",
      "|    std                  | 2.09        |\n",
      "|    value_loss           | 1.55e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 335\n",
      "day: 1940, episode: 335\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 16514148.43\n",
      "total_reward: 6514148.43\n",
      "total_cost: 157858.57\n",
      "total_trades: 73693\n",
      "Sharpe: 0.396\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 234        |\n",
      "|    iterations           | 317        |\n",
      "|    time_elapsed         | 2763       |\n",
      "|    total_timesteps      | 649216     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03338051 |\n",
      "|    clip_fraction        | 0.257      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -81.8      |\n",
      "|    explained_variance   | 0.085      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.65e+03   |\n",
      "|    n_updates            | 3160       |\n",
      "|    policy_gradient_loss | -0.0108    |\n",
      "|    reward               | -15.052846 |\n",
      "|    std                  | 2.09       |\n",
      "|    value_loss           | 2.28e+03   |\n",
      "----------------------------------------\n",
      "Episode: 336\n",
      "day: 1940, episode: 336\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 20703088.19\n",
      "total_reward: 10703088.19\n",
      "total_cost: 151006.81\n",
      "total_trades: 73701\n",
      "Sharpe: 0.498\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 234          |\n",
      "|    iterations           | 318          |\n",
      "|    time_elapsed         | 2772         |\n",
      "|    total_timesteps      | 651264       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0190876    |\n",
      "|    clip_fraction        | 0.201        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -81.9        |\n",
      "|    explained_variance   | 0.0858       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 759          |\n",
      "|    n_updates            | 3170         |\n",
      "|    policy_gradient_loss | -0.0226      |\n",
      "|    reward               | -0.044062488 |\n",
      "|    std                  | 2.1          |\n",
      "|    value_loss           | 1.89e+03     |\n",
      "------------------------------------------\n",
      "Episode: 337\n",
      "day: 1940, episode: 337\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 17758313.97\n",
      "total_reward: 7758313.97\n",
      "total_cost: 157589.03\n",
      "total_trades: 73697\n",
      "Sharpe: 0.428\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 319         |\n",
      "|    time_elapsed         | 2781        |\n",
      "|    total_timesteps      | 653312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016148798 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.9       |\n",
      "|    explained_variance   | 0.0105      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.28e+03    |\n",
      "|    n_updates            | 3180        |\n",
      "|    policy_gradient_loss | -0.0239     |\n",
      "|    reward               | -7.6148314  |\n",
      "|    std                  | 2.1         |\n",
      "|    value_loss           | 2.33e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 338\n",
      "day: 1940, episode: 338\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 16761717.41\n",
      "total_reward: 6761717.41\n",
      "total_cost: 158782.59\n",
      "total_trades: 73682\n",
      "Sharpe: 0.404\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 320         |\n",
      "|    time_elapsed         | 2789        |\n",
      "|    total_timesteps      | 655360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024011329 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82         |\n",
      "|    explained_variance   | 0.0598      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 883         |\n",
      "|    n_updates            | 3190        |\n",
      "|    policy_gradient_loss | -0.0176     |\n",
      "|    reward               | -9.570485   |\n",
      "|    std                  | 2.11        |\n",
      "|    value_loss           | 2.26e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 339\n",
      "day: 1940, episode: 339\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13420943.29\n",
      "total_reward: 3420943.29\n",
      "total_cost: 150796.71\n",
      "total_trades: 73686\n",
      "Sharpe: 0.295\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 321         |\n",
      "|    time_elapsed         | 2798        |\n",
      "|    total_timesteps      | 657408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029869497 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.1       |\n",
      "|    explained_variance   | 0.00456     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 922         |\n",
      "|    n_updates            | 3200        |\n",
      "|    policy_gradient_loss | -0.0194     |\n",
      "|    reward               | 8.338407    |\n",
      "|    std                  | 2.11        |\n",
      "|    value_loss           | 1.33e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 340\n",
      "day: 1940, episode: 340\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 16418328.23\n",
      "total_reward: 6418328.23\n",
      "total_cost: 152873.77\n",
      "total_trades: 73693\n",
      "Sharpe: 0.391\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 322         |\n",
      "|    time_elapsed         | 2807        |\n",
      "|    total_timesteps      | 659456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021395735 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.2       |\n",
      "|    explained_variance   | 0.0799      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 848         |\n",
      "|    n_updates            | 3210        |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    reward               | 14.661103   |\n",
      "|    std                  | 2.12        |\n",
      "|    value_loss           | 1.51e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 341\n",
      "day: 1940, episode: 341\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 17820112.73\n",
      "total_reward: 7820112.73\n",
      "total_cost: 155483.27\n",
      "total_trades: 73695\n",
      "Sharpe: 0.431\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 323         |\n",
      "|    time_elapsed         | 2816        |\n",
      "|    total_timesteps      | 661504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027076347 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.3       |\n",
      "|    explained_variance   | 0.0567      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 580         |\n",
      "|    n_updates            | 3220        |\n",
      "|    policy_gradient_loss | -0.0176     |\n",
      "|    reward               | -22.671057  |\n",
      "|    std                  | 2.12        |\n",
      "|    value_loss           | 1.58e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 342\n",
      "day: 1940, episode: 342\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 16278295.26\n",
      "total_reward: 6278295.26\n",
      "total_cost: 154477.74\n",
      "total_trades: 73689\n",
      "Sharpe: 0.386\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 234        |\n",
      "|    iterations           | 324        |\n",
      "|    time_elapsed         | 2827       |\n",
      "|    total_timesteps      | 663552     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02738687 |\n",
      "|    clip_fraction        | 0.258      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -82.4      |\n",
      "|    explained_variance   | 0.0598     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 597        |\n",
      "|    n_updates            | 3230       |\n",
      "|    policy_gradient_loss | -0.0156    |\n",
      "|    reward               | -18.93975  |\n",
      "|    std                  | 2.13       |\n",
      "|    value_loss           | 1.7e+03    |\n",
      "----------------------------------------\n",
      "Episode: 343\n",
      "day: 1940, episode: 343\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 15658900.26\n",
      "total_reward: 5658900.26\n",
      "total_cost: 153358.74\n",
      "total_trades: 73697\n",
      "Sharpe: 0.367\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 325         |\n",
      "|    time_elapsed         | 2835        |\n",
      "|    total_timesteps      | 665600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032298606 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.4       |\n",
      "|    explained_variance   | 0.0389      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 370         |\n",
      "|    n_updates            | 3240        |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    reward               | -18.282612  |\n",
      "|    std                  | 2.13        |\n",
      "|    value_loss           | 1.27e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 344\n",
      "day: 1940, episode: 344\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14723839.25\n",
      "total_reward: 4723839.25\n",
      "total_cost: 136493.75\n",
      "total_trades: 73696\n",
      "Sharpe: 0.334\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 326         |\n",
      "|    time_elapsed         | 2843        |\n",
      "|    total_timesteps      | 667648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018217715 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.5       |\n",
      "|    explained_variance   | -0.0225     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.03e+03    |\n",
      "|    n_updates            | 3250        |\n",
      "|    policy_gradient_loss | -0.0225     |\n",
      "|    reward               | -14.902709  |\n",
      "|    std                  | 2.13        |\n",
      "|    value_loss           | 1.82e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 345\n",
      "day: 1940, episode: 345\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 18205484.77\n",
      "total_reward: 8205484.77\n",
      "total_cost: 146897.23\n",
      "total_trades: 73694\n",
      "Sharpe: 0.433\n",
      "=================================\n",
      "Episode: 346\n",
      "day: 1940, episode: 346\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 17457990.42\n",
      "total_reward: 7457990.42\n",
      "total_cost: 143139.58\n",
      "total_trades: 73689\n",
      "Sharpe: 0.411\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 327         |\n",
      "|    time_elapsed         | 2853        |\n",
      "|    total_timesteps      | 669696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022446487 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.5       |\n",
      "|    explained_variance   | -0.0223     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.16e+03    |\n",
      "|    n_updates            | 3260        |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    reward               | -3.928608   |\n",
      "|    std                  | 2.14        |\n",
      "|    value_loss           | 1.96e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 347\n",
      "day: 1940, episode: 347\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 17934261.86\n",
      "total_reward: 7934261.86\n",
      "total_cost: 143494.14\n",
      "total_trades: 73692\n",
      "Sharpe: 0.425\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 328         |\n",
      "|    time_elapsed         | 2862        |\n",
      "|    total_timesteps      | 671744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037008464 |\n",
      "|    clip_fraction        | 0.27        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.6       |\n",
      "|    explained_variance   | 0.0121      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.11e+03    |\n",
      "|    n_updates            | 3270        |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    reward               | 9.589835    |\n",
      "|    std                  | 2.14        |\n",
      "|    value_loss           | 2.04e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 348\n",
      "day: 1940, episode: 348\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 21722471.85\n",
      "total_reward: 11722471.85\n",
      "total_cost: 155042.15\n",
      "total_trades: 73680\n",
      "Sharpe: 0.550\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 329         |\n",
      "|    time_elapsed         | 2871        |\n",
      "|    total_timesteps      | 673792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026720956 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.6       |\n",
      "|    explained_variance   | 0.0393      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 762         |\n",
      "|    n_updates            | 3280        |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    reward               | -9.581085   |\n",
      "|    std                  | 2.14        |\n",
      "|    value_loss           | 1.69e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 349\n",
      "day: 1940, episode: 349\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14975923.87\n",
      "total_reward: 4975923.87\n",
      "total_cost: 153801.13\n",
      "total_trades: 73703\n",
      "Sharpe: 0.346\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 330         |\n",
      "|    time_elapsed         | 2880        |\n",
      "|    total_timesteps      | 675840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024604063 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.7       |\n",
      "|    explained_variance   | -0.00673    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 971         |\n",
      "|    n_updates            | 3290        |\n",
      "|    policy_gradient_loss | -0.0219     |\n",
      "|    reward               | -17.730104  |\n",
      "|    std                  | 2.15        |\n",
      "|    value_loss           | 2.24e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 350\n",
      "day: 1940, episode: 350\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 15488419.11\n",
      "total_reward: 5488419.11\n",
      "total_cost: 151820.89\n",
      "total_trades: 73694\n",
      "Sharpe: 0.367\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 331         |\n",
      "|    time_elapsed         | 2889        |\n",
      "|    total_timesteps      | 677888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030251728 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.8       |\n",
      "|    explained_variance   | 0.00571     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 739         |\n",
      "|    n_updates            | 3300        |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    reward               | -11.473698  |\n",
      "|    std                  | 2.15        |\n",
      "|    value_loss           | 1.56e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 351\n",
      "day: 1940, episode: 351\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13728674.52\n",
      "total_reward: 3728674.52\n",
      "total_cost: 151507.48\n",
      "total_trades: 73692\n",
      "Sharpe: 0.309\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 332         |\n",
      "|    time_elapsed         | 2899        |\n",
      "|    total_timesteps      | 679936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023593964 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.8       |\n",
      "|    explained_variance   | 0.0161      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 694         |\n",
      "|    n_updates            | 3310        |\n",
      "|    policy_gradient_loss | -0.0245     |\n",
      "|    reward               | -7.1391716  |\n",
      "|    std                  | 2.15        |\n",
      "|    value_loss           | 1.67e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 352\n",
      "day: 1940, episode: 352\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 19167516.22\n",
      "total_reward: 9167516.22\n",
      "total_cost: 156605.78\n",
      "total_trades: 73694\n",
      "Sharpe: 0.478\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 333         |\n",
      "|    time_elapsed         | 2908        |\n",
      "|    total_timesteps      | 681984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020517632 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.9       |\n",
      "|    explained_variance   | -0.0162     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 784         |\n",
      "|    n_updates            | 3320        |\n",
      "|    policy_gradient_loss | -0.0255     |\n",
      "|    reward               | 8.203092    |\n",
      "|    std                  | 2.16        |\n",
      "|    value_loss           | 1.17e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 353\n",
      "day: 1940, episode: 353\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 18692962.55\n",
      "total_reward: 8692962.55\n",
      "total_cost: 150863.45\n",
      "total_trades: 73690\n",
      "Sharpe: 0.450\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 334         |\n",
      "|    time_elapsed         | 2918        |\n",
      "|    total_timesteps      | 684032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015228154 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.1       |\n",
      "|    explained_variance   | 0.0167      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.11e+03    |\n",
      "|    n_updates            | 3330        |\n",
      "|    policy_gradient_loss | -0.0233     |\n",
      "|    reward               | 31.962032   |\n",
      "|    std                  | 2.17        |\n",
      "|    value_loss           | 1.82e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 354\n",
      "day: 1940, episode: 354\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14791270.66\n",
      "total_reward: 4791270.66\n",
      "total_cost: 145654.34\n",
      "total_trades: 73697\n",
      "Sharpe: 0.339\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 234        |\n",
      "|    iterations           | 335        |\n",
      "|    time_elapsed         | 2928       |\n",
      "|    total_timesteps      | 686080     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02494869 |\n",
      "|    clip_fraction        | 0.224      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -83.1      |\n",
      "|    explained_variance   | -0.0116    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 827        |\n",
      "|    n_updates            | 3340       |\n",
      "|    policy_gradient_loss | -0.0179    |\n",
      "|    reward               | 22.219913  |\n",
      "|    std                  | 2.17       |\n",
      "|    value_loss           | 2.12e+03   |\n",
      "----------------------------------------\n",
      "Episode: 355\n",
      "day: 1940, episode: 355\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 19634470.50\n",
      "total_reward: 9634470.50\n",
      "total_cost: 150369.50\n",
      "total_trades: 73686\n",
      "Sharpe: 0.484\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 336         |\n",
      "|    time_elapsed         | 2938        |\n",
      "|    total_timesteps      | 688128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020700485 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.2       |\n",
      "|    explained_variance   | 0.00528     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.14e+03    |\n",
      "|    n_updates            | 3350        |\n",
      "|    policy_gradient_loss | -0.0307     |\n",
      "|    reward               | 5.575392    |\n",
      "|    std                  | 2.17        |\n",
      "|    value_loss           | 1.88e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 356\n",
      "day: 1940, episode: 356\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14949662.69\n",
      "total_reward: 4949662.69\n",
      "total_cost: 141302.31\n",
      "total_trades: 73688\n",
      "Sharpe: 0.337\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 337         |\n",
      "|    time_elapsed         | 2947        |\n",
      "|    total_timesteps      | 690176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015890386 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.2       |\n",
      "|    explained_variance   | -0.0137     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.17e+03    |\n",
      "|    n_updates            | 3360        |\n",
      "|    policy_gradient_loss | -0.0257     |\n",
      "|    reward               | 0.4358331   |\n",
      "|    std                  | 2.18        |\n",
      "|    value_loss           | 2.23e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 357\n",
      "day: 1940, episode: 357\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 17061862.30\n",
      "total_reward: 7061862.30\n",
      "total_cost: 143454.70\n",
      "total_trades: 73698\n",
      "Sharpe: 0.401\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 338         |\n",
      "|    time_elapsed         | 2957        |\n",
      "|    total_timesteps      | 692224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028054658 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.3       |\n",
      "|    explained_variance   | 0.00246     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 781         |\n",
      "|    n_updates            | 3370        |\n",
      "|    policy_gradient_loss | -0.0212     |\n",
      "|    reward               | 0.57523614  |\n",
      "|    std                  | 2.18        |\n",
      "|    value_loss           | 2.03e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 358\n",
      "day: 1940, episode: 358\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13358177.45\n",
      "total_reward: 3358177.45\n",
      "total_cost: 139997.55\n",
      "total_trades: 73689\n",
      "Sharpe: 0.294\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 339         |\n",
      "|    time_elapsed         | 2967        |\n",
      "|    total_timesteps      | 694272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034823023 |\n",
      "|    clip_fraction        | 0.355       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.4       |\n",
      "|    explained_variance   | -0.0485     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 876         |\n",
      "|    n_updates            | 3380        |\n",
      "|    policy_gradient_loss | -0.00132    |\n",
      "|    reward               | -3.6538944  |\n",
      "|    std                  | 2.19        |\n",
      "|    value_loss           | 1.57e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 359\n",
      "day: 1940, episode: 359\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12537417.46\n",
      "total_reward: 2537417.46\n",
      "total_cost: 158685.54\n",
      "total_trades: 73706\n",
      "Sharpe: 0.248\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 233        |\n",
      "|    iterations           | 340        |\n",
      "|    time_elapsed         | 2976       |\n",
      "|    total_timesteps      | 696320     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03675759 |\n",
      "|    clip_fraction        | 0.271      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -83.5      |\n",
      "|    explained_variance   | -0.0105    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.95e+03   |\n",
      "|    n_updates            | 3390       |\n",
      "|    policy_gradient_loss | -0.0166    |\n",
      "|    reward               | -9.13344   |\n",
      "|    std                  | 2.19       |\n",
      "|    value_loss           | 2.5e+03    |\n",
      "----------------------------------------\n",
      "Episode: 360\n",
      "day: 1940, episode: 360\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10774436.29\n",
      "total_reward: 774436.29\n",
      "total_cost: 144607.71\n",
      "total_trades: 73700\n",
      "Sharpe: 0.175\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 341         |\n",
      "|    time_elapsed         | 2986        |\n",
      "|    total_timesteps      | 698368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035666924 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.6       |\n",
      "|    explained_variance   | -0.00116    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 783         |\n",
      "|    n_updates            | 3400        |\n",
      "|    policy_gradient_loss | -0.00712    |\n",
      "|    reward               | 13.234076   |\n",
      "|    std                  | 2.2         |\n",
      "|    value_loss           | 2.06e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 361\n",
      "day: 1940, episode: 361\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14661384.75\n",
      "total_reward: 4661384.75\n",
      "total_cost: 144688.25\n",
      "total_trades: 73697\n",
      "Sharpe: 0.327\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 233        |\n",
      "|    iterations           | 342        |\n",
      "|    time_elapsed         | 2995       |\n",
      "|    total_timesteps      | 700416     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03683818 |\n",
      "|    clip_fraction        | 0.326      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -83.7      |\n",
      "|    explained_variance   | -0.0235    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 781        |\n",
      "|    n_updates            | 3410       |\n",
      "|    policy_gradient_loss | -0.0123    |\n",
      "|    reward               | 25.4701    |\n",
      "|    std                  | 2.2        |\n",
      "|    value_loss           | 1.83e+03   |\n",
      "----------------------------------------\n",
      "Episode: 362\n",
      "day: 1940, episode: 362\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 17009462.01\n",
      "total_reward: 7009462.01\n",
      "total_cost: 159253.99\n",
      "total_trades: 73696\n",
      "Sharpe: 0.413\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 343         |\n",
      "|    time_elapsed         | 3005        |\n",
      "|    total_timesteps      | 702464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022845067 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.7       |\n",
      "|    explained_variance   | 0.00354     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.11e+03    |\n",
      "|    n_updates            | 3420        |\n",
      "|    policy_gradient_loss | -0.0196     |\n",
      "|    reward               | -1.8824975  |\n",
      "|    std                  | 2.21        |\n",
      "|    value_loss           | 2.21e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 363\n",
      "day: 1940, episode: 363\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10201485.91\n",
      "total_reward: 201485.91\n",
      "total_cost: 152536.09\n",
      "total_trades: 73688\n",
      "Sharpe: 0.175\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 233        |\n",
      "|    iterations           | 344        |\n",
      "|    time_elapsed         | 3014       |\n",
      "|    total_timesteps      | 704512     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03136418 |\n",
      "|    clip_fraction        | 0.252      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -83.8      |\n",
      "|    explained_variance   | -0.0295    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 612        |\n",
      "|    n_updates            | 3430       |\n",
      "|    policy_gradient_loss | -0.0178    |\n",
      "|    reward               | -5.3683195 |\n",
      "|    std                  | 2.21       |\n",
      "|    value_loss           | 1.49e+03   |\n",
      "----------------------------------------\n",
      "Episode: 364\n",
      "day: 1940, episode: 364\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8224636.65\n",
      "total_reward: -1775363.35\n",
      "total_cost: 143227.35\n",
      "total_trades: 73684\n",
      "Sharpe: 0.078\n",
      "=================================\n",
      "Episode: 365\n",
      "day: 1940, episode: 365\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11701287.40\n",
      "total_reward: 1701287.40\n",
      "total_cost: 157021.60\n",
      "total_trades: 73700\n",
      "Sharpe: 0.209\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 345         |\n",
      "|    time_elapsed         | 3024        |\n",
      "|    total_timesteps      | 706560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044819564 |\n",
      "|    clip_fraction        | 0.345       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.9       |\n",
      "|    explained_variance   | 0.0139      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 537         |\n",
      "|    n_updates            | 3440        |\n",
      "|    policy_gradient_loss | -0.00734    |\n",
      "|    reward               | -8.1401615  |\n",
      "|    std                  | 2.22        |\n",
      "|    value_loss           | 1.14e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 366\n",
      "day: 1940, episode: 366\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9193035.97\n",
      "total_reward: -806964.03\n",
      "total_cost: 157137.03\n",
      "total_trades: 73693\n",
      "Sharpe: 0.114\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 346         |\n",
      "|    time_elapsed         | 3033        |\n",
      "|    total_timesteps      | 708608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019432904 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84         |\n",
      "|    explained_variance   | -0.00987    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 729         |\n",
      "|    n_updates            | 3450        |\n",
      "|    policy_gradient_loss | -0.0225     |\n",
      "|    reward               | -11.509201  |\n",
      "|    std                  | 2.22        |\n",
      "|    value_loss           | 1.8e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 367\n",
      "day: 1940, episode: 367\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9666695.03\n",
      "total_reward: -333304.97\n",
      "total_cost: 152568.97\n",
      "total_trades: 73709\n",
      "Sharpe: 0.107\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 347         |\n",
      "|    time_elapsed         | 3042        |\n",
      "|    total_timesteps      | 710656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027417263 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.1       |\n",
      "|    explained_variance   | -0.019      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 424         |\n",
      "|    n_updates            | 3460        |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    reward               | -2.8382523  |\n",
      "|    std                  | 2.23        |\n",
      "|    value_loss           | 861         |\n",
      "-----------------------------------------\n",
      "Episode: 368\n",
      "day: 1940, episode: 368\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9930902.15\n",
      "total_reward: -69097.85\n",
      "total_cost: 144985.85\n",
      "total_trades: 73699\n",
      "Sharpe: 0.140\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 233        |\n",
      "|    iterations           | 348        |\n",
      "|    time_elapsed         | 3052       |\n",
      "|    total_timesteps      | 712704     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03758126 |\n",
      "|    clip_fraction        | 0.27       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -84.2      |\n",
      "|    explained_variance   | -0.0107    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 766        |\n",
      "|    n_updates            | 3470       |\n",
      "|    policy_gradient_loss | -0.0175    |\n",
      "|    reward               | -24.898863 |\n",
      "|    std                  | 2.23       |\n",
      "|    value_loss           | 1.58e+03   |\n",
      "----------------------------------------\n",
      "Episode: 369\n",
      "day: 1940, episode: 369\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11369076.21\n",
      "total_reward: 1369076.21\n",
      "total_cost: 153013.79\n",
      "total_trades: 73683\n",
      "Sharpe: 0.205\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 233        |\n",
      "|    iterations           | 349        |\n",
      "|    time_elapsed         | 3062       |\n",
      "|    total_timesteps      | 714752     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03139832 |\n",
      "|    clip_fraction        | 0.273      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -84.3      |\n",
      "|    explained_variance   | 0.00585    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 588        |\n",
      "|    n_updates            | 3480       |\n",
      "|    policy_gradient_loss | -0.0149    |\n",
      "|    reward               | -0.9270363 |\n",
      "|    std                  | 2.24       |\n",
      "|    value_loss           | 1.31e+03   |\n",
      "----------------------------------------\n",
      "Episode: 370\n",
      "day: 1940, episode: 370\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 15265231.63\n",
      "total_reward: 5265231.63\n",
      "total_cost: 160524.37\n",
      "total_trades: 73703\n",
      "Sharpe: 0.368\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 350         |\n",
      "|    time_elapsed         | 3072        |\n",
      "|    total_timesteps      | 716800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019703712 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.3       |\n",
      "|    explained_variance   | 0.0236      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 584         |\n",
      "|    n_updates            | 3490        |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    reward               | 0.25437126  |\n",
      "|    std                  | 2.24        |\n",
      "|    value_loss           | 1.19e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 371\n",
      "day: 1940, episode: 371\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9567347.21\n",
      "total_reward: -432652.79\n",
      "total_cost: 153251.79\n",
      "total_trades: 73693\n",
      "Sharpe: 0.129\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 351         |\n",
      "|    time_elapsed         | 3082        |\n",
      "|    total_timesteps      | 718848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018265681 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.3       |\n",
      "|    explained_variance   | -0.0084     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 569         |\n",
      "|    n_updates            | 3500        |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    reward               | 7.691732    |\n",
      "|    std                  | 2.24        |\n",
      "|    value_loss           | 1.56e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 372\n",
      "day: 1940, episode: 372\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9072802.09\n",
      "total_reward: -927197.91\n",
      "total_cost: 148935.91\n",
      "total_trades: 73700\n",
      "Sharpe: 0.070\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 352         |\n",
      "|    time_elapsed         | 3092        |\n",
      "|    total_timesteps      | 720896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024022548 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.4       |\n",
      "|    explained_variance   | -0.000261   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 423         |\n",
      "|    n_updates            | 3510        |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    reward               | 29.077017   |\n",
      "|    std                  | 2.25        |\n",
      "|    value_loss           | 934         |\n",
      "-----------------------------------------\n",
      "Episode: 373\n",
      "day: 1940, episode: 373\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11907727.85\n",
      "total_reward: 1907727.85\n",
      "total_cost: 157098.15\n",
      "total_trades: 73694\n",
      "Sharpe: 0.217\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 233        |\n",
      "|    iterations           | 353        |\n",
      "|    time_elapsed         | 3102       |\n",
      "|    total_timesteps      | 722944     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02536635 |\n",
      "|    clip_fraction        | 0.21       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -84.5      |\n",
      "|    explained_variance   | 0.0152     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 408        |\n",
      "|    n_updates            | 3520       |\n",
      "|    policy_gradient_loss | -0.0158    |\n",
      "|    reward               | 6.1185365  |\n",
      "|    std                  | 2.25       |\n",
      "|    value_loss           | 1.22e+03   |\n",
      "----------------------------------------\n",
      "Episode: 374\n",
      "day: 1940, episode: 374\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11263797.19\n",
      "total_reward: 1263797.19\n",
      "total_cost: 150798.81\n",
      "total_trades: 73700\n",
      "Sharpe: 0.190\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 232         |\n",
      "|    iterations           | 354         |\n",
      "|    time_elapsed         | 3111        |\n",
      "|    total_timesteps      | 724992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020762026 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.6       |\n",
      "|    explained_variance   | 0.0065      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 880         |\n",
      "|    n_updates            | 3530        |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    reward               | -34.61561   |\n",
      "|    std                  | 2.26        |\n",
      "|    value_loss           | 1.52e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 375\n",
      "day: 1940, episode: 375\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11370581.00\n",
      "total_reward: 1370581.00\n",
      "total_cost: 157255.00\n",
      "total_trades: 73693\n",
      "Sharpe: 0.209\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 232         |\n",
      "|    iterations           | 355         |\n",
      "|    time_elapsed         | 3122        |\n",
      "|    total_timesteps      | 727040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027100507 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.7       |\n",
      "|    explained_variance   | 0.00259     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 630         |\n",
      "|    n_updates            | 3540        |\n",
      "|    policy_gradient_loss | -0.0214     |\n",
      "|    reward               | -10.257124  |\n",
      "|    std                  | 2.26        |\n",
      "|    value_loss           | 1.18e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 376\n",
      "day: 1940, episode: 376\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10259274.72\n",
      "total_reward: 259274.72\n",
      "total_cost: 156515.28\n",
      "total_trades: 73698\n",
      "Sharpe: 0.162\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 232         |\n",
      "|    iterations           | 356         |\n",
      "|    time_elapsed         | 3131        |\n",
      "|    total_timesteps      | 729088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028068457 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.8       |\n",
      "|    explained_variance   | -0.00269    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 656         |\n",
      "|    n_updates            | 3550        |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    reward               | -1.1629016  |\n",
      "|    std                  | 2.27        |\n",
      "|    value_loss           | 1.12e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 377\n",
      "day: 1940, episode: 377\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11860374.91\n",
      "total_reward: 1860374.91\n",
      "total_cost: 157827.09\n",
      "total_trades: 73689\n",
      "Sharpe: 0.224\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 232        |\n",
      "|    iterations           | 357        |\n",
      "|    time_elapsed         | 3141       |\n",
      "|    total_timesteps      | 731136     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04068947 |\n",
      "|    clip_fraction        | 0.291      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -85        |\n",
      "|    explained_variance   | 0.000357   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 281        |\n",
      "|    n_updates            | 3560       |\n",
      "|    policy_gradient_loss | -0.00532   |\n",
      "|    reward               | -1.4844819 |\n",
      "|    std                  | 2.28       |\n",
      "|    value_loss           | 912        |\n",
      "----------------------------------------\n",
      "Episode: 378\n",
      "day: 1940, episode: 378\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10768735.50\n",
      "total_reward: 768735.50\n",
      "total_cost: 155685.50\n",
      "total_trades: 73694\n",
      "Sharpe: 0.183\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 232         |\n",
      "|    iterations           | 358         |\n",
      "|    time_elapsed         | 3151        |\n",
      "|    total_timesteps      | 733184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024286099 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.1       |\n",
      "|    explained_variance   | -0.0041     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 352         |\n",
      "|    n_updates            | 3570        |\n",
      "|    policy_gradient_loss | -0.0197     |\n",
      "|    reward               | -18.087646  |\n",
      "|    std                  | 2.29        |\n",
      "|    value_loss           | 853         |\n",
      "-----------------------------------------\n",
      "Episode: 379\n",
      "day: 1940, episode: 379\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11269566.26\n",
      "total_reward: 1269566.26\n",
      "total_cost: 164296.74\n",
      "total_trades: 73702\n",
      "Sharpe: 0.209\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 232        |\n",
      "|    iterations           | 359        |\n",
      "|    time_elapsed         | 3160       |\n",
      "|    total_timesteps      | 735232     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03227882 |\n",
      "|    clip_fraction        | 0.288      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -85.1      |\n",
      "|    explained_variance   | -0.0143    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 443        |\n",
      "|    n_updates            | 3580       |\n",
      "|    policy_gradient_loss | -0.0129    |\n",
      "|    reward               | 10.388796  |\n",
      "|    std                  | 2.29       |\n",
      "|    value_loss           | 1.01e+03   |\n",
      "----------------------------------------\n",
      "Episode: 380\n",
      "day: 1940, episode: 380\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12251094.92\n",
      "total_reward: 2251094.92\n",
      "total_cost: 148780.08\n",
      "total_trades: 73698\n",
      "Sharpe: 0.234\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 232         |\n",
      "|    iterations           | 360         |\n",
      "|    time_elapsed         | 3169        |\n",
      "|    total_timesteps      | 737280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017267123 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.2       |\n",
      "|    explained_variance   | -0.00396    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 570         |\n",
      "|    n_updates            | 3590        |\n",
      "|    policy_gradient_loss | -0.022      |\n",
      "|    reward               | 23.007448   |\n",
      "|    std                  | 2.3         |\n",
      "|    value_loss           | 1.54e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 381\n",
      "day: 1940, episode: 381\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9615759.33\n",
      "total_reward: -384240.67\n",
      "total_cost: 147790.67\n",
      "total_trades: 73688\n",
      "Sharpe: 0.124\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 232         |\n",
      "|    iterations           | 361         |\n",
      "|    time_elapsed         | 3178        |\n",
      "|    total_timesteps      | 739328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022929356 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.3       |\n",
      "|    explained_variance   | 0.00571     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 767         |\n",
      "|    n_updates            | 3600        |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    reward               | 10.402459   |\n",
      "|    std                  | 2.3         |\n",
      "|    value_loss           | 1.6e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 382\n",
      "day: 1940, episode: 382\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11696285.94\n",
      "total_reward: 1696285.94\n",
      "total_cost: 166592.06\n",
      "total_trades: 73691\n",
      "Sharpe: 0.236\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 232         |\n",
      "|    iterations           | 362         |\n",
      "|    time_elapsed         | 3187        |\n",
      "|    total_timesteps      | 741376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025422053 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.4       |\n",
      "|    explained_variance   | -0.0106     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 607         |\n",
      "|    n_updates            | 3610        |\n",
      "|    policy_gradient_loss | -0.0181     |\n",
      "|    reward               | -9.050901   |\n",
      "|    std                  | 2.31        |\n",
      "|    value_loss           | 1.35e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 383\n",
      "day: 1940, episode: 383\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13410176.39\n",
      "total_reward: 3410176.39\n",
      "total_cost: 157854.61\n",
      "total_trades: 73703\n",
      "Sharpe: 0.281\n",
      "=================================\n",
      "Episode: 384\n",
      "day: 1940, episode: 384\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 15084404.73\n",
      "total_reward: 5084404.73\n",
      "total_cost: 164891.27\n",
      "total_trades: 73699\n",
      "Sharpe: 0.346\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 232         |\n",
      "|    iterations           | 363         |\n",
      "|    time_elapsed         | 3197        |\n",
      "|    total_timesteps      | 743424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017280344 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.5       |\n",
      "|    explained_variance   | 0.005       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.15e+03    |\n",
      "|    n_updates            | 3620        |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    reward               | -0.7186075  |\n",
      "|    std                  | 2.31        |\n",
      "|    value_loss           | 1.74e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 385\n",
      "day: 1940, episode: 385\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 15029911.07\n",
      "total_reward: 5029911.07\n",
      "total_cost: 161187.93\n",
      "total_trades: 73697\n",
      "Sharpe: 0.350\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 232        |\n",
      "|    iterations           | 364        |\n",
      "|    time_elapsed         | 3206       |\n",
      "|    total_timesteps      | 745472     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01705432 |\n",
      "|    clip_fraction        | 0.161      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -85.6      |\n",
      "|    explained_variance   | -0.0142    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.07e+03   |\n",
      "|    n_updates            | 3630       |\n",
      "|    policy_gradient_loss | -0.0215    |\n",
      "|    reward               | -6.0727243 |\n",
      "|    std                  | 2.32       |\n",
      "|    value_loss           | 2.19e+03   |\n",
      "----------------------------------------\n",
      "Episode: 386\n",
      "day: 1940, episode: 386\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11883416.92\n",
      "total_reward: 1883416.92\n",
      "total_cost: 158514.08\n",
      "total_trades: 73696\n",
      "Sharpe: 0.245\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 232         |\n",
      "|    iterations           | 365         |\n",
      "|    time_elapsed         | 3216        |\n",
      "|    total_timesteps      | 747520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024617936 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.6       |\n",
      "|    explained_variance   | -0.00355    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 564         |\n",
      "|    n_updates            | 3640        |\n",
      "|    policy_gradient_loss | -0.0191     |\n",
      "|    reward               | 3.7662106   |\n",
      "|    std                  | 2.32        |\n",
      "|    value_loss           | 1.43e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 387\n",
      "day: 1940, episode: 387\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10989058.37\n",
      "total_reward: 989058.37\n",
      "total_cost: 163958.63\n",
      "total_trades: 73694\n",
      "Sharpe: 0.193\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 231        |\n",
      "|    iterations           | 366        |\n",
      "|    time_elapsed         | 3232       |\n",
      "|    total_timesteps      | 749568     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02516279 |\n",
      "|    clip_fraction        | 0.201      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -85.7      |\n",
      "|    explained_variance   | 0.003      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 518        |\n",
      "|    n_updates            | 3650       |\n",
      "|    policy_gradient_loss | -0.0214    |\n",
      "|    reward               | -4.2456427 |\n",
      "|    std                  | 2.33       |\n",
      "|    value_loss           | 1.1e+03    |\n",
      "----------------------------------------\n",
      "Episode: 388\n",
      "day: 1940, episode: 388\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14697467.45\n",
      "total_reward: 4697467.45\n",
      "total_cost: 159388.55\n",
      "total_trades: 73704\n",
      "Sharpe: 0.335\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 231        |\n",
      "|    iterations           | 367        |\n",
      "|    time_elapsed         | 3248       |\n",
      "|    total_timesteps      | 751616     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03208847 |\n",
      "|    clip_fraction        | 0.307      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -85.8      |\n",
      "|    explained_variance   | 0.0171     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 405        |\n",
      "|    n_updates            | 3660       |\n",
      "|    policy_gradient_loss | -0.0069    |\n",
      "|    reward               | -1.038753  |\n",
      "|    std                  | 2.33       |\n",
      "|    value_loss           | 1.16e+03   |\n",
      "----------------------------------------\n",
      "Episode: 389\n",
      "day: 1940, episode: 389\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11604450.75\n",
      "total_reward: 1604450.75\n",
      "total_cost: 173890.25\n",
      "total_trades: 73684\n",
      "Sharpe: 0.226\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 230         |\n",
      "|    iterations           | 368         |\n",
      "|    time_elapsed         | 3265        |\n",
      "|    total_timesteps      | 753664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037524737 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.8       |\n",
      "|    explained_variance   | 0.00759     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 478         |\n",
      "|    n_updates            | 3670        |\n",
      "|    policy_gradient_loss | -0.0046     |\n",
      "|    reward               | 3.2088401   |\n",
      "|    std                  | 2.33        |\n",
      "|    value_loss           | 1.53e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 390\n",
      "day: 1940, episode: 390\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13294707.96\n",
      "total_reward: 3294707.96\n",
      "total_cost: 170646.04\n",
      "total_trades: 73696\n",
      "Sharpe: 0.279\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 230         |\n",
      "|    iterations           | 369         |\n",
      "|    time_elapsed         | 3282        |\n",
      "|    total_timesteps      | 755712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026286002 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.9       |\n",
      "|    explained_variance   | -0.0184     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 647         |\n",
      "|    n_updates            | 3680        |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    reward               | -8.763634   |\n",
      "|    std                  | 2.34        |\n",
      "|    value_loss           | 942         |\n",
      "-----------------------------------------\n",
      "Episode: 391\n",
      "day: 1940, episode: 391\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7888626.92\n",
      "total_reward: -2111373.08\n",
      "total_cost: 159354.08\n",
      "total_trades: 73700\n",
      "Sharpe: 0.032\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 229       |\n",
      "|    iterations           | 370       |\n",
      "|    time_elapsed         | 3297      |\n",
      "|    total_timesteps      | 757760    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.019923  |\n",
      "|    clip_fraction        | 0.199     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -86       |\n",
      "|    explained_variance   | 0.0067    |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 749       |\n",
      "|    n_updates            | 3690      |\n",
      "|    policy_gradient_loss | -0.0144   |\n",
      "|    reward               | 2.1297865 |\n",
      "|    std                  | 2.34      |\n",
      "|    value_loss           | 1.61e+03  |\n",
      "---------------------------------------\n",
      "Episode: 392\n",
      "day: 1940, episode: 392\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11281951.11\n",
      "total_reward: 1281951.11\n",
      "total_cost: 164320.89\n",
      "total_trades: 73696\n",
      "Sharpe: 0.187\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 229        |\n",
      "|    iterations           | 371        |\n",
      "|    time_elapsed         | 3306       |\n",
      "|    total_timesteps      | 759808     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02893262 |\n",
      "|    clip_fraction        | 0.26       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -86.1      |\n",
      "|    explained_variance   | 0.028      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 375        |\n",
      "|    n_updates            | 3700       |\n",
      "|    policy_gradient_loss | -0.0135    |\n",
      "|    reward               | -30.657028 |\n",
      "|    std                  | 2.35       |\n",
      "|    value_loss           | 1.26e+03   |\n",
      "----------------------------------------\n",
      "Episode: 393\n",
      "day: 1940, episode: 393\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9392983.80\n",
      "total_reward: -607016.20\n",
      "total_cost: 159227.20\n",
      "total_trades: 73684\n",
      "Sharpe: 0.093\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 229        |\n",
      "|    iterations           | 372        |\n",
      "|    time_elapsed         | 3315       |\n",
      "|    total_timesteps      | 761856     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03157513 |\n",
      "|    clip_fraction        | 0.264      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -86.2      |\n",
      "|    explained_variance   | 0.0153     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 610        |\n",
      "|    n_updates            | 3710       |\n",
      "|    policy_gradient_loss | -0.00897   |\n",
      "|    reward               | -32.165783 |\n",
      "|    std                  | 2.36       |\n",
      "|    value_loss           | 1.5e+03    |\n",
      "----------------------------------------\n",
      "Episode: 394\n",
      "day: 1940, episode: 394\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10569472.37\n",
      "total_reward: 569472.37\n",
      "total_cost: 151136.63\n",
      "total_trades: 73692\n",
      "Sharpe: 0.182\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 229         |\n",
      "|    iterations           | 373         |\n",
      "|    time_elapsed         | 3324        |\n",
      "|    total_timesteps      | 763904      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023124855 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.3       |\n",
      "|    explained_variance   | -0.0135     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 742         |\n",
      "|    n_updates            | 3720        |\n",
      "|    policy_gradient_loss | -0.0251     |\n",
      "|    reward               | 3.4436595   |\n",
      "|    std                  | 2.36        |\n",
      "|    value_loss           | 1.36e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 395\n",
      "day: 1940, episode: 395\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10379184.19\n",
      "total_reward: 379184.19\n",
      "total_cost: 159909.81\n",
      "total_trades: 73691\n",
      "Sharpe: 0.175\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 229        |\n",
      "|    iterations           | 374        |\n",
      "|    time_elapsed         | 3333       |\n",
      "|    total_timesteps      | 765952     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03304268 |\n",
      "|    clip_fraction        | 0.265      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -86.4      |\n",
      "|    explained_variance   | 0.00732    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 515        |\n",
      "|    n_updates            | 3730       |\n",
      "|    policy_gradient_loss | -0.0191    |\n",
      "|    reward               | -11.155658 |\n",
      "|    std                  | 2.37       |\n",
      "|    value_loss           | 1.3e+03    |\n",
      "----------------------------------------\n",
      "Episode: 396\n",
      "day: 1940, episode: 396\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10489289.25\n",
      "total_reward: 489289.25\n",
      "total_cost: 159430.75\n",
      "total_trades: 73697\n",
      "Sharpe: 0.176\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 229         |\n",
      "|    iterations           | 375         |\n",
      "|    time_elapsed         | 3342        |\n",
      "|    total_timesteps      | 768000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029084146 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.5       |\n",
      "|    explained_variance   | -0.0286     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 412         |\n",
      "|    n_updates            | 3740        |\n",
      "|    policy_gradient_loss | -0.0244     |\n",
      "|    reward               | -0.7872574  |\n",
      "|    std                  | 2.38        |\n",
      "|    value_loss           | 811         |\n",
      "-----------------------------------------\n",
      "Episode: 397\n",
      "day: 1940, episode: 397\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11810611.98\n",
      "total_reward: 1810611.98\n",
      "total_cost: 158814.02\n",
      "total_trades: 73689\n",
      "Sharpe: 0.227\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 229         |\n",
      "|    iterations           | 376         |\n",
      "|    time_elapsed         | 3351        |\n",
      "|    total_timesteps      | 770048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022879142 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.6       |\n",
      "|    explained_variance   | 0.00486     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 486         |\n",
      "|    n_updates            | 3750        |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    reward               | 2.5553248   |\n",
      "|    std                  | 2.38        |\n",
      "|    value_loss           | 963         |\n",
      "-----------------------------------------\n",
      "Episode: 398\n",
      "day: 1940, episode: 398\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14198406.56\n",
      "total_reward: 4198406.56\n",
      "total_cost: 164266.44\n",
      "total_trades: 73703\n",
      "Sharpe: 0.321\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 229         |\n",
      "|    iterations           | 377         |\n",
      "|    time_elapsed         | 3360        |\n",
      "|    total_timesteps      | 772096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043276377 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.7       |\n",
      "|    explained_variance   | -0.0453     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 525         |\n",
      "|    n_updates            | 3760        |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    reward               | -4.865224   |\n",
      "|    std                  | 2.39        |\n",
      "|    value_loss           | 981         |\n",
      "-----------------------------------------\n",
      "Episode: 399\n",
      "day: 1940, episode: 399\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8035723.48\n",
      "total_reward: -1964276.52\n",
      "total_cost: 152698.52\n",
      "total_trades: 73691\n",
      "Sharpe: 0.034\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 229        |\n",
      "|    iterations           | 378        |\n",
      "|    time_elapsed         | 3369       |\n",
      "|    total_timesteps      | 774144     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03055467 |\n",
      "|    clip_fraction        | 0.264      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -86.8      |\n",
      "|    explained_variance   | -0.00945   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 452        |\n",
      "|    n_updates            | 3770       |\n",
      "|    policy_gradient_loss | -0.0101    |\n",
      "|    reward               | 4.5697074  |\n",
      "|    std                  | 2.39       |\n",
      "|    value_loss           | 1.05e+03   |\n",
      "----------------------------------------\n",
      "Episode: 400\n",
      "day: 1940, episode: 400\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8746792.59\n",
      "total_reward: -1253207.41\n",
      "total_cost: 157937.41\n",
      "total_trades: 73695\n",
      "Sharpe: 0.075\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 229         |\n",
      "|    iterations           | 379         |\n",
      "|    time_elapsed         | 3378        |\n",
      "|    total_timesteps      | 776192      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018582202 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.9       |\n",
      "|    explained_variance   | -0.000167   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 243         |\n",
      "|    n_updates            | 3780        |\n",
      "|    policy_gradient_loss | -0.0199     |\n",
      "|    reward               | 1.4685285   |\n",
      "|    std                  | 2.4         |\n",
      "|    value_loss           | 702         |\n",
      "-----------------------------------------\n",
      "Episode: 401\n",
      "day: 1940, episode: 401\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11065060.92\n",
      "total_reward: 1065060.92\n",
      "total_cost: 157721.08\n",
      "total_trades: 73697\n",
      "Sharpe: 0.184\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 229        |\n",
      "|    iterations           | 380        |\n",
      "|    time_elapsed         | 3388       |\n",
      "|    total_timesteps      | 778240     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04223285 |\n",
      "|    clip_fraction        | 0.27       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -87        |\n",
      "|    explained_variance   | -0.0456    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 611        |\n",
      "|    n_updates            | 3790       |\n",
      "|    policy_gradient_loss | -0.00282   |\n",
      "|    reward               | -28.279305 |\n",
      "|    std                  | 2.41       |\n",
      "|    value_loss           | 1.08e+03   |\n",
      "----------------------------------------\n",
      "Episode: 402\n",
      "day: 1940, episode: 402\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12101838.14\n",
      "total_reward: 2101838.14\n",
      "total_cost: 163672.86\n",
      "total_trades: 73687\n",
      "Sharpe: 0.233\n",
      "=================================\n",
      "Episode: 403\n",
      "day: 1940, episode: 403\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9177488.78\n",
      "total_reward: -822511.22\n",
      "total_cost: 169085.22\n",
      "total_trades: 73693\n",
      "Sharpe: 0.105\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 229         |\n",
      "|    iterations           | 381         |\n",
      "|    time_elapsed         | 3396        |\n",
      "|    total_timesteps      | 780288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016900064 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.1       |\n",
      "|    explained_variance   | 0.00602     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 342         |\n",
      "|    n_updates            | 3800        |\n",
      "|    policy_gradient_loss | -0.0205     |\n",
      "|    reward               | 7.392579    |\n",
      "|    std                  | 2.41        |\n",
      "|    value_loss           | 958         |\n",
      "-----------------------------------------\n",
      "Episode: 404\n",
      "day: 1940, episode: 404\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14986016.14\n",
      "total_reward: 4986016.14\n",
      "total_cost: 174685.86\n",
      "total_trades: 73694\n",
      "Sharpe: 0.351\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 229         |\n",
      "|    iterations           | 382         |\n",
      "|    time_elapsed         | 3405        |\n",
      "|    total_timesteps      | 782336      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016009834 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.2       |\n",
      "|    explained_variance   | 0.00639     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 231         |\n",
      "|    n_updates            | 3810        |\n",
      "|    policy_gradient_loss | -0.0228     |\n",
      "|    reward               | 6.06714     |\n",
      "|    std                  | 2.42        |\n",
      "|    value_loss           | 743         |\n",
      "-----------------------------------------\n",
      "Episode: 405\n",
      "day: 1940, episode: 405\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 15084032.97\n",
      "total_reward: 5084032.97\n",
      "total_cost: 170293.03\n",
      "total_trades: 73692\n",
      "Sharpe: 0.356\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 229        |\n",
      "|    iterations           | 383        |\n",
      "|    time_elapsed         | 3414       |\n",
      "|    total_timesteps      | 784384     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01788755 |\n",
      "|    clip_fraction        | 0.168      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -87.2      |\n",
      "|    explained_variance   | -0.0305    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 654        |\n",
      "|    n_updates            | 3820       |\n",
      "|    policy_gradient_loss | -0.025     |\n",
      "|    reward               | 15.574537  |\n",
      "|    std                  | 2.42       |\n",
      "|    value_loss           | 1.3e+03    |\n",
      "----------------------------------------\n",
      "Episode: 406\n",
      "day: 1940, episode: 406\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9111619.50\n",
      "total_reward: -888380.50\n",
      "total_cost: 163020.50\n",
      "total_trades: 73698\n",
      "Sharpe: 0.106\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 229         |\n",
      "|    iterations           | 384         |\n",
      "|    time_elapsed         | 3423        |\n",
      "|    total_timesteps      | 786432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043131813 |\n",
      "|    clip_fraction        | 0.296       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.3       |\n",
      "|    explained_variance   | 0.00827     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 538         |\n",
      "|    n_updates            | 3830        |\n",
      "|    policy_gradient_loss | 0.00501     |\n",
      "|    reward               | -4.3525014  |\n",
      "|    std                  | 2.43        |\n",
      "|    value_loss           | 1.5e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 407\n",
      "day: 1940, episode: 407\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14479114.38\n",
      "total_reward: 4479114.38\n",
      "total_cost: 172558.62\n",
      "total_trades: 73701\n",
      "Sharpe: 0.332\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 229        |\n",
      "|    iterations           | 385        |\n",
      "|    time_elapsed         | 3432       |\n",
      "|    total_timesteps      | 788480     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04577721 |\n",
      "|    clip_fraction        | 0.234      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -87.4      |\n",
      "|    explained_variance   | -0.0029    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 292        |\n",
      "|    n_updates            | 3840       |\n",
      "|    policy_gradient_loss | -0.015     |\n",
      "|    reward               | -4.521186  |\n",
      "|    std                  | 2.43       |\n",
      "|    value_loss           | 719        |\n",
      "----------------------------------------\n",
      "Episode: 408\n",
      "day: 1940, episode: 408\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10606342.96\n",
      "total_reward: 606342.96\n",
      "total_cost: 165954.04\n",
      "total_trades: 73688\n",
      "Sharpe: 0.147\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 229        |\n",
      "|    iterations           | 386        |\n",
      "|    time_elapsed         | 3441       |\n",
      "|    total_timesteps      | 790528     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02150122 |\n",
      "|    clip_fraction        | 0.205      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -87.5      |\n",
      "|    explained_variance   | -0.00562   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 448        |\n",
      "|    n_updates            | 3850       |\n",
      "|    policy_gradient_loss | -0.0224    |\n",
      "|    reward               | 15.027586  |\n",
      "|    std                  | 2.43       |\n",
      "|    value_loss           | 1.43e+03   |\n",
      "----------------------------------------\n",
      "Episode: 409\n",
      "day: 1940, episode: 409\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8453164.69\n",
      "total_reward: -1546835.31\n",
      "total_cost: 171760.31\n",
      "total_trades: 73699\n",
      "Sharpe: 0.066\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 229         |\n",
      "|    iterations           | 387         |\n",
      "|    time_elapsed         | 3449        |\n",
      "|    total_timesteps      | 792576      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018833026 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.5       |\n",
      "|    explained_variance   | -0.025      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 331         |\n",
      "|    n_updates            | 3860        |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    reward               | 0.47147387  |\n",
      "|    std                  | 2.44        |\n",
      "|    value_loss           | 1.02e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 410\n",
      "day: 1940, episode: 410\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12873621.20\n",
      "total_reward: 2873621.20\n",
      "total_cost: 178380.80\n",
      "total_trades: 73693\n",
      "Sharpe: 0.263\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 229         |\n",
      "|    iterations           | 388         |\n",
      "|    time_elapsed         | 3459        |\n",
      "|    total_timesteps      | 794624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031436536 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.6       |\n",
      "|    explained_variance   | 0.00889     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 381         |\n",
      "|    n_updates            | 3870        |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    reward               | 17.875051   |\n",
      "|    std                  | 2.44        |\n",
      "|    value_loss           | 876         |\n",
      "-----------------------------------------\n",
      "Episode: 411\n",
      "day: 1940, episode: 411\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9204485.78\n",
      "total_reward: -795514.22\n",
      "total_cost: 172801.22\n",
      "total_trades: 73702\n",
      "Sharpe: 0.114\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 229         |\n",
      "|    iterations           | 389         |\n",
      "|    time_elapsed         | 3467        |\n",
      "|    total_timesteps      | 796672      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026906494 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.6       |\n",
      "|    explained_variance   | -0.0193     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 613         |\n",
      "|    n_updates            | 3880        |\n",
      "|    policy_gradient_loss | -0.00637    |\n",
      "|    reward               | -16.500374  |\n",
      "|    std                  | 2.45        |\n",
      "|    value_loss           | 1.15e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 412\n",
      "day: 1940, episode: 412\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7905076.15\n",
      "total_reward: -2094923.85\n",
      "total_cost: 171539.85\n",
      "total_trades: 73694\n",
      "Sharpe: 0.050\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 229         |\n",
      "|    iterations           | 390         |\n",
      "|    time_elapsed         | 3476        |\n",
      "|    total_timesteps      | 798720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023401234 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.8       |\n",
      "|    explained_variance   | 0.0177      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 298         |\n",
      "|    n_updates            | 3890        |\n",
      "|    policy_gradient_loss | -0.0218     |\n",
      "|    reward               | -41.945644  |\n",
      "|    std                  | 2.46        |\n",
      "|    value_loss           | 962         |\n",
      "-----------------------------------------\n",
      "Episode: 413\n",
      "day: 1940, episode: 413\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10537637.89\n",
      "total_reward: 537637.89\n",
      "total_cost: 179675.11\n",
      "total_trades: 73693\n",
      "Sharpe: 0.155\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 229         |\n",
      "|    iterations           | 391         |\n",
      "|    time_elapsed         | 3486        |\n",
      "|    total_timesteps      | 800768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027118124 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.9       |\n",
      "|    explained_variance   | -0.00598    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 357         |\n",
      "|    n_updates            | 3900        |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    reward               | 5.4093637   |\n",
      "|    std                  | 2.46        |\n",
      "|    value_loss           | 919         |\n",
      "-----------------------------------------\n",
      "Episode: 414\n",
      "day: 1940, episode: 414\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9404533.57\n",
      "total_reward: -595466.43\n",
      "total_cost: 172088.43\n",
      "total_trades: 73698\n",
      "Sharpe: 0.122\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 229        |\n",
      "|    iterations           | 392        |\n",
      "|    time_elapsed         | 3494       |\n",
      "|    total_timesteps      | 802816     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01928187 |\n",
      "|    clip_fraction        | 0.188      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -87.9      |\n",
      "|    explained_variance   | -0.00449   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 369        |\n",
      "|    n_updates            | 3910       |\n",
      "|    policy_gradient_loss | -0.0204    |\n",
      "|    reward               | 10.829191  |\n",
      "|    std                  | 2.46       |\n",
      "|    value_loss           | 941        |\n",
      "----------------------------------------\n",
      "Episode: 415\n",
      "day: 1940, episode: 415\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12119241.44\n",
      "total_reward: 2119241.44\n",
      "total_cost: 174671.56\n",
      "total_trades: 73704\n",
      "Sharpe: 0.229\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 229         |\n",
      "|    iterations           | 393         |\n",
      "|    time_elapsed         | 3502        |\n",
      "|    total_timesteps      | 804864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024888948 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88         |\n",
      "|    explained_variance   | -0.0172     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 659         |\n",
      "|    n_updates            | 3920        |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    reward               | -5.5175676  |\n",
      "|    std                  | 2.47        |\n",
      "|    value_loss           | 1.09e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 416\n",
      "day: 1940, episode: 416\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14604344.09\n",
      "total_reward: 4604344.09\n",
      "total_cost: 173541.91\n",
      "total_trades: 73698\n",
      "Sharpe: 0.327\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 229         |\n",
      "|    iterations           | 394         |\n",
      "|    time_elapsed         | 3510        |\n",
      "|    total_timesteps      | 806912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017507907 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.1       |\n",
      "|    explained_variance   | -0.00852    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 628         |\n",
      "|    n_updates            | 3930        |\n",
      "|    policy_gradient_loss | -0.0187     |\n",
      "|    reward               | -0.5150479  |\n",
      "|    std                  | 2.48        |\n",
      "|    value_loss           | 1.38e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 417\n",
      "day: 1940, episode: 417\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9255057.98\n",
      "total_reward: -744942.02\n",
      "total_cost: 168181.02\n",
      "total_trades: 73702\n",
      "Sharpe: 0.129\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 229         |\n",
      "|    iterations           | 395         |\n",
      "|    time_elapsed         | 3518        |\n",
      "|    total_timesteps      | 808960      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022347638 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.2       |\n",
      "|    explained_variance   | -0.0365     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 682         |\n",
      "|    n_updates            | 3940        |\n",
      "|    policy_gradient_loss | -0.0202     |\n",
      "|    reward               | 4.5136304   |\n",
      "|    std                  | 2.49        |\n",
      "|    value_loss           | 1.24e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 418\n",
      "day: 1940, episode: 418\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12719363.67\n",
      "total_reward: 2719363.67\n",
      "total_cost: 174328.33\n",
      "total_trades: 73694\n",
      "Sharpe: 0.254\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 229         |\n",
      "|    iterations           | 396         |\n",
      "|    time_elapsed         | 3527        |\n",
      "|    total_timesteps      | 811008      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015094143 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.3       |\n",
      "|    explained_variance   | -0.00099    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 856         |\n",
      "|    n_updates            | 3950        |\n",
      "|    policy_gradient_loss | -0.0186     |\n",
      "|    reward               | -3.912189   |\n",
      "|    std                  | 2.49        |\n",
      "|    value_loss           | 1.37e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 419\n",
      "day: 1940, episode: 419\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11159720.47\n",
      "total_reward: 1159720.47\n",
      "total_cost: 168457.53\n",
      "total_trades: 73704\n",
      "Sharpe: 0.185\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 229         |\n",
      "|    iterations           | 397         |\n",
      "|    time_elapsed         | 3535        |\n",
      "|    total_timesteps      | 813056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034055233 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.4       |\n",
      "|    explained_variance   | 0.0062      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 639         |\n",
      "|    n_updates            | 3960        |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    reward               | 3.2346582   |\n",
      "|    std                  | 2.49        |\n",
      "|    value_loss           | 1.3e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 420\n",
      "day: 1940, episode: 420\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 6144435.82\n",
      "total_reward: -3855564.18\n",
      "total_cost: 148921.18\n",
      "total_trades: 73696\n",
      "Sharpe: -0.043\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 229         |\n",
      "|    iterations           | 398         |\n",
      "|    time_elapsed         | 3546        |\n",
      "|    total_timesteps      | 815104      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039604522 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.4       |\n",
      "|    explained_variance   | 0.029       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1e+03       |\n",
      "|    n_updates            | 3970        |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    reward               | -3.204911   |\n",
      "|    std                  | 2.5         |\n",
      "|    value_loss           | 941         |\n",
      "-----------------------------------------\n",
      "Episode: 421\n",
      "day: 1940, episode: 421\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12964570.01\n",
      "total_reward: 2964570.01\n",
      "total_cost: 169761.99\n",
      "total_trades: 73699\n",
      "Sharpe: 0.264\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 229         |\n",
      "|    iterations           | 399         |\n",
      "|    time_elapsed         | 3555        |\n",
      "|    total_timesteps      | 817152      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020948883 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.5       |\n",
      "|    explained_variance   | 0.016       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 728         |\n",
      "|    n_updates            | 3980        |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    reward               | 1.2432207   |\n",
      "|    std                  | 2.5         |\n",
      "|    value_loss           | 1.73e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 422\n",
      "day: 1940, episode: 422\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13980274.61\n",
      "total_reward: 3980274.61\n",
      "total_cost: 164433.39\n",
      "total_trades: 73703\n",
      "Sharpe: 0.315\n",
      "=================================\n",
      "Episode: 423\n",
      "day: 1940, episode: 423\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8900199.24\n",
      "total_reward: -1099800.76\n",
      "total_cost: 162202.76\n",
      "total_trades: 73697\n",
      "Sharpe: 0.108\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 229         |\n",
      "|    iterations           | 400         |\n",
      "|    time_elapsed         | 3563        |\n",
      "|    total_timesteps      | 819200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026723929 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.6       |\n",
      "|    explained_variance   | -0.0122     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 658         |\n",
      "|    n_updates            | 3990        |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    reward               | -1.5912638  |\n",
      "|    std                  | 2.51        |\n",
      "|    value_loss           | 1.49e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 424\n",
      "day: 1940, episode: 424\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8467213.38\n",
      "total_reward: -1532786.62\n",
      "total_cost: 163849.62\n",
      "total_trades: 73693\n",
      "Sharpe: 0.049\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 229        |\n",
      "|    iterations           | 401        |\n",
      "|    time_elapsed         | 3572       |\n",
      "|    total_timesteps      | 821248     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02030843 |\n",
      "|    clip_fraction        | 0.204      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -88.7      |\n",
      "|    explained_variance   | 0.00625    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 420        |\n",
      "|    n_updates            | 4000       |\n",
      "|    policy_gradient_loss | -0.019     |\n",
      "|    reward               | 4.289608   |\n",
      "|    std                  | 2.51       |\n",
      "|    value_loss           | 970        |\n",
      "----------------------------------------\n",
      "Episode: 425\n",
      "day: 1940, episode: 425\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10330375.05\n",
      "total_reward: 330375.05\n",
      "total_cost: 158037.95\n",
      "total_trades: 73699\n",
      "Sharpe: 0.183\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 229        |\n",
      "|    iterations           | 402        |\n",
      "|    time_elapsed         | 3580       |\n",
      "|    total_timesteps      | 823296     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03231646 |\n",
      "|    clip_fraction        | 0.282      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -88.7      |\n",
      "|    explained_variance   | 0.0405     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 773        |\n",
      "|    n_updates            | 4010       |\n",
      "|    policy_gradient_loss | -0.0104    |\n",
      "|    reward               | -15.15266  |\n",
      "|    std                  | 2.52       |\n",
      "|    value_loss           | 1.34e+03   |\n",
      "----------------------------------------\n",
      "Episode: 426\n",
      "day: 1940, episode: 426\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 16536091.92\n",
      "total_reward: 6536091.92\n",
      "total_cost: 166093.08\n",
      "total_trades: 73691\n",
      "Sharpe: 0.382\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 229         |\n",
      "|    iterations           | 403         |\n",
      "|    time_elapsed         | 3588        |\n",
      "|    total_timesteps      | 825344      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.04034614  |\n",
      "|    clip_fraction        | 0.32        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.8       |\n",
      "|    explained_variance   | 0.0222      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 460         |\n",
      "|    n_updates            | 4020        |\n",
      "|    policy_gradient_loss | -0.00994    |\n",
      "|    reward               | 0.035063423 |\n",
      "|    std                  | 2.53        |\n",
      "|    value_loss           | 938         |\n",
      "-----------------------------------------\n",
      "Episode: 427\n",
      "day: 1940, episode: 427\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13046389.79\n",
      "total_reward: 3046389.79\n",
      "total_cost: 171648.21\n",
      "total_trades: 73693\n",
      "Sharpe: 0.280\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 230         |\n",
      "|    iterations           | 404         |\n",
      "|    time_elapsed         | 3596        |\n",
      "|    total_timesteps      | 827392      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024161702 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.9       |\n",
      "|    explained_variance   | 0.0257      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.01e+03    |\n",
      "|    n_updates            | 4030        |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    reward               | -10.343138  |\n",
      "|    std                  | 2.53        |\n",
      "|    value_loss           | 2.57e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 428\n",
      "day: 1940, episode: 428\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9559340.13\n",
      "total_reward: -440659.87\n",
      "total_cost: 167234.87\n",
      "total_trades: 73698\n",
      "Sharpe: 0.147\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 229        |\n",
      "|    iterations           | 405        |\n",
      "|    time_elapsed         | 3606       |\n",
      "|    total_timesteps      | 829440     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02297391 |\n",
      "|    clip_fraction        | 0.221      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -88.9      |\n",
      "|    explained_variance   | -0.003     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 582        |\n",
      "|    n_updates            | 4040       |\n",
      "|    policy_gradient_loss | -0.0202    |\n",
      "|    reward               | -6.1792507 |\n",
      "|    std                  | 2.53       |\n",
      "|    value_loss           | 1.35e+03   |\n",
      "----------------------------------------\n",
      "Episode: 429\n",
      "day: 1940, episode: 429\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11602699.43\n",
      "total_reward: 1602699.43\n",
      "total_cost: 161808.57\n",
      "total_trades: 73690\n",
      "Sharpe: 0.230\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 230        |\n",
      "|    iterations           | 406        |\n",
      "|    time_elapsed         | 3614       |\n",
      "|    total_timesteps      | 831488     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03137087 |\n",
      "|    clip_fraction        | 0.251      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -89        |\n",
      "|    explained_variance   | 0.0188     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 500        |\n",
      "|    n_updates            | 4050       |\n",
      "|    policy_gradient_loss | -0.0132    |\n",
      "|    reward               | -6.806876  |\n",
      "|    std                  | 2.54       |\n",
      "|    value_loss           | 1e+03      |\n",
      "----------------------------------------\n",
      "Episode: 430\n",
      "day: 1940, episode: 430\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11507685.22\n",
      "total_reward: 1507685.22\n",
      "total_cost: 160208.78\n",
      "total_trades: 73692\n",
      "Sharpe: 0.225\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 230         |\n",
      "|    iterations           | 407         |\n",
      "|    time_elapsed         | 3622        |\n",
      "|    total_timesteps      | 833536      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029234277 |\n",
      "|    clip_fraction        | 0.267       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.1       |\n",
      "|    explained_variance   | -0.0165     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 545         |\n",
      "|    n_updates            | 4060        |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    reward               | 43.039658   |\n",
      "|    std                  | 2.55        |\n",
      "|    value_loss           | 1.19e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 431\n",
      "day: 1940, episode: 431\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8782996.29\n",
      "total_reward: -1217003.71\n",
      "total_cost: 161702.71\n",
      "total_trades: 73700\n",
      "Sharpe: 0.101\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 230        |\n",
      "|    iterations           | 408        |\n",
      "|    time_elapsed         | 3630       |\n",
      "|    total_timesteps      | 835584     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02068649 |\n",
      "|    clip_fraction        | 0.185      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -89.2      |\n",
      "|    explained_variance   | 0.0046     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 617        |\n",
      "|    n_updates            | 4070       |\n",
      "|    policy_gradient_loss | -0.0231    |\n",
      "|    reward               | 1.256761   |\n",
      "|    std                  | 2.55       |\n",
      "|    value_loss           | 1.35e+03   |\n",
      "----------------------------------------\n",
      "Episode: 432\n",
      "day: 1940, episode: 432\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10388183.51\n",
      "total_reward: 388183.51\n",
      "total_cost: 166870.49\n",
      "total_trades: 73698\n",
      "Sharpe: 0.150\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 230         |\n",
      "|    iterations           | 409         |\n",
      "|    time_elapsed         | 3638        |\n",
      "|    total_timesteps      | 837632      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015992135 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.2       |\n",
      "|    explained_variance   | 0.0124      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 687         |\n",
      "|    n_updates            | 4080        |\n",
      "|    policy_gradient_loss | -0.0248     |\n",
      "|    reward               | -1.5572449  |\n",
      "|    std                  | 2.55        |\n",
      "|    value_loss           | 1.14e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 433\n",
      "day: 1940, episode: 433\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12330430.99\n",
      "total_reward: 2330430.99\n",
      "total_cost: 173726.01\n",
      "total_trades: 73692\n",
      "Sharpe: 0.239\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 230         |\n",
      "|    iterations           | 410         |\n",
      "|    time_elapsed         | 3646        |\n",
      "|    total_timesteps      | 839680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013361894 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.4       |\n",
      "|    explained_variance   | 0.000202    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 976         |\n",
      "|    n_updates            | 4090        |\n",
      "|    policy_gradient_loss | -0.0211     |\n",
      "|    reward               | 3.9993486   |\n",
      "|    std                  | 2.57        |\n",
      "|    value_loss           | 1.42e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 434\n",
      "day: 1940, episode: 434\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10620442.09\n",
      "total_reward: 620442.09\n",
      "total_cost: 174132.91\n",
      "total_trades: 73694\n",
      "Sharpe: 0.163\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 230         |\n",
      "|    iterations           | 411         |\n",
      "|    time_elapsed         | 3655        |\n",
      "|    total_timesteps      | 841728      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016558476 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.5       |\n",
      "|    explained_variance   | -0.0123     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 744         |\n",
      "|    n_updates            | 4100        |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    reward               | 1.6680481   |\n",
      "|    std                  | 2.57        |\n",
      "|    value_loss           | 1.43e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 435\n",
      "day: 1940, episode: 435\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12345633.11\n",
      "total_reward: 2345633.11\n",
      "total_cost: 184823.89\n",
      "total_trades: 73693\n",
      "Sharpe: 0.255\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 230         |\n",
      "|    iterations           | 412         |\n",
      "|    time_elapsed         | 3664        |\n",
      "|    total_timesteps      | 843776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014124711 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.6       |\n",
      "|    explained_variance   | 0.00876     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 671         |\n",
      "|    n_updates            | 4110        |\n",
      "|    policy_gradient_loss | -0.0244     |\n",
      "|    reward               | -4.687768   |\n",
      "|    std                  | 2.58        |\n",
      "|    value_loss           | 1.26e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 436\n",
      "day: 1940, episode: 436\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10651861.01\n",
      "total_reward: 651861.01\n",
      "total_cost: 183849.99\n",
      "total_trades: 73692\n",
      "Sharpe: 0.191\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 230        |\n",
      "|    iterations           | 413        |\n",
      "|    time_elapsed         | 3673       |\n",
      "|    total_timesteps      | 845824     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02060756 |\n",
      "|    clip_fraction        | 0.21       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -89.7      |\n",
      "|    explained_variance   | 0.0189     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 419        |\n",
      "|    n_updates            | 4120       |\n",
      "|    policy_gradient_loss | -0.0153    |\n",
      "|    reward               | -24.614115 |\n",
      "|    std                  | 2.59       |\n",
      "|    value_loss           | 1.17e+03   |\n",
      "----------------------------------------\n",
      "Episode: 437\n",
      "day: 1940, episode: 437\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13156026.94\n",
      "total_reward: 3156026.94\n",
      "total_cost: 187521.06\n",
      "total_trades: 73703\n",
      "Sharpe: 0.276\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 230         |\n",
      "|    iterations           | 414         |\n",
      "|    time_elapsed         | 3681        |\n",
      "|    total_timesteps      | 847872      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013210248 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.8       |\n",
      "|    explained_variance   | 0.018       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.06e+03    |\n",
      "|    n_updates            | 4130        |\n",
      "|    policy_gradient_loss | -0.0223     |\n",
      "|    reward               | -9.309577   |\n",
      "|    std                  | 2.6         |\n",
      "|    value_loss           | 1.78e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 438\n",
      "day: 1940, episode: 438\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12061897.60\n",
      "total_reward: 2061897.60\n",
      "total_cost: 183511.40\n",
      "total_trades: 73698\n",
      "Sharpe: 0.243\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 230         |\n",
      "|    iterations           | 415         |\n",
      "|    time_elapsed         | 3689        |\n",
      "|    total_timesteps      | 849920      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.057225265 |\n",
      "|    clip_fraction        | 0.312       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.9       |\n",
      "|    explained_variance   | -0.0278     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 591         |\n",
      "|    n_updates            | 4140        |\n",
      "|    policy_gradient_loss | -0.00528    |\n",
      "|    reward               | -0.9394137  |\n",
      "|    std                  | 2.6         |\n",
      "|    value_loss           | 1.37e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 439\n",
      "day: 1940, episode: 439\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11865455.43\n",
      "total_reward: 1865455.43\n",
      "total_cost: 188230.57\n",
      "total_trades: 73695\n",
      "Sharpe: 0.215\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 230         |\n",
      "|    iterations           | 416         |\n",
      "|    time_elapsed         | 3697        |\n",
      "|    total_timesteps      | 851968      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025634117 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90         |\n",
      "|    explained_variance   | -0.00273    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 552         |\n",
      "|    n_updates            | 4150        |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    reward               | 9.039637    |\n",
      "|    std                  | 2.61        |\n",
      "|    value_loss           | 1.82e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 440\n",
      "day: 1940, episode: 440\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 15324129.11\n",
      "total_reward: 5324129.11\n",
      "total_cost: 179501.89\n",
      "total_trades: 73691\n",
      "Sharpe: 0.365\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 230        |\n",
      "|    iterations           | 417        |\n",
      "|    time_elapsed         | 3705       |\n",
      "|    total_timesteps      | 854016     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02130866 |\n",
      "|    clip_fraction        | 0.229      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -90.1      |\n",
      "|    explained_variance   | -0.00614   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 602        |\n",
      "|    n_updates            | 4160       |\n",
      "|    policy_gradient_loss | -0.0142    |\n",
      "|    reward               | -5.6451445 |\n",
      "|    std                  | 2.61       |\n",
      "|    value_loss           | 1.38e+03   |\n",
      "----------------------------------------\n",
      "Episode: 441\n",
      "day: 1940, episode: 441\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12899215.61\n",
      "total_reward: 2899215.61\n",
      "total_cost: 184244.39\n",
      "total_trades: 73704\n",
      "Sharpe: 0.262\n",
      "=================================\n",
      "Episode: 442\n",
      "day: 1940, episode: 442\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10267551.70\n",
      "total_reward: 267551.70\n",
      "total_cost: 175479.30\n",
      "total_trades: 73701\n",
      "Sharpe: 0.161\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 230         |\n",
      "|    iterations           | 418         |\n",
      "|    time_elapsed         | 3713        |\n",
      "|    total_timesteps      | 856064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016586673 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.1       |\n",
      "|    explained_variance   | 0.000402    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.09e+03    |\n",
      "|    n_updates            | 4170        |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    reward               | -8.231484   |\n",
      "|    std                  | 2.62        |\n",
      "|    value_loss           | 2.03e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 443\n",
      "day: 1940, episode: 443\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12252724.19\n",
      "total_reward: 2252724.19\n",
      "total_cost: 181281.81\n",
      "total_trades: 73701\n",
      "Sharpe: 0.234\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 230         |\n",
      "|    iterations           | 419         |\n",
      "|    time_elapsed         | 3723        |\n",
      "|    total_timesteps      | 858112      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022942036 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.2       |\n",
      "|    explained_variance   | -0.0279     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 698         |\n",
      "|    n_updates            | 4180        |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    reward               | -0.18602675 |\n",
      "|    std                  | 2.62        |\n",
      "|    value_loss           | 1.35e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 444\n",
      "day: 1940, episode: 444\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10863696.83\n",
      "total_reward: 863696.83\n",
      "total_cost: 189249.17\n",
      "total_trades: 73700\n",
      "Sharpe: 0.192\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 230        |\n",
      "|    iterations           | 420        |\n",
      "|    time_elapsed         | 3731       |\n",
      "|    total_timesteps      | 860160     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03082407 |\n",
      "|    clip_fraction        | 0.318      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -90.3      |\n",
      "|    explained_variance   | 0.00217    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 708        |\n",
      "|    n_updates            | 4190       |\n",
      "|    policy_gradient_loss | -0.0103    |\n",
      "|    reward               | -3.5544302 |\n",
      "|    std                  | 2.63       |\n",
      "|    value_loss           | 1.85e+03   |\n",
      "----------------------------------------\n",
      "Episode: 445\n",
      "day: 1940, episode: 445\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9271376.43\n",
      "total_reward: -728623.57\n",
      "total_cost: 176690.57\n",
      "total_trades: 73700\n",
      "Sharpe: 0.108\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 230         |\n",
      "|    iterations           | 421         |\n",
      "|    time_elapsed         | 3739        |\n",
      "|    total_timesteps      | 862208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024629332 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.4       |\n",
      "|    explained_variance   | -0.00569    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 502         |\n",
      "|    n_updates            | 4200        |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    reward               | -4.939828   |\n",
      "|    std                  | 2.64        |\n",
      "|    value_loss           | 1.4e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 446\n",
      "day: 1940, episode: 446\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12555716.43\n",
      "total_reward: 2555716.43\n",
      "total_cost: 184825.57\n",
      "total_trades: 73702\n",
      "Sharpe: 0.252\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 230         |\n",
      "|    iterations           | 422         |\n",
      "|    time_elapsed         | 3747        |\n",
      "|    total_timesteps      | 864256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016526403 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.6       |\n",
      "|    explained_variance   | -0.00128    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 496         |\n",
      "|    n_updates            | 4210        |\n",
      "|    policy_gradient_loss | -0.0194     |\n",
      "|    reward               | -3.3872938  |\n",
      "|    std                  | 2.65        |\n",
      "|    value_loss           | 1.13e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 447\n",
      "day: 1940, episode: 447\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 17729198.90\n",
      "total_reward: 7729198.90\n",
      "total_cost: 184776.10\n",
      "total_trades: 73699\n",
      "Sharpe: 0.446\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 230         |\n",
      "|    iterations           | 423         |\n",
      "|    time_elapsed         | 3755        |\n",
      "|    total_timesteps      | 866304      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020987496 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.7       |\n",
      "|    explained_variance   | -0.00687    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.17e+03    |\n",
      "|    n_updates            | 4220        |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    reward               | 8.577759    |\n",
      "|    std                  | 2.65        |\n",
      "|    value_loss           | 2.21e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 448\n",
      "day: 1940, episode: 448\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10437886.21\n",
      "total_reward: 437886.21\n",
      "total_cost: 177622.79\n",
      "total_trades: 73691\n",
      "Sharpe: 0.181\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 230         |\n",
      "|    iterations           | 424         |\n",
      "|    time_elapsed         | 3763        |\n",
      "|    total_timesteps      | 868352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015608494 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.7       |\n",
      "|    explained_variance   | -0.0106     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.01e+03    |\n",
      "|    n_updates            | 4230        |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    reward               | -17.678894  |\n",
      "|    std                  | 2.66        |\n",
      "|    value_loss           | 2.65e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 449\n",
      "day: 1940, episode: 449\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13207484.71\n",
      "total_reward: 3207484.71\n",
      "total_cost: 175318.29\n",
      "total_trades: 73702\n",
      "Sharpe: 0.278\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 230         |\n",
      "|    iterations           | 425         |\n",
      "|    time_elapsed         | 3771        |\n",
      "|    total_timesteps      | 870400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027328555 |\n",
      "|    clip_fraction        | 0.267       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.8       |\n",
      "|    explained_variance   | -0.00926    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 897         |\n",
      "|    n_updates            | 4240        |\n",
      "|    policy_gradient_loss | -0.00832    |\n",
      "|    reward               | 16.90036    |\n",
      "|    std                  | 2.66        |\n",
      "|    value_loss           | 1.36e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 450\n",
      "day: 1940, episode: 450\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14558134.77\n",
      "total_reward: 4558134.77\n",
      "total_cost: 181707.23\n",
      "total_trades: 73699\n",
      "Sharpe: 0.333\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 230        |\n",
      "|    iterations           | 426        |\n",
      "|    time_elapsed         | 3780       |\n",
      "|    total_timesteps      | 872448     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01565381 |\n",
      "|    clip_fraction        | 0.158      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -90.8      |\n",
      "|    explained_variance   | -0.0189    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.07e+03   |\n",
      "|    n_updates            | 4250       |\n",
      "|    policy_gradient_loss | -0.0119    |\n",
      "|    reward               | 2.2100947  |\n",
      "|    std                  | 2.66       |\n",
      "|    value_loss           | 1.77e+03   |\n",
      "----------------------------------------\n",
      "Episode: 451\n",
      "day: 1940, episode: 451\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10729317.83\n",
      "total_reward: 729317.83\n",
      "total_cost: 183028.17\n",
      "total_trades: 73687\n",
      "Sharpe: 0.178\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 230         |\n",
      "|    iterations           | 427         |\n",
      "|    time_elapsed         | 3790        |\n",
      "|    total_timesteps      | 874496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013069081 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.9       |\n",
      "|    explained_variance   | 0.00509     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 942         |\n",
      "|    n_updates            | 4260        |\n",
      "|    policy_gradient_loss | -0.0194     |\n",
      "|    reward               | -6.05025    |\n",
      "|    std                  | 2.67        |\n",
      "|    value_loss           | 2.18e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 452\n",
      "day: 1940, episode: 452\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11617038.03\n",
      "total_reward: 1617038.03\n",
      "total_cost: 180525.97\n",
      "total_trades: 73699\n",
      "Sharpe: 0.227\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 230        |\n",
      "|    iterations           | 428        |\n",
      "|    time_elapsed         | 3799       |\n",
      "|    total_timesteps      | 876544     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03157873 |\n",
      "|    clip_fraction        | 0.295      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -91        |\n",
      "|    explained_variance   | -0.0166    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 477        |\n",
      "|    n_updates            | 4270       |\n",
      "|    policy_gradient_loss | -0.000548  |\n",
      "|    reward               | -2.811279  |\n",
      "|    std                  | 2.68       |\n",
      "|    value_loss           | 1.3e+03    |\n",
      "----------------------------------------\n",
      "Episode: 453\n",
      "day: 1940, episode: 453\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9641577.34\n",
      "total_reward: -358422.66\n",
      "total_cost: 177638.66\n",
      "total_trades: 73690\n",
      "Sharpe: 0.127\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 230         |\n",
      "|    iterations           | 429         |\n",
      "|    time_elapsed         | 3808        |\n",
      "|    total_timesteps      | 878592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030340562 |\n",
      "|    clip_fraction        | 0.289       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.1       |\n",
      "|    explained_variance   | -0.00909    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 443         |\n",
      "|    n_updates            | 4280        |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    reward               | 14.341619   |\n",
      "|    std                  | 2.68        |\n",
      "|    value_loss           | 1.75e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 454\n",
      "day: 1940, episode: 454\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11321823.61\n",
      "total_reward: 1321823.61\n",
      "total_cost: 176866.39\n",
      "total_trades: 73701\n",
      "Sharpe: 0.194\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 230         |\n",
      "|    iterations           | 430         |\n",
      "|    time_elapsed         | 3817        |\n",
      "|    total_timesteps      | 880640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028564112 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.1       |\n",
      "|    explained_variance   | -0.00214    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.1e+03     |\n",
      "|    n_updates            | 4290        |\n",
      "|    policy_gradient_loss | -0.00701    |\n",
      "|    reward               | -0.92371356 |\n",
      "|    std                  | 2.68        |\n",
      "|    value_loss           | 2.91e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 455\n",
      "day: 1940, episode: 455\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12839765.05\n",
      "total_reward: 2839765.05\n",
      "total_cost: 179114.95\n",
      "total_trades: 73699\n",
      "Sharpe: 0.275\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 230        |\n",
      "|    iterations           | 431        |\n",
      "|    time_elapsed         | 3826       |\n",
      "|    total_timesteps      | 882688     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02330346 |\n",
      "|    clip_fraction        | 0.215      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -91.2      |\n",
      "|    explained_variance   | -0.011     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.44e+03   |\n",
      "|    n_updates            | 4300       |\n",
      "|    policy_gradient_loss | -0.0145    |\n",
      "|    reward               | -4.3741508 |\n",
      "|    std                  | 2.69       |\n",
      "|    value_loss           | 2.46e+03   |\n",
      "----------------------------------------\n",
      "Episode: 456\n",
      "day: 1940, episode: 456\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10990664.99\n",
      "total_reward: 990664.99\n",
      "total_cost: 180349.01\n",
      "total_trades: 73695\n",
      "Sharpe: 0.193\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 230         |\n",
      "|    iterations           | 432         |\n",
      "|    time_elapsed         | 3836        |\n",
      "|    total_timesteps      | 884736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018194236 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.3       |\n",
      "|    explained_variance   | 0.00025     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 700         |\n",
      "|    n_updates            | 4310        |\n",
      "|    policy_gradient_loss | -0.0176     |\n",
      "|    reward               | 34.1632     |\n",
      "|    std                  | 2.7         |\n",
      "|    value_loss           | 2.15e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 457\n",
      "day: 1940, episode: 457\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13329860.20\n",
      "total_reward: 3329860.20\n",
      "total_cost: 171773.80\n",
      "total_trades: 73700\n",
      "Sharpe: 0.294\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 230        |\n",
      "|    iterations           | 433        |\n",
      "|    time_elapsed         | 3844       |\n",
      "|    total_timesteps      | 886784     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01224931 |\n",
      "|    clip_fraction        | 0.135      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -91.3      |\n",
      "|    explained_variance   | 0.00781    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 654        |\n",
      "|    n_updates            | 4320       |\n",
      "|    policy_gradient_loss | -0.02      |\n",
      "|    reward               | -17.58066  |\n",
      "|    std                  | 2.7        |\n",
      "|    value_loss           | 2.19e+03   |\n",
      "----------------------------------------\n",
      "Episode: 458\n",
      "day: 1940, episode: 458\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14835884.29\n",
      "total_reward: 4835884.29\n",
      "total_cost: 177383.71\n",
      "total_trades: 73706\n",
      "Sharpe: 0.334\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 230         |\n",
      "|    iterations           | 434         |\n",
      "|    time_elapsed         | 3852        |\n",
      "|    total_timesteps      | 888832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020173203 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.4       |\n",
      "|    explained_variance   | -0.0286     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.82e+03    |\n",
      "|    n_updates            | 4330        |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    reward               | -5.3774166  |\n",
      "|    std                  | 2.7         |\n",
      "|    value_loss           | 2.93e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 459\n",
      "day: 1940, episode: 459\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11729891.11\n",
      "total_reward: 1729891.11\n",
      "total_cost: 181446.89\n",
      "total_trades: 73707\n",
      "Sharpe: 0.216\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 230        |\n",
      "|    iterations           | 435        |\n",
      "|    time_elapsed         | 3860       |\n",
      "|    total_timesteps      | 890880     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02206985 |\n",
      "|    clip_fraction        | 0.191      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -91.5      |\n",
      "|    explained_variance   | -0.0196    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.29e+03   |\n",
      "|    n_updates            | 4340       |\n",
      "|    policy_gradient_loss | -0.0221    |\n",
      "|    reward               | -0.6914269 |\n",
      "|    std                  | 2.71       |\n",
      "|    value_loss           | 2.77e+03   |\n",
      "----------------------------------------\n",
      "Episode: 460\n",
      "day: 1940, episode: 460\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12635013.06\n",
      "total_reward: 2635013.06\n",
      "total_cost: 175184.94\n",
      "total_trades: 73686\n",
      "Sharpe: 0.253\n",
      "=================================\n",
      "Episode: 461\n",
      "day: 1940, episode: 461\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10056134.20\n",
      "total_reward: 56134.20\n",
      "total_cost: 174008.80\n",
      "total_trades: 73695\n",
      "Sharpe: 0.168\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 230         |\n",
      "|    iterations           | 436         |\n",
      "|    time_elapsed         | 3868        |\n",
      "|    total_timesteps      | 892928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017397515 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.5       |\n",
      "|    explained_variance   | -0.00383    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 918         |\n",
      "|    n_updates            | 4350        |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    reward               | -0.46938992 |\n",
      "|    std                  | 2.71        |\n",
      "|    value_loss           | 2.77e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 462\n",
      "day: 1940, episode: 462\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9355685.63\n",
      "total_reward: -644314.37\n",
      "total_cost: 185051.37\n",
      "total_trades: 73708\n",
      "Sharpe: 0.139\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 230         |\n",
      "|    iterations           | 437         |\n",
      "|    time_elapsed         | 3877        |\n",
      "|    total_timesteps      | 894976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028622687 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.6       |\n",
      "|    explained_variance   | 0.0136      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.34e+03    |\n",
      "|    n_updates            | 4360        |\n",
      "|    policy_gradient_loss | -0.0189     |\n",
      "|    reward               | -4.509679   |\n",
      "|    std                  | 2.72        |\n",
      "|    value_loss           | 1.53e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 463\n",
      "day: 1940, episode: 463\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12807746.95\n",
      "total_reward: 2807746.95\n",
      "total_cost: 175391.05\n",
      "total_trades: 73696\n",
      "Sharpe: 0.259\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 230         |\n",
      "|    iterations           | 438         |\n",
      "|    time_elapsed         | 3884        |\n",
      "|    total_timesteps      | 897024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033085767 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.8       |\n",
      "|    explained_variance   | 0.00438     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 838         |\n",
      "|    n_updates            | 4370        |\n",
      "|    policy_gradient_loss | -0.00943    |\n",
      "|    reward               | -7.6797767  |\n",
      "|    std                  | 2.73        |\n",
      "|    value_loss           | 1.38e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 464\n",
      "day: 1940, episode: 464\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10031724.32\n",
      "total_reward: 31724.32\n",
      "total_cost: 172248.68\n",
      "total_trades: 73696\n",
      "Sharpe: 0.179\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 230         |\n",
      "|    iterations           | 439         |\n",
      "|    time_elapsed         | 3893        |\n",
      "|    total_timesteps      | 899072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028127026 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.9       |\n",
      "|    explained_variance   | 0.0226      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 997         |\n",
      "|    n_updates            | 4380        |\n",
      "|    policy_gradient_loss | -0.00901    |\n",
      "|    reward               | -8.988278   |\n",
      "|    std                  | 2.74        |\n",
      "|    value_loss           | 2.52e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 465\n",
      "day: 1940, episode: 465\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13108559.94\n",
      "total_reward: 3108559.94\n",
      "total_cost: 176378.06\n",
      "total_trades: 73701\n",
      "Sharpe: 0.272\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 230         |\n",
      "|    iterations           | 440         |\n",
      "|    time_elapsed         | 3901        |\n",
      "|    total_timesteps      | 901120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029468305 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92         |\n",
      "|    explained_variance   | -0.00691    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 633         |\n",
      "|    n_updates            | 4390        |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | 4.11565     |\n",
      "|    std                  | 2.75        |\n",
      "|    value_loss           | 1.43e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 466\n",
      "day: 1940, episode: 466\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10790173.30\n",
      "total_reward: 790173.30\n",
      "total_cost: 164166.70\n",
      "total_trades: 73696\n",
      "Sharpe: 0.187\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 230         |\n",
      "|    iterations           | 441         |\n",
      "|    time_elapsed         | 3910        |\n",
      "|    total_timesteps      | 903168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038620505 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.1       |\n",
      "|    explained_variance   | 0.00724     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.2e+03     |\n",
      "|    n_updates            | 4400        |\n",
      "|    policy_gradient_loss | -0.00383    |\n",
      "|    reward               | -10.518545  |\n",
      "|    std                  | 2.76        |\n",
      "|    value_loss           | 1.99e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 467\n",
      "day: 1940, episode: 467\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11874992.60\n",
      "total_reward: 1874992.60\n",
      "total_cost: 183789.40\n",
      "total_trades: 73712\n",
      "Sharpe: 0.224\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 230         |\n",
      "|    iterations           | 442         |\n",
      "|    time_elapsed         | 3918        |\n",
      "|    total_timesteps      | 905216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027939478 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.2       |\n",
      "|    explained_variance   | 0.0286      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 683         |\n",
      "|    n_updates            | 4410        |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    reward               | -0.99159163 |\n",
      "|    std                  | 2.76        |\n",
      "|    value_loss           | 1.43e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 468\n",
      "day: 1940, episode: 468\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14548198.40\n",
      "total_reward: 4548198.40\n",
      "total_cost: 191477.60\n",
      "total_trades: 73697\n",
      "Sharpe: 0.326\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 231         |\n",
      "|    iterations           | 443         |\n",
      "|    time_elapsed         | 3926        |\n",
      "|    total_timesteps      | 907264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031973686 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.3       |\n",
      "|    explained_variance   | -0.00552    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 693         |\n",
      "|    n_updates            | 4420        |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    reward               | -10.933424  |\n",
      "|    std                  | 2.77        |\n",
      "|    value_loss           | 2.05e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 469\n",
      "day: 1940, episode: 469\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10208218.35\n",
      "total_reward: 208218.35\n",
      "total_cost: 189915.65\n",
      "total_trades: 73703\n",
      "Sharpe: 0.177\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 231         |\n",
      "|    iterations           | 444         |\n",
      "|    time_elapsed         | 3934        |\n",
      "|    total_timesteps      | 909312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019903485 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.3       |\n",
      "|    explained_variance   | -0.0535     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.16e+03    |\n",
      "|    n_updates            | 4430        |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    reward               | 18.393097   |\n",
      "|    std                  | 2.77        |\n",
      "|    value_loss           | 1.92e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 470\n",
      "day: 1940, episode: 470\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12269925.07\n",
      "total_reward: 2269925.07\n",
      "total_cost: 176105.93\n",
      "total_trades: 73705\n",
      "Sharpe: 0.252\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 231         |\n",
      "|    iterations           | 445         |\n",
      "|    time_elapsed         | 3943        |\n",
      "|    total_timesteps      | 911360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025456121 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.4       |\n",
      "|    explained_variance   | -0.00974    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 642         |\n",
      "|    n_updates            | 4440        |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    reward               | 1.754639    |\n",
      "|    std                  | 2.78        |\n",
      "|    value_loss           | 1.34e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 471\n",
      "day: 1940, episode: 471\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 16012264.46\n",
      "total_reward: 6012264.46\n",
      "total_cost: 191564.54\n",
      "total_trades: 73704\n",
      "Sharpe: 0.370\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 231        |\n",
      "|    iterations           | 446        |\n",
      "|    time_elapsed         | 3951       |\n",
      "|    total_timesteps      | 913408     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02169645 |\n",
      "|    clip_fraction        | 0.225      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -92.5      |\n",
      "|    explained_variance   | -0.000262  |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 571        |\n",
      "|    n_updates            | 4450       |\n",
      "|    policy_gradient_loss | -0.0155    |\n",
      "|    reward               | -3.9856086 |\n",
      "|    std                  | 2.79       |\n",
      "|    value_loss           | 2.02e+03   |\n",
      "----------------------------------------\n",
      "Episode: 472\n",
      "day: 1940, episode: 472\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14716124.07\n",
      "total_reward: 4716124.07\n",
      "total_cost: 177853.93\n",
      "total_trades: 73695\n",
      "Sharpe: 0.328\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 231         |\n",
      "|    iterations           | 447         |\n",
      "|    time_elapsed         | 3959        |\n",
      "|    total_timesteps      | 915456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017981367 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.6       |\n",
      "|    explained_variance   | -0.00174    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.22e+03    |\n",
      "|    n_updates            | 4460        |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    reward               | 0.16377923  |\n",
      "|    std                  | 2.79        |\n",
      "|    value_loss           | 2.01e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 473\n",
      "day: 1940, episode: 473\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12572317.92\n",
      "total_reward: 2572317.92\n",
      "total_cost: 177429.08\n",
      "total_trades: 73698\n",
      "Sharpe: 0.270\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 231        |\n",
      "|    iterations           | 448        |\n",
      "|    time_elapsed         | 3968       |\n",
      "|    total_timesteps      | 917504     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02248244 |\n",
      "|    clip_fraction        | 0.229      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -92.7      |\n",
      "|    explained_variance   | 0.034      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 758        |\n",
      "|    n_updates            | 4470       |\n",
      "|    policy_gradient_loss | -0.0229    |\n",
      "|    reward               | -9.783725  |\n",
      "|    std                  | 2.8        |\n",
      "|    value_loss           | 1.66e+03   |\n",
      "----------------------------------------\n",
      "Episode: 474\n",
      "day: 1940, episode: 474\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14661818.48\n",
      "total_reward: 4661818.48\n",
      "total_cost: 180079.52\n",
      "total_trades: 73700\n",
      "Sharpe: 0.334\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 231         |\n",
      "|    iterations           | 449         |\n",
      "|    time_elapsed         | 3976        |\n",
      "|    total_timesteps      | 919552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024493165 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.7       |\n",
      "|    explained_variance   | 0.018       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 727         |\n",
      "|    n_updates            | 4480        |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    reward               | 5.6569314   |\n",
      "|    std                  | 2.8         |\n",
      "|    value_loss           | 1.52e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 475\n",
      "day: 1940, episode: 475\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 16353082.03\n",
      "total_reward: 6353082.03\n",
      "total_cost: 182131.97\n",
      "total_trades: 73701\n",
      "Sharpe: 0.376\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 231         |\n",
      "|    iterations           | 450         |\n",
      "|    time_elapsed         | 3985        |\n",
      "|    total_timesteps      | 921600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033619408 |\n",
      "|    clip_fraction        | 0.287       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.8       |\n",
      "|    explained_variance   | 0.00689     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 738         |\n",
      "|    n_updates            | 4490        |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    reward               | 6.7238507   |\n",
      "|    std                  | 2.81        |\n",
      "|    value_loss           | 2.02e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 476\n",
      "day: 1940, episode: 476\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13762249.12\n",
      "total_reward: 3762249.12\n",
      "total_cost: 187659.88\n",
      "total_trades: 73701\n",
      "Sharpe: 0.298\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 231         |\n",
      "|    iterations           | 451         |\n",
      "|    time_elapsed         | 3993        |\n",
      "|    total_timesteps      | 923648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024743298 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.9       |\n",
      "|    explained_variance   | 0.0365      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 800         |\n",
      "|    n_updates            | 4500        |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    reward               | -4.7747855  |\n",
      "|    std                  | 2.82        |\n",
      "|    value_loss           | 1.69e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 477\n",
      "day: 1940, episode: 477\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14413536.44\n",
      "total_reward: 4413536.44\n",
      "total_cost: 188106.56\n",
      "total_trades: 73696\n",
      "Sharpe: 0.322\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 231        |\n",
      "|    iterations           | 452        |\n",
      "|    time_elapsed         | 4001       |\n",
      "|    total_timesteps      | 925696     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03877624 |\n",
      "|    clip_fraction        | 0.265      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -93.1      |\n",
      "|    explained_variance   | 0.00329    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 998        |\n",
      "|    n_updates            | 4510       |\n",
      "|    policy_gradient_loss | 0.00402    |\n",
      "|    reward               | 40.810715  |\n",
      "|    std                  | 2.83       |\n",
      "|    value_loss           | 1.86e+03   |\n",
      "----------------------------------------\n",
      "Episode: 478\n",
      "day: 1940, episode: 478\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 15709905.00\n",
      "total_reward: 5709905.00\n",
      "total_cost: 197766.00\n",
      "total_trades: 73702\n",
      "Sharpe: 0.360\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 231         |\n",
      "|    iterations           | 453         |\n",
      "|    time_elapsed         | 4009        |\n",
      "|    total_timesteps      | 927744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016741224 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.2       |\n",
      "|    explained_variance   | -0.024      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.3e+03     |\n",
      "|    n_updates            | 4520        |\n",
      "|    policy_gradient_loss | -0.0203     |\n",
      "|    reward               | -0.6678173  |\n",
      "|    std                  | 2.83        |\n",
      "|    value_loss           | 2.22e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 479\n",
      "day: 1940, episode: 479\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12279309.31\n",
      "total_reward: 2279309.31\n",
      "total_cost: 193890.69\n",
      "total_trades: 73701\n",
      "Sharpe: 0.257\n",
      "=================================\n",
      "Episode: 480\n",
      "day: 1940, episode: 480\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9372015.55\n",
      "total_reward: -627984.45\n",
      "total_cost: 200369.45\n",
      "total_trades: 73698\n",
      "Sharpe: 0.120\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 231         |\n",
      "|    iterations           | 454         |\n",
      "|    time_elapsed         | 4017        |\n",
      "|    total_timesteps      | 929792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025211435 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.3       |\n",
      "|    explained_variance   | -0.016      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 645         |\n",
      "|    n_updates            | 4530        |\n",
      "|    policy_gradient_loss | -0.0197     |\n",
      "|    reward               | -6.722288   |\n",
      "|    std                  | 2.84        |\n",
      "|    value_loss           | 1.45e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 481\n",
      "day: 1940, episode: 481\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14514145.14\n",
      "total_reward: 4514145.14\n",
      "total_cost: 200870.86\n",
      "total_trades: 73696\n",
      "Sharpe: 0.336\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 231        |\n",
      "|    iterations           | 455        |\n",
      "|    time_elapsed         | 4027       |\n",
      "|    total_timesteps      | 931840     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02328784 |\n",
      "|    clip_fraction        | 0.227      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -93.4      |\n",
      "|    explained_variance   | -0.0121    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 511        |\n",
      "|    n_updates            | 4540       |\n",
      "|    policy_gradient_loss | -0.017     |\n",
      "|    reward               | 2.0036016  |\n",
      "|    std                  | 2.85       |\n",
      "|    value_loss           | 992        |\n",
      "----------------------------------------\n",
      "Episode: 482\n",
      "day: 1940, episode: 482\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10651805.20\n",
      "total_reward: 651805.20\n",
      "total_cost: 194657.80\n",
      "total_trades: 73701\n",
      "Sharpe: 0.188\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 231         |\n",
      "|    iterations           | 456         |\n",
      "|    time_elapsed         | 4035        |\n",
      "|    total_timesteps      | 933888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038183697 |\n",
      "|    clip_fraction        | 0.349       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.4       |\n",
      "|    explained_variance   | 0.00377     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 803         |\n",
      "|    n_updates            | 4550        |\n",
      "|    policy_gradient_loss | -8.18e-05   |\n",
      "|    reward               | 9.531617    |\n",
      "|    std                  | 2.85        |\n",
      "|    value_loss           | 1.42e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 483\n",
      "day: 1940, episode: 483\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11705413.34\n",
      "total_reward: 1705413.34\n",
      "total_cost: 197947.66\n",
      "total_trades: 73702\n",
      "Sharpe: 0.219\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 231         |\n",
      "|    iterations           | 457         |\n",
      "|    time_elapsed         | 4043        |\n",
      "|    total_timesteps      | 935936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022191238 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.5       |\n",
      "|    explained_variance   | -0.0258     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 581         |\n",
      "|    n_updates            | 4560        |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    reward               | 0.6675914   |\n",
      "|    std                  | 2.86        |\n",
      "|    value_loss           | 1.19e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 484\n",
      "day: 1940, episode: 484\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12970295.02\n",
      "total_reward: 2970295.02\n",
      "total_cost: 205015.98\n",
      "total_trades: 73700\n",
      "Sharpe: 0.265\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 231         |\n",
      "|    iterations           | 458         |\n",
      "|    time_elapsed         | 4051        |\n",
      "|    total_timesteps      | 937984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026539702 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.6       |\n",
      "|    explained_variance   | -0.0079     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.17e+03    |\n",
      "|    n_updates            | 4570        |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    reward               | 5.1712484   |\n",
      "|    std                  | 2.87        |\n",
      "|    value_loss           | 1.56e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 485\n",
      "day: 1940, episode: 485\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10642751.60\n",
      "total_reward: 642751.60\n",
      "total_cost: 190716.40\n",
      "total_trades: 73701\n",
      "Sharpe: 0.157\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 231         |\n",
      "|    iterations           | 459         |\n",
      "|    time_elapsed         | 4059        |\n",
      "|    total_timesteps      | 940032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019247899 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.7       |\n",
      "|    explained_variance   | -0.0019     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.42e+03    |\n",
      "|    n_updates            | 4580        |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    reward               | -14.250341  |\n",
      "|    std                  | 2.88        |\n",
      "|    value_loss           | 2.49e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 486\n",
      "day: 1940, episode: 486\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13800053.32\n",
      "total_reward: 3800053.32\n",
      "total_cost: 202853.68\n",
      "total_trades: 73704\n",
      "Sharpe: 0.299\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 231        |\n",
      "|    iterations           | 460        |\n",
      "|    time_elapsed         | 4067       |\n",
      "|    total_timesteps      | 942080     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02154534 |\n",
      "|    clip_fraction        | 0.232      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -93.8      |\n",
      "|    explained_variance   | -0.0182    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.07e+03   |\n",
      "|    n_updates            | 4590       |\n",
      "|    policy_gradient_loss | -0.00972   |\n",
      "|    reward               | 10.106089  |\n",
      "|    std                  | 2.89       |\n",
      "|    value_loss           | 1.98e+03   |\n",
      "----------------------------------------\n",
      "Episode: 487\n",
      "day: 1940, episode: 487\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10253071.49\n",
      "total_reward: 253071.49\n",
      "total_cost: 185629.51\n",
      "total_trades: 73703\n",
      "Sharpe: 0.186\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 231         |\n",
      "|    iterations           | 461         |\n",
      "|    time_elapsed         | 4076        |\n",
      "|    total_timesteps      | 944128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022846062 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.9       |\n",
      "|    explained_variance   | 0.0254      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 578         |\n",
      "|    n_updates            | 4600        |\n",
      "|    policy_gradient_loss | -0.00654    |\n",
      "|    reward               | 1.2562288   |\n",
      "|    std                  | 2.89        |\n",
      "|    value_loss           | 2.37e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 488\n",
      "day: 1940, episode: 488\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8252144.27\n",
      "total_reward: -1747855.73\n",
      "total_cost: 184462.73\n",
      "total_trades: 73692\n",
      "Sharpe: 0.085\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 231        |\n",
      "|    iterations           | 462        |\n",
      "|    time_elapsed         | 4085       |\n",
      "|    total_timesteps      | 946176     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02853471 |\n",
      "|    clip_fraction        | 0.241      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -94        |\n",
      "|    explained_variance   | 0.0199     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 660        |\n",
      "|    n_updates            | 4610       |\n",
      "|    policy_gradient_loss | -0.0104    |\n",
      "|    reward               | -4.709718  |\n",
      "|    std                  | 2.9        |\n",
      "|    value_loss           | 1.27e+03   |\n",
      "----------------------------------------\n",
      "Episode: 489\n",
      "day: 1940, episode: 489\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10033125.59\n",
      "total_reward: 33125.59\n",
      "total_cost: 195466.41\n",
      "total_trades: 73698\n",
      "Sharpe: 0.165\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 231         |\n",
      "|    iterations           | 463         |\n",
      "|    time_elapsed         | 4093        |\n",
      "|    total_timesteps      | 948224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016990848 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.1       |\n",
      "|    explained_variance   | -0.0316     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.04e+03    |\n",
      "|    n_updates            | 4620        |\n",
      "|    policy_gradient_loss | -0.0198     |\n",
      "|    reward               | 5.81333     |\n",
      "|    std                  | 2.9         |\n",
      "|    value_loss           | 1.57e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 490\n",
      "day: 1940, episode: 490\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10093214.64\n",
      "total_reward: 93214.64\n",
      "total_cost: 182657.36\n",
      "total_trades: 73701\n",
      "Sharpe: 0.160\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 231        |\n",
      "|    iterations           | 464        |\n",
      "|    time_elapsed         | 4101       |\n",
      "|    total_timesteps      | 950272     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02356555 |\n",
      "|    clip_fraction        | 0.215      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -94.1      |\n",
      "|    explained_variance   | -0.0126    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 760        |\n",
      "|    n_updates            | 4630       |\n",
      "|    policy_gradient_loss | -0.0179    |\n",
      "|    reward               | 0.37355238 |\n",
      "|    std                  | 2.91       |\n",
      "|    value_loss           | 1.27e+03   |\n",
      "----------------------------------------\n",
      "Episode: 491\n",
      "day: 1940, episode: 491\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12475412.20\n",
      "total_reward: 2475412.20\n",
      "total_cost: 199988.80\n",
      "total_trades: 73705\n",
      "Sharpe: 0.260\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 231         |\n",
      "|    iterations           | 465         |\n",
      "|    time_elapsed         | 4110        |\n",
      "|    total_timesteps      | 952320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016859662 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.2       |\n",
      "|    explained_variance   | -0.0253     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 379         |\n",
      "|    n_updates            | 4640        |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    reward               | -1.181571   |\n",
      "|    std                  | 2.91        |\n",
      "|    value_loss           | 1.45e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 492\n",
      "day: 1940, episode: 492\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10226220.42\n",
      "total_reward: 226220.42\n",
      "total_cost: 189329.58\n",
      "total_trades: 73700\n",
      "Sharpe: 0.166\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 231        |\n",
      "|    iterations           | 466        |\n",
      "|    time_elapsed         | 4118       |\n",
      "|    total_timesteps      | 954368     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02924329 |\n",
      "|    clip_fraction        | 0.319      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -94.3      |\n",
      "|    explained_variance   | -0.00702   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 464        |\n",
      "|    n_updates            | 4650       |\n",
      "|    policy_gradient_loss | -0.00879   |\n",
      "|    reward               | 0.33223632 |\n",
      "|    std                  | 2.93       |\n",
      "|    value_loss           | 1.23e+03   |\n",
      "----------------------------------------\n",
      "Episode: 493\n",
      "day: 1940, episode: 493\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9387928.31\n",
      "total_reward: -612071.69\n",
      "total_cost: 190719.69\n",
      "total_trades: 73705\n",
      "Sharpe: 0.145\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 231        |\n",
      "|    iterations           | 467        |\n",
      "|    time_elapsed         | 4126       |\n",
      "|    total_timesteps      | 956416     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05096044 |\n",
      "|    clip_fraction        | 0.287      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -94.5      |\n",
      "|    explained_variance   | -0.00134   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.34e+03   |\n",
      "|    n_updates            | 4660       |\n",
      "|    policy_gradient_loss | -0.00309   |\n",
      "|    reward               | 11.711254  |\n",
      "|    std                  | 2.94       |\n",
      "|    value_loss           | 1.31e+03   |\n",
      "----------------------------------------\n",
      "Episode: 494\n",
      "day: 1940, episode: 494\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14366698.29\n",
      "total_reward: 4366698.29\n",
      "total_cost: 178390.71\n",
      "total_trades: 73699\n",
      "Sharpe: 0.316\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 231        |\n",
      "|    iterations           | 468        |\n",
      "|    time_elapsed         | 4134       |\n",
      "|    total_timesteps      | 958464     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03400793 |\n",
      "|    clip_fraction        | 0.251      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -94.6      |\n",
      "|    explained_variance   | -0.0299    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 743        |\n",
      "|    n_updates            | 4670       |\n",
      "|    policy_gradient_loss | -0.00517   |\n",
      "|    reward               | -6.0741587 |\n",
      "|    std                  | 2.95       |\n",
      "|    value_loss           | 1.83e+03   |\n",
      "----------------------------------------\n",
      "Episode: 495\n",
      "day: 1940, episode: 495\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9574938.82\n",
      "total_reward: -425061.18\n",
      "total_cost: 189261.18\n",
      "total_trades: 73697\n",
      "Sharpe: 0.148\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 231         |\n",
      "|    iterations           | 469         |\n",
      "|    time_elapsed         | 4143        |\n",
      "|    total_timesteps      | 960512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022737455 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.7       |\n",
      "|    explained_variance   | 0.00562     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 746         |\n",
      "|    n_updates            | 4680        |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    reward               | -7.2388477  |\n",
      "|    std                  | 2.95        |\n",
      "|    value_loss           | 1.87e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 496\n",
      "day: 1940, episode: 496\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8236243.42\n",
      "total_reward: -1763756.58\n",
      "total_cost: 184740.58\n",
      "total_trades: 73695\n",
      "Sharpe: 0.070\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 231         |\n",
      "|    iterations           | 470         |\n",
      "|    time_elapsed         | 4151        |\n",
      "|    total_timesteps      | 962560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019177973 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.8       |\n",
      "|    explained_variance   | 0.00263     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 823         |\n",
      "|    n_updates            | 4690        |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    reward               | 8.800387    |\n",
      "|    std                  | 2.96        |\n",
      "|    value_loss           | 1.55e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 497\n",
      "day: 1940, episode: 497\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 6240686.47\n",
      "total_reward: -3759313.53\n",
      "total_cost: 180887.53\n",
      "total_trades: 73687\n",
      "Sharpe: -0.032\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 231         |\n",
      "|    iterations           | 471         |\n",
      "|    time_elapsed         | 4159        |\n",
      "|    total_timesteps      | 964608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021446593 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.9       |\n",
      "|    explained_variance   | 0.0296      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 747         |\n",
      "|    n_updates            | 4700        |\n",
      "|    policy_gradient_loss | -0.0185     |\n",
      "|    reward               | 0.27163306  |\n",
      "|    std                  | 2.97        |\n",
      "|    value_loss           | 1.46e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 498\n",
      "day: 1940, episode: 498\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 6781547.98\n",
      "total_reward: -3218452.02\n",
      "total_cost: 178373.02\n",
      "total_trades: 73697\n",
      "Sharpe: -0.005\n",
      "=================================\n",
      "Episode: 499\n",
      "day: 1940, episode: 499\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7658529.56\n",
      "total_reward: -2341470.44\n",
      "total_cost: 182940.44\n",
      "total_trades: 73700\n",
      "Sharpe: 0.040\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 231         |\n",
      "|    iterations           | 472         |\n",
      "|    time_elapsed         | 4167        |\n",
      "|    total_timesteps      | 966656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025238283 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95         |\n",
      "|    explained_variance   | -0.0601     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 560         |\n",
      "|    n_updates            | 4710        |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    reward               | 6.90892     |\n",
      "|    std                  | 2.98        |\n",
      "|    value_loss           | 1.03e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 500\n",
      "day: 1940, episode: 500\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11709254.04\n",
      "total_reward: 1709254.04\n",
      "total_cost: 187315.96\n",
      "total_trades: 73702\n",
      "Sharpe: 0.214\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 231         |\n",
      "|    iterations           | 473         |\n",
      "|    time_elapsed         | 4176        |\n",
      "|    total_timesteps      | 968704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022902448 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.1       |\n",
      "|    explained_variance   | 0.0222      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 637         |\n",
      "|    n_updates            | 4720        |\n",
      "|    policy_gradient_loss | -0.0207     |\n",
      "|    reward               | -5.26765    |\n",
      "|    std                  | 2.99        |\n",
      "|    value_loss           | 1.41e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 501\n",
      "day: 1940, episode: 501\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11825532.96\n",
      "total_reward: 1825532.96\n",
      "total_cost: 182524.04\n",
      "total_trades: 73693\n",
      "Sharpe: 0.221\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 232        |\n",
      "|    iterations           | 474        |\n",
      "|    time_elapsed         | 4184       |\n",
      "|    total_timesteps      | 970752     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01915009 |\n",
      "|    clip_fraction        | 0.169      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -95.3      |\n",
      "|    explained_variance   | 0.00432    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.19e+03   |\n",
      "|    n_updates            | 4730       |\n",
      "|    policy_gradient_loss | -0.0138    |\n",
      "|    reward               | 6.6426234  |\n",
      "|    std                  | 3          |\n",
      "|    value_loss           | 2.63e+03   |\n",
      "----------------------------------------\n",
      "Episode: 502\n",
      "day: 1940, episode: 502\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7653193.33\n",
      "total_reward: -2346806.67\n",
      "total_cost: 177759.67\n",
      "total_trades: 73700\n",
      "Sharpe: 0.077\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 232         |\n",
      "|    iterations           | 475         |\n",
      "|    time_elapsed         | 4192        |\n",
      "|    total_timesteps      | 972800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022289533 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.3       |\n",
      "|    explained_variance   | -0.0277     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.1e+03     |\n",
      "|    n_updates            | 4740        |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    reward               | 9.874486    |\n",
      "|    std                  | 3           |\n",
      "|    value_loss           | 2.42e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 503\n",
      "day: 1940, episode: 503\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11541315.68\n",
      "total_reward: 1541315.68\n",
      "total_cost: 178028.32\n",
      "total_trades: 73700\n",
      "Sharpe: 0.205\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 232         |\n",
      "|    iterations           | 476         |\n",
      "|    time_elapsed         | 4201        |\n",
      "|    total_timesteps      | 974848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024098102 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.4       |\n",
      "|    explained_variance   | -0.00689    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.19e+03    |\n",
      "|    n_updates            | 4750        |\n",
      "|    policy_gradient_loss | -0.00858    |\n",
      "|    reward               | -23.66848   |\n",
      "|    std                  | 3.01        |\n",
      "|    value_loss           | 1.83e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 504\n",
      "day: 1940, episode: 504\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10713523.63\n",
      "total_reward: 713523.63\n",
      "total_cost: 184514.37\n",
      "total_trades: 73702\n",
      "Sharpe: 0.177\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 231         |\n",
      "|    iterations           | 477         |\n",
      "|    time_elapsed         | 4211        |\n",
      "|    total_timesteps      | 976896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017390095 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.5       |\n",
      "|    explained_variance   | 0.00101     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.08e+03    |\n",
      "|    n_updates            | 4760        |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    reward               | 7.550045    |\n",
      "|    std                  | 3.01        |\n",
      "|    value_loss           | 2.36e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 505\n",
      "day: 1940, episode: 505\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7151371.48\n",
      "total_reward: -2848628.52\n",
      "total_cost: 169891.52\n",
      "total_trades: 73700\n",
      "Sharpe: 0.048\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 231         |\n",
      "|    iterations           | 478         |\n",
      "|    time_elapsed         | 4220        |\n",
      "|    total_timesteps      | 978944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038157687 |\n",
      "|    clip_fraction        | 0.337       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.6       |\n",
      "|    explained_variance   | -0.000518   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.11e+03    |\n",
      "|    n_updates            | 4770        |\n",
      "|    policy_gradient_loss | -0.00451    |\n",
      "|    reward               | 8.82163     |\n",
      "|    std                  | 3.03        |\n",
      "|    value_loss           | 2.56e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 506\n",
      "day: 1940, episode: 506\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8703088.11\n",
      "total_reward: -1296911.89\n",
      "total_cost: 183856.89\n",
      "total_trades: 73701\n",
      "Sharpe: 0.085\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 231         |\n",
      "|    iterations           | 479         |\n",
      "|    time_elapsed         | 4229        |\n",
      "|    total_timesteps      | 980992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026405722 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.7       |\n",
      "|    explained_variance   | -0.00964    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 863         |\n",
      "|    n_updates            | 4780        |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    reward               | -20.96048   |\n",
      "|    std                  | 3.03        |\n",
      "|    value_loss           | 1.75e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 507\n",
      "day: 1940, episode: 507\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11527748.20\n",
      "total_reward: 1527748.20\n",
      "total_cost: 184523.80\n",
      "total_trades: 73701\n",
      "Sharpe: 0.206\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 231        |\n",
      "|    iterations           | 480        |\n",
      "|    time_elapsed         | 4239       |\n",
      "|    total_timesteps      | 983040     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01893761 |\n",
      "|    clip_fraction        | 0.176      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -95.7      |\n",
      "|    explained_variance   | 0.00992    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.51e+03   |\n",
      "|    n_updates            | 4790       |\n",
      "|    policy_gradient_loss | -0.0247    |\n",
      "|    reward               | 45.0045    |\n",
      "|    std                  | 3.03       |\n",
      "|    value_loss           | 2.53e+03   |\n",
      "----------------------------------------\n",
      "Episode: 508\n",
      "day: 1940, episode: 508\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11856851.97\n",
      "total_reward: 1856851.97\n",
      "total_cost: 169692.03\n",
      "total_trades: 73707\n",
      "Sharpe: 0.220\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 231         |\n",
      "|    iterations           | 481         |\n",
      "|    time_elapsed         | 4247        |\n",
      "|    total_timesteps      | 985088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013592179 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.8       |\n",
      "|    explained_variance   | -0.0104     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.25e+03    |\n",
      "|    n_updates            | 4800        |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    reward               | -12.498149  |\n",
      "|    std                  | 3.04        |\n",
      "|    value_loss           | 3.44e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 509\n",
      "day: 1940, episode: 509\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10060130.81\n",
      "total_reward: 60130.81\n",
      "total_cost: 189273.19\n",
      "total_trades: 73692\n",
      "Sharpe: 0.168\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 231         |\n",
      "|    iterations           | 482         |\n",
      "|    time_elapsed         | 4256        |\n",
      "|    total_timesteps      | 987136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026395831 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96         |\n",
      "|    explained_variance   | -0.0132     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 925         |\n",
      "|    n_updates            | 4810        |\n",
      "|    policy_gradient_loss | -0.00993    |\n",
      "|    reward               | 6.028629    |\n",
      "|    std                  | 3.06        |\n",
      "|    value_loss           | 2.09e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 510\n",
      "day: 1940, episode: 510\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7736295.03\n",
      "total_reward: -2263704.97\n",
      "total_cost: 170226.97\n",
      "total_trades: 73689\n",
      "Sharpe: 0.061\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 231        |\n",
      "|    iterations           | 483        |\n",
      "|    time_elapsed         | 4265       |\n",
      "|    total_timesteps      | 989184     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02386424 |\n",
      "|    clip_fraction        | 0.227      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -96.1      |\n",
      "|    explained_variance   | 0.0237     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.31e+03   |\n",
      "|    n_updates            | 4820       |\n",
      "|    policy_gradient_loss | -0.016     |\n",
      "|    reward               | -1.1271989 |\n",
      "|    std                  | 3.07       |\n",
      "|    value_loss           | 1.52e+03   |\n",
      "----------------------------------------\n",
      "Episode: 511\n",
      "day: 1940, episode: 511\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10240940.02\n",
      "total_reward: 240940.02\n",
      "total_cost: 186530.98\n",
      "total_trades: 73702\n",
      "Sharpe: 0.171\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 231         |\n",
      "|    iterations           | 484         |\n",
      "|    time_elapsed         | 4274        |\n",
      "|    total_timesteps      | 991232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023981255 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.3       |\n",
      "|    explained_variance   | 0.0187      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 759         |\n",
      "|    n_updates            | 4830        |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    reward               | -10.613989  |\n",
      "|    std                  | 3.08        |\n",
      "|    value_loss           | 1.37e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 512\n",
      "day: 1940, episode: 512\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10915093.81\n",
      "total_reward: 915093.81\n",
      "total_cost: 169629.19\n",
      "total_trades: 73709\n",
      "Sharpe: 0.181\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 231        |\n",
      "|    iterations           | 485        |\n",
      "|    time_elapsed         | 4284       |\n",
      "|    total_timesteps      | 993280     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02417966 |\n",
      "|    clip_fraction        | 0.239      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -96.4      |\n",
      "|    explained_variance   | 0.0167     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.26e+03   |\n",
      "|    n_updates            | 4840       |\n",
      "|    policy_gradient_loss | -0.0198    |\n",
      "|    reward               | -11.080371 |\n",
      "|    std                  | 3.09       |\n",
      "|    value_loss           | 1.98e+03   |\n",
      "----------------------------------------\n",
      "Episode: 513\n",
      "day: 1940, episode: 513\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11899635.10\n",
      "total_reward: 1899635.10\n",
      "total_cost: 178212.90\n",
      "total_trades: 73705\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 231         |\n",
      "|    iterations           | 486         |\n",
      "|    time_elapsed         | 4293        |\n",
      "|    total_timesteps      | 995328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020977177 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.5       |\n",
      "|    explained_variance   | 0.000692    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.24e+03    |\n",
      "|    n_updates            | 4850        |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    reward               | -3.6203353  |\n",
      "|    std                  | 3.1         |\n",
      "|    value_loss           | 1.67e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 514\n",
      "day: 1940, episode: 514\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8833465.96\n",
      "total_reward: -1166534.04\n",
      "total_cost: 169315.04\n",
      "total_trades: 73705\n",
      "Sharpe: 0.095\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 231         |\n",
      "|    iterations           | 487         |\n",
      "|    time_elapsed         | 4302        |\n",
      "|    total_timesteps      | 997376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032340974 |\n",
      "|    clip_fraction        | 0.27        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.7       |\n",
      "|    explained_variance   | -0.00972    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 495         |\n",
      "|    n_updates            | 4860        |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    reward               | -9.692591   |\n",
      "|    std                  | 3.11        |\n",
      "|    value_loss           | 1.47e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 515\n",
      "day: 1940, episode: 515\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7665027.76\n",
      "total_reward: -2334972.24\n",
      "total_cost: 171823.24\n",
      "total_trades: 73691\n",
      "Sharpe: 0.030\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 231         |\n",
      "|    iterations           | 488         |\n",
      "|    time_elapsed         | 4311        |\n",
      "|    total_timesteps      | 999424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015930671 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.7       |\n",
      "|    explained_variance   | -0.00137    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 863         |\n",
      "|    n_updates            | 4870        |\n",
      "|    policy_gradient_loss | -0.0237     |\n",
      "|    reward               | -45.193756  |\n",
      "|    std                  | 3.11        |\n",
      "|    value_loss           | 1.57e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 516\n",
      "day: 1940, episode: 516\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13466041.09\n",
      "total_reward: 3466041.09\n",
      "total_cost: 184856.91\n",
      "total_trades: 73706\n",
      "Sharpe: 0.284\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 231        |\n",
      "|    iterations           | 489        |\n",
      "|    time_elapsed         | 4319       |\n",
      "|    total_timesteps      | 1001472    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0197083  |\n",
      "|    clip_fraction        | 0.201      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -96.8      |\n",
      "|    explained_variance   | -0.0279    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.29e+03   |\n",
      "|    n_updates            | 4880       |\n",
      "|    policy_gradient_loss | -0.0189    |\n",
      "|    reward               | -15.644306 |\n",
      "|    std                  | 3.12       |\n",
      "|    value_loss           | 2.19e+03   |\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# trained_ddpg = agent.train_model(model=model_ddpg, \n",
    "                            #   tb_log_name='ddpg',\n",
    "                            #   total_timesteps=150000)\n",
    "\n",
    "# trained_sac = agent.train_model(model = model_sac,\n",
    "#                                     tb_log_name = 'sac',\n",
    "#                                     total_timesteps = 100000)\n",
    "\n",
    "# trained_a2c = agent.train_model(model = model_a2c,\n",
    "#                                     tb_log_name = 'a2c',\n",
    "#                                     total_timesteps = 1000000)\n",
    "\n",
    "trained_ppo = agent.train_model(model = model_ppo,\n",
    "                                    tb_log_name = 'ppo',\n",
    "                                    total_timesteps = 1000000)\n",
    "\n",
    "# trained_sac.save('trained_models/sac')\n",
    "# trained_a2c.save('trained_models/a2c')\n",
    "# trained_ddpg.save('trained_models/ddpg')\n",
    "trained_ppo.save('trained_models/ppo')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0767b826",
   "metadata": {
    "id": "0767b826"
   },
   "source": [
    "## Trading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3e75bbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.stablebaselines3_models import DDPG, SAC, A2C, PPO\n",
    "trained_ddpg = DDPG.load('trained_models/ddpg')\n",
    "trained_sac = SAC.load('trained_models/sac')\n",
    "trained_a2c = A2C.load('trained_models/a2c')\n",
    "trained_ppo = PPO.load('trained_models/ppo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "responsible-equity",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-13T04:35:58.328183Z",
     "start_time": "2022-10-13T04:35:58.281829Z"
    },
    "id": "responsible-equity"
   },
   "outputs": [],
   "source": [
    "trade = ts_processor.data_split(ts_processor.dataframe, trade_start_date, trade_stop_date)\n",
    "env_kwargs = {\n",
    "    \"stock_dim\": stock_dimension,\n",
    "    \"hmax\": 1000, \n",
    "    \"initial_amount\": 1e6, \n",
    "    \"buy_cost_pct\":6.87e-5,\n",
    "    \"sell_cost_pct\":2e-4,\n",
    "    \"reward_scaling\": 1e-4,\n",
    "    \"state_space\": state_space, \n",
    "    \"action_space\": stock_dimension,\n",
    "    \"tech_indicator_list\": config.INDICATORS, \n",
    "    \"print_verbosity\": 1,\n",
    "    \"initial_buy\":False,\n",
    "    \"hundred_each_trade\":True\n",
    "}\n",
    "e_trade_gym = StockTradingEnv(df = trade, **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "first-hierarchy",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-13T04:36:01.897346Z",
     "start_time": "2022-10-13T04:35:59.665241Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "first-hierarchy",
    "outputId": "2e8d17c8-11ba-47ce-a938-93ae7f21f3bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 2\n",
      "day: 666, episode: 2\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1590655.20\n",
      "total_reward: 590655.20\n",
      "total_cost: 74573.80\n",
      "total_trades: 18431\n",
      "Sharpe: 0.800\n",
      "=================================\n",
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "df_account_value, df_actions = DRLAgent.DRL_prediction(model=trained_ppo,\n",
    "                       environment = e_trade_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fb26cf36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-13T04:36:08.006544Z",
     "start_time": "2022-10-13T04:36:07.983050Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>account_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>1.000000e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>9.990049e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>9.958757e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>1.002974e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>9.933779e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-01-09</td>\n",
       "      <td>1.007915e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-01-10</td>\n",
       "      <td>1.010106e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-01-13</td>\n",
       "      <td>1.022365e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-01-14</td>\n",
       "      <td>1.018045e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-01-15</td>\n",
       "      <td>1.011067e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2020-01-16</td>\n",
       "      <td>1.009201e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2020-01-17</td>\n",
       "      <td>1.018054e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2020-01-20</td>\n",
       "      <td>1.026330e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2020-01-21</td>\n",
       "      <td>1.014109e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>1.020356e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>9.866326e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2020-02-03</td>\n",
       "      <td>9.179440e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2020-02-04</td>\n",
       "      <td>9.427388e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2020-02-05</td>\n",
       "      <td>9.559450e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2020-02-06</td>\n",
       "      <td>9.694344e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2020-02-07</td>\n",
       "      <td>9.731720e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2020-02-10</td>\n",
       "      <td>9.720870e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2020-02-11</td>\n",
       "      <td>9.803104e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2020-02-12</td>\n",
       "      <td>9.962093e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2020-02-13</td>\n",
       "      <td>9.838136e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>2022-08-25</td>\n",
       "      <td>1.721943e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>2022-08-26</td>\n",
       "      <td>1.722266e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>2022-08-29</td>\n",
       "      <td>1.711012e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>2022-08-30</td>\n",
       "      <td>1.707591e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>2022-08-31</td>\n",
       "      <td>1.698268e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>1.683709e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>2022-09-02</td>\n",
       "      <td>1.659460e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>2022-09-05</td>\n",
       "      <td>1.639370e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>2022-09-06</td>\n",
       "      <td>1.676419e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>2022-09-07</td>\n",
       "      <td>1.672913e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>2022-09-08</td>\n",
       "      <td>1.669641e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>2022-09-09</td>\n",
       "      <td>1.686088e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>2022-09-13</td>\n",
       "      <td>1.701885e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>2022-09-14</td>\n",
       "      <td>1.681592e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>2022-09-15</td>\n",
       "      <td>1.667045e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>2022-09-16</td>\n",
       "      <td>1.622261e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>2022-09-19</td>\n",
       "      <td>1.618253e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>2022-09-20</td>\n",
       "      <td>1.610455e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>2022-09-21</td>\n",
       "      <td>1.595897e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>2022-09-22</td>\n",
       "      <td>1.590422e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>2022-09-23</td>\n",
       "      <td>1.582487e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>2022-09-26</td>\n",
       "      <td>1.583221e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>2022-09-27</td>\n",
       "      <td>1.607189e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>2022-09-28</td>\n",
       "      <td>1.587467e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>2022-09-29</td>\n",
       "      <td>1.590655e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>667 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  account_value\n",
       "0    2020-01-02   1.000000e+06\n",
       "1    2020-01-03   9.990049e+05\n",
       "2    2020-01-06   9.958757e+05\n",
       "3    2020-01-07   1.002974e+06\n",
       "4    2020-01-08   9.933779e+05\n",
       "5    2020-01-09   1.007915e+06\n",
       "6    2020-01-10   1.010106e+06\n",
       "7    2020-01-13   1.022365e+06\n",
       "8    2020-01-14   1.018045e+06\n",
       "9    2020-01-15   1.011067e+06\n",
       "10   2020-01-16   1.009201e+06\n",
       "11   2020-01-17   1.018054e+06\n",
       "12   2020-01-20   1.026330e+06\n",
       "13   2020-01-21   1.014109e+06\n",
       "14   2020-01-22   1.020356e+06\n",
       "15   2020-01-23   9.866326e+05\n",
       "16   2020-02-03   9.179440e+05\n",
       "17   2020-02-04   9.427388e+05\n",
       "18   2020-02-05   9.559450e+05\n",
       "19   2020-02-06   9.694344e+05\n",
       "20   2020-02-07   9.731720e+05\n",
       "21   2020-02-10   9.720870e+05\n",
       "22   2020-02-11   9.803104e+05\n",
       "23   2020-02-12   9.962093e+05\n",
       "24   2020-02-13   9.838136e+05\n",
       "..          ...            ...\n",
       "642  2022-08-25   1.721943e+06\n",
       "643  2022-08-26   1.722266e+06\n",
       "644  2022-08-29   1.711012e+06\n",
       "645  2022-08-30   1.707591e+06\n",
       "646  2022-08-31   1.698268e+06\n",
       "647  2022-09-01   1.683709e+06\n",
       "648  2022-09-02   1.659460e+06\n",
       "649  2022-09-05   1.639370e+06\n",
       "650  2022-09-06   1.676419e+06\n",
       "651  2022-09-07   1.672913e+06\n",
       "652  2022-09-08   1.669641e+06\n",
       "653  2022-09-09   1.686088e+06\n",
       "654  2022-09-13   1.701885e+06\n",
       "655  2022-09-14   1.681592e+06\n",
       "656  2022-09-15   1.667045e+06\n",
       "657  2022-09-16   1.622261e+06\n",
       "658  2022-09-19   1.618253e+06\n",
       "659  2022-09-20   1.610455e+06\n",
       "660  2022-09-21   1.595897e+06\n",
       "661  2022-09-22   1.590422e+06\n",
       "662  2022-09-23   1.582487e+06\n",
       "663  2022-09-26   1.583221e+06\n",
       "664  2022-09-27   1.607189e+06\n",
       "665  2022-09-28   1.587467e+06\n",
       "666  2022-09-29   1.590655e+06\n",
       "\n",
       "[667 rows x 2 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_account_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8b9d6c2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-13T04:36:08.838436Z",
     "start_time": "2022-10-13T04:36:08.785645Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "8b9d6c2b",
    "outputId": "3bee87a7-ec13-4b20-9698-040a8e3ecd4b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>600010.SH</th>\n",
       "      <th>600028.SH</th>\n",
       "      <th>600030.SH</th>\n",
       "      <th>600031.SH</th>\n",
       "      <th>600036.SH</th>\n",
       "      <th>600048.SH</th>\n",
       "      <th>600104.SH</th>\n",
       "      <th>600111.SH</th>\n",
       "      <th>600196.SH</th>\n",
       "      <th>600276.SH</th>\n",
       "      <th>600309.SH</th>\n",
       "      <th>600436.SH</th>\n",
       "      <th>600438.SH</th>\n",
       "      <th>600519.SH</th>\n",
       "      <th>600570.SH</th>\n",
       "      <th>600585.SH</th>\n",
       "      <th>600588.SH</th>\n",
       "      <th>600690.SH</th>\n",
       "      <th>600809.SH</th>\n",
       "      <th>600837.SH</th>\n",
       "      <th>600887.SH</th>\n",
       "      <th>600893.SH</th>\n",
       "      <th>600900.SH</th>\n",
       "      <th>601012.SH</th>\n",
       "      <th>601088.SH</th>\n",
       "      <th>601166.SH</th>\n",
       "      <th>601288.SH</th>\n",
       "      <th>601318.SH</th>\n",
       "      <th>601398.SH</th>\n",
       "      <th>601601.SH</th>\n",
       "      <th>601628.SH</th>\n",
       "      <th>601633.SH</th>\n",
       "      <th>601668.SH</th>\n",
       "      <th>601688.SH</th>\n",
       "      <th>601857.SH</th>\n",
       "      <th>601888.SH</th>\n",
       "      <th>601899.SH</th>\n",
       "      <th>601919.SH</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-02</th>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03</th>\n",
       "      <td>-700</td>\n",
       "      <td>700</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "      <td>1000</td>\n",
       "      <td>-400</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-06</th>\n",
       "      <td>1000</td>\n",
       "      <td>-700</td>\n",
       "      <td>1000</td>\n",
       "      <td>500</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-300</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>600</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>600</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-600</td>\n",
       "      <td>1000</td>\n",
       "      <td>-400</td>\n",
       "      <td>1000</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>-500</td>\n",
       "      <td>-600</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>600</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-07</th>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-700</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-900</td>\n",
       "      <td>0</td>\n",
       "      <td>-600</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>1000</td>\n",
       "      <td>-600</td>\n",
       "      <td>200</td>\n",
       "      <td>-500</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-600</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-08</th>\n",
       "      <td>-300</td>\n",
       "      <td>500</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-500</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-09</th>\n",
       "      <td>0</td>\n",
       "      <td>-500</td>\n",
       "      <td>-700</td>\n",
       "      <td>-500</td>\n",
       "      <td>-800</td>\n",
       "      <td>0</td>\n",
       "      <td>-600</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-600</td>\n",
       "      <td>-1000</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-700</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-200</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-300</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>800</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-13</th>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>400</td>\n",
       "      <td>-800</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-14</th>\n",
       "      <td>-1000</td>\n",
       "      <td>-100</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>900</td>\n",
       "      <td>-500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-300</td>\n",
       "      <td>0</td>\n",
       "      <td>-200</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-200</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>-700</td>\n",
       "      <td>-1000</td>\n",
       "      <td>200</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-900</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>800</td>\n",
       "      <td>-400</td>\n",
       "      <td>0</td>\n",
       "      <td>-800</td>\n",
       "      <td>-500</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-500</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-900</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-700</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-700</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-500</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-300</td>\n",
       "      <td>800</td>\n",
       "      <td>600</td>\n",
       "      <td>0</td>\n",
       "      <td>-500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>700</td>\n",
       "      <td>300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-300</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-700</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-21</th>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>900</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-400</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-22</th>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-800</td>\n",
       "      <td>0</td>\n",
       "      <td>-500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-300</td>\n",
       "      <td>-100</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-400</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-23</th>\n",
       "      <td>1000</td>\n",
       "      <td>200</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-300</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-300</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>800</td>\n",
       "      <td>-1000</td>\n",
       "      <td>600</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-900</td>\n",
       "      <td>-600</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-03</th>\n",
       "      <td>1000</td>\n",
       "      <td>-200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-400</td>\n",
       "      <td>300</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>400</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "      <td>-400</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-04</th>\n",
       "      <td>-1000</td>\n",
       "      <td>600</td>\n",
       "      <td>-400</td>\n",
       "      <td>1000</td>\n",
       "      <td>800</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>400</td>\n",
       "      <td>200</td>\n",
       "      <td>-400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-400</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>600</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-600</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-05</th>\n",
       "      <td>-1000</td>\n",
       "      <td>-300</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>200</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-200</td>\n",
       "      <td>1000</td>\n",
       "      <td>-800</td>\n",
       "      <td>1000</td>\n",
       "      <td>-700</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-300</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-06</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>800</td>\n",
       "      <td>-400</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>-600</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-07</th>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-300</td>\n",
       "      <td>-400</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-900</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>400</td>\n",
       "      <td>1000</td>\n",
       "      <td>-800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-400</td>\n",
       "      <td>-400</td>\n",
       "      <td>1000</td>\n",
       "      <td>600</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>600</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-10</th>\n",
       "      <td>0</td>\n",
       "      <td>-400</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-400</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>700</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-900</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>100</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>300</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-11</th>\n",
       "      <td>0</td>\n",
       "      <td>-900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>-1000</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-700</td>\n",
       "      <td>-600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-12</th>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>300</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-200</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "      <td>0</td>\n",
       "      <td>-200</td>\n",
       "      <td>-900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>-400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-13</th>\n",
       "      <td>-100</td>\n",
       "      <td>800</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-500</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "      <td>1000</td>\n",
       "      <td>-100</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>800</td>\n",
       "      <td>0</td>\n",
       "      <td>800</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>700</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-300</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-24</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-900</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>600</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-300</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-800</td>\n",
       "      <td>-500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-25</th>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "      <td>-400</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>700</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-700</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-26</th>\n",
       "      <td>1000</td>\n",
       "      <td>-400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-400</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-29</th>\n",
       "      <td>200</td>\n",
       "      <td>-600</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>400</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-30</th>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-31</th>\n",
       "      <td>-1000</td>\n",
       "      <td>700</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-700</td>\n",
       "      <td>-200</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>700</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>900</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-100</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-01</th>\n",
       "      <td>300</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>200</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-700</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-900</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-400</td>\n",
       "      <td>-200</td>\n",
       "      <td>1000</td>\n",
       "      <td>-100</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-02</th>\n",
       "      <td>-600</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-700</td>\n",
       "      <td>0</td>\n",
       "      <td>-300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-400</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>300</td>\n",
       "      <td>-500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-05</th>\n",
       "      <td>-1000</td>\n",
       "      <td>-700</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-800</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>700</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-200</td>\n",
       "      <td>400</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-900</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-200</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>600</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-06</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-700</td>\n",
       "      <td>-700</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>900</td>\n",
       "      <td>-400</td>\n",
       "      <td>300</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>800</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>300</td>\n",
       "      <td>-600</td>\n",
       "      <td>400</td>\n",
       "      <td>-500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-07</th>\n",
       "      <td>-900</td>\n",
       "      <td>0</td>\n",
       "      <td>-400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>900</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-400</td>\n",
       "      <td>-300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-08</th>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-700</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-900</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-900</td>\n",
       "      <td>-400</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>700</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>600</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-09</th>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-600</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>-900</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-500</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>-1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-13</th>\n",
       "      <td>0</td>\n",
       "      <td>700</td>\n",
       "      <td>-600</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-600</td>\n",
       "      <td>-200</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>900</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-200</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-14</th>\n",
       "      <td>0</td>\n",
       "      <td>-200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-900</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-300</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-900</td>\n",
       "      <td>1000</td>\n",
       "      <td>-200</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-700</td>\n",
       "      <td>1000</td>\n",
       "      <td>200</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-15</th>\n",
       "      <td>0</td>\n",
       "      <td>-500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-200</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-200</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-400</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-300</td>\n",
       "      <td>-300</td>\n",
       "      <td>-200</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>-500</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-400</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-600</td>\n",
       "      <td>1000</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-400</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-500</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-400</td>\n",
       "      <td>300</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-300</td>\n",
       "      <td>700</td>\n",
       "      <td>1000</td>\n",
       "      <td>-900</td>\n",
       "      <td>1000</td>\n",
       "      <td>-100</td>\n",
       "      <td>1000</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-600</td>\n",
       "      <td>-300</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "      <td>-1000</td>\n",
       "      <td>200</td>\n",
       "      <td>-800</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-300</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-800</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-200</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-400</td>\n",
       "      <td>-400</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-700</td>\n",
       "      <td>-300</td>\n",
       "      <td>-100</td>\n",
       "      <td>300</td>\n",
       "      <td>600</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>100</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-300</td>\n",
       "      <td>900</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-200</td>\n",
       "      <td>300</td>\n",
       "      <td>100</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>700</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-700</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>800</td>\n",
       "      <td>-100</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-200</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>900</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>600</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-100</td>\n",
       "      <td>1000</td>\n",
       "      <td>-400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-600</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-800</td>\n",
       "      <td>-400</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-900</td>\n",
       "      <td>1000</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-700</td>\n",
       "      <td>0</td>\n",
       "      <td>-300</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-600</td>\n",
       "      <td>-400</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-100</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>600</td>\n",
       "      <td>0</td>\n",
       "      <td>-900</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-27</th>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-800</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-300</td>\n",
       "      <td>700</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-500</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-28</th>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>900</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>-500</td>\n",
       "      <td>0</td>\n",
       "      <td>-300</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-200</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-700</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>300</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>666 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            600010.SH  600028.SH  600030.SH  600031.SH  600036.SH  600048.SH  \\\n",
       "date                                                                           \n",
       "2020-01-02       1000          0       1000          0          0       1000   \n",
       "2020-01-03       -700        700       1000          0          0      -1000   \n",
       "2020-01-06       1000       -700       1000        500        200          0   \n",
       "2020-01-07      -1000          0          0       1000       1000          0   \n",
       "2020-01-08       -300        500       1000      -1000       1000          0   \n",
       "2020-01-09          0       -500       -700       -500       -800          0   \n",
       "2020-01-10          0          0      -1000          0       -400          0   \n",
       "2020-01-13       1000        100       1000       1000      -1000          0   \n",
       "2020-01-14      -1000       -100      -1000      -1000       1000          0   \n",
       "2020-01-15          0          0      -1000       1000      -1000          0   \n",
       "2020-01-16          0          0       1000      -1000          0          0   \n",
       "2020-01-17          0          0      -1000          0          0          0   \n",
       "2020-01-20          0          0       -800          0          0          0   \n",
       "2020-01-21          0       1000       -100          0          0          0   \n",
       "2020-01-22          0      -1000       1000          0          0       1000   \n",
       "2020-01-23       1000        200      -1000          0          0       -600   \n",
       "2020-02-03       1000       -200          0          0          0       -400   \n",
       "2020-02-04      -1000        600       -400       1000        800        100   \n",
       "2020-02-05      -1000       -300          0       1000       1000        200   \n",
       "2020-02-06          0          0          0      -1000      -1000          0   \n",
       "2020-02-07          0       1000          0       1000       1000       -300   \n",
       "2020-02-10          0       -400          0      -1000      -1000          0   \n",
       "2020-02-11          0       -900          0          0          0          0   \n",
       "2020-02-12        100          0       1000          0       -800          0   \n",
       "2020-02-13       -100        800      -1000      -1000       1000       1000   \n",
       "...               ...        ...        ...        ...        ...        ...   \n",
       "2022-08-24       1000       1000          0          0       1000          0   \n",
       "2022-08-25      -1000      -1000          0          0      -1000          0   \n",
       "2022-08-26       1000       -400          0          0      -1000          0   \n",
       "2022-08-29        200       -600       1000          0       1000          0   \n",
       "2022-08-30       1000          0       1000          0          0       1000   \n",
       "2022-08-31      -1000        700      -1000          0      -1000          0   \n",
       "2022-09-01        300       1000       1000          0      -1000        200   \n",
       "2022-09-02       -600      -1000      -1000          0       1000      -1000   \n",
       "2022-09-05      -1000       -700       1000       1000       1000       1000   \n",
       "2022-09-06          0          0       1000      -1000       1000       1000   \n",
       "2022-09-07       -900          0       -400          0          0      -1000   \n",
       "2022-09-08          0       1000      -1000          0      -1000       1000   \n",
       "2022-09-09          0      -1000      -1000          0      -1000       -600   \n",
       "2022-09-13          0        700       -600          0      -1000       1000   \n",
       "2022-09-14          0       -200          0          0       -900      -1000   \n",
       "2022-09-15          0       -500          0          0       -200       1000   \n",
       "2022-09-16          0          0          0       1000          0      -1000   \n",
       "2022-09-19          0          0          0       1000       -400      -1000   \n",
       "2022-09-20          0          0          0      -1000          0       -600   \n",
       "2022-09-21          0          0       1000       1000          0          0   \n",
       "2022-09-22          0          0      -1000        700          0          0   \n",
       "2022-09-23          0          0          0          0          0          0   \n",
       "2022-09-26          0          0       1000      -1000          0          0   \n",
       "2022-09-27       1000          0       1000       1000       1000          0   \n",
       "2022-09-28      -1000          0        900      -1000      -1000       1000   \n",
       "\n",
       "            600104.SH  600111.SH  600196.SH  600276.SH  600309.SH  600436.SH  \\\n",
       "date                                                                           \n",
       "2020-01-02          0          0          0          0       1000          0   \n",
       "2020-01-03          0          0       1000          0      -1000          0   \n",
       "2020-01-06          0          0       -300          0       1000        600   \n",
       "2020-01-07          0          0       -700          0      -1000       1000   \n",
       "2020-01-08        600          0          0          0       1000      -1000   \n",
       "2020-01-09       -600       1000          0          0      -1000       -600   \n",
       "2020-01-10          0      -1000          0          0          0          0   \n",
       "2020-01-13       1000        500          0          0          0          0   \n",
       "2020-01-14        900       -500          0          0          0          0   \n",
       "2020-01-15      -1000          0          0       1000          0          0   \n",
       "2020-01-16       -900          0       1000      -1000          0       1000   \n",
       "2020-01-17          0          0       1000          0          0       -700   \n",
       "2020-01-20          0          0      -1000          0          0        700   \n",
       "2020-01-21        900          0       -100          0        100      -1000   \n",
       "2020-01-22       -800          0       -500       1000       1000          0   \n",
       "2020-01-23          0          0       -100      -1000       -300          0   \n",
       "2020-02-03        300          0       1000          0       1000          0   \n",
       "2020-02-04       1000       1000       1000          0      -1000        400   \n",
       "2020-02-05      -1000       1000       -200       1000       -800       1000   \n",
       "2020-02-06          0       1000       1000       1000          0          0   \n",
       "2020-02-07       -400      -1000       1000       -900          0      -1000   \n",
       "2020-02-10          0      -1000       -400       1000          0        700   \n",
       "2020-02-11          0        100          0      -1000       1000       1000   \n",
       "2020-02-12          0      -1000          0       1000          0      -1000   \n",
       "2020-02-13          0       -100       1000          0      -1000       -900   \n",
       "...               ...        ...        ...        ...        ...        ...   \n",
       "2022-08-24          0       1000       1000          0          0        100   \n",
       "2022-08-25          0      -1000          0          0          0       -100   \n",
       "2022-08-26          0       -400      -1000          0       1000          0   \n",
       "2022-08-29       1000      -1000       1000          0       1000          0   \n",
       "2022-08-30       1000       1000      -1000          0      -1000          0   \n",
       "2022-08-31      -1000       1000          0       1000      -1000          0   \n",
       "2022-09-01       1000       1000        100      -1000       -700          0   \n",
       "2022-09-02          0       1000      -1000          0      -1000          0   \n",
       "2022-09-05       -800       1000      -1000        700      -1000          0   \n",
       "2022-09-06        100      -1000      -1000       -700       -700          0   \n",
       "2022-09-07      -1000      -1000          0          0       1000        900   \n",
       "2022-09-08       1000      -1000       -700       1000       1000       -900   \n",
       "2022-09-09      -1000          0          0      -1000      -1000          0   \n",
       "2022-09-13          0      -1000       1000       1000       1000          0   \n",
       "2022-09-14       -300      -1000      -1000       1000       1000          0   \n",
       "2022-09-15          0          0       -200      -1000          0       1000   \n",
       "2022-09-16          0      -1000       1000      -1000       1000        100   \n",
       "2022-09-19       1000       -500      -1000          0      -1000      -1000   \n",
       "2022-09-20       -300          0      -1000          0          0       -100   \n",
       "2022-09-21       -400       -400       1000          0      -1000          0   \n",
       "2022-09-22       1000       -700      -1000          0          0       1000   \n",
       "2022-09-23       -300          0          0          0          0       -600   \n",
       "2022-09-26      -1000          0          0          0       -600       -400   \n",
       "2022-09-27          0          0          0          0       1000          0   \n",
       "2022-09-28       1000          0          0          0       -600          0   \n",
       "\n",
       "            600438.SH  600519.SH  600570.SH  600585.SH  600588.SH  600690.SH  \\\n",
       "date                                                                           \n",
       "2020-01-02          0          0          0       1000       1000       1000   \n",
       "2020-01-03          0          0          0      -1000       1000       1000   \n",
       "2020-01-06       1000          0        600          0      -1000       1000   \n",
       "2020-01-07       -900          0       -600          0       1000      -1000   \n",
       "2020-01-08       1000          0          0          0        200      -1000   \n",
       "2020-01-09      -1000        200          0          0      -1000      -1000   \n",
       "2020-01-10       1000       -200          0          0       1000       1000   \n",
       "2020-01-13       1000          0       1000       1000       1000       1000   \n",
       "2020-01-14      -1000          0       -300          0       -200      -1000   \n",
       "2020-01-15        400          0       -700      -1000        200      -1000   \n",
       "2020-01-16          0          0          0          0          0       1000   \n",
       "2020-01-17          0          0          0          0       -500      -1000   \n",
       "2020-01-20        300          0          0          0          0          0   \n",
       "2020-01-21       1000        100       1000          0       1000          0   \n",
       "2020-01-22       -300       -100       1000          0          0          0   \n",
       "2020-01-23      -1000          0      -1000          0      -1000       1000   \n",
       "2020-02-03      -1000        400      -1000          0          0          0   \n",
       "2020-02-04        200       -400          0          0       1000      -1000   \n",
       "2020-02-05       -700          0          0          0      -1000          0   \n",
       "2020-02-06          0          0          0          0       1000          0   \n",
       "2020-02-07       1000          0          0          0       1000          0   \n",
       "2020-02-10      -1000          0          0          0          0          0   \n",
       "2020-02-11          0          0          0        200      -1000        200   \n",
       "2020-02-12          0          0       1000        300      -1000       -200   \n",
       "2020-02-13          0          0      -1000       -500      -1000          0   \n",
       "...               ...        ...        ...        ...        ...        ...   \n",
       "2022-08-24       1000          0       -900       1000          0          0   \n",
       "2022-08-25       -400        100          0      -1000       1000        700   \n",
       "2022-08-26        300       -100          0        100          0          0   \n",
       "2022-08-29       1000          0          0       1000      -1000      -1000   \n",
       "2022-08-30          0          0          0          0       1000      -1000   \n",
       "2022-08-31       1000          0          0      -1000       -700       -200   \n",
       "2022-09-01      -1000          0       1000      -1000       -300          0   \n",
       "2022-09-02        200        200          0          0          0          0   \n",
       "2022-09-05       1000       -200        400       1000          0       1000   \n",
       "2022-09-06       1000          0       1000      -1000          0      -1000   \n",
       "2022-09-07      -1000          0          0       -300          0          0   \n",
       "2022-09-08       1000          0        100          0        600          0   \n",
       "2022-09-09       1000        200          0          0        500          0   \n",
       "2022-09-13       -600       -200       1000          0       1000          0   \n",
       "2022-09-14      -1000          0      -1000          0       1000          0   \n",
       "2022-09-15       1000          0          0          0      -1000          0   \n",
       "2022-09-16      -1000          0       -400          0        100          0   \n",
       "2022-09-19       1000          0      -1000          0      -1000       1000   \n",
       "2022-09-20          0        300      -1000        200       -800      -1000   \n",
       "2022-09-21       -700       -300       -100        300        600       1000   \n",
       "2022-09-22      -1000          0        800       -100       1000      -1000   \n",
       "2022-09-23      -1000          0       -800       -400       1000          0   \n",
       "2022-09-26       1000          0          0          0      -1000          0   \n",
       "2022-09-27      -1000          0       1000          0       -900          0   \n",
       "2022-09-28          0        100       -500          0       -300       1000   \n",
       "\n",
       "            600809.SH  600837.SH  600887.SH  600893.SH  600900.SH  601012.SH  \\\n",
       "date                                                                           \n",
       "2020-01-02          0        900          0          0       1000          0   \n",
       "2020-01-03       1000       -900          0          0        300       1000   \n",
       "2020-01-06      -1000       1000       1000          0       1000       1000   \n",
       "2020-01-07       1000      -1000       1000          0      -1000          0   \n",
       "2020-01-08      -1000       1000      -1000          0      -1000       1000   \n",
       "2020-01-09       1000       -700        200          0       1000      -1000   \n",
       "2020-01-10       1000       -300          0       1000       1000      -1000   \n",
       "2020-01-13      -1000          0      -1000      -1000      -1000      -1000   \n",
       "2020-01-14          0          0       -200          0      -1000          0   \n",
       "2020-01-15      -1000          0       1000       1000       1000       1000   \n",
       "2020-01-16          0       1000      -1000       1000       1000       -900   \n",
       "2020-01-17          0          0          0          0          0       -100   \n",
       "2020-01-20          0      -1000          0          0          0       1000   \n",
       "2020-01-21       1000          0          0      -1000      -1000      -1000   \n",
       "2020-01-22          0          0          0        100      -1000          0   \n",
       "2020-01-23       1000        100          0      -1000       -300          0   \n",
       "2020-02-03      -1000          0          0       -100          0          0   \n",
       "2020-02-04      -1000       -100          0        500          0          0   \n",
       "2020-02-05          0       1000       1000       1000          0          0   \n",
       "2020-02-06          0      -1000      -1000          0          0        800   \n",
       "2020-02-07          0          0       1000        400       1000       -800   \n",
       "2020-02-10          0          0       -900       1000          0          0   \n",
       "2020-02-11          0          0          0      -1000       -100          0   \n",
       "2020-02-12          0        300          0       -200       -900          0   \n",
       "2020-02-13        300       1000       -100       1000          0        800   \n",
       "...               ...        ...        ...        ...        ...        ...   \n",
       "2022-08-24          0          0          0          0       1000        600   \n",
       "2022-08-25          0          0          0          0          0      -1000   \n",
       "2022-08-26          0          0      -1000       1000          0          0   \n",
       "2022-08-29          0       1000      -1000      -1000       1000        400   \n",
       "2022-08-30          0      -1000          0          0      -1000       1000   \n",
       "2022-08-31          0       1000      -1000          0        700      -1000   \n",
       "2022-09-01          0      -1000       1000          0      -1000       1000   \n",
       "2022-09-02          0          0      -1000          0       -700          0   \n",
       "2022-09-05          0          0      -1000          0       1000       -900   \n",
       "2022-09-06          0        900       -400        300       1000       1000   \n",
       "2022-09-07          0          0       -200          0          0      -1000   \n",
       "2022-09-08          0       -900       -400       1000      -1000      -1000   \n",
       "2022-09-09          0          0          0       -100          0       -900   \n",
       "2022-09-13          0        900          0      -1000       1000       1000   \n",
       "2022-09-14       1000       -900       1000       -200      -1000       -700   \n",
       "2022-09-15      -1000          0       -400          0      -1000       -300   \n",
       "2022-09-16          0          0       -600       1000        400          0   \n",
       "2022-09-19          0          0       1000          0       -400        300   \n",
       "2022-09-20          0          0          0          0       1000       -300   \n",
       "2022-09-21          0          0      -1000        100      -1000          0   \n",
       "2022-09-22       1000       1000       1000       -200       1000          0   \n",
       "2022-09-23       1000       1000       1000       -900       1000        200   \n",
       "2022-09-26          0      -1000      -1000       1000       1000       -100   \n",
       "2022-09-27          0      -1000          0       -800       1000          0   \n",
       "2022-09-28      -1000          0      -1000       -200       1000       1000   \n",
       "\n",
       "            601088.SH  601166.SH  601288.SH  601318.SH  601398.SH  601601.SH  \\\n",
       "date                                                                           \n",
       "2020-01-02       1000          0          0        200          0          0   \n",
       "2020-01-03       -400       1000       1000       1000       1000          0   \n",
       "2020-01-06       -600       1000       -400       1000       -100          0   \n",
       "2020-01-07        200       1000       -600        200       -500          0   \n",
       "2020-01-08       1000       1000          0      -1000       1000          0   \n",
       "2020-01-09       1000      -1000          0       1000        400          0   \n",
       "2020-01-10       1000      -1000          0       1000      -1000          0   \n",
       "2020-01-13       1000      -1000          0      -1000       1000        400   \n",
       "2020-01-14        100          0          0       1000          0          0   \n",
       "2020-01-15       -900      -1000       1000      -1000        800       -400   \n",
       "2020-01-16          0          0       1000       1000       -700          0   \n",
       "2020-01-17          0          0      -1000       1000          0          0   \n",
       "2020-01-20          0          0      -1000      -1000       -300       1000   \n",
       "2020-01-21       1000          0          0      -1000       -400      -1000   \n",
       "2020-01-22       1000          0          0      -1000        100          0   \n",
       "2020-01-23       1000          0        800      -1000        600       1000   \n",
       "2020-02-03      -1000          0       -100       -400          0      -1000   \n",
       "2020-02-04      -1000          0       -400       1000       1000       1000   \n",
       "2020-02-05       1000          0       -300          0      -1000      -1000   \n",
       "2020-02-06       -400          0        400       -600       1000          0   \n",
       "2020-02-07          0          0       -400       -400       1000        600   \n",
       "2020-02-10          0          0          0          0      -1000        100   \n",
       "2020-02-11          0          0        100          0          0       -700   \n",
       "2020-02-12          0       1000       -100          0       -400          0   \n",
       "2020-02-13          0        800       1000          0       1000          0   \n",
       "...               ...        ...        ...        ...        ...        ...   \n",
       "2022-08-24      -1000          0      -1000       -300      -1000          0   \n",
       "2022-08-25          0          0       1000       -700      -1000          0   \n",
       "2022-08-26          0          0      -1000          0      -1000          0   \n",
       "2022-08-29       1000          0          0          0      -1000          0   \n",
       "2022-08-30       1000          0       1000          0          0          0   \n",
       "2022-08-31      -1000        900      -1000          0      -1000        200   \n",
       "2022-09-01       1000       -900       1000          0       -400       -200   \n",
       "2022-09-02       -300          0          0          0          0          0   \n",
       "2022-09-05       1000          0        200          0          0          0   \n",
       "2022-09-06        800          0       1000       1000          0       1000   \n",
       "2022-09-07      -1000          0        200       1000          0      -1000   \n",
       "2022-09-08        700          0       1000       1000          0       1000   \n",
       "2022-09-09      -1000          0      -1000          0          0          0   \n",
       "2022-09-13       -100          0      -1000       -100          0       1000   \n",
       "2022-09-14       1000        200      -1000      -1000          0       1000   \n",
       "2022-09-15       -300       -200      -1000       1000       1000       1000   \n",
       "2022-09-16       1000          0          0      -1000      -1000          0   \n",
       "2022-09-19      -1000          0       -300        700       1000       -900   \n",
       "2022-09-20      -1000          0          0       -800        200        100   \n",
       "2022-09-21       -100          0          0      -1000       -300        900   \n",
       "2022-09-22      -1000       1000          0        900       1000      -1000   \n",
       "2022-09-23          0       -100          0       1000      -1000      -1000   \n",
       "2022-09-26       1000       1000          0       1000       1000      -1000   \n",
       "2022-09-27      -1000          0          0       -300        700      -1000   \n",
       "2022-09-28       1000       1000          0       -700       1000       1000   \n",
       "\n",
       "            601628.SH  601633.SH  601668.SH  601688.SH  601857.SH  601888.SH  \\\n",
       "date                                                                           \n",
       "2020-01-02       1000       1000          0          0          0          0   \n",
       "2020-01-03       1000       1000          0        200          0          0   \n",
       "2020-01-06       -500       -600          0       1000       1000          0   \n",
       "2020-01-07      -1000       1000          0          0      -1000          0   \n",
       "2020-01-08       -500       1000          0      -1000       1000          0   \n",
       "2020-01-09          0       1000       1000       -200       1000          0   \n",
       "2020-01-10        800       1000      -1000          0        200          0   \n",
       "2020-01-13       -800       1000       1000       1000       1000          0   \n",
       "2020-01-14          0          0       -500          0          0          0   \n",
       "2020-01-15          0       -800       -500      -1000       -500       1000   \n",
       "2020-01-16       1000      -1000          0        300        100          0   \n",
       "2020-01-17          0      -1000          0       -300        800        600   \n",
       "2020-01-20          0        100          0          0       -700          0   \n",
       "2020-01-21      -1000       1000          0       1000      -1000      -1000   \n",
       "2020-01-22          0          0          0       -400      -1000          0   \n",
       "2020-01-23       1000       1000          0          0       -900       -600   \n",
       "2020-02-03          0          0          0          0       1000          0   \n",
       "2020-02-04        600       1000       1000       -600       1000          0   \n",
       "2020-02-05       1000      -1000      -1000          0       1000          0   \n",
       "2020-02-06      -1000      -1000          0          0      -1000          0   \n",
       "2020-02-07          0      -1000          0          0        600       1000   \n",
       "2020-02-10      -1000       1000          0       1000       1000      -1000   \n",
       "2020-02-11       -600          0          0          0          0          0   \n",
       "2020-02-12          0          0          0      -1000          0          0   \n",
       "2020-02-13          0        700       1000          0       1000       1000   \n",
       "...               ...        ...        ...        ...        ...        ...   \n",
       "2022-08-24          0       1000          0          0      -1000       -800   \n",
       "2022-08-25          0          0          0          0          0          0   \n",
       "2022-08-26          0      -1000          0          0       1000       1000   \n",
       "2022-08-29          0      -1000          0          0          0      -1000   \n",
       "2022-08-30        200      -1000          0        100          0          0   \n",
       "2022-08-31          0      -1000       1000       -100      -1000       1000   \n",
       "2022-09-01       1000       -100      -1000          0      -1000          0   \n",
       "2022-09-02      -1000       -400       1000          0       1000      -1000   \n",
       "2022-09-05       -200          0       1000          0      -1000        600   \n",
       "2022-09-06        100       1000      -1000       1000        300       -600   \n",
       "2022-09-07          0      -1000      -1000       -400       -300          0   \n",
       "2022-09-08        600       1000          0       1000          0          0   \n",
       "2022-09-09       -500      -1000          0      -1000          0          0   \n",
       "2022-09-13       -200       1000          0        800          0          0   \n",
       "2022-09-14          0          0          0       -900          0          0   \n",
       "2022-09-15          0        100          0       -500        400          0   \n",
       "2022-09-16          0      -1000          0          0       -400          0   \n",
       "2022-09-19       1000       -100       1000        400          0          0   \n",
       "2022-09-20          0          0      -1000       1000       1000          0   \n",
       "2022-09-21      -1000          0       1000       -200        300        100   \n",
       "2022-09-22       1000          0        600       1000      -1000       -100   \n",
       "2022-09-23          0          0       -700          0       -300          0   \n",
       "2022-09-26        600          0       -900          0        500          0   \n",
       "2022-09-27      -1000          0          0       1000       -500          0   \n",
       "2022-09-28          0       1000          0      -1000       1000        300   \n",
       "\n",
       "            601899.SH  601919.SH  \n",
       "date                              \n",
       "2020-01-02       1000          0  \n",
       "2020-01-03      -1000       1000  \n",
       "2020-01-06        600        400  \n",
       "2020-01-07       -600        100  \n",
       "2020-01-08          0       1000  \n",
       "2020-01-09          0      -1000  \n",
       "2020-01-10       1000      -1000  \n",
       "2020-01-13      -1000       1000  \n",
       "2020-01-14          0       1000  \n",
       "2020-01-15          0      -1000  \n",
       "2020-01-16          0      -1000  \n",
       "2020-01-17          0       -500  \n",
       "2020-01-20          0          0  \n",
       "2020-01-21          0          0  \n",
       "2020-01-22          0       1000  \n",
       "2020-01-23       1000      -1000  \n",
       "2020-02-03          0          0  \n",
       "2020-02-04       1000          0  \n",
       "2020-02-05       1000          0  \n",
       "2020-02-06      -1000       1000  \n",
       "2020-02-07      -1000      -1000  \n",
       "2020-02-10        300       1000  \n",
       "2020-02-11      -1000       1000  \n",
       "2020-02-12          0       1000  \n",
       "2020-02-13       -300       1000  \n",
       "...               ...        ...  \n",
       "2022-08-24       -500          0  \n",
       "2022-08-25          0       1000  \n",
       "2022-08-26          0          0  \n",
       "2022-08-29       1000       1000  \n",
       "2022-08-30       1000       1000  \n",
       "2022-08-31       1000          0  \n",
       "2022-09-01       1000       1000  \n",
       "2022-09-02        300       -500  \n",
       "2022-09-05      -1000       1000  \n",
       "2022-09-06        400       -500  \n",
       "2022-09-07          0       1000  \n",
       "2022-09-08      -1000      -1000  \n",
       "2022-09-09        100      -1000  \n",
       "2022-09-13      -1000       1000  \n",
       "2022-09-14      -1000      -1000  \n",
       "2022-09-15       1000      -1000  \n",
       "2022-09-16          0      -1000  \n",
       "2022-09-19      -1000       -500  \n",
       "2022-09-20       -200       -100  \n",
       "2022-09-21      -1000          0  \n",
       "2022-09-22       1000       -400  \n",
       "2022-09-23       1000          0  \n",
       "2022-09-26       1000       1000  \n",
       "2022-09-27      -1000      -1000  \n",
       "2022-09-28       1000          0  \n",
       "\n",
       "[666 rows x 38 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_actions.to_csv(\"./results/ppo/action.csv\",index=False)\n",
    "df_actions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea8a81c",
   "metadata": {
    "id": "6ea8a81c"
   },
   "source": [
    "## Backtesting\n",
    "回测在评估交易策略的表现方面起着关键作用。自动回测工具是首选，因为它减少了人为错误。在量化金融中通常使用[Quantopian Pyfolio](https://github.com/quantopian/pyfolio)软件包来回测我们的交易策略。它很容易使用，由各种单独的图表组成，提供了交易策略表现的全面图像。\n",
    "\n",
    "### Backtesting Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d884a6cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-13T04:36:44.348532Z",
     "start_time": "2022-10-13T04:36:44.313157Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Backtest Results===========\n",
      "Annual return          0.191675\n",
      "Cumulative returns     0.590655\n",
      "Annual volatility      0.262728\n",
      "Sharpe ratio           0.800130\n",
      "Calmar ratio           0.627010\n",
      "Stability              0.617317\n",
      "Max drawdown          -0.305696\n",
      "Omega ratio            1.144056\n",
      "Sortino ratio          1.154764\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             1.113703\n",
      "Daily value at risk   -0.032266\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"==============Get Backtest Results===========\")\n",
    "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
    "\n",
    "perf_stats_all = backtest_stats(account_value=df_account_value)\n",
    "perf_stats_all = pd.DataFrame(perf_stats_all)\n",
    "perf_stats_all.to_csv(\"./results/ppo/\"+\"/perf_stats_all_\"+now+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9e8d1b73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-13T04:36:45.842322Z",
     "start_time": "2022-10-13T04:36:45.836886Z"
    }
   },
   "outputs": [],
   "source": [
    "plotter = ReturnPlotter(df_account_value, trade, '20200101', '20220928', token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b90bb2a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-13T04:36:46.592457Z",
     "start_time": "2022-10-13T04:36:46.362627Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Baseline Stats===========\n",
      "Annual return         -0.061707\n",
      "Cumulative returns    -0.154926\n",
      "Annual volatility      0.205370\n",
      "Sharpe ratio          -0.207751\n",
      "Calmar ratio          -0.175489\n",
      "Stability              0.039829\n",
      "Max drawdown          -0.351629\n",
      "Omega ratio            0.965096\n",
      "Sortino ratio         -0.284098\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             0.921966\n",
      "Daily value at risk   -0.026043\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#baseline stats\n",
    "print(\"==============Get Baseline Stats===========\")\n",
    "baseline_df = plotter.get_baseline(\"000016.SH\") # 沪深300 399300.SZ 上证50 000016.SH\n",
    "stats = backtest_stats(baseline_df, value_col_name = 'close')\n",
    "base_stats = pd.DataFrame(stats)\n",
    "base_stats.to_csv(\"./results/\"+\"base_stats\"+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "dcb3dbf1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-13T04:36:47.511799Z",
     "start_time": "2022-10-13T04:36:47.465613Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts_code</th>\n",
       "      <th>date</th>\n",
       "      <th>close</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>pre_close</th>\n",
       "      <th>change</th>\n",
       "      <th>pct_chg</th>\n",
       "      <th>vol</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>3090.8331</td>\n",
       "      <td>3073.9313</td>\n",
       "      <td>3107.5172</td>\n",
       "      <td>3073.9313</td>\n",
       "      <td>3063.2190</td>\n",
       "      <td>27.6141</td>\n",
       "      <td>0.9015</td>\n",
       "      <td>50036392.0</td>\n",
       "      <td>9.477373e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>3078.2793</td>\n",
       "      <td>3097.2518</td>\n",
       "      <td>3097.4088</td>\n",
       "      <td>3072.1137</td>\n",
       "      <td>3090.8331</td>\n",
       "      <td>-12.5538</td>\n",
       "      <td>-0.4062</td>\n",
       "      <td>37185493.0</td>\n",
       "      <td>7.234679e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>3056.8359</td>\n",
       "      <td>3062.2801</td>\n",
       "      <td>3090.8402</td>\n",
       "      <td>3040.1945</td>\n",
       "      <td>3078.2793</td>\n",
       "      <td>-21.4434</td>\n",
       "      <td>-0.6966</td>\n",
       "      <td>47707827.0</td>\n",
       "      <td>7.777039e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>3074.0152</td>\n",
       "      <td>3063.7464</td>\n",
       "      <td>3080.2714</td>\n",
       "      <td>3061.5608</td>\n",
       "      <td>3056.8359</td>\n",
       "      <td>17.1793</td>\n",
       "      <td>0.5620</td>\n",
       "      <td>34371788.0</td>\n",
       "      <td>5.688658e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>3037.8525</td>\n",
       "      <td>3058.3585</td>\n",
       "      <td>3058.6969</td>\n",
       "      <td>3030.1048</td>\n",
       "      <td>3074.0152</td>\n",
       "      <td>-36.1627</td>\n",
       "      <td>-1.1764</td>\n",
       "      <td>37653773.0</td>\n",
       "      <td>5.985484e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2020-01-09</td>\n",
       "      <td>3067.5456</td>\n",
       "      <td>3060.7743</td>\n",
       "      <td>3071.5392</td>\n",
       "      <td>3055.9906</td>\n",
       "      <td>3037.8525</td>\n",
       "      <td>29.6931</td>\n",
       "      <td>0.9774</td>\n",
       "      <td>33150515.0</td>\n",
       "      <td>5.767682e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2020-01-10</td>\n",
       "      <td>3067.8810</td>\n",
       "      <td>3079.0765</td>\n",
       "      <td>3081.9568</td>\n",
       "      <td>3058.1642</td>\n",
       "      <td>3067.5456</td>\n",
       "      <td>0.3354</td>\n",
       "      <td>0.0109</td>\n",
       "      <td>28542389.0</td>\n",
       "      <td>5.163493e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2020-01-13</td>\n",
       "      <td>3090.1284</td>\n",
       "      <td>3069.6784</td>\n",
       "      <td>3090.1310</td>\n",
       "      <td>3054.8783</td>\n",
       "      <td>3067.8810</td>\n",
       "      <td>22.2474</td>\n",
       "      <td>0.7252</td>\n",
       "      <td>29330835.0</td>\n",
       "      <td>5.705225e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2020-01-14</td>\n",
       "      <td>3080.6016</td>\n",
       "      <td>3097.7248</td>\n",
       "      <td>3108.1770</td>\n",
       "      <td>3078.4579</td>\n",
       "      <td>3090.1284</td>\n",
       "      <td>-9.5268</td>\n",
       "      <td>-0.3083</td>\n",
       "      <td>35129017.0</td>\n",
       "      <td>5.696145e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2020-01-15</td>\n",
       "      <td>3058.0078</td>\n",
       "      <td>3078.2528</td>\n",
       "      <td>3086.9662</td>\n",
       "      <td>3052.7047</td>\n",
       "      <td>3080.6016</td>\n",
       "      <td>-22.5938</td>\n",
       "      <td>-0.7334</td>\n",
       "      <td>28116086.0</td>\n",
       "      <td>4.697157e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2020-01-16</td>\n",
       "      <td>3043.0931</td>\n",
       "      <td>3067.9500</td>\n",
       "      <td>3068.1971</td>\n",
       "      <td>3039.0726</td>\n",
       "      <td>3058.0078</td>\n",
       "      <td>-14.9147</td>\n",
       "      <td>-0.4877</td>\n",
       "      <td>28312318.0</td>\n",
       "      <td>4.549775e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2020-01-17</td>\n",
       "      <td>3053.1729</td>\n",
       "      <td>3054.0361</td>\n",
       "      <td>3067.5589</td>\n",
       "      <td>3042.5897</td>\n",
       "      <td>3043.0931</td>\n",
       "      <td>10.0798</td>\n",
       "      <td>0.3312</td>\n",
       "      <td>23304514.0</td>\n",
       "      <td>4.622461e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2020-01-20</td>\n",
       "      <td>3065.9906</td>\n",
       "      <td>3070.6701</td>\n",
       "      <td>3072.2888</td>\n",
       "      <td>3054.4484</td>\n",
       "      <td>3053.1729</td>\n",
       "      <td>12.8177</td>\n",
       "      <td>0.4198</td>\n",
       "      <td>27274849.0</td>\n",
       "      <td>5.562321e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2020-01-21</td>\n",
       "      <td>3012.1123</td>\n",
       "      <td>3048.9459</td>\n",
       "      <td>3050.8233</td>\n",
       "      <td>3011.1846</td>\n",
       "      <td>3065.9906</td>\n",
       "      <td>-53.8783</td>\n",
       "      <td>-1.7573</td>\n",
       "      <td>32801291.0</td>\n",
       "      <td>5.974027e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>3017.8785</td>\n",
       "      <td>2996.8099</td>\n",
       "      <td>3023.9019</td>\n",
       "      <td>2965.6635</td>\n",
       "      <td>3012.1123</td>\n",
       "      <td>5.7662</td>\n",
       "      <td>0.1914</td>\n",
       "      <td>33159760.0</td>\n",
       "      <td>6.050915e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>2932.4932</td>\n",
       "      <td>2993.7726</td>\n",
       "      <td>2993.7726</td>\n",
       "      <td>2910.3942</td>\n",
       "      <td>3017.8785</td>\n",
       "      <td>-85.3853</td>\n",
       "      <td>-2.8293</td>\n",
       "      <td>42839352.0</td>\n",
       "      <td>7.550661e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2020-02-03</td>\n",
       "      <td>2727.0931</td>\n",
       "      <td>2676.0073</td>\n",
       "      <td>2755.8448</td>\n",
       "      <td>2676.0073</td>\n",
       "      <td>2932.4932</td>\n",
       "      <td>-205.4001</td>\n",
       "      <td>-7.0043</td>\n",
       "      <td>58609184.0</td>\n",
       "      <td>9.613125e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2020-02-04</td>\n",
       "      <td>2794.6606</td>\n",
       "      <td>2724.1314</td>\n",
       "      <td>2796.7145</td>\n",
       "      <td>2724.1314</td>\n",
       "      <td>2727.0931</td>\n",
       "      <td>67.5675</td>\n",
       "      <td>2.4776</td>\n",
       "      <td>57016369.0</td>\n",
       "      <td>9.185602e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2020-02-05</td>\n",
       "      <td>2812.8993</td>\n",
       "      <td>2803.7374</td>\n",
       "      <td>2833.2097</td>\n",
       "      <td>2782.4231</td>\n",
       "      <td>2794.6606</td>\n",
       "      <td>18.2387</td>\n",
       "      <td>0.6526</td>\n",
       "      <td>44182070.0</td>\n",
       "      <td>7.342200e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2020-02-06</td>\n",
       "      <td>2854.8878</td>\n",
       "      <td>2829.5111</td>\n",
       "      <td>2866.3906</td>\n",
       "      <td>2809.3661</td>\n",
       "      <td>2812.8993</td>\n",
       "      <td>41.9885</td>\n",
       "      <td>1.4927</td>\n",
       "      <td>42134251.0</td>\n",
       "      <td>7.041728e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2020-02-07</td>\n",
       "      <td>2851.7105</td>\n",
       "      <td>2836.7992</td>\n",
       "      <td>2851.8244</td>\n",
       "      <td>2819.6678</td>\n",
       "      <td>2854.8878</td>\n",
       "      <td>-3.1773</td>\n",
       "      <td>-0.1113</td>\n",
       "      <td>34443628.0</td>\n",
       "      <td>5.906509e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2020-02-10</td>\n",
       "      <td>2850.0642</td>\n",
       "      <td>2826.7970</td>\n",
       "      <td>2854.8289</td>\n",
       "      <td>2817.7707</td>\n",
       "      <td>2851.7105</td>\n",
       "      <td>-1.6463</td>\n",
       "      <td>-0.0577</td>\n",
       "      <td>33654934.0</td>\n",
       "      <td>5.664824e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2020-02-11</td>\n",
       "      <td>2879.8575</td>\n",
       "      <td>2858.9245</td>\n",
       "      <td>2893.0673</td>\n",
       "      <td>2854.0722</td>\n",
       "      <td>2850.0642</td>\n",
       "      <td>29.7933</td>\n",
       "      <td>1.0454</td>\n",
       "      <td>36028244.0</td>\n",
       "      <td>5.851942e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2020-02-12</td>\n",
       "      <td>2895.5859</td>\n",
       "      <td>2876.6708</td>\n",
       "      <td>2895.9268</td>\n",
       "      <td>2870.7680</td>\n",
       "      <td>2879.8575</td>\n",
       "      <td>15.7284</td>\n",
       "      <td>0.5462</td>\n",
       "      <td>31230750.0</td>\n",
       "      <td>5.212694e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2020-02-13</td>\n",
       "      <td>2875.4794</td>\n",
       "      <td>2898.3985</td>\n",
       "      <td>2906.7218</td>\n",
       "      <td>2871.2649</td>\n",
       "      <td>2895.5859</td>\n",
       "      <td>-20.1065</td>\n",
       "      <td>-0.6944</td>\n",
       "      <td>37434764.0</td>\n",
       "      <td>5.784494e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2022-08-24</td>\n",
       "      <td>2708.0902</td>\n",
       "      <td>2738.3837</td>\n",
       "      <td>2750.8719</td>\n",
       "      <td>2706.1522</td>\n",
       "      <td>2735.6660</td>\n",
       "      <td>-27.5758</td>\n",
       "      <td>-1.0080</td>\n",
       "      <td>30925306.0</td>\n",
       "      <td>6.473540e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2022-08-25</td>\n",
       "      <td>2752.5560</td>\n",
       "      <td>2715.6384</td>\n",
       "      <td>2756.9393</td>\n",
       "      <td>2707.4573</td>\n",
       "      <td>2708.0902</td>\n",
       "      <td>44.4658</td>\n",
       "      <td>1.6420</td>\n",
       "      <td>31964009.0</td>\n",
       "      <td>6.690695e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2022-08-26</td>\n",
       "      <td>2751.5894</td>\n",
       "      <td>2758.5070</td>\n",
       "      <td>2763.6428</td>\n",
       "      <td>2745.5172</td>\n",
       "      <td>2752.5560</td>\n",
       "      <td>-0.9666</td>\n",
       "      <td>-0.0351</td>\n",
       "      <td>26031347.0</td>\n",
       "      <td>5.915288e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2022-08-29</td>\n",
       "      <td>2732.2055</td>\n",
       "      <td>2721.8592</td>\n",
       "      <td>2736.5962</td>\n",
       "      <td>2718.9674</td>\n",
       "      <td>2751.5894</td>\n",
       "      <td>-19.3839</td>\n",
       "      <td>-0.7045</td>\n",
       "      <td>24890507.0</td>\n",
       "      <td>4.933771e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2022-08-30</td>\n",
       "      <td>2726.6602</td>\n",
       "      <td>2731.9805</td>\n",
       "      <td>2741.5952</td>\n",
       "      <td>2705.0459</td>\n",
       "      <td>2732.2055</td>\n",
       "      <td>-5.5453</td>\n",
       "      <td>-0.2030</td>\n",
       "      <td>25930522.0</td>\n",
       "      <td>4.997384e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2022-08-31</td>\n",
       "      <td>2761.7831</td>\n",
       "      <td>2713.2938</td>\n",
       "      <td>2779.6158</td>\n",
       "      <td>2713.2938</td>\n",
       "      <td>2726.6602</td>\n",
       "      <td>35.1229</td>\n",
       "      <td>1.2881</td>\n",
       "      <td>39886395.0</td>\n",
       "      <td>8.449570e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>2732.3990</td>\n",
       "      <td>2750.0334</td>\n",
       "      <td>2757.8794</td>\n",
       "      <td>2731.6963</td>\n",
       "      <td>2761.7831</td>\n",
       "      <td>-29.3841</td>\n",
       "      <td>-1.0640</td>\n",
       "      <td>25422479.0</td>\n",
       "      <td>5.389230e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2022-09-02</td>\n",
       "      <td>2711.2642</td>\n",
       "      <td>2737.1969</td>\n",
       "      <td>2740.6630</td>\n",
       "      <td>2698.3276</td>\n",
       "      <td>2732.3990</td>\n",
       "      <td>-21.1348</td>\n",
       "      <td>-0.7735</td>\n",
       "      <td>22781335.0</td>\n",
       "      <td>4.629397e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2022-09-05</td>\n",
       "      <td>2697.7665</td>\n",
       "      <td>2700.1077</td>\n",
       "      <td>2706.9588</td>\n",
       "      <td>2676.6046</td>\n",
       "      <td>2711.2642</td>\n",
       "      <td>-13.4977</td>\n",
       "      <td>-0.4978</td>\n",
       "      <td>24938690.0</td>\n",
       "      <td>5.355364e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2022-09-06</td>\n",
       "      <td>2724.4980</td>\n",
       "      <td>2706.0966</td>\n",
       "      <td>2726.7159</td>\n",
       "      <td>2703.9982</td>\n",
       "      <td>2697.7665</td>\n",
       "      <td>26.7315</td>\n",
       "      <td>0.9909</td>\n",
       "      <td>29124448.0</td>\n",
       "      <td>5.935016e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2022-09-07</td>\n",
       "      <td>2710.6862</td>\n",
       "      <td>2709.7667</td>\n",
       "      <td>2718.1716</td>\n",
       "      <td>2703.0843</td>\n",
       "      <td>2724.4980</td>\n",
       "      <td>-13.8118</td>\n",
       "      <td>-0.5069</td>\n",
       "      <td>23454754.0</td>\n",
       "      <td>5.220405e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2022-09-08</td>\n",
       "      <td>2708.2782</td>\n",
       "      <td>2714.0277</td>\n",
       "      <td>2725.2493</td>\n",
       "      <td>2707.4661</td>\n",
       "      <td>2710.6862</td>\n",
       "      <td>-2.4080</td>\n",
       "      <td>-0.0888</td>\n",
       "      <td>24209022.0</td>\n",
       "      <td>4.556862e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2022-09-09</td>\n",
       "      <td>2757.5659</td>\n",
       "      <td>2719.0141</td>\n",
       "      <td>2763.1682</td>\n",
       "      <td>2710.7661</td>\n",
       "      <td>2708.2782</td>\n",
       "      <td>49.2877</td>\n",
       "      <td>1.8199</td>\n",
       "      <td>32485640.0</td>\n",
       "      <td>6.684816e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2022-09-13</td>\n",
       "      <td>2769.2348</td>\n",
       "      <td>2769.4104</td>\n",
       "      <td>2781.3967</td>\n",
       "      <td>2751.0927</td>\n",
       "      <td>2757.5659</td>\n",
       "      <td>11.6689</td>\n",
       "      <td>0.4232</td>\n",
       "      <td>29928992.0</td>\n",
       "      <td>6.246759e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2022-09-14</td>\n",
       "      <td>2745.4284</td>\n",
       "      <td>2734.9100</td>\n",
       "      <td>2760.4016</td>\n",
       "      <td>2732.7832</td>\n",
       "      <td>2769.2348</td>\n",
       "      <td>-23.8064</td>\n",
       "      <td>-0.8597</td>\n",
       "      <td>24848499.0</td>\n",
       "      <td>4.615128e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2022-09-15</td>\n",
       "      <td>2743.7886</td>\n",
       "      <td>2753.1287</td>\n",
       "      <td>2769.4571</td>\n",
       "      <td>2728.8354</td>\n",
       "      <td>2745.4284</td>\n",
       "      <td>-1.6398</td>\n",
       "      <td>-0.0597</td>\n",
       "      <td>33698861.0</td>\n",
       "      <td>6.522469e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2022-09-16</td>\n",
       "      <td>2678.0331</td>\n",
       "      <td>2731.9648</td>\n",
       "      <td>2738.6483</td>\n",
       "      <td>2678.0331</td>\n",
       "      <td>2743.7886</td>\n",
       "      <td>-65.7555</td>\n",
       "      <td>-2.3965</td>\n",
       "      <td>38441774.0</td>\n",
       "      <td>6.550020e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2022-09-19</td>\n",
       "      <td>2679.5857</td>\n",
       "      <td>2677.3329</td>\n",
       "      <td>2695.4014</td>\n",
       "      <td>2669.0870</td>\n",
       "      <td>2678.0331</td>\n",
       "      <td>1.5526</td>\n",
       "      <td>0.0580</td>\n",
       "      <td>27260379.0</td>\n",
       "      <td>4.697462e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2022-09-20</td>\n",
       "      <td>2673.8804</td>\n",
       "      <td>2688.1681</td>\n",
       "      <td>2691.5533</td>\n",
       "      <td>2666.6566</td>\n",
       "      <td>2679.5857</td>\n",
       "      <td>-5.7053</td>\n",
       "      <td>-0.2129</td>\n",
       "      <td>23751394.0</td>\n",
       "      <td>4.343682e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2022-09-21</td>\n",
       "      <td>2652.2142</td>\n",
       "      <td>2667.1680</td>\n",
       "      <td>2670.0647</td>\n",
       "      <td>2641.7189</td>\n",
       "      <td>2673.8804</td>\n",
       "      <td>-21.6662</td>\n",
       "      <td>-0.8103</td>\n",
       "      <td>23960147.0</td>\n",
       "      <td>4.560560e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2022-09-22</td>\n",
       "      <td>2629.3701</td>\n",
       "      <td>2631.9968</td>\n",
       "      <td>2645.5662</td>\n",
       "      <td>2621.8224</td>\n",
       "      <td>2652.2142</td>\n",
       "      <td>-22.8441</td>\n",
       "      <td>-0.8613</td>\n",
       "      <td>24229236.0</td>\n",
       "      <td>4.345603e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2022-09-23</td>\n",
       "      <td>2629.8089</td>\n",
       "      <td>2625.2488</td>\n",
       "      <td>2649.8066</td>\n",
       "      <td>2618.9402</td>\n",
       "      <td>2629.3701</td>\n",
       "      <td>0.4388</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>30277934.0</td>\n",
       "      <td>4.635576e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2022-09-26</td>\n",
       "      <td>2614.8998</td>\n",
       "      <td>2612.6673</td>\n",
       "      <td>2650.2542</td>\n",
       "      <td>2611.5292</td>\n",
       "      <td>2629.8089</td>\n",
       "      <td>-14.9091</td>\n",
       "      <td>-0.5669</td>\n",
       "      <td>34384533.0</td>\n",
       "      <td>5.579267e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2022-09-27</td>\n",
       "      <td>2642.9212</td>\n",
       "      <td>2616.0501</td>\n",
       "      <td>2645.7366</td>\n",
       "      <td>2605.2407</td>\n",
       "      <td>2614.8998</td>\n",
       "      <td>28.0214</td>\n",
       "      <td>1.0716</td>\n",
       "      <td>26144970.0</td>\n",
       "      <td>5.021519e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2022-09-28</td>\n",
       "      <td>2611.9815</td>\n",
       "      <td>2635.2559</td>\n",
       "      <td>2637.0155</td>\n",
       "      <td>2608.6405</td>\n",
       "      <td>2642.9212</td>\n",
       "      <td>-30.9397</td>\n",
       "      <td>-1.1707</td>\n",
       "      <td>24732086.0</td>\n",
       "      <td>4.772510e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>666 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ts_code       date      close       open       high        low  \\\n",
       "665  000016.SH 2020-01-02  3090.8331  3073.9313  3107.5172  3073.9313   \n",
       "664  000016.SH 2020-01-03  3078.2793  3097.2518  3097.4088  3072.1137   \n",
       "663  000016.SH 2020-01-06  3056.8359  3062.2801  3090.8402  3040.1945   \n",
       "662  000016.SH 2020-01-07  3074.0152  3063.7464  3080.2714  3061.5608   \n",
       "661  000016.SH 2020-01-08  3037.8525  3058.3585  3058.6969  3030.1048   \n",
       "660  000016.SH 2020-01-09  3067.5456  3060.7743  3071.5392  3055.9906   \n",
       "659  000016.SH 2020-01-10  3067.8810  3079.0765  3081.9568  3058.1642   \n",
       "658  000016.SH 2020-01-13  3090.1284  3069.6784  3090.1310  3054.8783   \n",
       "657  000016.SH 2020-01-14  3080.6016  3097.7248  3108.1770  3078.4579   \n",
       "656  000016.SH 2020-01-15  3058.0078  3078.2528  3086.9662  3052.7047   \n",
       "655  000016.SH 2020-01-16  3043.0931  3067.9500  3068.1971  3039.0726   \n",
       "654  000016.SH 2020-01-17  3053.1729  3054.0361  3067.5589  3042.5897   \n",
       "653  000016.SH 2020-01-20  3065.9906  3070.6701  3072.2888  3054.4484   \n",
       "652  000016.SH 2020-01-21  3012.1123  3048.9459  3050.8233  3011.1846   \n",
       "651  000016.SH 2020-01-22  3017.8785  2996.8099  3023.9019  2965.6635   \n",
       "650  000016.SH 2020-01-23  2932.4932  2993.7726  2993.7726  2910.3942   \n",
       "649  000016.SH 2020-02-03  2727.0931  2676.0073  2755.8448  2676.0073   \n",
       "648  000016.SH 2020-02-04  2794.6606  2724.1314  2796.7145  2724.1314   \n",
       "647  000016.SH 2020-02-05  2812.8993  2803.7374  2833.2097  2782.4231   \n",
       "646  000016.SH 2020-02-06  2854.8878  2829.5111  2866.3906  2809.3661   \n",
       "645  000016.SH 2020-02-07  2851.7105  2836.7992  2851.8244  2819.6678   \n",
       "644  000016.SH 2020-02-10  2850.0642  2826.7970  2854.8289  2817.7707   \n",
       "643  000016.SH 2020-02-11  2879.8575  2858.9245  2893.0673  2854.0722   \n",
       "642  000016.SH 2020-02-12  2895.5859  2876.6708  2895.9268  2870.7680   \n",
       "641  000016.SH 2020-02-13  2875.4794  2898.3985  2906.7218  2871.2649   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "24   000016.SH 2022-08-24  2708.0902  2738.3837  2750.8719  2706.1522   \n",
       "23   000016.SH 2022-08-25  2752.5560  2715.6384  2756.9393  2707.4573   \n",
       "22   000016.SH 2022-08-26  2751.5894  2758.5070  2763.6428  2745.5172   \n",
       "21   000016.SH 2022-08-29  2732.2055  2721.8592  2736.5962  2718.9674   \n",
       "20   000016.SH 2022-08-30  2726.6602  2731.9805  2741.5952  2705.0459   \n",
       "19   000016.SH 2022-08-31  2761.7831  2713.2938  2779.6158  2713.2938   \n",
       "18   000016.SH 2022-09-01  2732.3990  2750.0334  2757.8794  2731.6963   \n",
       "17   000016.SH 2022-09-02  2711.2642  2737.1969  2740.6630  2698.3276   \n",
       "16   000016.SH 2022-09-05  2697.7665  2700.1077  2706.9588  2676.6046   \n",
       "15   000016.SH 2022-09-06  2724.4980  2706.0966  2726.7159  2703.9982   \n",
       "14   000016.SH 2022-09-07  2710.6862  2709.7667  2718.1716  2703.0843   \n",
       "13   000016.SH 2022-09-08  2708.2782  2714.0277  2725.2493  2707.4661   \n",
       "12   000016.SH 2022-09-09  2757.5659  2719.0141  2763.1682  2710.7661   \n",
       "11   000016.SH 2022-09-13  2769.2348  2769.4104  2781.3967  2751.0927   \n",
       "10   000016.SH 2022-09-14  2745.4284  2734.9100  2760.4016  2732.7832   \n",
       "9    000016.SH 2022-09-15  2743.7886  2753.1287  2769.4571  2728.8354   \n",
       "8    000016.SH 2022-09-16  2678.0331  2731.9648  2738.6483  2678.0331   \n",
       "7    000016.SH 2022-09-19  2679.5857  2677.3329  2695.4014  2669.0870   \n",
       "6    000016.SH 2022-09-20  2673.8804  2688.1681  2691.5533  2666.6566   \n",
       "5    000016.SH 2022-09-21  2652.2142  2667.1680  2670.0647  2641.7189   \n",
       "4    000016.SH 2022-09-22  2629.3701  2631.9968  2645.5662  2621.8224   \n",
       "3    000016.SH 2022-09-23  2629.8089  2625.2488  2649.8066  2618.9402   \n",
       "2    000016.SH 2022-09-26  2614.8998  2612.6673  2650.2542  2611.5292   \n",
       "1    000016.SH 2022-09-27  2642.9212  2616.0501  2645.7366  2605.2407   \n",
       "0    000016.SH 2022-09-28  2611.9815  2635.2559  2637.0155  2608.6405   \n",
       "\n",
       "     pre_close    change  pct_chg         vol        amount  \n",
       "665  3063.2190   27.6141   0.9015  50036392.0  9.477373e+07  \n",
       "664  3090.8331  -12.5538  -0.4062  37185493.0  7.234679e+07  \n",
       "663  3078.2793  -21.4434  -0.6966  47707827.0  7.777039e+07  \n",
       "662  3056.8359   17.1793   0.5620  34371788.0  5.688658e+07  \n",
       "661  3074.0152  -36.1627  -1.1764  37653773.0  5.985484e+07  \n",
       "660  3037.8525   29.6931   0.9774  33150515.0  5.767682e+07  \n",
       "659  3067.5456    0.3354   0.0109  28542389.0  5.163493e+07  \n",
       "658  3067.8810   22.2474   0.7252  29330835.0  5.705225e+07  \n",
       "657  3090.1284   -9.5268  -0.3083  35129017.0  5.696145e+07  \n",
       "656  3080.6016  -22.5938  -0.7334  28116086.0  4.697157e+07  \n",
       "655  3058.0078  -14.9147  -0.4877  28312318.0  4.549775e+07  \n",
       "654  3043.0931   10.0798   0.3312  23304514.0  4.622461e+07  \n",
       "653  3053.1729   12.8177   0.4198  27274849.0  5.562321e+07  \n",
       "652  3065.9906  -53.8783  -1.7573  32801291.0  5.974027e+07  \n",
       "651  3012.1123    5.7662   0.1914  33159760.0  6.050915e+07  \n",
       "650  3017.8785  -85.3853  -2.8293  42839352.0  7.550661e+07  \n",
       "649  2932.4932 -205.4001  -7.0043  58609184.0  9.613125e+07  \n",
       "648  2727.0931   67.5675   2.4776  57016369.0  9.185602e+07  \n",
       "647  2794.6606   18.2387   0.6526  44182070.0  7.342200e+07  \n",
       "646  2812.8993   41.9885   1.4927  42134251.0  7.041728e+07  \n",
       "645  2854.8878   -3.1773  -0.1113  34443628.0  5.906509e+07  \n",
       "644  2851.7105   -1.6463  -0.0577  33654934.0  5.664824e+07  \n",
       "643  2850.0642   29.7933   1.0454  36028244.0  5.851942e+07  \n",
       "642  2879.8575   15.7284   0.5462  31230750.0  5.212694e+07  \n",
       "641  2895.5859  -20.1065  -0.6944  37434764.0  5.784494e+07  \n",
       "..         ...       ...      ...         ...           ...  \n",
       "24   2735.6660  -27.5758  -1.0080  30925306.0  6.473540e+07  \n",
       "23   2708.0902   44.4658   1.6420  31964009.0  6.690695e+07  \n",
       "22   2752.5560   -0.9666  -0.0351  26031347.0  5.915288e+07  \n",
       "21   2751.5894  -19.3839  -0.7045  24890507.0  4.933771e+07  \n",
       "20   2732.2055   -5.5453  -0.2030  25930522.0  4.997384e+07  \n",
       "19   2726.6602   35.1229   1.2881  39886395.0  8.449570e+07  \n",
       "18   2761.7831  -29.3841  -1.0640  25422479.0  5.389230e+07  \n",
       "17   2732.3990  -21.1348  -0.7735  22781335.0  4.629397e+07  \n",
       "16   2711.2642  -13.4977  -0.4978  24938690.0  5.355364e+07  \n",
       "15   2697.7665   26.7315   0.9909  29124448.0  5.935016e+07  \n",
       "14   2724.4980  -13.8118  -0.5069  23454754.0  5.220405e+07  \n",
       "13   2710.6862   -2.4080  -0.0888  24209022.0  4.556862e+07  \n",
       "12   2708.2782   49.2877   1.8199  32485640.0  6.684816e+07  \n",
       "11   2757.5659   11.6689   0.4232  29928992.0  6.246759e+07  \n",
       "10   2769.2348  -23.8064  -0.8597  24848499.0  4.615128e+07  \n",
       "9    2745.4284   -1.6398  -0.0597  33698861.0  6.522469e+07  \n",
       "8    2743.7886  -65.7555  -2.3965  38441774.0  6.550020e+07  \n",
       "7    2678.0331    1.5526   0.0580  27260379.0  4.697462e+07  \n",
       "6    2679.5857   -5.7053  -0.2129  23751394.0  4.343682e+07  \n",
       "5    2673.8804  -21.6662  -0.8103  23960147.0  4.560560e+07  \n",
       "4    2652.2142  -22.8441  -0.8613  24229236.0  4.345603e+07  \n",
       "3    2629.3701    0.4388   0.0167  30277934.0  4.635576e+07  \n",
       "2    2629.8089  -14.9091  -0.5669  34384533.0  5.579267e+07  \n",
       "1    2614.8998   28.0214   1.0716  26144970.0  5.021519e+07  \n",
       "0    2642.9212  -30.9397  -1.1707  24732086.0  4.772510e+07  \n",
       "\n",
       "[666 rows x 11 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446aae45",
   "metadata": {},
   "source": [
    "### Backtesting Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c35320bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-13T04:36:51.032707Z",
     "start_time": "2022-10-13T04:36:50.986460Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ts_code</th>\n",
       "      <th>close</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>pre_close</th>\n",
       "      <th>change</th>\n",
       "      <th>pct_chg</th>\n",
       "      <th>vol</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>3090.8331</td>\n",
       "      <td>3073.9313</td>\n",
       "      <td>3107.5172</td>\n",
       "      <td>3073.9313</td>\n",
       "      <td>3063.2190</td>\n",
       "      <td>27.6141</td>\n",
       "      <td>0.9015</td>\n",
       "      <td>50036392.0</td>\n",
       "      <td>9.477373e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>3078.2793</td>\n",
       "      <td>3097.2518</td>\n",
       "      <td>3097.4088</td>\n",
       "      <td>3072.1137</td>\n",
       "      <td>3090.8331</td>\n",
       "      <td>-12.5538</td>\n",
       "      <td>-0.4062</td>\n",
       "      <td>37185493.0</td>\n",
       "      <td>7.234679e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>3056.8359</td>\n",
       "      <td>3062.2801</td>\n",
       "      <td>3090.8402</td>\n",
       "      <td>3040.1945</td>\n",
       "      <td>3078.2793</td>\n",
       "      <td>-21.4434</td>\n",
       "      <td>-0.6966</td>\n",
       "      <td>47707827.0</td>\n",
       "      <td>7.777039e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>3074.0152</td>\n",
       "      <td>3063.7464</td>\n",
       "      <td>3080.2714</td>\n",
       "      <td>3061.5608</td>\n",
       "      <td>3056.8359</td>\n",
       "      <td>17.1793</td>\n",
       "      <td>0.5620</td>\n",
       "      <td>34371788.0</td>\n",
       "      <td>5.688658e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>3037.8525</td>\n",
       "      <td>3058.3585</td>\n",
       "      <td>3058.6969</td>\n",
       "      <td>3030.1048</td>\n",
       "      <td>3074.0152</td>\n",
       "      <td>-36.1627</td>\n",
       "      <td>-1.1764</td>\n",
       "      <td>37653773.0</td>\n",
       "      <td>5.985484e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-01-09</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>3067.5456</td>\n",
       "      <td>3060.7743</td>\n",
       "      <td>3071.5392</td>\n",
       "      <td>3055.9906</td>\n",
       "      <td>3037.8525</td>\n",
       "      <td>29.6931</td>\n",
       "      <td>0.9774</td>\n",
       "      <td>33150515.0</td>\n",
       "      <td>5.767682e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-01-10</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>3067.8810</td>\n",
       "      <td>3079.0765</td>\n",
       "      <td>3081.9568</td>\n",
       "      <td>3058.1642</td>\n",
       "      <td>3067.5456</td>\n",
       "      <td>0.3354</td>\n",
       "      <td>0.0109</td>\n",
       "      <td>28542389.0</td>\n",
       "      <td>5.163493e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-01-13</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>3090.1284</td>\n",
       "      <td>3069.6784</td>\n",
       "      <td>3090.1310</td>\n",
       "      <td>3054.8783</td>\n",
       "      <td>3067.8810</td>\n",
       "      <td>22.2474</td>\n",
       "      <td>0.7252</td>\n",
       "      <td>29330835.0</td>\n",
       "      <td>5.705225e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-01-14</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>3080.6016</td>\n",
       "      <td>3097.7248</td>\n",
       "      <td>3108.1770</td>\n",
       "      <td>3078.4579</td>\n",
       "      <td>3090.1284</td>\n",
       "      <td>-9.5268</td>\n",
       "      <td>-0.3083</td>\n",
       "      <td>35129017.0</td>\n",
       "      <td>5.696145e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-01-15</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>3058.0078</td>\n",
       "      <td>3078.2528</td>\n",
       "      <td>3086.9662</td>\n",
       "      <td>3052.7047</td>\n",
       "      <td>3080.6016</td>\n",
       "      <td>-22.5938</td>\n",
       "      <td>-0.7334</td>\n",
       "      <td>28116086.0</td>\n",
       "      <td>4.697157e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2020-01-16</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>3043.0931</td>\n",
       "      <td>3067.9500</td>\n",
       "      <td>3068.1971</td>\n",
       "      <td>3039.0726</td>\n",
       "      <td>3058.0078</td>\n",
       "      <td>-14.9147</td>\n",
       "      <td>-0.4877</td>\n",
       "      <td>28312318.0</td>\n",
       "      <td>4.549775e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2020-01-17</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>3053.1729</td>\n",
       "      <td>3054.0361</td>\n",
       "      <td>3067.5589</td>\n",
       "      <td>3042.5897</td>\n",
       "      <td>3043.0931</td>\n",
       "      <td>10.0798</td>\n",
       "      <td>0.3312</td>\n",
       "      <td>23304514.0</td>\n",
       "      <td>4.622461e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2020-01-20</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>3065.9906</td>\n",
       "      <td>3070.6701</td>\n",
       "      <td>3072.2888</td>\n",
       "      <td>3054.4484</td>\n",
       "      <td>3053.1729</td>\n",
       "      <td>12.8177</td>\n",
       "      <td>0.4198</td>\n",
       "      <td>27274849.0</td>\n",
       "      <td>5.562321e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2020-01-21</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>3012.1123</td>\n",
       "      <td>3048.9459</td>\n",
       "      <td>3050.8233</td>\n",
       "      <td>3011.1846</td>\n",
       "      <td>3065.9906</td>\n",
       "      <td>-53.8783</td>\n",
       "      <td>-1.7573</td>\n",
       "      <td>32801291.0</td>\n",
       "      <td>5.974027e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>3017.8785</td>\n",
       "      <td>2996.8099</td>\n",
       "      <td>3023.9019</td>\n",
       "      <td>2965.6635</td>\n",
       "      <td>3012.1123</td>\n",
       "      <td>5.7662</td>\n",
       "      <td>0.1914</td>\n",
       "      <td>33159760.0</td>\n",
       "      <td>6.050915e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2932.4932</td>\n",
       "      <td>2993.7726</td>\n",
       "      <td>2993.7726</td>\n",
       "      <td>2910.3942</td>\n",
       "      <td>3017.8785</td>\n",
       "      <td>-85.3853</td>\n",
       "      <td>-2.8293</td>\n",
       "      <td>42839352.0</td>\n",
       "      <td>7.550661e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2020-02-03</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2727.0931</td>\n",
       "      <td>2676.0073</td>\n",
       "      <td>2755.8448</td>\n",
       "      <td>2676.0073</td>\n",
       "      <td>2932.4932</td>\n",
       "      <td>-205.4001</td>\n",
       "      <td>-7.0043</td>\n",
       "      <td>58609184.0</td>\n",
       "      <td>9.613125e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2020-02-04</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2794.6606</td>\n",
       "      <td>2724.1314</td>\n",
       "      <td>2796.7145</td>\n",
       "      <td>2724.1314</td>\n",
       "      <td>2727.0931</td>\n",
       "      <td>67.5675</td>\n",
       "      <td>2.4776</td>\n",
       "      <td>57016369.0</td>\n",
       "      <td>9.185602e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2020-02-05</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2812.8993</td>\n",
       "      <td>2803.7374</td>\n",
       "      <td>2833.2097</td>\n",
       "      <td>2782.4231</td>\n",
       "      <td>2794.6606</td>\n",
       "      <td>18.2387</td>\n",
       "      <td>0.6526</td>\n",
       "      <td>44182070.0</td>\n",
       "      <td>7.342200e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2020-02-06</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2854.8878</td>\n",
       "      <td>2829.5111</td>\n",
       "      <td>2866.3906</td>\n",
       "      <td>2809.3661</td>\n",
       "      <td>2812.8993</td>\n",
       "      <td>41.9885</td>\n",
       "      <td>1.4927</td>\n",
       "      <td>42134251.0</td>\n",
       "      <td>7.041728e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2020-02-07</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2851.7105</td>\n",
       "      <td>2836.7992</td>\n",
       "      <td>2851.8244</td>\n",
       "      <td>2819.6678</td>\n",
       "      <td>2854.8878</td>\n",
       "      <td>-3.1773</td>\n",
       "      <td>-0.1113</td>\n",
       "      <td>34443628.0</td>\n",
       "      <td>5.906509e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2020-02-10</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2850.0642</td>\n",
       "      <td>2826.7970</td>\n",
       "      <td>2854.8289</td>\n",
       "      <td>2817.7707</td>\n",
       "      <td>2851.7105</td>\n",
       "      <td>-1.6463</td>\n",
       "      <td>-0.0577</td>\n",
       "      <td>33654934.0</td>\n",
       "      <td>5.664824e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2020-02-11</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2879.8575</td>\n",
       "      <td>2858.9245</td>\n",
       "      <td>2893.0673</td>\n",
       "      <td>2854.0722</td>\n",
       "      <td>2850.0642</td>\n",
       "      <td>29.7933</td>\n",
       "      <td>1.0454</td>\n",
       "      <td>36028244.0</td>\n",
       "      <td>5.851942e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2020-02-12</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2895.5859</td>\n",
       "      <td>2876.6708</td>\n",
       "      <td>2895.9268</td>\n",
       "      <td>2870.7680</td>\n",
       "      <td>2879.8575</td>\n",
       "      <td>15.7284</td>\n",
       "      <td>0.5462</td>\n",
       "      <td>31230750.0</td>\n",
       "      <td>5.212694e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2020-02-13</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2875.4794</td>\n",
       "      <td>2898.3985</td>\n",
       "      <td>2906.7218</td>\n",
       "      <td>2871.2649</td>\n",
       "      <td>2895.5859</td>\n",
       "      <td>-20.1065</td>\n",
       "      <td>-0.6944</td>\n",
       "      <td>37434764.0</td>\n",
       "      <td>5.784494e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>2022-08-25</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2752.5560</td>\n",
       "      <td>2715.6384</td>\n",
       "      <td>2756.9393</td>\n",
       "      <td>2707.4573</td>\n",
       "      <td>2708.0902</td>\n",
       "      <td>44.4658</td>\n",
       "      <td>1.6420</td>\n",
       "      <td>31964009.0</td>\n",
       "      <td>6.690695e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>2022-08-26</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2751.5894</td>\n",
       "      <td>2758.5070</td>\n",
       "      <td>2763.6428</td>\n",
       "      <td>2745.5172</td>\n",
       "      <td>2752.5560</td>\n",
       "      <td>-0.9666</td>\n",
       "      <td>-0.0351</td>\n",
       "      <td>26031347.0</td>\n",
       "      <td>5.915288e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>2022-08-29</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2732.2055</td>\n",
       "      <td>2721.8592</td>\n",
       "      <td>2736.5962</td>\n",
       "      <td>2718.9674</td>\n",
       "      <td>2751.5894</td>\n",
       "      <td>-19.3839</td>\n",
       "      <td>-0.7045</td>\n",
       "      <td>24890507.0</td>\n",
       "      <td>4.933771e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>2022-08-30</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2726.6602</td>\n",
       "      <td>2731.9805</td>\n",
       "      <td>2741.5952</td>\n",
       "      <td>2705.0459</td>\n",
       "      <td>2732.2055</td>\n",
       "      <td>-5.5453</td>\n",
       "      <td>-0.2030</td>\n",
       "      <td>25930522.0</td>\n",
       "      <td>4.997384e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>2022-08-31</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2761.7831</td>\n",
       "      <td>2713.2938</td>\n",
       "      <td>2779.6158</td>\n",
       "      <td>2713.2938</td>\n",
       "      <td>2726.6602</td>\n",
       "      <td>35.1229</td>\n",
       "      <td>1.2881</td>\n",
       "      <td>39886395.0</td>\n",
       "      <td>8.449570e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2732.3990</td>\n",
       "      <td>2750.0334</td>\n",
       "      <td>2757.8794</td>\n",
       "      <td>2731.6963</td>\n",
       "      <td>2761.7831</td>\n",
       "      <td>-29.3841</td>\n",
       "      <td>-1.0640</td>\n",
       "      <td>25422479.0</td>\n",
       "      <td>5.389230e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>2022-09-02</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2711.2642</td>\n",
       "      <td>2737.1969</td>\n",
       "      <td>2740.6630</td>\n",
       "      <td>2698.3276</td>\n",
       "      <td>2732.3990</td>\n",
       "      <td>-21.1348</td>\n",
       "      <td>-0.7735</td>\n",
       "      <td>22781335.0</td>\n",
       "      <td>4.629397e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>2022-09-05</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2697.7665</td>\n",
       "      <td>2700.1077</td>\n",
       "      <td>2706.9588</td>\n",
       "      <td>2676.6046</td>\n",
       "      <td>2711.2642</td>\n",
       "      <td>-13.4977</td>\n",
       "      <td>-0.4978</td>\n",
       "      <td>24938690.0</td>\n",
       "      <td>5.355364e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>2022-09-06</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2724.4980</td>\n",
       "      <td>2706.0966</td>\n",
       "      <td>2726.7159</td>\n",
       "      <td>2703.9982</td>\n",
       "      <td>2697.7665</td>\n",
       "      <td>26.7315</td>\n",
       "      <td>0.9909</td>\n",
       "      <td>29124448.0</td>\n",
       "      <td>5.935016e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>2022-09-07</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2710.6862</td>\n",
       "      <td>2709.7667</td>\n",
       "      <td>2718.1716</td>\n",
       "      <td>2703.0843</td>\n",
       "      <td>2724.4980</td>\n",
       "      <td>-13.8118</td>\n",
       "      <td>-0.5069</td>\n",
       "      <td>23454754.0</td>\n",
       "      <td>5.220405e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>2022-09-08</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2708.2782</td>\n",
       "      <td>2714.0277</td>\n",
       "      <td>2725.2493</td>\n",
       "      <td>2707.4661</td>\n",
       "      <td>2710.6862</td>\n",
       "      <td>-2.4080</td>\n",
       "      <td>-0.0888</td>\n",
       "      <td>24209022.0</td>\n",
       "      <td>4.556862e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>2022-09-09</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2757.5659</td>\n",
       "      <td>2719.0141</td>\n",
       "      <td>2763.1682</td>\n",
       "      <td>2710.7661</td>\n",
       "      <td>2708.2782</td>\n",
       "      <td>49.2877</td>\n",
       "      <td>1.8199</td>\n",
       "      <td>32485640.0</td>\n",
       "      <td>6.684816e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>2022-09-13</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2769.2348</td>\n",
       "      <td>2769.4104</td>\n",
       "      <td>2781.3967</td>\n",
       "      <td>2751.0927</td>\n",
       "      <td>2757.5659</td>\n",
       "      <td>11.6689</td>\n",
       "      <td>0.4232</td>\n",
       "      <td>29928992.0</td>\n",
       "      <td>6.246759e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>2022-09-14</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2745.4284</td>\n",
       "      <td>2734.9100</td>\n",
       "      <td>2760.4016</td>\n",
       "      <td>2732.7832</td>\n",
       "      <td>2769.2348</td>\n",
       "      <td>-23.8064</td>\n",
       "      <td>-0.8597</td>\n",
       "      <td>24848499.0</td>\n",
       "      <td>4.615128e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>2022-09-15</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2743.7886</td>\n",
       "      <td>2753.1287</td>\n",
       "      <td>2769.4571</td>\n",
       "      <td>2728.8354</td>\n",
       "      <td>2745.4284</td>\n",
       "      <td>-1.6398</td>\n",
       "      <td>-0.0597</td>\n",
       "      <td>33698861.0</td>\n",
       "      <td>6.522469e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>2022-09-16</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2678.0331</td>\n",
       "      <td>2731.9648</td>\n",
       "      <td>2738.6483</td>\n",
       "      <td>2678.0331</td>\n",
       "      <td>2743.7886</td>\n",
       "      <td>-65.7555</td>\n",
       "      <td>-2.3965</td>\n",
       "      <td>38441774.0</td>\n",
       "      <td>6.550020e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>2022-09-19</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2679.5857</td>\n",
       "      <td>2677.3329</td>\n",
       "      <td>2695.4014</td>\n",
       "      <td>2669.0870</td>\n",
       "      <td>2678.0331</td>\n",
       "      <td>1.5526</td>\n",
       "      <td>0.0580</td>\n",
       "      <td>27260379.0</td>\n",
       "      <td>4.697462e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>2022-09-20</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2673.8804</td>\n",
       "      <td>2688.1681</td>\n",
       "      <td>2691.5533</td>\n",
       "      <td>2666.6566</td>\n",
       "      <td>2679.5857</td>\n",
       "      <td>-5.7053</td>\n",
       "      <td>-0.2129</td>\n",
       "      <td>23751394.0</td>\n",
       "      <td>4.343682e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>2022-09-21</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2652.2142</td>\n",
       "      <td>2667.1680</td>\n",
       "      <td>2670.0647</td>\n",
       "      <td>2641.7189</td>\n",
       "      <td>2673.8804</td>\n",
       "      <td>-21.6662</td>\n",
       "      <td>-0.8103</td>\n",
       "      <td>23960147.0</td>\n",
       "      <td>4.560560e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>2022-09-22</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2629.3701</td>\n",
       "      <td>2631.9968</td>\n",
       "      <td>2645.5662</td>\n",
       "      <td>2621.8224</td>\n",
       "      <td>2652.2142</td>\n",
       "      <td>-22.8441</td>\n",
       "      <td>-0.8613</td>\n",
       "      <td>24229236.0</td>\n",
       "      <td>4.345603e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>2022-09-23</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2629.8089</td>\n",
       "      <td>2625.2488</td>\n",
       "      <td>2649.8066</td>\n",
       "      <td>2618.9402</td>\n",
       "      <td>2629.3701</td>\n",
       "      <td>0.4388</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>30277934.0</td>\n",
       "      <td>4.635576e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>2022-09-26</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2614.8998</td>\n",
       "      <td>2612.6673</td>\n",
       "      <td>2650.2542</td>\n",
       "      <td>2611.5292</td>\n",
       "      <td>2629.8089</td>\n",
       "      <td>-14.9091</td>\n",
       "      <td>-0.5669</td>\n",
       "      <td>34384533.0</td>\n",
       "      <td>5.579267e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>2022-09-27</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2642.9212</td>\n",
       "      <td>2616.0501</td>\n",
       "      <td>2645.7366</td>\n",
       "      <td>2605.2407</td>\n",
       "      <td>2614.8998</td>\n",
       "      <td>28.0214</td>\n",
       "      <td>1.0716</td>\n",
       "      <td>26144970.0</td>\n",
       "      <td>5.021519e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>2022-09-28</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2611.9815</td>\n",
       "      <td>2635.2559</td>\n",
       "      <td>2637.0155</td>\n",
       "      <td>2608.6405</td>\n",
       "      <td>2642.9212</td>\n",
       "      <td>-30.9397</td>\n",
       "      <td>-1.1707</td>\n",
       "      <td>24732086.0</td>\n",
       "      <td>4.772510e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>2022-09-29</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2611.9815</td>\n",
       "      <td>2635.2559</td>\n",
       "      <td>2637.0155</td>\n",
       "      <td>2608.6405</td>\n",
       "      <td>2642.9212</td>\n",
       "      <td>-30.9397</td>\n",
       "      <td>-1.1707</td>\n",
       "      <td>24732086.0</td>\n",
       "      <td>4.772510e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>667 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date    ts_code      close       open       high        low  \\\n",
       "0   2020-01-02  000016.SH  3090.8331  3073.9313  3107.5172  3073.9313   \n",
       "1   2020-01-03  000016.SH  3078.2793  3097.2518  3097.4088  3072.1137   \n",
       "2   2020-01-06  000016.SH  3056.8359  3062.2801  3090.8402  3040.1945   \n",
       "3   2020-01-07  000016.SH  3074.0152  3063.7464  3080.2714  3061.5608   \n",
       "4   2020-01-08  000016.SH  3037.8525  3058.3585  3058.6969  3030.1048   \n",
       "5   2020-01-09  000016.SH  3067.5456  3060.7743  3071.5392  3055.9906   \n",
       "6   2020-01-10  000016.SH  3067.8810  3079.0765  3081.9568  3058.1642   \n",
       "7   2020-01-13  000016.SH  3090.1284  3069.6784  3090.1310  3054.8783   \n",
       "8   2020-01-14  000016.SH  3080.6016  3097.7248  3108.1770  3078.4579   \n",
       "9   2020-01-15  000016.SH  3058.0078  3078.2528  3086.9662  3052.7047   \n",
       "10  2020-01-16  000016.SH  3043.0931  3067.9500  3068.1971  3039.0726   \n",
       "11  2020-01-17  000016.SH  3053.1729  3054.0361  3067.5589  3042.5897   \n",
       "12  2020-01-20  000016.SH  3065.9906  3070.6701  3072.2888  3054.4484   \n",
       "13  2020-01-21  000016.SH  3012.1123  3048.9459  3050.8233  3011.1846   \n",
       "14  2020-01-22  000016.SH  3017.8785  2996.8099  3023.9019  2965.6635   \n",
       "15  2020-01-23  000016.SH  2932.4932  2993.7726  2993.7726  2910.3942   \n",
       "16  2020-02-03  000016.SH  2727.0931  2676.0073  2755.8448  2676.0073   \n",
       "17  2020-02-04  000016.SH  2794.6606  2724.1314  2796.7145  2724.1314   \n",
       "18  2020-02-05  000016.SH  2812.8993  2803.7374  2833.2097  2782.4231   \n",
       "19  2020-02-06  000016.SH  2854.8878  2829.5111  2866.3906  2809.3661   \n",
       "20  2020-02-07  000016.SH  2851.7105  2836.7992  2851.8244  2819.6678   \n",
       "21  2020-02-10  000016.SH  2850.0642  2826.7970  2854.8289  2817.7707   \n",
       "22  2020-02-11  000016.SH  2879.8575  2858.9245  2893.0673  2854.0722   \n",
       "23  2020-02-12  000016.SH  2895.5859  2876.6708  2895.9268  2870.7680   \n",
       "24  2020-02-13  000016.SH  2875.4794  2898.3985  2906.7218  2871.2649   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "642 2022-08-25  000016.SH  2752.5560  2715.6384  2756.9393  2707.4573   \n",
       "643 2022-08-26  000016.SH  2751.5894  2758.5070  2763.6428  2745.5172   \n",
       "644 2022-08-29  000016.SH  2732.2055  2721.8592  2736.5962  2718.9674   \n",
       "645 2022-08-30  000016.SH  2726.6602  2731.9805  2741.5952  2705.0459   \n",
       "646 2022-08-31  000016.SH  2761.7831  2713.2938  2779.6158  2713.2938   \n",
       "647 2022-09-01  000016.SH  2732.3990  2750.0334  2757.8794  2731.6963   \n",
       "648 2022-09-02  000016.SH  2711.2642  2737.1969  2740.6630  2698.3276   \n",
       "649 2022-09-05  000016.SH  2697.7665  2700.1077  2706.9588  2676.6046   \n",
       "650 2022-09-06  000016.SH  2724.4980  2706.0966  2726.7159  2703.9982   \n",
       "651 2022-09-07  000016.SH  2710.6862  2709.7667  2718.1716  2703.0843   \n",
       "652 2022-09-08  000016.SH  2708.2782  2714.0277  2725.2493  2707.4661   \n",
       "653 2022-09-09  000016.SH  2757.5659  2719.0141  2763.1682  2710.7661   \n",
       "654 2022-09-13  000016.SH  2769.2348  2769.4104  2781.3967  2751.0927   \n",
       "655 2022-09-14  000016.SH  2745.4284  2734.9100  2760.4016  2732.7832   \n",
       "656 2022-09-15  000016.SH  2743.7886  2753.1287  2769.4571  2728.8354   \n",
       "657 2022-09-16  000016.SH  2678.0331  2731.9648  2738.6483  2678.0331   \n",
       "658 2022-09-19  000016.SH  2679.5857  2677.3329  2695.4014  2669.0870   \n",
       "659 2022-09-20  000016.SH  2673.8804  2688.1681  2691.5533  2666.6566   \n",
       "660 2022-09-21  000016.SH  2652.2142  2667.1680  2670.0647  2641.7189   \n",
       "661 2022-09-22  000016.SH  2629.3701  2631.9968  2645.5662  2621.8224   \n",
       "662 2022-09-23  000016.SH  2629.8089  2625.2488  2649.8066  2618.9402   \n",
       "663 2022-09-26  000016.SH  2614.8998  2612.6673  2650.2542  2611.5292   \n",
       "664 2022-09-27  000016.SH  2642.9212  2616.0501  2645.7366  2605.2407   \n",
       "665 2022-09-28  000016.SH  2611.9815  2635.2559  2637.0155  2608.6405   \n",
       "666 2022-09-29  000016.SH  2611.9815  2635.2559  2637.0155  2608.6405   \n",
       "\n",
       "     pre_close    change  pct_chg         vol        amount  \n",
       "0    3063.2190   27.6141   0.9015  50036392.0  9.477373e+07  \n",
       "1    3090.8331  -12.5538  -0.4062  37185493.0  7.234679e+07  \n",
       "2    3078.2793  -21.4434  -0.6966  47707827.0  7.777039e+07  \n",
       "3    3056.8359   17.1793   0.5620  34371788.0  5.688658e+07  \n",
       "4    3074.0152  -36.1627  -1.1764  37653773.0  5.985484e+07  \n",
       "5    3037.8525   29.6931   0.9774  33150515.0  5.767682e+07  \n",
       "6    3067.5456    0.3354   0.0109  28542389.0  5.163493e+07  \n",
       "7    3067.8810   22.2474   0.7252  29330835.0  5.705225e+07  \n",
       "8    3090.1284   -9.5268  -0.3083  35129017.0  5.696145e+07  \n",
       "9    3080.6016  -22.5938  -0.7334  28116086.0  4.697157e+07  \n",
       "10   3058.0078  -14.9147  -0.4877  28312318.0  4.549775e+07  \n",
       "11   3043.0931   10.0798   0.3312  23304514.0  4.622461e+07  \n",
       "12   3053.1729   12.8177   0.4198  27274849.0  5.562321e+07  \n",
       "13   3065.9906  -53.8783  -1.7573  32801291.0  5.974027e+07  \n",
       "14   3012.1123    5.7662   0.1914  33159760.0  6.050915e+07  \n",
       "15   3017.8785  -85.3853  -2.8293  42839352.0  7.550661e+07  \n",
       "16   2932.4932 -205.4001  -7.0043  58609184.0  9.613125e+07  \n",
       "17   2727.0931   67.5675   2.4776  57016369.0  9.185602e+07  \n",
       "18   2794.6606   18.2387   0.6526  44182070.0  7.342200e+07  \n",
       "19   2812.8993   41.9885   1.4927  42134251.0  7.041728e+07  \n",
       "20   2854.8878   -3.1773  -0.1113  34443628.0  5.906509e+07  \n",
       "21   2851.7105   -1.6463  -0.0577  33654934.0  5.664824e+07  \n",
       "22   2850.0642   29.7933   1.0454  36028244.0  5.851942e+07  \n",
       "23   2879.8575   15.7284   0.5462  31230750.0  5.212694e+07  \n",
       "24   2895.5859  -20.1065  -0.6944  37434764.0  5.784494e+07  \n",
       "..         ...       ...      ...         ...           ...  \n",
       "642  2708.0902   44.4658   1.6420  31964009.0  6.690695e+07  \n",
       "643  2752.5560   -0.9666  -0.0351  26031347.0  5.915288e+07  \n",
       "644  2751.5894  -19.3839  -0.7045  24890507.0  4.933771e+07  \n",
       "645  2732.2055   -5.5453  -0.2030  25930522.0  4.997384e+07  \n",
       "646  2726.6602   35.1229   1.2881  39886395.0  8.449570e+07  \n",
       "647  2761.7831  -29.3841  -1.0640  25422479.0  5.389230e+07  \n",
       "648  2732.3990  -21.1348  -0.7735  22781335.0  4.629397e+07  \n",
       "649  2711.2642  -13.4977  -0.4978  24938690.0  5.355364e+07  \n",
       "650  2697.7665   26.7315   0.9909  29124448.0  5.935016e+07  \n",
       "651  2724.4980  -13.8118  -0.5069  23454754.0  5.220405e+07  \n",
       "652  2710.6862   -2.4080  -0.0888  24209022.0  4.556862e+07  \n",
       "653  2708.2782   49.2877   1.8199  32485640.0  6.684816e+07  \n",
       "654  2757.5659   11.6689   0.4232  29928992.0  6.246759e+07  \n",
       "655  2769.2348  -23.8064  -0.8597  24848499.0  4.615128e+07  \n",
       "656  2745.4284   -1.6398  -0.0597  33698861.0  6.522469e+07  \n",
       "657  2743.7886  -65.7555  -2.3965  38441774.0  6.550020e+07  \n",
       "658  2678.0331    1.5526   0.0580  27260379.0  4.697462e+07  \n",
       "659  2679.5857   -5.7053  -0.2129  23751394.0  4.343682e+07  \n",
       "660  2673.8804  -21.6662  -0.8103  23960147.0  4.560560e+07  \n",
       "661  2652.2142  -22.8441  -0.8613  24229236.0  4.345603e+07  \n",
       "662  2629.3701    0.4388   0.0167  30277934.0  4.635576e+07  \n",
       "663  2629.8089  -14.9091  -0.5669  34384533.0  5.579267e+07  \n",
       "664  2614.8998   28.0214   1.0716  26144970.0  5.021519e+07  \n",
       "665  2642.9212  -30.9397  -1.1707  24732086.0  4.772510e+07  \n",
       "666  2642.9212  -30.9397  -1.1707  24732086.0  4.772510e+07  \n",
       "\n",
       "[667 rows x 11 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure the baseline and backtest results have the same time period\n",
    "df_account_value['date'] = pd.to_datetime(df_account_value['date'])\n",
    "baseline_df[\"date\"] = pd.to_datetime(baseline_df[\"date\"], format=\"%Y%m%d\")\n",
    "baseline_df = pd.merge(df_account_value[['date']], baseline_df, on='date', how='left')\n",
    "baseline_df = baseline_df.fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
    "baseline_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d5e2b788",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-13T04:37:02.997649Z",
     "start_time": "2022-10-13T04:36:54.128917Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\"><th>Start date</th><td colspan=2>2020-01-02</td></tr>\n",
       "    <tr style=\"text-align: right;\"><th>End date</th><td colspan=2>2022-09-29</td></tr>\n",
       "    <tr style=\"text-align: right;\"><th>Total months</th><td colspan=2>31</td></tr>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Backtest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Annual return</th>\n",
       "      <td>19.167%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cumulative returns</th>\n",
       "      <td>59.066%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Annual volatility</th>\n",
       "      <td>26.273%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sharpe ratio</th>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Calmar ratio</th>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stability</th>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max drawdown</th>\n",
       "      <td>-30.57%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Omega ratio</th>\n",
       "      <td>1.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sortino ratio</th>\n",
       "      <td>1.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Skew</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kurtosis</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tail ratio</th>\n",
       "      <td>1.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Daily value at risk</th>\n",
       "      <td>-3.227%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alpha</th>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beta</th>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Worst drawdown periods</th>\n",
       "      <th>Net drawdown in %</th>\n",
       "      <th>Peak date</th>\n",
       "      <th>Valley date</th>\n",
       "      <th>Recovery date</th>\n",
       "      <th>Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30.57</td>\n",
       "      <td>2021-12-13</td>\n",
       "      <td>2022-09-23</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.22</td>\n",
       "      <td>2021-02-18</td>\n",
       "      <td>2021-03-09</td>\n",
       "      <td>2021-09-17</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.98</td>\n",
       "      <td>2020-03-05</td>\n",
       "      <td>2020-03-23</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.56</td>\n",
       "      <td>2020-01-20</td>\n",
       "      <td>2020-02-03</td>\n",
       "      <td>2020-03-04</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.43</td>\n",
       "      <td>2020-07-15</td>\n",
       "      <td>2020-07-16</td>\n",
       "      <td>2020-07-30</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Stress Events</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>New Normal</th>\n",
       "      <td>0.08%</td>\n",
       "      <td>-7.43%</td>\n",
       "      <td>5.28%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"870.631256pt\" height=\"3576.760469pt\" viewBox=\"0 0 870.631256 3576.760469\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2022-10-18T19:00:38.739083</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.5.3, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 3576.760469 \nL 870.631256 3576.760469 \nL 870.631256 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 75.177125 526.818509 \nL 856.377125 526.818509 \nL 856.377125 23.229937 \nL 75.177125 23.229937 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path id=\"m3df85e8871\" d=\"M 0 0 \nL 0 6 \n\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"109.976744\" y=\"526.818509\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"195.822897\" y=\"526.818509\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"283.087996\" y=\"526.818509\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"369.643622\" y=\"526.818509\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"454.780304\" y=\"526.818509\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"542.045402\" y=\"526.818509\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"628.601028\" y=\"526.818509\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"713.73771\" y=\"526.818509\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_9\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"801.002808\" y=\"526.818509\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_10\">\n     <g id=\"line2d_10\">\n      <defs>\n       <path id=\"m3466dc2b85\" d=\"M 0 0 \nL 0 4 \n\" style=\"stroke: #000000\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m3466dc2b85\" x=\"207.883927\" y=\"526.818509\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_11\">\n     <g id=\"line2d_11\">\n      <g>\n       <use xlink:href=\"#m3466dc2b85\" x=\"349.778396\" y=\"526.818509\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_12\">\n     <g id=\"line2d_12\">\n      <g>\n       <use xlink:href=\"#m3466dc2b85\" x=\"491.672866\" y=\"526.818509\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_13\">\n     <g id=\"line2d_13\">\n      <g>\n       <use xlink:href=\"#m3466dc2b85\" x=\"633.567335\" y=\"526.818509\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_14\">\n     <g id=\"line2d_14\">\n      <g>\n       <use xlink:href=\"#m3466dc2b85\" x=\"775.461804\" y=\"526.818509\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_15\">\n      <defs>\n       <path id=\"m3e69cb0aea\" d=\"M 0 0 \nL -6 0 \n\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"512.803563\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0.80 -->\n      <g transform=\"translate(38.735719 517.400617)scale(0.121 -0.121)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_16\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"449.706021\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 1.00 -->\n      <g transform=\"translate(38.735719 454.303076)scale(0.121 -0.121)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_17\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"386.60848\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 1.20 -->\n      <g transform=\"translate(38.735719 391.205535)scale(0.121 -0.121)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_18\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"323.510939\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 1.40 -->\n      <g transform=\"translate(38.735719 328.107993)scale(0.121 -0.121)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_19\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"260.413397\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 1.60 -->\n      <g transform=\"translate(38.735719 265.010452)scale(0.121 -0.121)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_20\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"197.315856\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 1.80 -->\n      <g transform=\"translate(38.735719 201.912911)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_21\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"134.218315\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 2.00 -->\n      <g transform=\"translate(38.735719 138.815369)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_22\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"71.120773\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 2.20 -->\n      <g transform=\"translate(38.735719 75.717828)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_9\">\n     <!-- Cumulative returns -->\n     <g transform=\"translate(31.990531 338.405879)rotate(-90)scale(0.132 -0.132)\">\n      <defs>\n       <path id=\"DejaVuSans-43\" d=\"M 4122 4306 \nL 4122 3641 \nQ 3803 3938 3442 4084 \nQ 3081 4231 2675 4231 \nQ 1875 4231 1450 3742 \nQ 1025 3253 1025 2328 \nQ 1025 1406 1450 917 \nQ 1875 428 2675 428 \nQ 3081 428 3442 575 \nQ 3803 722 4122 1019 \nL 4122 359 \nQ 3791 134 3420 21 \nQ 3050 -91 2638 -91 \nQ 1578 -91 968 557 \nQ 359 1206 359 2328 \nQ 359 3453 968 4101 \nQ 1578 4750 2638 4750 \nQ 3056 4750 3426 4639 \nQ 3797 4528 4122 4306 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-75\" d=\"M 544 1381 \nL 544 3500 \nL 1119 3500 \nL 1119 1403 \nQ 1119 906 1312 657 \nQ 1506 409 1894 409 \nQ 2359 409 2629 706 \nQ 2900 1003 2900 1516 \nL 2900 3500 \nL 3475 3500 \nL 3475 0 \nL 2900 0 \nL 2900 538 \nQ 2691 219 2414 64 \nQ 2138 -91 1772 -91 \nQ 1169 -91 856 284 \nQ 544 659 544 1381 \nz\nM 1991 3584 \nL 1991 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6d\" d=\"M 3328 2828 \nQ 3544 3216 3844 3400 \nQ 4144 3584 4550 3584 \nQ 5097 3584 5394 3201 \nQ 5691 2819 5691 2113 \nL 5691 0 \nL 5113 0 \nL 5113 2094 \nQ 5113 2597 4934 2840 \nQ 4756 3084 4391 3084 \nQ 3944 3084 3684 2787 \nQ 3425 2491 3425 1978 \nL 3425 0 \nL 2847 0 \nL 2847 2094 \nQ 2847 2600 2669 2842 \nQ 2491 3084 2119 3084 \nQ 1678 3084 1418 2786 \nQ 1159 2488 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1356 3278 1631 3431 \nQ 1906 3584 2284 3584 \nQ 2666 3584 2933 3390 \nQ 3200 3197 3328 2828 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-76\" d=\"M 191 3500 \nL 800 3500 \nL 1894 563 \nL 2988 3500 \nL 3597 3500 \nL 2284 0 \nL 1503 0 \nL 191 3500 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-43\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"69.824219\"/>\n      <use xlink:href=\"#DejaVuSans-6d\" x=\"133.203125\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"230.615234\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"293.994141\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"321.777344\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"383.056641\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"422.265625\"/>\n      <use xlink:href=\"#DejaVuSans-76\" x=\"450.048828\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"509.228516\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"570.751953\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"602.539062\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"641.402344\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"702.925781\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"742.134766\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"805.513672\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"844.876953\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"908.255859\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_23\">\n    <path d=\"M 110.686216 449.706021 \nL 111.395688 450.987414 \nL 113.524105 453.176186 \nL 114.233578 451.422659 \nL 114.94305 455.11386 \nL 115.652522 452.083025 \nL 116.361995 452.04879 \nL 118.490412 449.777952 \nL 119.199884 450.750372 \nL 119.909356 453.056567 \nL 120.618829 454.578942 \nL 121.328301 453.550076 \nL 123.456718 452.241747 \nL 124.16619 457.741216 \nL 124.875663 457.152648 \nL 125.585135 465.868101 \nL 133.389331 486.833713 \nL 134.098803 479.936959 \nL 134.808276 478.075297 \nL 135.517748 473.789445 \nL 136.22722 474.113758 \nL 138.355637 474.281799 \nL 139.06511 471.240736 \nL 139.774582 469.635306 \nL 140.484054 471.687618 \nL 141.193527 469.688536 \nL 143.321944 464.074011 \nL 144.031416 466.694385 \nL 144.740889 466.75918 \nL 145.450361 461.20446 \nL 146.159833 462.229753 \nL 148.28825 466.119199 \nL 148.997723 468.233029 \nL 149.707195 469.013942 \nL 150.416667 467.956169 \nL 151.12614 477.244165 \nL 153.254557 468.379778 \nL 153.964029 466.995967 \nL 154.673501 464.329528 \nL 155.382974 457.133091 \nL 156.092446 462.566928 \nL 158.220863 472.366366 \nL 158.930335 466.712921 \nL 159.639808 470.372746 \nL 161.058752 479.517555 \nL 163.18717 490.209257 \nL 163.896642 491.069949 \nL 165.315587 502.890057 \nL 166.025059 496.905878 \nL 168.153476 503.928119 \nL 168.862948 495.786423 \nL 169.572421 489.580125 \nL 170.281893 490.693344 \nL 170.991365 489.451698 \nL 173.119782 490.615595 \nL 173.829255 490.683269 \nL 174.538727 491.428344 \nL 175.248199 487.569316 \nL 175.957672 488.698417 \nL 178.795561 483.739572 \nL 179.505033 485.119576 \nL 180.214506 484.231396 \nL 180.923978 484.511216 \nL 183.052395 485.601346 \nL 183.761868 480.849545 \nL 184.47134 483.016708 \nL 185.180812 482.631559 \nL 185.890285 478.46558 \nL 188.018702 477.371562 \nL 188.728174 480.970724 \nL 189.437646 478.959446 \nL 190.147119 479.630682 \nL 190.856591 481.839184 \nL 192.985008 478.859119 \nL 195.113425 473.072909 \nL 199.370259 472.875144 \nL 200.079731 473.836888 \nL 200.789204 471.939419 \nL 202.917621 472.058323 \nL 204.336566 472.480421 \nL 205.046038 475.867121 \nL 205.75551 477.382044 \nL 207.883927 475.597723 \nL 208.5934 473.199427 \nL 209.302872 473.66165 \nL 210.012344 474.612543 \nL 210.721817 481.861119 \nL 212.850234 480.442328 \nL 213.559706 478.489445 \nL 214.269178 479.85325 \nL 214.978651 478.405449 \nL 215.688123 478.711717 \nL 217.81654 472.210594 \nL 218.526012 470.621842 \nL 219.235485 470.296457 \nL 219.944957 470.882892 \nL 220.65443 469.557363 \nL 222.782847 468.206215 \nL 223.492319 466.295671 \nL 224.201791 468.319658 \nL 224.911264 471.582116 \nL 225.620736 470.806093 \nL 227.749153 475.451219 \nL 228.458625 471.329038 \nL 229.168098 471.110635 \nL 229.87757 470.31188 \nL 230.587042 466.537449 \nL 232.715459 466.950239 \nL 233.424932 466.590486 \nL 234.134404 464.74734 \nL 237.681766 466.583606 \nL 238.391238 464.890159 \nL 239.810183 450.379187 \nL 242.648072 420.78869 \nL 243.357545 420.010431 \nL 244.067017 415.092181 \nL 244.776489 413.859599 \nL 245.485962 423.070633 \nL 247.614379 419.157701 \nL 248.323851 423.453281 \nL 249.033323 426.950944 \nL 249.742796 442.439307 \nL 250.452268 440.003276 \nL 252.580685 429.589466 \nL 253.290157 429.701786 \nL 253.99963 429.237776 \nL 254.709102 429.977819 \nL 255.418574 442.821026 \nL 257.546991 442.316259 \nL 258.256464 440.003327 \nL 258.965936 434.134745 \nL 259.675409 435.345891 \nL 260.384881 433.527151 \nL 262.513298 430.284964 \nL 263.22277 427.117423 \nL 263.932243 429.14092 \nL 264.641715 429.152056 \nL 265.351187 432.056496 \nL 267.479604 429.80941 \nL 268.189077 432.150515 \nL 268.898549 433.48626 \nL 269.608021 434.291966 \nL 270.317494 429.528314 \nL 272.445911 421.328386 \nL 273.155383 421.48328 \nL 273.864855 427.574124 \nL 274.574328 431.976125 \nL 275.2838 429.914902 \nL 277.412217 428.486526 \nL 278.12169 427.249576 \nL 278.831162 430.612728 \nL 279.540634 429.296468 \nL 280.250107 421.370276 \nL 282.378524 423.876176 \nL 283.087996 422.732162 \nL 283.797468 423.527487 \nL 284.506941 424.843431 \nL 285.216413 427.415882 \nL 287.34483 433.109839 \nL 288.054302 429.385403 \nL 288.763775 434.918832 \nL 289.473247 433.918679 \nL 290.182719 431.877758 \nL 292.311136 428.952975 \nL 293.020609 426.555353 \nL 293.730081 428.806716 \nL 294.439553 431.960457 \nL 295.149026 423.479085 \nL 297.277443 427.172542 \nL 297.986915 431.365111 \nL 298.696388 430.832326 \nL 299.40586 436.65275 \nL 300.115332 435.523741 \nL 302.243749 433.408308 \nL 303.662694 435.254128 \nL 310.047945 429.697437 \nL 312.176362 419.385342 \nL 312.885834 419.486577 \nL 313.595307 421.262141 \nL 314.304779 421.067837 \nL 315.014252 420.17292 \nL 317.142669 422.812646 \nL 317.852141 421.874043 \nL 318.561613 420.453036 \nL 319.271086 421.258854 \nL 319.980558 423.59855 \nL 322.108975 427.875819 \nL 322.818447 428.959365 \nL 323.52792 427.005368 \nL 324.237392 425.861314 \nL 324.946864 430.358221 \nL 327.075281 431.83696 \nL 327.784754 427.591956 \nL 328.494226 425.070215 \nL 329.203698 421.26162 \nL 329.913171 422.321496 \nL 332.041588 416.283321 \nL 332.75106 416.501194 \nL 333.460533 417.0025 \nL 334.170005 418.41876 \nL 334.879477 424.445534 \nL 337.007894 420.485148 \nL 337.717367 420.264244 \nL 338.426839 419.471093 \nL 339.136311 417.118434 \nL 339.845784 416.930764 \nL 341.974201 411.023619 \nL 342.683673 413.787904 \nL 343.393145 416.077513 \nL 344.102618 413.480065 \nL 344.81209 408.078401 \nL 346.940507 411.063101 \nL 347.649979 402.428202 \nL 349.068924 404.183791 \nL 349.778396 403.703388 \nL 352.616286 408.037746 \nL 353.325758 411.154037 \nL 354.035231 412.122935 \nL 354.744703 415.305348 \nL 356.87312 411.231611 \nL 357.582592 411.123241 \nL 358.292065 409.431264 \nL 359.001537 403.905573 \nL 359.711009 407.127559 \nL 361.839426 405.669184 \nL 362.548899 410.911564 \nL 363.258371 408.494049 \nL 363.967843 409.036317 \nL 364.677316 406.66702 \nL 366.805733 405.508431 \nL 367.515205 406.170562 \nL 368.224677 400.374839 \nL 368.93415 393.58621 \nL 371.772039 393.308543 \nL 372.481512 389.225232 \nL 373.190984 383.786363 \nL 373.900456 376.496223 \nL 374.609929 378.512187 \nL 376.738346 379.715597 \nL 377.447818 366.487752 \nL 378.15729 369.84531 \nL 378.866763 376.174217 \nL 379.576235 375.489282 \nL 381.704652 372.277718 \nL 382.414124 376.432479 \nL 383.123597 375.824161 \nL 383.833069 372.210585 \nL 384.542541 372.584312 \nL 386.670958 367.301797 \nL 387.380431 375.963336 \nL 388.089903 375.455221 \nL 388.799375 383.951138 \nL 389.508848 386.174941 \nL 391.637265 382.793845 \nL 392.346737 380.23201 \nL 393.05621 379.797959 \nL 393.765682 377.154762 \nL 394.475154 373.158794 \nL 396.603571 368.085904 \nL 397.313044 361.720466 \nL 398.022516 353.993478 \nL 403.698295 355.443391 \nL 404.407767 355.429887 \nL 406.536184 368.963448 \nL 407.245656 367.345779 \nL 407.955129 376.761366 \nL 408.664601 372.111259 \nL 409.374074 381.723313 \nL 411.502491 378.558079 \nL 412.211963 385.610809 \nL 412.921435 375.542533 \nL 413.630908 386.643095 \nL 414.34038 388.682372 \nL 416.468797 400.446259 \nL 417.178269 406.960222 \nL 417.887742 404.669868 \nL 418.597214 395.151352 \nL 419.306686 394.408962 \nL 421.435103 401.115208 \nL 422.144576 397.819577 \nL 422.854048 398.669909 \nL 423.56352 397.162223 \nL 424.272993 406.714576 \nL 426.40141 404.019179 \nL 427.110882 406.271348 \nL 427.820354 411.407655 \nL 428.529827 411.6291 \nL 429.239299 404.907094 \nL 431.367716 404.092273 \nL 432.077189 400.057119 \nL 432.786661 403.922976 \nL 433.496133 399.505267 \nL 434.205606 396.023211 \nL 437.043495 398.274339 \nL 437.752967 401.973481 \nL 438.46244 400.486475 \nL 439.171912 406.501214 \nL 441.300329 410.282494 \nL 442.009801 411.875451 \nL 442.719274 411.088118 \nL 443.428746 414.934153 \nL 444.138218 413.238624 \nL 446.266635 406.574226 \nL 446.976108 406.908145 \nL 447.68558 406.298397 \nL 448.395053 409.224854 \nL 449.104525 405.489578 \nL 451.232942 411.242472 \nL 451.942414 410.360436 \nL 452.651887 410.693487 \nL 453.361359 406.184811 \nL 454.070831 408.841002 \nL 458.327665 413.051393 \nL 459.037138 417.504613 \nL 461.165555 418.15026 \nL 461.875027 414.299224 \nL 462.584499 413.263376 \nL 463.293972 416.73108 \nL 464.003444 407.63152 \nL 466.131861 403.867561 \nL 466.841334 404.093773 \nL 467.550806 406.771011 \nL 468.260278 405.649872 \nL 468.969751 409.792906 \nL 471.098168 408.171491 \nL 471.80764 393.519567 \nL 472.517112 391.896825 \nL 473.226585 391.105573 \nL 473.936057 391.681872 \nL 476.064474 392.607788 \nL 476.773946 392.538491 \nL 478.192891 398.637021 \nL 478.902363 396.437848 \nL 481.03078 397.621098 \nL 481.740253 399.7468 \nL 482.449725 399.00693 \nL 483.159197 396.950474 \nL 483.86867 400.104695 \nL 486.706559 405.01528 \nL 487.416032 409.341165 \nL 488.125504 409.819597 \nL 488.834976 412.576758 \nL 490.963393 414.958742 \nL 491.672866 411.544074 \nL 492.382338 410.866785 \nL 493.09181 409.583923 \nL 493.801283 404.367102 \nL 495.9297 405.824191 \nL 496.639172 409.70396 \nL 497.348644 408.079463 \nL 498.058117 404.343574 \nL 498.767589 417.307961 \nL 500.896006 417.659722 \nL 501.605478 417.609901 \nL 502.314951 415.659212 \nL 503.024423 420.878585 \nL 503.733896 422.068837 \nL 506.571785 418.99163 \nL 507.281257 424.336225 \nL 507.99073 416.996447 \nL 508.700202 421.221149 \nL 510.828619 419.6424 \nL 511.538091 420.33008 \nL 512.247564 419.320496 \nL 512.957036 418.89216 \nL 513.666508 422.492191 \nL 515.794925 435.667367 \nL 516.504398 446.078115 \nL 517.923342 440.319179 \nL 518.632815 445.420281 \nL 520.761232 437.42563 \nL 521.470704 436.131193 \nL 522.180176 435.184239 \nL 522.889649 435.770521 \nL 523.599121 439.002449 \nL 525.727538 434.969541 \nL 526.437011 429.51431 \nL 527.146483 432.175961 \nL 527.855955 435.897672 \nL 528.565428 436.742512 \nL 530.693845 436.254036 \nL 531.403317 443.679156 \nL 532.112789 439.527528 \nL 532.822262 444.24093 \nL 533.531734 451.551341 \nL 535.660151 448.781902 \nL 536.369623 443.894508 \nL 537.079096 442.666081 \nL 537.788568 449.910339 \nL 538.49804 446.417678 \nL 540.626457 447.473797 \nL 541.33593 449.070592 \nL 542.045402 442.131866 \nL 542.754875 441.921587 \nL 543.464347 441.025201 \nL 545.592764 437.420128 \nL 546.302236 433.658323 \nL 547.011709 437.209992 \nL 547.721181 438.126446 \nL 548.430653 433.222251 \nL 550.55907 434.272389 \nL 551.268543 439.761385 \nL 551.978015 444.010339 \nL 552.687487 445.85224 \nL 553.39696 442.449821 \nL 556.944321 446.490343 \nL 557.653794 445.930621 \nL 558.363266 444.165662 \nL 560.491683 438.565713 \nL 561.201156 437.424639 \nL 561.910628 438.642145 \nL 562.6201 438.870317 \nL 568.295879 432.820424 \nL 570.424296 430.764101 \nL 571.133768 432.502133 \nL 571.843241 429.094681 \nL 572.552713 431.347453 \nL 573.262185 428.8833 \nL 575.390602 435.538603 \nL 576.100075 432.778911 \nL 576.809547 432.949361 \nL 577.519019 430.546197 \nL 578.228492 426.505613 \nL 580.356909 427.100122 \nL 581.066381 429.37294 \nL 581.775854 433.755884 \nL 582.485326 434.520016 \nL 583.194798 431.698877 \nL 585.323215 433.366132 \nL 586.032688 437.335633 \nL 586.74216 440.456517 \nL 587.451632 437.82169 \nL 588.161105 438.405307 \nL 590.289522 438.943849 \nL 590.998994 439.894385 \nL 591.708466 441.583994 \nL 592.417939 435.156966 \nL 593.127411 436.465744 \nL 595.9653 436.299877 \nL 596.674773 437.667357 \nL 597.384245 441.280718 \nL 598.093717 437.245615 \nL 600.222135 437.322812 \nL 600.931607 436.097621 \nL 601.641079 435.313626 \nL 602.350552 436.720587 \nL 603.060024 439.853536 \nL 605.188441 439.885117 \nL 605.897913 442.099969 \nL 606.607386 440.561906 \nL 607.316858 439.494865 \nL 608.02633 436.376513 \nL 610.154747 435.690598 \nL 610.86422 433.000265 \nL 612.283164 422.212861 \nL 612.992637 422.88178 \nL 615.121054 421.612248 \nL 615.830526 423.201561 \nL 616.539998 426.418587 \nL 617.249471 425.206379 \nL 617.958943 430.509798 \nL 620.08736 432.913289 \nL 620.796833 431.108675 \nL 621.506305 432.380514 \nL 622.215777 429.663703 \nL 622.92525 429.352587 \nL 625.053667 430.556956 \nL 625.763139 428.008859 \nL 626.472611 434.393977 \nL 627.182084 432.25572 \nL 627.891556 430.977043 \nL 630.729445 432.023813 \nL 631.438918 433.022731 \nL 632.14839 437.503082 \nL 632.857862 436.18822 \nL 634.986279 434.876666 \nL 635.695752 437.080156 \nL 636.405224 434.857088 \nL 637.824169 444.784903 \nL 639.952586 443.901632 \nL 640.662058 439.836541 \nL 641.371531 439.87046 \nL 642.081003 435.12319 \nL 642.790475 436.65079 \nL 644.918892 437.56849 \nL 645.628365 444.1823 \nL 646.337837 442.27097 \nL 647.047309 446.806613 \nL 647.756782 453.463519 \nL 654.851505 447.314759 \nL 655.560978 447.085658 \nL 656.27045 444.731999 \nL 656.979922 444.165601 \nL 657.689395 444.390251 \nL 659.817812 448.362355 \nL 661.236756 445.087363 \nL 661.946229 444.77145 \nL 662.655701 442.358017 \nL 664.784118 444.190884 \nL 665.49359 448.53303 \nL 666.203063 446.929202 \nL 666.912535 452.889874 \nL 667.622007 451.262202 \nL 669.750424 450.732427 \nL 670.459897 446.148055 \nL 671.169369 448.031284 \nL 671.878841 449.067499 \nL 672.588314 452.610043 \nL 674.716731 461.562396 \nL 675.426203 465.799662 \nL 676.135676 468.452066 \nL 676.845148 465.769306 \nL 677.55462 465.54241 \nL 679.683037 474.096773 \nL 680.39251 489.30793 \nL 681.101982 476.559486 \nL 681.811454 471.510033 \nL 682.520927 467.838888 \nL 684.649344 469.990414 \nL 685.358816 469.106399 \nL 686.068288 467.499734 \nL 686.777761 468.815555 \nL 687.487233 473.632264 \nL 689.61565 473.963569 \nL 690.325122 475.089302 \nL 691.034595 467.603592 \nL 691.744067 469.304572 \nL 692.453539 464.770776 \nL 696.000901 466.000275 \nL 696.710374 468.931427 \nL 697.419846 466.5828 \nL 699.548263 474.657853 \nL 700.257735 469.770816 \nL 700.967208 470.993589 \nL 701.67668 466.265876 \nL 702.386152 466.063549 \nL 704.514569 470.438113 \nL 705.933514 475.783535 \nL 706.642986 479.644145 \nL 707.352459 477.949953 \nL 709.480876 491.292262 \nL 710.190348 491.535663 \nL 710.89982 486.073562 \nL 712.318765 478.847309 \nL 716.575599 479.29712 \nL 717.285072 487.582105 \nL 719.413489 490.095997 \nL 720.832433 485.390486 \nL 721.541906 487.377063 \nL 722.251378 484.675522 \nL 724.379795 487.51633 \nL 725.089267 483.807593 \nL 725.79874 484.952035 \nL 726.508212 485.052362 \nL 727.217684 478.581299 \nL 729.346101 481.173338 \nL 730.055574 486.109083 \nL 730.765046 485.16754 \nL 731.474519 485.016289 \nL 732.183991 483.161303 \nL 734.312408 481.591537 \nL 735.02188 478.042685 \nL 735.731353 479.589149 \nL 736.440825 480.380381 \nL 739.278714 476.773756 \nL 739.988187 474.613983 \nL 740.697659 471.296488 \nL 741.407131 472.407818 \nL 742.116604 469.227773 \nL 744.245021 474.826925 \nL 745.663965 466.736153 \nL 746.373438 470.069163 \nL 747.08291 465.489751 \nL 749.211327 466.641614 \nL 749.9208 466.482391 \nL 750.630272 469.972123 \nL 752.049217 461.554485 \nL 754.177634 457.553842 \nL 754.887106 454.954546 \nL 755.596578 458.034816 \nL 756.306051 453.01678 \nL 757.015523 454.356874 \nL 759.853412 453.658435 \nL 760.562885 459.311533 \nL 761.272357 460.079095 \nL 761.981829 459.660783 \nL 764.110246 464.86752 \nL 764.819719 466.938705 \nL 765.529191 467.725639 \nL 766.238663 469.66459 \nL 766.948136 475.37097 \nL 769.076553 471.36508 \nL 769.786025 472.695732 \nL 770.495498 471.830712 \nL 771.20497 475.649841 \nL 771.914442 474.447993 \nL 774.042859 475.588791 \nL 774.752332 473.814871 \nL 775.461804 476.337786 \nL 776.171276 476.625119 \nL 776.880749 480.174981 \nL 779.009166 481.261691 \nL 779.718638 486.459905 \nL 780.42811 488.504561 \nL 781.847055 482.011625 \nL 783.975472 483.35673 \nL 784.684944 483.059609 \nL 785.394417 486.438929 \nL 786.103889 480.712452 \nL 786.813361 479.709532 \nL 788.941779 481.161273 \nL 789.651251 482.529559 \nL 790.360723 480.835979 \nL 791.070196 483.54686 \nL 791.779668 484.431202 \nL 793.908085 483.845482 \nL 794.617557 485.95866 \nL 795.32703 488.773378 \nL 796.036502 484.234662 \nL 796.745974 484.333325 \nL 799.583864 486.8779 \nL 800.293336 483.292833 \nL 801.002808 486.292129 \nL 801.712281 488.449402 \nL 803.840698 489.82714 \nL 804.55017 487.0986 \nL 805.259642 488.508399 \nL 805.969115 488.754189 \nL 806.678587 483.723292 \nL 809.516477 482.532223 \nL 810.225949 484.962191 \nL 810.935421 485.129569 \nL 811.644894 491.841368 \nL 813.773311 491.682891 \nL 814.482783 492.265243 \nL 815.901728 496.808501 \nL 816.6112 496.763712 \nL 818.739617 498.285515 \nL 819.449089 495.425312 \nL 820.158562 498.583391 \nL 820.868034 498.583391 \nL 820.868034 498.583391 \n\" clip-path=\"url(#p359f445ed0)\" style=\"fill: none; stroke: #808080; stroke-opacity: 0.6; stroke-width: 2; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_24\">\n    <path d=\"M 110.686216 449.706021 \nL 113.524105 451.007176 \nL 114.233578 448.767731 \nL 114.94305 451.795223 \nL 115.652522 447.209066 \nL 116.361995 446.517591 \nL 118.490412 442.65023 \nL 119.199884 444.013176 \nL 119.909356 446.214404 \nL 120.618829 446.803273 \nL 121.328301 444.010362 \nL 123.456718 441.399081 \nL 124.16619 445.254691 \nL 124.875663 443.283804 \nL 125.585135 453.923262 \nL 133.389331 475.593691 \nL 134.098803 467.771228 \nL 135.517748 459.349085 \nL 136.22722 458.169919 \nL 138.355637 458.51223 \nL 139.06511 455.91786 \nL 139.774582 450.901947 \nL 140.484054 454.812639 \nL 141.193527 453.737369 \nL 143.321944 446.880842 \nL 144.031416 447.794539 \nL 144.740889 448.332367 \nL 145.450361 443.867334 \nL 146.159833 442.609743 \nL 148.28825 444.6309 \nL 148.997723 444.703666 \nL 149.707195 447.465517 \nL 150.416667 444.619522 \nL 151.12614 455.452317 \nL 153.254557 446.580375 \nL 153.964029 444.32542 \nL 154.673501 441.343458 \nL 155.382974 433.94891 \nL 156.092446 440.395106 \nL 158.220863 452.298754 \nL 158.930335 445.574989 \nL 159.639808 448.886572 \nL 160.34928 456.22334 \nL 161.058752 460.487468 \nL 163.18717 471.795282 \nL 163.896642 474.481254 \nL 164.606114 478.864732 \nL 165.315587 485.647789 \nL 166.025059 477.975518 \nL 168.153476 486.871744 \nL 169.572421 471.830495 \nL 170.281893 472.896765 \nL 170.991365 470.463041 \nL 173.119782 477.433165 \nL 173.829255 476.322123 \nL 174.538727 476.462021 \nL 175.248199 474.340686 \nL 175.957672 475.892323 \nL 178.795561 471.417946 \nL 179.505033 471.743732 \nL 180.214506 469.889556 \nL 180.923978 470.894226 \nL 183.052395 472.448663 \nL 183.761868 465.778176 \nL 184.47134 469.183161 \nL 185.180812 468.933616 \nL 185.890285 463.704501 \nL 188.018702 462.436809 \nL 188.728174 465.262175 \nL 189.437646 464.289806 \nL 190.147119 465.183728 \nL 190.856591 467.72331 \nL 192.985008 465.927208 \nL 193.69448 460.026854 \nL 194.403953 461.659874 \nL 195.113425 456.655976 \nL 199.370259 454.141879 \nL 200.079731 454.180612 \nL 200.789204 451.954691 \nL 202.917621 451.908311 \nL 203.627093 451.447613 \nL 204.336566 449.597554 \nL 205.046038 453.874458 \nL 205.75551 454.888445 \nL 207.883927 453.169999 \nL 208.5934 450.485298 \nL 209.302872 454.041235 \nL 210.012344 456.675651 \nL 210.721817 464.77337 \nL 212.850234 463.290707 \nL 213.559706 460.439581 \nL 214.269178 460.795148 \nL 214.978651 460.440191 \nL 215.688123 460.629619 \nL 217.81654 453.553297 \nL 218.526012 453.182946 \nL 219.235485 450.804694 \nL 219.944957 452.60169 \nL 220.65443 460.569379 \nL 222.782847 460.784103 \nL 223.492319 456.607985 \nL 224.201791 453.616648 \nL 224.911264 455.724293 \nL 225.620736 454.74913 \nL 227.749153 459.289894 \nL 228.458625 454.418158 \nL 229.168098 450.690587 \nL 229.87757 451.505988 \nL 230.587042 443.110348 \nL 232.715459 444.554463 \nL 233.424932 440.878678 \nL 234.134404 440.716596 \nL 237.681766 439.745187 \nL 239.100711 431.151074 \nL 239.810183 428.784284 \nL 240.519655 429.570108 \nL 242.648072 422.161125 \nL 243.357545 416.607256 \nL 244.067017 417.222069 \nL 244.776489 412.214092 \nL 245.485962 409.651851 \nL 247.614379 391.474809 \nL 248.323851 391.898848 \nL 249.033323 387.453701 \nL 249.742796 415.526007 \nL 250.452268 414.469235 \nL 252.580685 406.392923 \nL 253.290157 395.569699 \nL 253.99963 394.390141 \nL 254.709102 389.513582 \nL 255.418574 405.753516 \nL 257.546991 399.957617 \nL 258.256464 397.024265 \nL 258.965936 388.254861 \nL 259.675409 381.707397 \nL 260.384881 370.884504 \nL 262.513298 368.20193 \nL 263.22277 374.3761 \nL 263.932243 370.650279 \nL 264.641715 368.977478 \nL 265.351187 375.984315 \nL 267.479604 374.8091 \nL 268.189077 377.990737 \nL 268.898549 386.782527 \nL 269.608021 385.812819 \nL 270.317494 379.034108 \nL 272.445911 370.210703 \nL 273.155383 368.649418 \nL 273.864855 371.895796 \nL 274.574328 377.971392 \nL 275.2838 373.881329 \nL 277.412217 368.784642 \nL 278.12169 369.732709 \nL 278.831162 374.913547 \nL 279.540634 370.003502 \nL 280.250107 358.315831 \nL 282.378524 356.850085 \nL 283.087996 353.673543 \nL 283.797468 356.166847 \nL 284.506941 355.742685 \nL 285.216413 357.833492 \nL 287.34483 367.004079 \nL 288.054302 366.153945 \nL 288.763775 375.221227 \nL 289.473247 371.227428 \nL 290.182719 364.594988 \nL 292.311136 363.011831 \nL 293.020609 363.941794 \nL 293.730081 365.260723 \nL 294.439553 374.938891 \nL 295.149026 367.671278 \nL 297.277443 368.76992 \nL 297.986915 374.827955 \nL 298.696388 373.033139 \nL 299.40586 379.525072 \nL 300.115332 379.523433 \nL 302.243749 378.393322 \nL 302.953222 373.260932 \nL 303.662694 373.925943 \nL 310.047945 361.995053 \nL 312.176362 347.993742 \nL 312.885834 344.179435 \nL 313.595307 348.493369 \nL 314.304779 354.33839 \nL 315.014252 356.485698 \nL 317.142669 361.296578 \nL 317.852141 358.241824 \nL 318.561613 363.49531 \nL 319.271086 365.089947 \nL 319.980558 369.816567 \nL 322.108975 372.81852 \nL 322.818447 368.407973 \nL 323.52792 359.502324 \nL 324.946864 366.32296 \nL 327.075281 365.628741 \nL 327.784754 356.842147 \nL 328.494226 352.127849 \nL 329.203698 349.686704 \nL 329.913171 353.634962 \nL 332.041588 349.436485 \nL 332.75106 354.835763 \nL 333.460533 358.798384 \nL 334.170005 356.770403 \nL 334.879477 356.58562 \nL 337.007894 352.031982 \nL 337.717367 361.345493 \nL 338.426839 359.080054 \nL 339.136311 346.461911 \nL 339.845784 340.224561 \nL 341.974201 334.608181 \nL 342.683673 334.03624 \nL 343.393145 341.854078 \nL 344.102618 336.983786 \nL 344.81209 328.770822 \nL 346.940507 336.028481 \nL 347.649979 323.000784 \nL 348.359452 325.571321 \nL 349.068924 324.604601 \nL 349.778396 319.034722 \nL 351.906813 321.743543 \nL 352.616286 323.220912 \nL 353.325758 327.626342 \nL 354.035231 325.017738 \nL 354.744703 325.357618 \nL 356.87312 322.397474 \nL 357.582592 313.521005 \nL 358.292065 307.158989 \nL 359.001537 306.87042 \nL 359.711009 308.052596 \nL 361.839426 297.074011 \nL 362.548899 307.306083 \nL 363.258371 292.014365 \nL 363.967843 296.06076 \nL 364.677316 283.913962 \nL 366.805733 274.024946 \nL 367.515205 276.801458 \nL 368.93415 257.156954 \nL 371.772039 237.392249 \nL 372.481512 220.022566 \nL 373.190984 212.949368 \nL 373.900456 189.431539 \nL 374.609929 189.843542 \nL 376.738346 203.234964 \nL 377.447818 184.805539 \nL 378.15729 188.864054 \nL 378.866763 208.801969 \nL 379.576235 212.419954 \nL 381.704652 203.236125 \nL 382.414124 221.116058 \nL 383.123597 213.499886 \nL 383.833069 197.385649 \nL 384.542541 187.306924 \nL 386.670958 182.784937 \nL 387.380431 188.146071 \nL 388.089903 188.326592 \nL 388.799375 210.326868 \nL 389.508848 208.653821 \nL 391.637265 186.625383 \nL 392.346737 182.00353 \nL 393.05621 173.299883 \nL 393.765682 168.490263 \nL 394.475154 174.234661 \nL 396.603571 143.467367 \nL 397.313044 128.392891 \nL 398.022516 110.536172 \nL 403.698295 97.907236 \nL 404.407767 112.718859 \nL 406.536184 122.76812 \nL 407.955129 146.912184 \nL 408.664601 129.057833 \nL 409.374074 144.333438 \nL 411.502491 141.101016 \nL 412.211963 160.937585 \nL 412.921435 150.159346 \nL 413.630908 185.077596 \nL 414.34038 197.985583 \nL 416.468797 220.792358 \nL 417.178269 239.533312 \nL 417.887742 213.510466 \nL 419.306686 179.507093 \nL 421.435103 199.502796 \nL 422.144576 179.853167 \nL 422.854048 174.047475 \nL 423.56352 171.883919 \nL 424.272993 187.398559 \nL 426.40141 191.532561 \nL 427.110882 200.819836 \nL 427.820354 217.158267 \nL 428.529827 210.310485 \nL 429.239299 185.01687 \nL 431.367716 174.637963 \nL 432.077189 173.594023 \nL 432.786661 193.75984 \nL 433.496133 178.7758 \nL 434.205606 158.393902 \nL 437.043495 167.322667 \nL 437.752967 180.72336 \nL 438.46244 163.819699 \nL 439.171912 182.496076 \nL 441.300329 198.086566 \nL 442.009801 195.254508 \nL 442.719274 193.302255 \nL 443.428746 197.851946 \nL 444.138218 194.596561 \nL 446.266635 179.001384 \nL 446.976108 174.946798 \nL 447.68558 172.856863 \nL 448.395053 176.310071 \nL 449.104525 173.330947 \nL 451.232942 180.999839 \nL 451.942414 179.157342 \nL 452.651887 173.772803 \nL 453.361359 178.97097 \nL 454.070831 180.747169 \nL 458.327665 181.202787 \nL 459.037138 188.619575 \nL 461.165555 182.281762 \nL 461.875027 178.379272 \nL 462.584499 175.893398 \nL 463.293972 183.518064 \nL 464.003444 170.828548 \nL 466.131861 160.280355 \nL 466.841334 161.631072 \nL 468.260278 163.271349 \nL 468.969751 169.6618 \nL 471.098168 168.655601 \nL 471.80764 148.748648 \nL 472.517112 147.13292 \nL 473.226585 149.246097 \nL 473.936057 149.693814 \nL 476.064474 147.669574 \nL 476.773946 153.117374 \nL 477.483419 156.722226 \nL 478.192891 159.38485 \nL 478.902363 154.809536 \nL 481.03078 153.905528 \nL 481.740253 148.181761 \nL 482.449725 147.218841 \nL 483.159197 140.05484 \nL 483.86867 151.831626 \nL 486.706559 153.845563 \nL 487.416032 167.716698 \nL 488.125504 172.87809 \nL 488.834976 168.9321 \nL 490.963393 169.492403 \nL 491.672866 169.331887 \nL 492.382338 187.375787 \nL 493.09181 185.831609 \nL 493.801283 180.101109 \nL 495.9297 173.68898 \nL 496.639172 179.625523 \nL 497.348644 175.262842 \nL 498.058117 186.236834 \nL 498.767589 204.329588 \nL 501.605478 189.935258 \nL 502.314951 177.030497 \nL 503.024423 181.280714 \nL 503.733896 191.166347 \nL 505.862313 181.303309 \nL 506.571785 177.334558 \nL 507.281257 197.851372 \nL 507.99073 191.65403 \nL 508.700202 184.18027 \nL 510.828619 178.093851 \nL 511.538091 180.006401 \nL 512.247564 176.063789 \nL 512.957036 177.30377 \nL 513.666508 184.863695 \nL 515.794925 194.631472 \nL 516.504398 219.558578 \nL 517.21387 223.733528 \nL 517.923342 212.104938 \nL 518.632815 207.508179 \nL 520.761232 178.089333 \nL 521.470704 175.898269 \nL 522.180176 162.893462 \nL 522.889649 155.710737 \nL 523.599121 162.95274 \nL 525.727538 158.98876 \nL 526.437011 150.142254 \nL 527.146483 156.794584 \nL 527.855955 156.093239 \nL 528.565428 159.577394 \nL 530.693845 158.815695 \nL 531.403317 172.066764 \nL 532.822262 179.730635 \nL 533.531734 204.026358 \nL 535.660151 176.855635 \nL 536.369623 171.300482 \nL 537.079096 162.373723 \nL 537.788568 173.090421 \nL 538.49804 164.535206 \nL 540.626457 155.501984 \nL 541.33593 158.618315 \nL 542.045402 149.912859 \nL 542.754875 155.727731 \nL 543.464347 156.059066 \nL 545.592764 137.742145 \nL 546.302236 130.639589 \nL 547.011709 145.754512 \nL 547.721181 143.407941 \nL 548.430653 119.139496 \nL 551.268543 111.734528 \nL 551.978015 127.100211 \nL 552.687487 121.682643 \nL 553.39696 96.275789 \nL 556.944321 106.800146 \nL 557.653794 106.182739 \nL 558.363266 90.033568 \nL 560.491683 79.536896 \nL 561.201156 92.755314 \nL 561.910628 98.624121 \nL 562.6201 98.048488 \nL 568.295879 82.979499 \nL 570.424296 94.067217 \nL 571.133768 92.544572 \nL 571.843241 75.583296 \nL 572.552713 72.286303 \nL 573.262185 66.558405 \nL 575.390602 68.186461 \nL 576.100075 63.957148 \nL 576.809547 60.798852 \nL 577.519019 65.201315 \nL 578.228492 62.157657 \nL 580.356909 56.710723 \nL 581.066381 60.295481 \nL 582.485326 74.122132 \nL 583.194798 66.217481 \nL 585.323215 80.33044 \nL 586.032688 86.252501 \nL 586.74216 95.962406 \nL 587.451632 84.41642 \nL 588.161105 86.346157 \nL 590.289522 84.326169 \nL 590.998994 85.806647 \nL 591.708466 92.331649 \nL 592.417939 85.805042 \nL 593.127411 83.661196 \nL 595.9653 76.798523 \nL 596.674773 79.32675 \nL 597.384245 88.068746 \nL 598.093717 80.089091 \nL 600.222135 81.781976 \nL 600.931607 84.477921 \nL 601.641079 85.223331 \nL 602.350552 88.971614 \nL 603.060024 93.339946 \nL 605.188441 96.413327 \nL 605.897913 102.172976 \nL 607.316858 94.756284 \nL 608.02633 86.260174 \nL 610.154747 83.364413 \nL 610.86422 81.611592 \nL 611.573692 63.529887 \nL 612.283164 54.292167 \nL 612.992637 54.347104 \nL 615.121054 46.120327 \nL 615.830526 51.788465 \nL 616.539998 62.948759 \nL 617.958943 95.893788 \nL 620.08736 95.018275 \nL 620.796833 99.942685 \nL 621.506305 103.877836 \nL 622.215777 102.201003 \nL 622.92525 107.867547 \nL 625.053667 109.393093 \nL 625.763139 103.09864 \nL 626.472611 128.450067 \nL 627.182084 125.053897 \nL 627.891556 124.44661 \nL 630.729445 127.430566 \nL 631.438918 134.510755 \nL 632.14839 138.708998 \nL 634.986279 138.052819 \nL 635.695752 144.076398 \nL 636.405224 140.803927 \nL 637.114697 155.371442 \nL 637.824169 157.643926 \nL 639.952586 155.533338 \nL 640.662058 152.435614 \nL 641.371531 156.439661 \nL 642.081003 157.887813 \nL 642.790475 158.408527 \nL 644.918892 159.519886 \nL 645.628365 172.967402 \nL 646.337837 170.293692 \nL 647.756782 195.178815 \nL 654.851505 190.157416 \nL 655.560978 193.505285 \nL 656.27045 178.911619 \nL 656.979922 176.961535 \nL 657.689395 168.697552 \nL 659.817812 167.450327 \nL 660.527284 163.104026 \nL 661.236756 161.114526 \nL 661.946229 163.35791 \nL 662.655701 161.032149 \nL 664.784118 162.812822 \nL 665.49359 169.228117 \nL 666.203063 166.010324 \nL 666.912535 179.913163 \nL 667.622007 177.922979 \nL 669.750424 175.657297 \nL 670.459897 172.118572 \nL 671.169369 173.964771 \nL 671.878841 173.59824 \nL 672.588314 180.000626 \nL 674.716731 196.620446 \nL 675.426203 207.817605 \nL 676.135676 212.537658 \nL 676.845148 208.897925 \nL 677.55462 202.340332 \nL 679.683037 210.270206 \nL 680.39251 236.615894 \nL 681.101982 213.811737 \nL 681.811454 202.103726 \nL 682.520927 196.594402 \nL 684.649344 200.080388 \nL 685.358816 202.569169 \nL 686.068288 201.184554 \nL 686.777761 207.272535 \nL 687.487233 214.490365 \nL 689.61565 217.292695 \nL 690.325122 216.38292 \nL 691.034595 198.127988 \nL 691.744067 203.484966 \nL 692.453539 194.060015 \nL 696.000901 199.765258 \nL 696.710374 201.268702 \nL 697.419846 199.827453 \nL 699.548263 213.193969 \nL 700.257735 203.679499 \nL 700.967208 206.841655 \nL 701.67668 201.190147 \nL 702.386152 203.622969 \nL 704.514569 209.928554 \nL 705.224042 216.994323 \nL 706.642986 228.705906 \nL 707.352459 228.769815 \nL 709.480876 254.376529 \nL 710.190348 254.018155 \nL 711.609293 237.746801 \nL 712.318765 231.223212 \nL 716.575599 223.488212 \nL 717.285072 238.394603 \nL 719.413489 242.422874 \nL 720.122961 242.566814 \nL 720.832433 227.784759 \nL 721.541906 229.16423 \nL 722.251378 225.871553 \nL 724.379795 228.952573 \nL 725.089267 220.163379 \nL 725.79874 218.402155 \nL 726.508212 223.265886 \nL 727.217684 210.429727 \nL 729.346101 216.28355 \nL 730.055574 225.155701 \nL 730.765046 218.524458 \nL 731.474519 217.937858 \nL 732.183991 217.119586 \nL 734.312408 211.497559 \nL 735.02188 211.835742 \nL 735.731353 213.983077 \nL 736.440825 214.037115 \nL 739.278714 211.669118 \nL 739.988187 210.632244 \nL 740.697659 201.441162 \nL 741.407131 205.348394 \nL 742.116604 197.241037 \nL 744.245021 207.941764 \nL 744.954493 198.907248 \nL 745.663965 186.356993 \nL 746.373438 193.951256 \nL 747.08291 177.768819 \nL 749.211327 179.77192 \nL 749.9208 180.867965 \nL 750.630272 190.127013 \nL 751.339744 180.436138 \nL 752.049217 172.430704 \nL 754.177634 163.845787 \nL 754.887106 165.383126 \nL 755.596578 170.120812 \nL 756.306051 157.197892 \nL 757.015523 162.841667 \nL 759.14394 165.552347 \nL 759.853412 165.710743 \nL 760.562885 179.417464 \nL 761.272357 178.462266 \nL 761.981829 179.534053 \nL 764.110246 192.021409 \nL 764.819719 198.814256 \nL 765.529191 195.14514 \nL 766.238663 194.019668 \nL 766.948136 203.403257 \nL 769.076553 193.972652 \nL 769.786025 198.5967 \nL 770.495498 194.318946 \nL 771.20497 198.129383 \nL 771.914442 197.481792 \nL 774.042859 199.811055 \nL 774.752332 200.211767 \nL 775.461804 205.295759 \nL 776.171276 204.87328 \nL 776.880749 218.916718 \nL 779.009166 222.580049 \nL 779.718638 233.76786 \nL 780.42811 233.113347 \nL 781.137583 225.763845 \nL 781.847055 221.063816 \nL 783.975472 220.387442 \nL 784.684944 217.550212 \nL 785.394417 222.501053 \nL 786.103889 213.929424 \nL 786.813361 209.544299 \nL 788.941779 212.437335 \nL 789.651251 216.326743 \nL 790.360723 214.271179 \nL 791.070196 219.705533 \nL 791.779668 226.981523 \nL 793.908085 217.759322 \nL 794.617557 219.56417 \nL 795.32703 227.910904 \nL 796.036502 221.941762 \nL 796.745974 221.839894 \nL 799.583864 226.469893 \nL 800.293336 229.410975 \nL 801.002808 234.004195 \nL 801.712281 241.65459 \nL 803.840698 247.992551 \nL 804.55017 236.304119 \nL 805.969115 238.442515 \nL 806.678587 233.253795 \nL 809.516477 228.269827 \nL 810.225949 234.672088 \nL 810.935421 239.261597 \nL 811.644894 253.390411 \nL 813.773311 254.654858 \nL 814.482783 257.114909 \nL 815.192255 261.707718 \nL 815.901728 263.435179 \nL 816.6112 265.938402 \nL 818.739617 265.706927 \nL 819.449089 258.145358 \nL 820.158562 264.367468 \nL 820.868034 263.361567 \nL 820.868034 263.361567 \n\" clip-path=\"url(#p359f445ed0)\" style=\"fill: none; stroke: #228b22; stroke-opacity: 0.6; stroke-width: 3; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_25\">\n    <path d=\"M 75.177125 449.706021 \nL 856.377125 449.706021 \n\" clip-path=\"url(#p359f445ed0)\" style=\"fill: none; stroke-dasharray: 7.4,3.2; stroke-dashoffset: 0; stroke: #000000; stroke-width: 2\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 75.177125 526.818509 \nL 75.177125 23.229937 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 856.377125 526.818509 \nL 856.377125 23.229937 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 75.177125 526.818509 \nL 856.377125 526.818509 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 75.177125 23.229937 \nL 856.377125 23.229937 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_10\">\n    <!-- Cumulative returns -->\n    <g transform=\"translate(402.395469 17.229937)scale(0.132 -0.132)\">\n     <use xlink:href=\"#DejaVuSans-43\"/>\n     <use xlink:href=\"#DejaVuSans-75\" x=\"69.824219\"/>\n     <use xlink:href=\"#DejaVuSans-6d\" x=\"133.203125\"/>\n     <use xlink:href=\"#DejaVuSans-75\" x=\"230.615234\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"293.994141\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"321.777344\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"383.056641\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"422.265625\"/>\n     <use xlink:href=\"#DejaVuSans-76\" x=\"450.048828\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"509.228516\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"570.751953\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"602.539062\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"641.402344\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"702.925781\"/>\n     <use xlink:href=\"#DejaVuSans-75\" x=\"742.134766\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"805.513672\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"844.876953\"/>\n     <use xlink:href=\"#DejaVuSans-73\" x=\"908.255859\"/>\n    </g>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 737.165656 68.767531 \nL 847.907125 68.767531 \nQ 850.327125 68.767531 850.327125 66.347531 \nL 850.327125 31.699938 \nQ 850.327125 29.279937 847.907125 29.279937 \nL 737.165656 29.279937 \nQ 734.745656 29.279937 734.745656 31.699938 \nL 734.745656 66.347531 \nQ 734.745656 68.767531 737.165656 68.767531 \nz\n\" style=\"fill: #ffffff; opacity: 0.5; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_26\">\n     <path d=\"M 739.585656 39.079047 \nL 751.685656 39.079047 \nL 763.785656 39.079047 \n\" style=\"fill: none; stroke: #808080; stroke-opacity: 0.6; stroke-width: 2; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_11\">\n     <!-- daily_return -->\n     <g transform=\"translate(773.465656 43.314047)scale(0.121 -0.121)\">\n      <defs>\n       <path id=\"DejaVuSans-64\" d=\"M 2906 2969 \nL 2906 4863 \nL 3481 4863 \nL 3481 0 \nL 2906 0 \nL 2906 525 \nQ 2725 213 2448 61 \nQ 2172 -91 1784 -91 \nQ 1150 -91 751 415 \nQ 353 922 353 1747 \nQ 353 2572 751 3078 \nQ 1150 3584 1784 3584 \nQ 2172 3584 2448 3432 \nQ 2725 3281 2906 2969 \nz\nM 947 1747 \nQ 947 1113 1208 752 \nQ 1469 391 1925 391 \nQ 2381 391 2643 752 \nQ 2906 1113 2906 1747 \nQ 2906 2381 2643 2742 \nQ 2381 3103 1925 3103 \nQ 1469 3103 1208 2742 \nQ 947 2381 947 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-79\" d=\"M 2059 -325 \nQ 1816 -950 1584 -1140 \nQ 1353 -1331 966 -1331 \nL 506 -1331 \nL 506 -850 \nL 844 -850 \nQ 1081 -850 1212 -737 \nQ 1344 -625 1503 -206 \nL 1606 56 \nL 191 3500 \nL 800 3500 \nL 1894 763 \nL 2988 3500 \nL 3597 3500 \nL 2059 -325 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-5f\" d=\"M 3263 -1063 \nL 3263 -1509 \nL -63 -1509 \nL -63 -1063 \nL 3263 -1063 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-64\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"63.476562\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"124.755859\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"152.539062\"/>\n      <use xlink:href=\"#DejaVuSans-79\" x=\"180.322266\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"239.501953\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"289.501953\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"328.365234\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"389.888672\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"429.097656\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"492.476562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"531.839844\"/>\n     </g>\n    </g>\n    <g id=\"line2d_27\">\n     <path d=\"M 739.585656 57.176109 \nL 751.685656 57.176109 \nL 763.785656 57.176109 \n\" style=\"fill: none; stroke: #228b22; stroke-opacity: 0.6; stroke-width: 3; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_12\">\n     <!-- Backtest -->\n     <g transform=\"translate(773.465656 61.411109)scale(0.121 -0.121)\">\n      <defs>\n       <path id=\"DejaVuSans-42\" d=\"M 1259 2228 \nL 1259 519 \nL 2272 519 \nQ 2781 519 3026 730 \nQ 3272 941 3272 1375 \nQ 3272 1813 3026 2020 \nQ 2781 2228 2272 2228 \nL 1259 2228 \nz\nM 1259 4147 \nL 1259 2741 \nL 2194 2741 \nQ 2656 2741 2882 2914 \nQ 3109 3088 3109 3444 \nQ 3109 3797 2882 3972 \nQ 2656 4147 2194 4147 \nL 1259 4147 \nz\nM 628 4666 \nL 2241 4666 \nQ 2963 4666 3353 4366 \nQ 3744 4066 3744 3513 \nQ 3744 3084 3544 2831 \nQ 3344 2578 2956 2516 \nQ 3422 2416 3680 2098 \nQ 3938 1781 3938 1306 \nQ 3938 681 3513 340 \nQ 3088 0 2303 0 \nL 628 0 \nL 628 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6b\" d=\"M 581 4863 \nL 1159 4863 \nL 1159 1991 \nL 2875 3500 \nL 3609 3500 \nL 1753 1863 \nL 3688 0 \nL 2938 0 \nL 1159 1709 \nL 1159 0 \nL 581 0 \nL 581 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-42\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"68.603516\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"129.882812\"/>\n      <use xlink:href=\"#DejaVuSans-6b\" x=\"184.863281\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"242.773438\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"281.982422\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"343.505859\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"395.605469\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_2\">\n   <g id=\"patch_8\">\n    <path d=\"M 75.177125 828.971652 \nL 856.377125 828.971652 \nL 856.377125 627.536223 \nL 75.177125 627.536223 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_3\">\n    <g id=\"xtick_15\">\n     <g id=\"line2d_28\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"109.976744\" y=\"828.971652\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_16\">\n     <g id=\"line2d_29\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"195.822897\" y=\"828.971652\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_17\">\n     <g id=\"line2d_30\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"283.087996\" y=\"828.971652\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_18\">\n     <g id=\"line2d_31\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"369.643622\" y=\"828.971652\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_19\">\n     <g id=\"line2d_32\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"454.780304\" y=\"828.971652\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_20\">\n     <g id=\"line2d_33\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"542.045402\" y=\"828.971652\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_21\">\n     <g id=\"line2d_34\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"628.601028\" y=\"828.971652\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_22\">\n     <g id=\"line2d_35\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"713.73771\" y=\"828.971652\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_23\">\n     <g id=\"line2d_36\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"801.002808\" y=\"828.971652\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_24\">\n     <g id=\"line2d_37\">\n      <g>\n       <use xlink:href=\"#m3466dc2b85\" x=\"207.883927\" y=\"828.971652\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_25\">\n     <g id=\"line2d_38\">\n      <g>\n       <use xlink:href=\"#m3466dc2b85\" x=\"349.778396\" y=\"828.971652\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_26\">\n     <g id=\"line2d_39\">\n      <g>\n       <use xlink:href=\"#m3466dc2b85\" x=\"491.672866\" y=\"828.971652\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_27\">\n     <g id=\"line2d_40\">\n      <g>\n       <use xlink:href=\"#m3466dc2b85\" x=\"633.567335\" y=\"828.971652\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_28\">\n     <g id=\"line2d_41\">\n      <g>\n       <use xlink:href=\"#m3466dc2b85\" x=\"775.461804\" y=\"828.971652\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_4\">\n    <g id=\"ytick_9\">\n     <g id=\"line2d_42\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"824.502601\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 0.80 -->\n      <g transform=\"translate(38.735719 829.099656)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_10\">\n     <g id=\"line2d_43\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"791.180906\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 1.00 -->\n      <g transform=\"translate(38.735719 795.777961)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_11\">\n     <g id=\"line2d_44\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"757.859211\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 1.20 -->\n      <g transform=\"translate(38.735719 762.456265)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_12\">\n     <g id=\"line2d_45\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"724.537515\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 1.40 -->\n      <g transform=\"translate(38.735719 729.13457)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_13\">\n     <g id=\"line2d_46\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"691.21582\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_17\">\n      <!-- 1.60 -->\n      <g transform=\"translate(38.735719 695.812875)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_14\">\n     <g id=\"line2d_47\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"657.894125\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_18\">\n      <!-- 1.80 -->\n      <g transform=\"translate(38.735719 662.49118)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_19\">\n     <!-- Cumulative returns -->\n     <g transform=\"translate(31.990531 791.635594)rotate(-90)scale(0.132 -0.132)\">\n      <use xlink:href=\"#DejaVuSans-43\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"69.824219\"/>\n      <use xlink:href=\"#DejaVuSans-6d\" x=\"133.203125\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"230.615234\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"293.994141\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"321.777344\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"383.056641\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"422.265625\"/>\n      <use xlink:href=\"#DejaVuSans-76\" x=\"450.048828\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"509.228516\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"570.751953\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"602.539062\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"641.402344\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"702.925781\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"742.134766\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"805.513672\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"844.876953\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"908.255859\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_48\">\n    <path d=\"M 110.686216 791.180906 \nL 111.395688 791.857607 \nL 113.524105 793.013493 \nL 114.233578 792.087459 \nL 114.94305 794.036776 \nL 115.652522 792.436197 \nL 116.361995 792.418118 \nL 118.490412 791.218892 \nL 119.199884 791.732425 \nL 119.909356 792.950323 \nL 120.618829 793.754286 \nL 121.328301 793.210944 \nL 123.456718 792.520018 \nL 124.16619 795.424277 \nL 124.875663 795.113456 \nL 125.585135 799.716071 \nL 133.389331 810.787972 \nL 134.098803 807.145808 \nL 134.808276 806.162668 \nL 135.517748 803.899317 \nL 136.22722 804.070587 \nL 138.355637 804.159329 \nL 139.06511 802.553349 \nL 139.774582 801.705524 \nL 140.484054 802.789346 \nL 141.193527 801.733635 \nL 143.321944 798.768615 \nL 144.031416 800.152429 \nL 144.740889 800.186648 \nL 145.450361 797.25321 \nL 146.159833 797.794666 \nL 148.28825 799.848675 \nL 148.997723 800.964985 \nL 149.707195 801.377383 \nL 150.416667 800.818775 \nL 151.12614 805.723749 \nL 153.254557 801.042483 \nL 153.964029 800.311694 \nL 154.673501 798.903553 \nL 155.382974 795.103128 \nL 156.092446 797.972727 \nL 158.220863 803.147792 \nL 158.930335 800.162218 \nL 159.639808 802.094965 \nL 161.058752 806.924322 \nL 163.18717 812.57059 \nL 163.896642 813.02512 \nL 165.315587 819.267297 \nL 166.025059 816.107063 \nL 168.153476 819.815496 \nL 168.862948 815.515881 \nL 169.572421 812.238347 \nL 170.281893 812.826235 \nL 170.991365 812.170525 \nL 173.119782 812.785177 \nL 173.829255 812.820915 \nL 174.538727 813.214388 \nL 175.248199 811.176442 \nL 175.957672 811.772718 \nL 178.795561 809.153961 \nL 179.505033 809.882739 \nL 180.214506 809.413693 \nL 180.923978 809.561465 \nL 183.052395 810.137161 \nL 183.761868 807.627743 \nL 184.47134 808.772218 \nL 185.180812 808.568822 \nL 185.890285 806.368776 \nL 188.018702 805.791027 \nL 188.728174 807.691738 \nL 189.437646 806.629585 \nL 190.147119 806.984064 \nL 190.856591 808.15037 \nL 192.985008 806.576603 \nL 195.113425 803.520916 \nL 199.370259 803.416477 \nL 200.079731 803.924372 \nL 200.789204 802.922322 \nL 203.627093 803.106415 \nL 204.336566 803.208025 \nL 205.046038 804.996535 \nL 205.75551 805.796563 \nL 207.883927 804.854266 \nL 208.5934 803.58773 \nL 209.302872 803.831829 \nL 210.012344 804.333994 \nL 210.721817 808.161954 \nL 212.850234 807.412693 \nL 213.559706 806.381379 \nL 214.269178 807.101602 \nL 214.978651 806.337021 \nL 215.688123 806.49876 \nL 217.81654 803.065529 \nL 218.526012 802.226512 \nL 219.235485 802.054677 \nL 219.944957 802.364372 \nL 220.65443 801.664363 \nL 222.782847 800.950824 \nL 223.492319 799.941869 \nL 224.201791 801.010733 \nL 224.911264 802.733631 \nL 225.620736 802.323815 \nL 227.749153 804.776897 \nL 228.458625 802.599981 \nL 229.168098 802.484643 \nL 229.87757 802.062822 \nL 230.587042 800.069552 \nL 232.715459 800.287545 \nL 233.424932 800.097561 \nL 234.134404 799.124199 \nL 237.681766 800.093927 \nL 238.391238 799.199621 \nL 239.810183 791.536403 \nL 242.648072 775.909717 \nL 243.357545 775.49872 \nL 244.067017 772.901401 \nL 244.776489 772.250477 \nL 245.485962 777.114807 \nL 247.614379 775.048394 \nL 248.323851 777.316882 \nL 249.033323 779.163991 \nL 249.742796 787.343368 \nL 250.452268 786.056904 \nL 252.580685 780.55739 \nL 253.290157 780.616706 \nL 253.99963 780.371663 \nL 254.709102 780.762479 \nL 255.418574 787.544953 \nL 257.546991 787.278386 \nL 258.256464 786.056931 \nL 258.965936 782.957743 \nL 259.675409 783.597348 \nL 260.384881 782.636874 \nL 262.513298 780.924681 \nL 263.22277 779.251909 \nL 263.932243 780.320514 \nL 264.641715 780.326395 \nL 265.351187 781.860224 \nL 267.479604 780.673542 \nL 268.189077 781.909875 \nL 268.898549 782.61528 \nL 269.608021 783.040772 \nL 270.317494 780.525096 \nL 272.445911 776.194729 \nL 273.155383 776.276528 \nL 273.864855 779.493092 \nL 274.574328 781.81778 \nL 275.2838 780.729252 \nL 277.412217 779.97493 \nL 278.12169 779.321698 \nL 278.831162 781.097773 \nL 279.540634 780.402658 \nL 280.250107 776.216851 \nL 282.378524 777.540212 \nL 283.087996 776.936061 \nL 283.797468 777.35607 \nL 284.506941 778.051018 \nL 285.216413 779.409524 \nL 287.34483 782.416493 \nL 288.054302 780.449625 \nL 288.763775 783.371818 \nL 289.473247 782.843639 \nL 290.182719 781.765833 \nL 292.311136 780.22126 \nL 293.020609 778.955081 \nL 293.730081 780.144021 \nL 294.439553 781.809506 \nL 295.149026 777.330509 \nL 297.277443 779.281017 \nL 297.986915 781.495105 \nL 298.696388 781.213742 \nL 299.40586 784.287498 \nL 300.115332 783.69127 \nL 302.243749 782.574114 \nL 303.662694 783.548888 \nL 310.047945 780.61441 \nL 312.176362 775.168611 \nL 312.885834 775.222073 \nL 313.595307 776.159745 \nL 314.304779 776.057133 \nL 315.014252 775.584529 \nL 317.142669 776.978564 \nL 317.852141 776.482889 \nL 318.561613 775.732458 \nL 319.271086 776.158009 \nL 319.980558 777.393598 \nL 322.108975 779.652416 \nL 322.818447 780.224635 \nL 323.52792 779.192733 \nL 324.237392 778.58856 \nL 324.946864 780.963368 \nL 327.075281 781.744287 \nL 327.784754 779.502509 \nL 328.494226 778.170782 \nL 329.203698 776.15947 \nL 329.913171 776.719189 \nL 332.041588 773.53044 \nL 332.75106 773.645498 \nL 333.460533 773.910237 \nL 334.170005 774.658161 \nL 334.879477 777.840889 \nL 337.007894 775.749417 \nL 337.717367 775.632757 \nL 338.426839 775.213896 \nL 339.136311 773.971461 \nL 339.845784 773.872353 \nL 341.974201 770.752801 \nL 343.393145 773.421753 \nL 344.102618 772.050045 \nL 344.81209 769.197437 \nL 346.940507 770.773651 \nL 347.649979 766.213577 \nL 349.068924 767.1407 \nL 349.778396 766.887 \nL 352.616286 769.175967 \nL 353.325758 770.821674 \nL 354.035231 771.333347 \nL 354.744703 773.013974 \nL 356.87312 770.862641 \nL 357.582592 770.805411 \nL 358.292065 769.911881 \nL 359.001537 766.993774 \nL 359.711009 768.695299 \nL 361.839426 767.925133 \nL 362.548899 770.693625 \nL 363.258371 769.416939 \nL 363.967843 769.70331 \nL 364.677316 768.452089 \nL 366.805733 767.84024 \nL 367.515205 768.18991 \nL 368.224677 765.1292 \nL 368.93415 761.544137 \nL 371.772039 761.397502 \nL 372.481512 759.241113 \nL 373.190984 756.368856 \nL 373.900456 752.518947 \nL 374.609929 753.583574 \nL 376.738346 754.219092 \nL 377.447818 747.233491 \nL 378.15729 749.006611 \nL 378.866763 752.348895 \nL 379.576235 751.987183 \nL 381.704652 750.291162 \nL 382.414124 752.485284 \nL 383.123597 752.164031 \nL 383.833069 750.255709 \nL 384.542541 750.453073 \nL 386.670958 747.663387 \nL 387.380431 752.23753 \nL 388.089903 751.969195 \nL 388.799375 756.455873 \nL 389.508848 757.63026 \nL 391.637265 755.844709 \nL 392.346737 754.491809 \nL 393.05621 754.262587 \nL 393.765682 752.866719 \nL 394.475154 750.756456 \nL 396.603571 748.077472 \nL 397.313044 744.715896 \nL 398.022516 740.635288 \nL 404.407767 741.393853 \nL 406.536184 748.540902 \nL 407.245656 747.686614 \nL 407.955129 752.658968 \nL 408.664601 750.203255 \nL 409.374074 755.279363 \nL 411.502491 753.607809 \nL 412.211963 757.332343 \nL 412.921435 752.015305 \nL 413.630908 757.877491 \nL 414.34038 758.954429 \nL 416.468797 765.166916 \nL 417.178269 768.606928 \nL 417.887742 767.397396 \nL 418.597214 762.370686 \nL 419.306686 761.978631 \nL 421.435103 765.520187 \nL 422.144576 763.77977 \nL 422.854048 764.228829 \nL 423.56352 763.432623 \nL 424.272993 768.477203 \nL 426.40141 767.053769 \nL 427.110882 768.243135 \nL 427.820354 770.955609 \nL 428.529827 771.072554 \nL 429.239299 767.522675 \nL 431.367716 767.092369 \nL 432.077189 764.961412 \nL 432.786661 767.002964 \nL 433.496133 764.66998 \nL 434.205606 762.831113 \nL 437.043495 764.019929 \nL 437.752967 765.97344 \nL 438.46244 765.188154 \nL 439.171912 768.364527 \nL 441.300329 770.361414 \nL 442.009801 771.202652 \nL 442.719274 770.786863 \nL 443.428746 772.817946 \nL 444.138218 771.92254 \nL 446.266635 768.403085 \nL 446.976108 768.579426 \nL 447.68558 768.25742 \nL 448.395053 769.802876 \nL 449.104525 767.830284 \nL 451.232942 770.868376 \nL 451.942414 770.402575 \nL 452.651887 770.578459 \nL 453.361359 768.197435 \nL 454.070831 769.600165 \nL 458.327665 771.823664 \nL 459.037138 774.175402 \nL 461.165555 774.516366 \nL 461.875027 772.482641 \nL 462.584499 771.935612 \nL 463.293972 773.7669 \nL 464.003444 768.961439 \nL 466.131861 766.9737 \nL 466.841334 767.093162 \nL 467.550806 768.507006 \nL 468.260278 767.914935 \nL 468.969751 770.102863 \nL 471.098168 769.246597 \nL 471.80764 761.508943 \nL 472.517112 760.651976 \nL 473.226585 760.234117 \nL 473.936057 760.53846 \nL 476.064474 761.027434 \nL 476.773946 760.990839 \nL 478.192891 764.211461 \nL 478.902363 763.050082 \nL 481.03078 763.674954 \nL 481.740253 764.797533 \nL 482.449725 764.40681 \nL 483.159197 763.320799 \nL 483.86867 764.986537 \nL 486.706559 767.579808 \nL 487.416032 769.8643 \nL 488.125504 770.116959 \nL 488.834976 771.57301 \nL 490.963393 772.830932 \nL 491.672866 771.027652 \nL 492.382338 770.669977 \nL 493.09181 769.9925 \nL 493.801283 767.237506 \nL 495.9297 768.006992 \nL 496.639172 770.055891 \nL 497.348644 769.197997 \nL 498.058117 767.225081 \nL 498.767589 774.07155 \nL 501.605478 774.231004 \nL 502.314951 773.200848 \nL 503.024423 775.95719 \nL 503.733896 776.58576 \nL 506.571785 774.960692 \nL 507.281257 777.783163 \nL 507.99073 773.90704 \nL 508.700202 776.138097 \nL 510.828619 775.304363 \nL 511.538091 775.667526 \nL 512.247564 775.134366 \nL 512.957036 774.908163 \nL 513.666508 776.809332 \nL 515.794925 783.767118 \nL 516.504398 789.265015 \nL 517.923342 786.223732 \nL 518.632815 788.917614 \nL 520.761232 784.695654 \nL 521.470704 784.012064 \nL 522.180176 783.51198 \nL 522.889649 783.821594 \nL 523.599121 785.528369 \nL 525.727538 783.398598 \nL 526.437011 780.5177 \nL 527.146483 781.923314 \nL 527.855955 783.888742 \nL 528.565428 784.334901 \nL 530.693845 784.076937 \nL 531.403317 787.99813 \nL 532.112789 785.805662 \nL 532.822262 788.294801 \nL 533.531734 792.155416 \nL 535.660151 790.69288 \nL 536.369623 788.111856 \nL 537.079096 787.463126 \nL 537.788568 791.288806 \nL 538.49804 789.444338 \nL 540.626457 790.002073 \nL 541.33593 790.845337 \nL 542.045402 787.181009 \nL 542.754875 787.069961 \nL 543.464347 786.596581 \nL 545.592764 784.692748 \nL 546.302236 782.706146 \nL 547.011709 784.581776 \nL 547.721181 785.065754 \nL 548.430653 782.475857 \nL 550.55907 783.030433 \nL 551.268543 785.929162 \nL 551.978015 788.173027 \nL 552.687487 789.145731 \nL 553.39696 787.34892 \nL 556.944321 789.482712 \nL 557.653794 789.187124 \nL 561.201156 784.695131 \nL 561.910628 785.338093 \nL 562.6201 785.45859 \nL 570.424296 781.177713 \nL 571.133768 782.095564 \nL 571.843241 780.296095 \nL 572.552713 781.48578 \nL 573.262185 780.184465 \nL 575.390602 783.699118 \nL 576.100075 782.24173 \nL 576.809547 782.331745 \nL 577.519019 781.062638 \nL 578.228492 778.928813 \nL 580.356909 779.242772 \nL 581.066381 780.443043 \nL 581.775854 782.757668 \nL 582.485326 783.161204 \nL 583.194798 781.671366 \nL 585.323215 782.55184 \nL 586.032688 784.648126 \nL 586.74216 786.29626 \nL 587.451632 784.904812 \nL 588.161105 785.21302 \nL 590.289522 785.497423 \nL 590.998994 785.999399 \nL 591.708466 786.891678 \nL 592.417939 783.497577 \nL 593.127411 784.18874 \nL 595.9653 784.101146 \nL 596.674773 784.823309 \nL 597.384245 786.731519 \nL 598.093717 784.600588 \nL 600.222135 784.641356 \nL 600.931607 783.994335 \nL 601.641079 783.580308 \nL 602.350552 784.323322 \nL 603.060024 785.977827 \nL 605.188441 785.994505 \nL 605.897913 787.164164 \nL 606.607386 786.351915 \nL 607.316858 785.788413 \nL 608.02633 784.141617 \nL 610.154747 783.779387 \nL 610.86422 782.358627 \nL 612.283164 776.661818 \nL 612.992637 777.015073 \nL 615.121054 776.344636 \nL 615.830526 777.183949 \nL 616.539998 778.882855 \nL 617.249471 778.24269 \nL 617.958943 781.043416 \nL 620.08736 782.312695 \nL 620.796833 781.359682 \nL 621.506305 782.031337 \nL 622.215777 780.596594 \nL 622.92525 780.432295 \nL 625.053667 781.06832 \nL 625.763139 779.722675 \nL 626.472611 783.094644 \nL 627.182084 781.965434 \nL 627.891556 781.290167 \nL 630.729445 781.842964 \nL 631.438918 782.370491 \nL 632.14839 784.736556 \nL 632.857862 784.04218 \nL 634.986279 783.349551 \nL 635.695752 784.51321 \nL 636.405224 783.339212 \nL 637.824169 788.582072 \nL 639.952586 788.115619 \nL 640.662058 785.968852 \nL 641.371531 785.986764 \nL 642.081003 783.47974 \nL 642.790475 784.286463 \nL 644.918892 784.771098 \nL 645.628365 788.263839 \nL 646.337837 787.254469 \nL 647.047309 789.649734 \nL 647.756782 793.165233 \nL 654.851505 789.918085 \nL 655.560978 789.797097 \nL 656.27045 788.554134 \nL 656.979922 788.25502 \nL 657.689395 788.373658 \nL 659.817812 790.471318 \nL 661.236756 788.741801 \nL 661.946229 788.574968 \nL 662.655701 787.300438 \nL 664.784118 788.268372 \nL 665.49359 790.561451 \nL 666.203063 789.714473 \nL 666.912535 792.862292 \nL 667.622007 792.002722 \nL 669.750424 791.722949 \nL 670.459897 789.30195 \nL 671.169369 790.29648 \nL 671.878841 790.843704 \nL 672.588314 792.714514 \nL 674.716731 797.442235 \nL 675.426203 799.679928 \nL 676.135676 801.080658 \nL 676.845148 799.663897 \nL 677.55462 799.544074 \nL 679.683037 804.061617 \nL 680.39251 812.094601 \nL 681.101982 805.362171 \nL 681.811454 802.695564 \nL 682.520927 800.75684 \nL 684.649344 801.893056 \nL 685.358816 801.42621 \nL 686.068288 800.577733 \nL 686.777761 801.272615 \nL 687.487233 803.816311 \nL 689.61565 803.991272 \nL 690.325122 804.58577 \nL 691.034595 800.63258 \nL 691.744067 801.530864 \nL 692.453539 799.136575 \nL 696.000901 799.785871 \nL 696.710374 801.333807 \nL 697.419846 800.093502 \nL 699.548263 804.357922 \nL 700.257735 801.777087 \nL 700.967208 802.422831 \nL 701.67668 799.926135 \nL 702.386152 799.819286 \nL 704.514569 802.129485 \nL 705.933514 804.952393 \nL 706.642986 806.991174 \nL 707.352459 806.096474 \nL 709.480876 813.142523 \nL 710.190348 813.271062 \nL 710.89982 810.386537 \nL 712.318765 806.570366 \nL 716.575599 806.807911 \nL 717.285072 811.183196 \nL 719.413489 812.510778 \nL 720.832433 810.025806 \nL 721.541906 811.074914 \nL 722.251378 809.648235 \nL 724.379795 811.14846 \nL 725.089267 809.189883 \nL 725.79874 809.794261 \nL 726.508212 809.847243 \nL 727.217684 806.429887 \nL 729.346101 807.798738 \nL 730.055574 810.405296 \nL 730.765046 809.908068 \nL 731.474519 809.828193 \nL 732.183991 808.848579 \nL 734.312408 808.019588 \nL 735.02188 806.145446 \nL 735.731353 806.96213 \nL 736.440825 807.379978 \nL 739.278714 805.475327 \nL 739.988187 804.334754 \nL 740.697659 802.582791 \nL 741.407131 803.169683 \nL 742.116604 801.490307 \nL 744.245021 804.447209 \nL 745.663965 800.174487 \nL 746.373438 801.934643 \nL 747.08291 799.516264 \nL 749.211327 800.124561 \nL 749.9208 800.040476 \nL 750.630272 801.883397 \nL 752.049217 797.438058 \nL 754.177634 795.325326 \nL 754.887106 793.952642 \nL 755.596578 795.579327 \nL 756.306051 792.929311 \nL 757.015523 793.637012 \nL 759.853412 793.268169 \nL 760.562885 796.253559 \nL 761.272357 796.658907 \nL 761.981829 796.437997 \nL 764.819719 800.281454 \nL 765.529191 800.697033 \nL 766.238663 801.720989 \nL 766.948136 804.734518 \nL 769.076553 802.619015 \nL 769.786025 803.32173 \nL 770.495498 802.864914 \nL 771.20497 804.881789 \nL 771.914442 804.247096 \nL 774.042859 804.849549 \nL 774.752332 803.912745 \nL 775.461804 805.245092 \nL 776.171276 805.396832 \nL 776.880749 807.271507 \nL 779.009166 807.845397 \nL 779.718638 810.590564 \nL 780.42811 811.670343 \nL 781.847055 808.241436 \nL 783.975472 808.951783 \nL 784.684944 808.794874 \nL 785.394417 810.579487 \nL 786.103889 807.555345 \nL 786.813361 807.025705 \nL 788.941779 807.792366 \nL 789.651251 808.514956 \nL 790.360723 807.620579 \nL 791.070196 809.05219 \nL 791.779668 809.51921 \nL 793.908085 809.209892 \nL 794.617557 810.325857 \nL 795.32703 811.812305 \nL 796.036502 809.415418 \nL 796.745974 809.467521 \nL 799.583864 810.811307 \nL 800.293336 808.918039 \nL 801.002808 810.501962 \nL 801.712281 811.641214 \nL 803.840698 812.368795 \nL 804.55017 810.927858 \nL 805.259642 811.67237 \nL 805.969115 811.802171 \nL 806.678587 809.145364 \nL 809.516477 808.516362 \nL 810.225949 809.799624 \nL 810.935421 809.888016 \nL 811.644894 813.432505 \nL 813.773311 813.348814 \nL 814.482783 813.656352 \nL 815.901728 816.055639 \nL 816.6112 816.031986 \nL 818.739617 816.835647 \nL 819.449089 815.325179 \nL 820.158562 816.992955 \nL 820.868034 816.992955 \nL 820.868034 816.992955 \n\" clip-path=\"url(#p5b198ceb87)\" style=\"fill: none; stroke: #808080; stroke-opacity: 0.6; stroke-width: 2; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_49\">\n    <path d=\"M 110.686216 791.180906 \nL 113.524105 791.717713 \nL 114.233578 790.793119 \nL 114.94305 792.041135 \nL 115.652522 790.146596 \nL 116.361995 789.86185 \nL 118.490412 788.270047 \nL 119.199884 788.829562 \nL 119.909356 789.734048 \nL 120.618829 789.97638 \nL 121.328301 788.826572 \nL 123.456718 787.753586 \nL 124.16619 789.335076 \nL 124.875663 788.524526 \nL 125.585135 792.894255 \nL 133.389331 801.861105 \nL 134.098803 798.571284 \nL 135.517748 795.055035 \nL 136.22722 794.564968 \nL 138.355637 794.707115 \nL 139.06511 793.629524 \nL 139.774582 791.549955 \nL 140.484054 793.165642 \nL 141.193527 792.720173 \nL 143.321944 789.88176 \nL 144.031416 790.258222 \nL 144.740889 790.479958 \nL 145.450361 788.63843 \nL 146.159833 788.121335 \nL 148.28825 788.951683 \nL 148.997723 788.981618 \nL 149.707195 790.117886 \nL 150.416667 788.944772 \nL 151.12614 793.401351 \nL 153.254557 789.723518 \nL 153.964029 788.794432 \nL 154.673501 787.567695 \nL 155.382974 784.531813 \nL 156.092446 787.165409 \nL 158.220863 792.049778 \nL 158.930335 789.26787 \nL 159.639808 790.631704 \nL 160.34928 793.660183 \nL 161.058752 795.429483 \nL 163.18717 800.135772 \nL 163.896642 801.2631 \nL 164.606114 803.106607 \nL 165.315587 805.968838 \nL 166.025059 802.714191 \nL 168.153476 806.465982 \nL 169.572421 800.096672 \nL 170.281893 800.54436 \nL 170.991365 799.521712 \nL 173.119782 802.445257 \nL 173.829255 801.976771 \nL 174.538727 802.035711 \nL 175.248199 801.14188 \nL 175.957672 801.794623 \nL 178.795561 799.91013 \nL 179.505033 800.046886 \nL 180.214506 799.268369 \nL 180.923978 799.689622 \nL 183.052395 800.341877 \nL 183.761868 797.539631 \nL 184.47134 798.963076 \nL 185.180812 798.858492 \nL 185.890285 796.667374 \nL 188.018702 796.138199 \nL 188.728174 797.316515 \nL 189.437646 796.910153 \nL 190.147119 797.283467 \nL 190.856591 798.344723 \nL 192.985008 797.592754 \nL 193.69448 795.125717 \nL 194.403953 795.80562 \nL 195.113425 793.719807 \nL 199.370259 792.675558 \nL 200.079731 792.691617 \nL 200.789204 791.768675 \nL 202.917621 791.749474 \nL 203.627093 791.558756 \nL 204.336566 790.793123 \nL 205.046038 792.560817 \nL 205.75551 792.981169 \nL 207.883927 792.26827 \nL 208.5934 791.155862 \nL 209.302872 792.626516 \nL 210.012344 793.718776 \nL 210.721817 797.082461 \nL 212.850234 796.462949 \nL 213.559706 795.272922 \nL 214.269178 795.421027 \nL 214.978651 795.273138 \nL 215.688123 795.352041 \nL 217.81654 792.404111 \nL 218.526012 792.250593 \nL 219.235485 791.265016 \nL 219.944957 792.00848 \nL 220.65443 795.309069 \nL 222.782847 795.398527 \nL 223.492319 793.65841 \nL 224.201791 792.415663 \nL 224.911264 793.289441 \nL 225.620736 792.88456 \nL 227.749153 794.768559 \nL 228.458625 792.740669 \nL 229.168098 791.194369 \nL 229.87757 791.531742 \nL 230.587042 788.056058 \nL 232.715459 788.650491 \nL 233.424932 787.135956 \nL 237.681766 786.670125 \nL 239.100711 783.145603 \nL 239.810183 782.179078 \nL 240.519655 782.49949 \nL 242.648072 779.476996 \nL 243.357545 777.222008 \nL 244.067017 777.470764 \nL 244.776489 775.443728 \nL 245.485962 774.409853 \nL 247.614379 767.086907 \nL 248.323851 767.25592 \nL 249.033323 765.48374 \nL 249.742796 776.646706 \nL 250.452268 776.219095 \nL 252.580685 772.95326 \nL 253.290157 768.598215 \nL 253.99963 768.126628 \nL 254.709102 766.178336 \nL 255.418574 772.648109 \nL 257.546991 770.316262 \nL 258.256464 769.140195 \nL 258.965936 765.630417 \nL 259.675409 763.023271 \nL 260.384881 758.729792 \nL 262.513298 757.671999 \nL 263.22277 760.102996 \nL 263.932243 758.630931 \nL 264.641715 757.971376 \nL 265.351187 760.731489 \nL 267.479604 760.266727 \nL 268.189077 761.524139 \nL 268.898549 765.004982 \nL 269.608021 764.619103 \nL 270.317494 761.923137 \nL 272.445911 758.427459 \nL 273.155383 757.81193 \nL 273.864855 759.090695 \nL 274.574328 761.488229 \nL 275.2838 759.868676 \nL 277.412217 757.855147 \nL 278.12169 758.228642 \nL 278.831162 760.270728 \nL 279.540634 758.329754 \nL 280.250107 753.722106 \nL 282.378524 753.147897 \nL 283.087996 751.904456 \nL 283.797468 752.878798 \nL 284.506941 752.712821 \nL 285.216413 753.530778 \nL 287.34483 757.122489 \nL 288.054302 756.787851 \nL 288.763775 760.355341 \nL 289.473247 758.775997 \nL 290.182719 756.159025 \nL 292.311136 755.53662 \nL 293.020609 755.901912 \nL 293.730081 756.420254 \nL 294.439553 760.226539 \nL 295.149026 757.352774 \nL 297.277443 757.785461 \nL 297.986915 760.172794 \nL 298.696388 759.463095 \nL 299.40586 762.027537 \nL 300.115332 762.026887 \nL 302.243749 761.578826 \nL 302.953222 759.545264 \nL 303.662694 759.808 \nL 310.047945 755.092523 \nL 312.176362 749.594595 \nL 312.885834 748.107825 \nL 313.595307 749.786008 \nL 314.304779 752.06496 \nL 315.014252 752.904794 \nL 317.142669 754.788544 \nL 317.852141 753.589305 \nL 318.561613 755.648335 \nL 319.271086 756.275121 \nL 319.980558 758.134578 \nL 322.108975 759.318641 \nL 322.818447 757.576072 \nL 323.52792 754.06609 \nL 324.946864 756.74387 \nL 327.075281 756.470557 \nL 327.784754 753.012596 \nL 328.494226 751.166025 \nL 329.203698 750.212228 \nL 329.913171 751.752896 \nL 332.041588 750.111148 \nL 332.75106 752.217784 \nL 333.460533 753.768332 \nL 334.170005 752.973102 \nL 334.879477 752.900722 \nL 337.007894 751.117227 \nL 337.717367 754.756191 \nL 338.426839 753.866573 \nL 339.136311 748.917588 \nL 339.845784 746.487363 \nL 341.974201 744.306114 \nL 342.683673 744.084622 \nL 343.393145 747.111309 \nL 344.102618 745.218146 \nL 344.81209 742.033581 \nL 346.940507 744.836135 \nL 347.649979 739.78685 \nL 348.359452 740.776715 \nL 349.068924 740.403973 \nL 349.778396 738.257404 \nL 351.906813 739.2985 \nL 352.616286 739.867065 \nL 353.325758 741.563734 \nL 354.035231 740.556865 \nL 354.744703 740.687881 \nL 356.87312 739.546614 \nL 357.582592 736.129349 \nL 358.292065 733.690636 \nL 359.001537 733.580357 \nL 359.711009 734.032073 \nL 361.839426 729.834717 \nL 362.548899 733.726581 \nL 363.258371 727.881782 \nL 363.967843 729.417453 \nL 364.677316 724.798846 \nL 366.805733 721.059494 \nL 367.515205 722.104755 \nL 368.93415 714.716058 \nL 371.772039 707.329621 \nL 372.481512 700.891461 \nL 373.190984 698.28803 \nL 373.900456 689.656098 \nL 374.609929 689.805966 \nL 376.738346 694.677939 \nL 377.447818 687.938099 \nL 378.15729 689.412025 \nL 378.866763 696.664013 \nL 379.576235 697.990301 \nL 381.704652 694.618853 \nL 382.414124 701.159219 \nL 383.123597 698.35323 \nL 383.833069 692.434281 \nL 384.542541 688.755246 \nL 386.670958 687.110888 \nL 387.380431 689.057076 \nL 388.089903 689.122742 \nL 388.799375 697.126032 \nL 389.508848 696.512126 \nL 391.637265 688.434356 \nL 392.346737 686.753661 \nL 393.05621 683.594148 \nL 393.765682 681.853827 \nL 394.475154 683.928722 \nL 396.603571 672.79183 \nL 397.313044 667.394405 \nL 398.022516 661.033929 \nL 403.698295 656.562423 \nL 404.407767 661.785022 \nL 406.536184 665.346013 \nL 407.955129 673.948838 \nL 408.664601 667.546557 \nL 409.374074 672.990487 \nL 411.502491 671.832309 \nL 412.211963 678.931695 \nL 412.921435 675.046509 \nL 413.630908 687.585057 \nL 414.34038 692.281168 \nL 416.468797 700.619935 \nL 417.178269 707.53497 \nL 417.887742 697.858125 \nL 419.306686 685.385154 \nL 421.435103 692.649352 \nL 422.144576 685.455642 \nL 422.854048 683.345803 \nL 423.56352 682.561238 \nL 424.272993 688.182781 \nL 426.40141 689.689491 \nL 427.110882 693.079743 \nL 427.820354 699.065453 \nL 428.529827 696.540343 \nL 429.239299 687.238554 \nL 431.367716 683.458112 \nL 432.077189 683.079327 \nL 432.786661 690.393495 \nL 433.496133 684.91678 \nL 434.205606 677.5088 \nL 437.043495 680.730176 \nL 437.752967 685.580769 \nL 438.46244 679.431512 \nL 439.171912 686.183847 \nL 441.300329 691.860045 \nL 442.009801 690.822742 \nL 442.719274 690.108465 \nL 443.428746 691.771832 \nL 444.138218 690.579574 \nL 446.266635 684.8751 \nL 446.976108 683.400633 \nL 447.68558 682.641762 \nL 448.395053 683.894679 \nL 449.104525 682.812385 \nL 451.232942 685.595367 \nL 451.942414 684.924818 \nL 452.651887 682.966543 \nL 453.361359 684.853269 \nL 454.070831 685.49921 \nL 458.327665 685.665012 \nL 459.037138 688.364489 \nL 461.165555 686.051229 \nL 461.875027 684.630236 \nL 462.584499 683.726386 \nL 463.293972 686.496113 \nL 464.003444 681.873307 \nL 466.131861 678.048547 \nL 466.841334 678.536445 \nL 468.260278 679.129315 \nL 468.969751 681.440147 \nL 471.098168 681.075444 \nL 471.80764 673.862706 \nL 472.517112 673.28143 \nL 473.226585 674.041234 \nL 473.936057 674.202334 \nL 476.064474 673.473845 \nL 476.773946 675.433007 \nL 477.483419 676.731926 \nL 478.192891 677.69258 \nL 478.902363 676.040253 \nL 481.03078 675.714316 \nL 481.740253 673.651298 \nL 482.449725 673.304937 \nL 483.159197 670.728937 \nL 483.86867 674.952959 \nL 486.706559 675.678341 \nL 487.416032 680.678064 \nL 488.125504 682.547895 \nL 488.834976 681.115644 \nL 490.963393 681.318719 \nL 491.672866 681.26053 \nL 492.382338 687.801283 \nL 493.09181 687.237706 \nL 493.801283 685.147471 \nL 495.9297 682.813622 \nL 496.639172 684.969242 \nL 497.348644 683.381592 \nL 498.058117 687.368741 \nL 498.767589 693.969604 \nL 501.605478 688.686611 \nL 502.314951 683.971329 \nL 503.024423 685.516861 \nL 503.733896 689.117359 \nL 505.862313 685.511548 \nL 506.571785 684.065984 \nL 507.281257 691.527912 \nL 507.99073 689.256106 \nL 508.700202 686.522876 \nL 510.828619 684.303278 \nL 511.538091 684.999165 \nL 512.247564 683.563608 \nL 512.957036 684.01444 \nL 513.666508 686.764344 \nL 515.794925 690.327482 \nL 516.504398 699.454591 \nL 517.21387 700.998545 \nL 517.923342 696.690874 \nL 518.632815 694.995897 \nL 520.761232 684.16777 \nL 521.470704 683.370157 \nL 522.180176 678.639866 \nL 522.889649 676.039613 \nL 523.599121 678.654562 \nL 525.727538 677.219477 \nL 526.437011 674.021349 \nL 527.146483 676.418681 \nL 527.855955 676.165329 \nL 528.565428 677.423619 \nL 530.693845 677.148188 \nL 531.403317 681.938473 \nL 532.822262 684.724498 \nL 533.531734 693.575627 \nL 535.660151 683.583298 \nL 536.369623 681.560984 \nL 537.079096 678.317915 \nL 537.788568 682.198644 \nL 538.49804 679.088356 \nL 540.626457 675.814526 \nL 541.33593 676.940287 \nL 542.045402 673.791942 \nL 542.754875 675.888389 \nL 543.464347 676.008095 \nL 546.302236 666.839732 \nL 547.011709 672.252976 \nL 547.721181 671.408089 \nL 548.430653 662.677404 \nL 551.268543 660.036569 \nL 551.978015 665.505365 \nL 552.687487 663.567036 \nL 553.39696 654.493574 \nL 556.944321 658.220851 \nL 557.653794 658.001426 \nL 558.363266 652.263245 \nL 560.491683 648.553059 \nL 561.201156 653.209624 \nL 561.910628 655.285976 \nL 562.6201 655.081927 \nL 568.295879 649.741336 \nL 570.424296 653.651927 \nL 571.133768 653.112954 \nL 571.843241 647.112125 \nL 572.552713 645.951943 \nL 573.262185 643.938447 \nL 575.390602 644.509721 \nL 576.100075 643.024923 \nL 576.809547 641.917595 \nL 577.519019 643.459625 \nL 578.228492 642.39207 \nL 580.356909 640.483381 \nL 581.066381 641.737421 \nL 582.485326 646.584958 \nL 583.194798 643.804555 \nL 585.323215 648.756397 \nL 586.032688 650.843656 \nL 586.74216 654.272493 \nL 587.451632 650.182335 \nL 588.161105 650.863405 \nL 590.289522 650.150038 \nL 590.998994 650.672535 \nL 591.708466 652.976466 \nL 592.417939 650.667076 \nL 593.127411 649.910088 \nL 595.9653 647.489497 \nL 596.674773 648.379645 \nL 597.384245 651.460046 \nL 598.093717 648.640323 \nL 600.222135 649.237003 \nL 600.931607 650.187738 \nL 601.641079 650.450838 \nL 603.060024 653.318236 \nL 605.188441 654.40614 \nL 605.897913 656.446968 \nL 607.316858 653.815594 \nL 608.02633 650.806745 \nL 610.154747 649.784037 \nL 610.86422 649.165561 \nL 611.573692 642.789087 \nL 612.283164 639.549802 \nL 612.992637 639.569011 \nL 615.121054 636.692379 \nL 615.830526 638.669376 \nL 616.539998 642.568758 \nL 617.958943 654.150071 \nL 620.08736 653.839827 \nL 620.796833 655.584322 \nL 621.506305 656.980627 \nL 622.215777 656.384863 \nL 622.92525 658.39702 \nL 625.053667 658.939754 \nL 625.763139 656.699273 \nL 626.472611 665.704217 \nL 627.182084 664.487368 \nL 627.891556 664.270029 \nL 630.729445 665.337719 \nL 631.438918 667.873676 \nL 632.14839 669.381084 \nL 634.986279 669.145143 \nL 635.695752 671.310626 \nL 636.405224 670.131672 \nL 637.114697 675.373806 \nL 637.824169 676.195838 \nL 639.952586 675.431744 \nL 640.662058 674.311129 \nL 641.371531 675.758008 \nL 642.081003 676.282057 \nL 642.790475 676.470589 \nL 644.918892 676.873047 \nL 645.628365 681.744772 \nL 646.337837 680.771334 \nL 647.756782 689.843703 \nL 654.851505 688.000014 \nL 655.560978 689.226889 \nL 656.27045 683.871971 \nL 656.979922 683.160317 \nL 657.689395 680.146689 \nL 659.817812 679.693243 \nL 660.527284 678.113805 \nL 661.236756 677.391968 \nL 661.946229 678.205334 \nL 662.655701 677.361413 \nL 664.784118 678.007 \nL 665.49359 680.334385 \nL 666.203063 679.164261 \nL 666.912535 684.213972 \nL 667.622007 683.487349 \nL 669.750424 682.660755 \nL 670.459897 681.370801 \nL 671.169369 682.042908 \nL 671.878841 681.909382 \nL 672.588314 684.241442 \nL 674.716731 690.309686 \nL 675.426203 694.424163 \nL 676.135676 696.166208 \nL 676.845148 694.820369 \nL 677.55462 692.399085 \nL 679.683037 695.319594 \nL 680.39251 705.052852 \nL 681.101982 696.536069 \nL 681.811454 692.203007 \nL 682.520927 690.173321 \nL 684.649344 691.454867 \nL 685.358816 692.371047 \nL 686.068288 691.860843 \nL 686.777761 694.102941 \nL 687.487233 696.767492 \nL 689.61565 697.804975 \nL 690.325122 697.46778 \nL 691.034595 690.704299 \nL 691.744067 692.675081 \nL 692.453539 689.200491 \nL 696.000901 691.296181 \nL 696.710374 691.849656 \nL 697.419846 691.318767 \nL 699.548263 696.239618 \nL 700.257735 692.718321 \nL 700.967208 693.884291 \nL 701.67668 691.797849 \nL 702.386152 692.694036 \nL 704.514569 695.019049 \nL 705.224042 697.630837 \nL 706.642986 701.977246 \nL 707.352459 702.001048 \nL 709.480876 711.538425 \nL 710.190348 711.403482 \nL 711.609293 705.288058 \nL 712.318765 702.848708 \nL 716.575599 699.964115 \nL 717.285072 705.505741 \nL 719.413489 707.012574 \nL 720.122961 707.066508 \nL 720.832433 701.527404 \nL 721.541906 702.041204 \nL 722.251378 700.814117 \nL 724.379795 701.960791 \nL 725.089267 698.685571 \nL 725.79874 698.031583 \nL 726.508212 699.83634 \nL 727.217684 695.063941 \nL 729.346101 697.22933 \nL 730.055574 700.518891 \nL 730.765046 698.051357 \nL 732.183991 697.530054 \nL 734.312408 695.444783 \nL 735.02188 695.56994 \nL 735.731353 696.364746 \nL 736.440825 696.384764 \nL 739.278714 695.507517 \nL 739.988187 695.123757 \nL 740.697659 691.723415 \nL 741.407131 693.16378 \nL 742.116604 690.170512 \nL 744.245021 694.108916 \nL 744.954493 690.769783 \nL 745.663965 686.147442 \nL 746.373438 688.931184 \nL 747.08291 682.982112 \nL 749.211327 683.714061 \nL 749.9208 684.114865 \nL 750.630272 687.502122 \nL 751.339744 683.944394 \nL 752.049217 681.016088 \nL 754.177634 677.885099 \nL 754.887106 678.444027 \nL 755.596578 680.167466 \nL 756.306051 675.458271 \nL 757.015523 677.50533 \nL 759.14394 678.490539 \nL 759.853412 678.548166 \nL 760.562885 683.535159 \nL 761.272357 683.185844 \nL 761.981829 683.577656 \nL 764.110246 688.144474 \nL 764.819719 690.64057 \nL 765.529191 689.288779 \nL 766.238663 688.874711 \nL 766.948136 692.325493 \nL 769.076553 688.844741 \nL 769.786025 690.545268 \nL 770.495498 688.969282 \nL 771.20497 690.370799 \nL 771.914442 690.132258 \nL 774.042859 690.99003 \nL 774.752332 691.137729 \nL 775.461804 693.011934 \nL 776.171276 692.855878 \nL 776.880749 698.042401 \nL 779.009166 699.402957 \nL 779.718638 703.564233 \nL 780.42811 703.319667 \nL 781.137583 700.57418 \nL 781.847055 698.82367 \nL 783.975472 698.572233 \nL 784.684944 697.517801 \nL 785.394417 699.355652 \nL 786.103889 696.167338 \nL 786.813361 694.541793 \nL 788.941779 695.612375 \nL 789.651251 697.053318 \nL 790.360723 696.290594 \nL 791.070196 698.305383 \nL 791.779668 701.008842 \nL 793.908085 697.57211 \nL 794.617557 698.242222 \nL 795.32703 701.343477 \nL 796.036502 699.118081 \nL 796.745974 699.080195 \nL 799.583864 700.802691 \nL 800.293336 701.898548 \nL 801.002808 703.612055 \nL 801.712281 706.471446 \nL 803.840698 708.847884 \nL 804.55017 704.453515 \nL 805.969115 705.253751 \nL 806.678587 703.31072 \nL 809.516477 701.448347 \nL 810.225949 703.835836 \nL 810.935421 705.551846 \nL 811.644894 710.844679 \nL 813.773311 711.32122 \nL 814.482783 712.248858 \nL 815.192255 713.982554 \nL 815.901728 714.635939 \nL 816.6112 715.583457 \nL 818.739617 715.495744 \nL 819.449089 712.630692 \nL 820.158562 714.980531 \nL 820.868034 714.59961 \nL 820.868034 714.59961 \n\" clip-path=\"url(#p5b198ceb87)\" style=\"fill: none; stroke: #228b22; stroke-opacity: 0.6; stroke-width: 3; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_50\">\n    <path d=\"M 75.177125 791.180906 \nL 856.377125 791.180906 \n\" clip-path=\"url(#p5b198ceb87)\" style=\"fill: none; stroke-dasharray: 7.4,3.2; stroke-dashoffset: 0; stroke: #000000; stroke-width: 2\"/>\n   </g>\n   <g id=\"patch_9\">\n    <path d=\"M 75.177125 828.971652 \nL 75.177125 627.536223 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_10\">\n    <path d=\"M 856.377125 828.971652 \nL 856.377125 627.536223 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_11\">\n    <path d=\"M 75.177125 828.971652 \nL 856.377125 828.971652 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_12\">\n    <path d=\"M 75.177125 627.536223 \nL 856.377125 627.536223 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_20\">\n    <!-- Cumulative returns volatility matched to benchmark -->\n    <g transform=\"translate(292.59725 621.536223)scale(0.132 -0.132)\">\n     <defs>\n      <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-62\" d=\"M 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\nM 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2969 \nz\n\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-43\"/>\n     <use xlink:href=\"#DejaVuSans-75\" x=\"69.824219\"/>\n     <use xlink:href=\"#DejaVuSans-6d\" x=\"133.203125\"/>\n     <use xlink:href=\"#DejaVuSans-75\" x=\"230.615234\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"293.994141\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"321.777344\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"383.056641\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"422.265625\"/>\n     <use xlink:href=\"#DejaVuSans-76\" x=\"450.048828\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"509.228516\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"570.751953\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"602.539062\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"641.402344\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"702.925781\"/>\n     <use xlink:href=\"#DejaVuSans-75\" x=\"742.134766\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"805.513672\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"844.876953\"/>\n     <use xlink:href=\"#DejaVuSans-73\" x=\"908.255859\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"960.355469\"/>\n     <use xlink:href=\"#DejaVuSans-76\" x=\"992.142578\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"1051.322266\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"1112.503906\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"1140.287109\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"1201.566406\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"1240.775391\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"1268.558594\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"1296.341797\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"1324.125\"/>\n     <use xlink:href=\"#DejaVuSans-79\" x=\"1363.333984\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"1422.513672\"/>\n     <use xlink:href=\"#DejaVuSans-6d\" x=\"1454.300781\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"1551.712891\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"1612.992188\"/>\n     <use xlink:href=\"#DejaVuSans-63\" x=\"1652.201172\"/>\n     <use xlink:href=\"#DejaVuSans-68\" x=\"1707.181641\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"1770.560547\"/>\n     <use xlink:href=\"#DejaVuSans-64\" x=\"1832.083984\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"1895.560547\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"1927.347656\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"1966.556641\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"2027.738281\"/>\n     <use xlink:href=\"#DejaVuSans-62\" x=\"2059.525391\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"2123.001953\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"2184.525391\"/>\n     <use xlink:href=\"#DejaVuSans-63\" x=\"2247.904297\"/>\n     <use xlink:href=\"#DejaVuSans-68\" x=\"2302.884766\"/>\n     <use xlink:href=\"#DejaVuSans-6d\" x=\"2366.263672\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"2463.675781\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"2524.955078\"/>\n     <use xlink:href=\"#DejaVuSans-6b\" x=\"2566.068359\"/>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_3\">\n   <g id=\"patch_13\">\n    <path d=\"M 75.177125 1131.124795 \nL 856.377125 1131.124795 \nL 856.377125 929.689366 \nL 75.177125 929.689366 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_5\">\n    <g id=\"xtick_29\">\n     <g id=\"line2d_51\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"109.976744\" y=\"1131.124795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_30\">\n     <g id=\"line2d_52\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"195.822897\" y=\"1131.124795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_31\">\n     <g id=\"line2d_53\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"283.087996\" y=\"1131.124795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_32\">\n     <g id=\"line2d_54\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"369.643622\" y=\"1131.124795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_33\">\n     <g id=\"line2d_55\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"454.780304\" y=\"1131.124795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_34\">\n     <g id=\"line2d_56\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"542.045402\" y=\"1131.124795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_35\">\n     <g id=\"line2d_57\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"628.601028\" y=\"1131.124795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_36\">\n     <g id=\"line2d_58\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"713.73771\" y=\"1131.124795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_37\">\n     <g id=\"line2d_59\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"801.002808\" y=\"1131.124795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_38\">\n     <g id=\"line2d_60\">\n      <g>\n       <use xlink:href=\"#m3466dc2b85\" x=\"207.883927\" y=\"1131.124795\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_39\">\n     <g id=\"line2d_61\">\n      <g>\n       <use xlink:href=\"#m3466dc2b85\" x=\"349.778396\" y=\"1131.124795\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_40\">\n     <g id=\"line2d_62\">\n      <g>\n       <use xlink:href=\"#m3466dc2b85\" x=\"491.672866\" y=\"1131.124795\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_41\">\n     <g id=\"line2d_63\">\n      <g>\n       <use xlink:href=\"#m3466dc2b85\" x=\"633.567335\" y=\"1131.124795\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_42\">\n     <g id=\"line2d_64\">\n      <g>\n       <use xlink:href=\"#m3466dc2b85\" x=\"775.461804\" y=\"1131.124795\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_6\">\n    <g id=\"ytick_15\">\n     <g id=\"line2d_65\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"1087.85873\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_21\">\n      <!-- 1.00 -->\n      <g transform=\"translate(38.735719 1092.455785)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_16\">\n     <g id=\"line2d_66\">\n      <defs>\n       <path id=\"md3e3106de0\" d=\"M 0 0 \nL -4 0 \n\" style=\"stroke: #000000\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#md3e3106de0\" x=\"75.177125\" y=\"1128.219949\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_17\">\n     <g id=\"line2d_67\">\n      <g>\n       <use xlink:href=\"#md3e3106de0\" x=\"75.177125\" y=\"1106.915874\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_18\">\n     <g id=\"line2d_68\">\n      <g>\n       <use xlink:href=\"#md3e3106de0\" x=\"75.177125\" y=\"962.485334\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n     <g id=\"text_22\">\n      <!-- $\\mathdefault{2\\times10^{0}}$ -->\n      <g transform=\"translate(23.975125 967.082389)scale(0.121 -0.121)\">\n       <defs>\n        <path id=\"DejaVuSans-d7\" d=\"M 4488 3438 \nL 3059 2003 \nL 4488 575 \nL 4116 197 \nL 2681 1631 \nL 1247 197 \nL 878 575 \nL 2303 2003 \nL 878 3438 \nL 1247 3816 \nL 2681 2381 \nL 4116 3816 \nL 4488 3438 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\" transform=\"translate(0 0.765625)\"/>\n       <use xlink:href=\"#DejaVuSans-d7\" transform=\"translate(83.105469 0.765625)\"/>\n       <use xlink:href=\"#DejaVuSans-31\" transform=\"translate(186.376953 0.765625)\"/>\n       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(250 0.765625)\"/>\n       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(314.580078 39.046875)scale(0.7)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_23\">\n     <!-- Cumulative returns -->\n     <g transform=\"translate(17.229938 1093.788737)rotate(-90)scale(0.132 -0.132)\">\n      <use xlink:href=\"#DejaVuSans-43\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"69.824219\"/>\n      <use xlink:href=\"#DejaVuSans-6d\" x=\"133.203125\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"230.615234\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"293.994141\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"321.777344\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"383.056641\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"422.265625\"/>\n      <use xlink:href=\"#DejaVuSans-76\" x=\"450.048828\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"509.228516\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"570.751953\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"602.539062\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"641.402344\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"702.925781\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"742.134766\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"805.513672\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"844.876953\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"908.255859\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_69\">\n    <path d=\"M 110.686216 1087.85873 \nL 111.395688 1088.594875 \nL 113.524105 1089.859269 \nL 114.233578 1088.845601 \nL 114.94305 1090.986036 \nL 115.652522 1089.226675 \nL 116.361995 1089.206899 \nL 118.490412 1087.899974 \nL 119.199884 1088.458471 \nL 119.909356 1089.78994 \nL 120.618829 1090.674276 \nL 121.328301 1090.076142 \nL 123.456718 1089.318387 \nL 124.16619 1092.525152 \nL 124.875663 1092.179227 \nL 125.585135 1097.370558 \nL 133.389331 1110.505152 \nL 134.098803 1106.078327 \nL 134.808276 1104.90172 \nL 135.517748 1102.22172 \nL 136.22722 1102.423135 \nL 138.355637 1102.527585 \nL 139.06511 1100.646607 \nL 139.774582 1099.661439 \nL 140.484054 1100.921792 \nL 141.193527 1099.694018 \nL 143.321944 1096.289667 \nL 144.031416 1097.870552 \nL 144.740889 1097.909819 \nL 145.450361 1094.574155 \nL 146.159833 1095.185242 \nL 148.28825 1097.522354 \nL 148.997723 1098.805305 \nL 149.707195 1099.281577 \nL 150.416667 1098.636751 \nL 151.12614 1104.378889 \nL 153.254557 1098.89471 \nL 153.964029 1098.053388 \nL 154.673501 1096.443215 \nL 155.382974 1092.167743 \nL 156.092446 1095.386655 \nL 158.220863 1101.340561 \nL 158.930335 1097.881785 \nL 159.639808 1100.113301 \nL 161.058752 1105.812587 \nL 163.18717 1112.711955 \nL 163.896642 1113.278977 \nL 165.315587 1121.251406 \nL 166.025059 1117.17129 \nL 168.153476 1121.968639 \nL 168.862948 1116.41814 \nL 169.572421 1112.298606 \nL 170.281893 1113.030652 \nL 170.991365 1112.214343 \nL 173.119782 1112.979428 \nL 173.829255 1113.024013 \nL 174.538727 1113.515612 \nL 175.248199 1110.983773 \nL 175.957672 1111.720895 \nL 178.795561 1108.505702 \nL 179.505033 1109.394739 \nL 180.214506 1108.822048 \nL 180.923978 1109.002278 \nL 183.052395 1109.70614 \nL 183.761868 1106.657906 \nL 184.47134 1108.041752 \nL 185.180812 1107.79504 \nL 185.890285 1105.147753 \nL 188.018702 1104.458931 \nL 188.728174 1106.735007 \nL 189.437646 1105.459565 \nL 190.147119 1105.884227 \nL 190.856591 1107.288529 \nL 192.985008 1105.396178 \nL 195.113425 1101.77751 \nL 199.370259 1101.6551 \nL 200.079731 1102.251171 \nL 200.789204 1101.077033 \nL 202.917621 1101.150387 \nL 204.336566 1101.411025 \nL 205.046038 1103.51596 \nL 205.75551 1104.465519 \nL 207.883927 1103.347621 \nL 208.5934 1101.855865 \nL 209.302872 1102.142416 \nL 210.012344 1102.733343 \nL 210.721817 1107.302532 \nL 212.850234 1106.399055 \nL 213.559706 1105.162808 \nL 214.269178 1106.025256 \nL 214.978651 1105.109825 \nL 215.688123 1105.303089 \nL 217.81654 1101.244368 \nL 218.526012 1100.266189 \nL 219.235485 1100.066503 \nL 219.944957 1100.426552 \nL 220.65443 1099.613746 \nL 222.782847 1098.788973 \nL 223.492319 1097.629113 \nL 224.201791 1098.858077 \nL 224.911264 1100.856787 \nL 225.620736 1100.379359 \nL 227.749153 1103.256141 \nL 228.458625 1100.700949 \nL 229.168098 1100.566571 \nL 229.87757 1100.075963 \nL 230.587042 1097.775482 \nL 232.715459 1098.025653 \nL 233.424932 1097.807606 \nL 234.134404 1096.694572 \nL 237.681766 1097.803438 \nL 238.391238 1096.780573 \nL 242.648072 1071.99618 \nL 243.357545 1071.587913 \nL 244.067017 1069.028944 \nL 244.776489 1068.393265 \nL 245.485962 1073.198605 \nL 247.614379 1071.141635 \nL 248.323851 1073.401019 \nL 249.033323 1075.261792 \nL 249.742796 1083.73983 \nL 250.452268 1082.379774 \nL 252.580685 1076.678276 \nL 253.290157 1076.738821 \nL 253.99963 1076.48883 \nL 254.709102 1076.887702 \nL 255.418574 1083.953876 \nL 257.546991 1083.670885 \nL 258.256464 1082.379802 \nL 258.965936 1079.144717 \nL 259.675409 1079.807645 \nL 260.384881 1078.813059 \nL 262.513298 1077.053507 \nL 263.22277 1075.350839 \nL 263.932243 1076.436691 \nL 264.641715 1076.442685 \nL 265.351187 1078.012805 \nL 267.479604 1076.796855 \nL 268.189077 1078.063859 \nL 268.898549 1078.790761 \nL 269.608021 1079.230636 \nL 270.317494 1076.645321 \nL 272.445911 1072.279841 \nL 273.155383 1072.361335 \nL 273.864855 1075.595346 \nL 274.574328 1077.969173 \nL 275.2838 1076.853756 \nL 277.412217 1076.084816 \nL 278.12169 1075.421557 \nL 278.831162 1077.23061 \nL 279.540634 1076.520432 \nL 280.250107 1072.301877 \nL 282.378524 1073.624986 \nL 283.087996 1073.019749 \nL 283.797468 1073.440299 \nL 284.506941 1074.138295 \nL 285.216413 1075.510589 \nL 287.34483 1078.58562 \nL 288.054302 1076.568329 \nL 288.763775 1079.573614 \nL 289.473247 1079.026706 \nL 290.182719 1077.915786 \nL 292.311136 1076.335561 \nL 293.020609 1075.050373 \nL 293.730081 1076.2569 \nL 294.439553 1077.960668 \nL 295.149026 1073.414677 \nL 297.277443 1075.380331 \nL 297.986915 1077.637809 \nL 298.696388 1077.349365 \nL 299.40586 1080.525699 \nL 300.115332 1079.905198 \nL 302.243749 1078.748259 \nL 303.662694 1079.757333 \nL 310.047945 1076.736477 \nL 312.176362 1071.260664 \nL 312.885834 1071.313622 \nL 313.595307 1072.245 \nL 314.304779 1072.142843 \nL 315.014252 1071.673077 \nL 317.142669 1073.062263 \nL 317.852141 1072.567089 \nL 318.561613 1071.819986 \nL 319.271086 1072.243271 \nL 319.980558 1073.477923 \nL 322.108975 1075.757047 \nL 322.818447 1076.338998 \nL 323.52792 1075.290898 \nL 324.237392 1074.680049 \nL 324.946864 1077.093076 \nL 327.075281 1077.893648 \nL 327.784754 1075.604899 \nL 328.494226 1074.258857 \nL 329.203698 1072.244726 \nL 329.913171 1072.80298 \nL 332.041588 1069.645381 \nL 332.75106 1069.758362 \nL 333.460533 1070.018589 \nL 334.170005 1070.755797 \nL 334.879477 1073.92696 \nL 337.007894 1071.836835 \nL 337.717367 1071.72096 \nL 338.426839 1071.305521 \nL 339.136311 1070.078823 \nL 339.845784 1069.981328 \nL 341.974201 1066.939093 \nL 343.393145 1069.538721 \nL 344.102618 1068.197976 \nL 344.81209 1065.441182 \nL 346.940507 1066.959257 \nL 347.649979 1062.601812 \nL 349.068924 1063.479277 \nL 349.778396 1063.238742 \nL 352.616286 1065.420591 \nL 353.325758 1067.005709 \nL 354.035231 1067.501389 \nL 354.744703 1069.139108 \nL 356.87312 1067.045346 \nL 357.582592 1066.989977 \nL 358.292065 1066.127696 \nL 359.001537 1063.339936 \nL 359.711009 1064.960229 \nL 361.839426 1064.225034 \nL 362.548899 1066.881875 \nL 363.258371 1065.651826 \nL 363.967843 1065.927009 \nL 364.677316 1064.727739 \nL 366.805733 1064.144177 \nL 367.515205 1064.477451 \nL 368.93415 1058.246048 \nL 371.772039 1058.110948 \nL 372.481512 1056.135752 \nL 373.190984 1053.5379 \nL 373.900456 1050.113307 \nL 374.609929 1051.053852 \nL 376.738346 1051.617641 \nL 377.447818 1045.514939 \nL 378.15729 1047.044567 \nL 378.866763 1049.963527 \nL 379.576235 1049.645346 \nL 381.704652 1048.160854 \nL 382.414124 1050.083647 \nL 383.123597 1049.800841 \nL 383.833069 1048.129952 \nL 384.542541 1048.302047 \nL 386.670958 1045.884613 \nL 387.380431 1049.865504 \nL 388.089903 1049.629537 \nL 388.799375 1053.616058 \nL 389.508848 1054.674202 \nL 391.637265 1053.067827 \nL 392.346737 1051.860117 \nL 393.05621 1051.656292 \nL 393.765682 1050.42001 \nL 394.475154 1048.566905 \nL 396.603571 1046.241408 \nL 397.313044 1043.365056 \nL 398.022516 1039.933828 \nL 404.407767 1040.566771 \nL 406.536184 1046.641556 \nL 407.245656 1045.904608 \nL 407.955129 1050.23673 \nL 408.664601 1048.084242 \nL 409.374074 1052.562172 \nL 411.502491 1051.07532 \nL 412.211963 1054.405186 \nL 412.921435 1049.670063 \nL 413.630908 1054.897752 \nL 414.34038 1055.874775 \nL 416.468797 1061.616301 \nL 417.178269 1064.875719 \nL 417.887742 1063.722978 \nL 418.597214 1059.009472 \nL 419.306686 1058.646957 \nL 421.435103 1061.948333 \nL 422.144576 1060.318417 \nL 422.854048 1060.73756 \nL 423.56352 1059.995059 \nL 424.272993 1064.751733 \nL 426.40141 1063.396821 \nL 427.110882 1064.528234 \nL 427.820354 1067.135327 \nL 428.529827 1067.248578 \nL 429.239299 1063.842034 \nL 431.367716 1063.43343 \nL 432.077189 1061.423432 \nL 432.786661 1063.348649 \nL 433.496133 1061.150271 \nL 434.205606 1059.436136 \nL 437.043495 1060.542456 \nL 437.752967 1062.375229 \nL 438.46244 1061.636245 \nL 439.171912 1064.64411 \nL 441.300329 1066.560994 \nL 442.009801 1067.374649 \nL 442.719274 1066.972036 \nL 443.428746 1068.947319 \nL 444.138218 1068.073853 \nL 446.266635 1064.680931 \nL 446.976108 1064.849427 \nL 447.68558 1064.541866 \nL 448.395053 1066.022784 \nL 449.104525 1064.134697 \nL 451.232942 1067.050896 \nL 451.942414 1066.60072 \nL 452.651887 1066.770572 \nL 453.361359 1064.48463 \nL 454.070831 1065.827845 \nL 458.327665 1067.977658 \nL 459.037138 1070.279611 \nL 461.165555 1070.615803 \nL 461.875027 1068.619736 \nL 462.584499 1068.086574 \nL 463.293972 1069.877649 \nL 464.003444 1065.214982 \nL 466.131861 1063.320907 \nL 466.841334 1063.434181 \nL 467.550806 1064.78021 \nL 468.260278 1064.215318 \nL 468.969751 1066.311654 \nL 471.098168 1065.488337 \nL 471.80764 1058.213614 \nL 472.517112 1057.425624 \nL 473.226585 1057.04264 \nL 473.936057 1057.321501 \nL 476.064474 1057.770439 \nL 476.773946 1057.736801 \nL 478.192891 1060.721331 \nL 478.902363 1059.639403 \nL 481.03078 1060.220722 \nL 481.740253 1061.269777 \nL 482.449725 1060.903953 \nL 483.159197 1059.891022 \nL 483.86867 1061.447001 \nL 486.706559 1063.896355 \nL 487.416032 1066.081894 \nL 488.125504 1066.325238 \nL 488.834976 1067.734029 \nL 490.963393 1068.960018 \nL 491.672866 1067.205086 \nL 492.382338 1066.859015 \nL 493.09181 1066.205327 \nL 493.801283 1063.571144 \nL 495.9297 1064.303034 \nL 496.639172 1066.266392 \nL 497.348644 1065.44172 \nL 498.058117 1063.55935 \nL 498.767589 1070.177337 \nL 501.605478 1070.334392 \nL 502.314951 1069.322131 \nL 503.024423 1072.043398 \nL 503.733896 1072.669744 \nL 506.571785 1071.054849 \nL 507.281257 1073.868946 \nL 507.99073 1070.015445 \nL 508.700202 1072.223443 \nL 510.828619 1071.395168 \nL 511.538091 1071.755486 \nL 512.247564 1071.226749 \nL 512.957036 1071.002888 \nL 513.666508 1072.893049 \nL 515.794925 1079.984016 \nL 516.504398 1085.790645 \nL 517.923342 1082.555569 \nL 518.632815 1085.418167 \nL 520.761232 1080.951703 \nL 521.470704 1080.238787 \nL 522.180176 1079.719024 \nL 522.889649 1080.040646 \nL 523.599121 1081.823954 \nL 525.727538 1079.601387 \nL 526.437011 1076.637775 \nL 527.146483 1078.07768 \nL 527.855955 1080.110474 \nL 528.565428 1080.575123 \nL 530.693845 1080.306323 \nL 531.403317 1084.435994 \nL 532.112789 1082.115349 \nL 532.822262 1084.75231 \nL 533.531734 1088.919796 \nL 535.660151 1087.329688 \nL 536.369623 1084.557186 \nL 537.079096 1083.866961 \nL 537.788568 1087.975908 \nL 538.49804 1085.983213 \nL 540.626457 1086.583457 \nL 541.33593 1087.494792 \nL 542.045402 1083.567618 \nL 542.754875 1083.449926 \nL 543.464347 1082.949078 \nL 545.592764 1080.948667 \nL 546.302236 1078.884609 \nL 547.011709 1080.832744 \nL 547.721181 1081.338855 \nL 548.430653 1078.646857 \nL 550.55907 1079.219935 \nL 551.268543 1082.245281 \nL 551.978015 1084.622405 \nL 552.687487 1085.662664 \nL 553.39696 1083.745722 \nL 556.944321 1086.024448 \nL 557.653794 1085.707065 \nL 560.491683 1081.581943 \nL 561.201156 1080.951156 \nL 561.910628 1081.624273 \nL 562.6201 1081.750701 \nL 568.295879 1078.428053 \nL 570.424296 1077.312462 \nL 571.133768 1078.254924 \nL 571.843241 1076.411806 \nL 572.552713 1077.628242 \nL 573.262185 1076.298084 \nL 575.390602 1079.913352 \nL 576.100075 1078.405464 \nL 576.809547 1078.498234 \nL 577.519019 1077.194647 \nL 578.228492 1075.023808 \nL 580.356909 1075.341583 \nL 581.066381 1076.561616 \nL 581.775854 1078.937843 \nL 582.485326 1079.355334 \nL 583.194798 1077.818741 \nL 585.323215 1078.725268 \nL 586.032688 1080.902045 \nL 586.74216 1082.632049 \nL 587.451632 1081.170396 \nL 588.161105 1081.493137 \nL 590.289522 1081.791463 \nL 590.998994 1082.319217 \nL 591.708466 1083.261136 \nL 592.417939 1079.704076 \nL 593.127411 1080.422773 \nL 595.9653 1080.331531 \nL 596.674773 1081.085146 \nL 597.384245 1083.091705 \nL 598.093717 1080.852391 \nL 600.222135 1080.894973 \nL 600.931607 1080.220335 \nL 601.641079 1079.789953 \nL 602.350552 1080.56305 \nL 603.060024 1082.296506 \nL 605.188441 1082.314064 \nL 605.897913 1083.54976 \nL 606.607386 1082.690759 \nL 607.316858 1082.097209 \nL 608.02633 1080.373682 \nL 610.154747 1079.996768 \nL 610.86422 1078.525948 \nL 612.283164 1072.745681 \nL 612.992637 1073.098789 \nL 615.121054 1072.429217 \nL 615.830526 1073.267838 \nL 616.539998 1074.977338 \nL 617.249471 1074.331283 \nL 617.958943 1077.174975 \nL 620.08736 1078.478597 \nL 620.796833 1077.49892 \nL 621.506305 1078.188815 \nL 622.215777 1076.718291 \nL 622.92525 1076.550654 \nL 625.053667 1077.200462 \nL 625.763139 1075.8284 \nL 626.472611 1079.286405 \nL 627.182084 1078.121006 \nL 627.891556 1077.427668 \nL 630.729445 1077.995061 \nL 631.438918 1078.538181 \nL 632.14839 1080.994449 \nL 632.857862 1080.270136 \nL 634.986279 1079.550523 \nL 635.695752 1080.761157 \nL 636.405224 1079.539803 \nL 637.824169 1085.05913 \nL 639.952586 1084.561197 \nL 640.662058 1082.287057 \nL 641.371531 1082.305915 \nL 642.081003 1079.685566 \nL 642.790475 1080.52462 \nL 644.918892 1081.030556 \nL 645.628365 1084.719272 \nL 646.337837 1083.645516 \nL 647.047309 1086.204032 \nL 647.756782 1090.025912 \nL 654.851505 1086.49294 \nL 655.560978 1086.362627 \nL 656.27045 1085.029268 \nL 656.979922 1084.709863 \nL 657.689395 1084.836481 \nL 659.817812 1087.090015 \nL 661.236756 1085.229954 \nL 661.946229 1085.051536 \nL 662.655701 1083.694279 \nL 664.784118 1084.724108 \nL 665.49359 1087.187477 \nL 666.203063 1086.273688 \nL 666.912535 1089.693371 \nL 667.622007 1088.753128 \nL 669.750424 1088.448149 \nL 670.459897 1085.830292 \nL 671.169369 1086.901109 \nL 671.878841 1087.493023 \nL 672.588314 1089.531376 \nL 674.716731 1094.787255 \nL 675.426203 1097.329206 \nL 676.135676 1098.938767 \nL 676.845148 1097.310868 \nL 677.55462 1097.173857 \nL 679.683037 1102.412581 \nL 680.39251 1112.120062 \nL 681.101982 1103.949318 \nL 681.811454 1100.812387 \nL 682.520927 1098.565397 \nL 684.649344 1099.878889 \nL 685.358816 1099.338048 \nL 686.068288 1098.359213 \nL 686.777761 1099.160463 \nL 687.487233 1102.124184 \nL 689.61565 1102.329832 \nL 690.325122 1103.030351 \nL 691.034595 1098.422327 \nL 691.744067 1099.45915 \nL 692.453539 1096.708682 \nL 696.000901 1097.450445 \nL 696.710374 1099.231192 \nL 697.419846 1097.80295 \nL 699.548263 1102.761549 \nL 700.257735 1099.744388 \nL 700.967208 1100.494596 \nL 701.67668 1097.611084 \nL 702.386152 1097.488701 \nL 704.514569 1100.153409 \nL 705.933514 1103.463713 \nL 706.642986 1105.892754 \nL 707.352459 1104.822774 \nL 709.480876 1113.425726 \nL 710.190348 1113.586531 \nL 710.89982 1110.011887 \nL 712.318765 1105.388718 \nL 716.575599 1105.673072 \nL 717.285072 1110.992105 \nL 719.413489 1112.637472 \nL 720.832433 1109.56978 \nL 721.541906 1110.858561 \nL 722.251378 1109.10819 \nL 724.379795 1110.949255 \nL 725.089267 1108.549421 \nL 725.79874 1109.286571 \nL 726.508212 1109.351336 \nL 727.217684 1105.220766 \nL 729.346101 1106.863993 \nL 730.055574 1110.034907 \nL 730.765046 1109.425717 \nL 731.474519 1109.328047 \nL 732.183991 1108.134461 \nL 734.312408 1107.130516 \nL 735.02188 1104.881176 \nL 735.731353 1105.857921 \nL 736.440825 1106.35971 \nL 739.278714 1104.083643 \nL 739.988187 1102.734239 \nL 740.697659 1100.680915 \nL 741.407131 1101.366167 \nL 742.116604 1099.412209 \nL 744.245021 1102.866837 \nL 745.663965 1097.895863 \nL 746.373438 1099.927146 \nL 747.08291 1097.142074 \nL 749.211327 1097.838579 \nL 749.9208 1097.742141 \nL 750.630272 1099.867682 \nL 752.049217 1094.782543 \nL 754.177634 1092.414953 \nL 754.887106 1090.893128 \nL 755.596578 1092.697961 \nL 756.306051 1089.766886 \nL 757.015523 1090.545009 \nL 759.853412 1090.139044 \nL 760.562885 1093.451344 \nL 761.272357 1093.905792 \nL 761.981829 1093.657982 \nL 764.110246 1096.766938 \nL 764.819719 1098.018658 \nL 765.529191 1098.496523 \nL 766.238663 1099.679361 \nL 766.948136 1103.206052 \nL 769.076553 1100.723135 \nL 769.786025 1101.54412 \nL 770.495498 1101.009997 \nL 771.20497 1103.380176 \nL 771.914442 1102.630946 \nL 774.042859 1103.342043 \nL 774.752332 1102.237503 \nL 775.461804 1103.810441 \nL 776.171276 1103.990452 \nL 776.880749 1106.229315 \nL 779.009166 1106.920269 \nL 779.718638 1110.262418 \nL 780.42811 1111.594125 \nL 781.847055 1107.398638 \nL 783.975472 1108.259838 \nL 784.684944 1108.069253 \nL 785.394417 1110.248807 \nL 786.103889 1106.570721 \nL 786.813361 1105.934178 \nL 788.941779 1106.85631 \nL 789.651251 1107.729758 \nL 790.360723 1106.649278 \nL 791.070196 1108.381899 \nL 791.779668 1108.950723 \nL 793.908085 1108.573778 \nL 794.617557 1109.937443 \nL 795.32703 1111.769939 \nL 796.036502 1108.824151 \nL 796.745974 1108.887679 \nL 799.583864 1110.533867 \nL 800.293336 1108.218835 \nL 801.002808 1110.153578 \nL 801.712281 1111.558069 \nL 803.840698 1112.460786 \nL 804.55017 1110.677355 \nL 805.259642 1111.596634 \nL 805.969115 1111.757383 \nL 806.678587 1108.49524 \nL 809.516477 1107.731463 \nL 810.225949 1109.293126 \nL 810.935421 1109.401192 \nL 811.644894 1113.788702 \nL 813.773311 1113.683869 \nL 814.482783 1114.069395 \nL 815.901728 1117.105652 \nL 816.6112 1117.075469 \nL 818.739617 1118.103819 \nL 819.449089 1116.175859 \nL 820.158562 1118.305794 \nL 820.868034 1118.305794 \nL 820.868034 1118.305794 \n\" clip-path=\"url(#p3989b2a8fc)\" style=\"fill: none; stroke: #808080; stroke-opacity: 0.6; stroke-width: 2; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_70\">\n    <path d=\"M 110.686216 1087.85873 \nL 113.524105 1088.606252 \nL 114.233578 1087.321587 \nL 114.94305 1089.060496 \nL 115.652522 1086.43281 \nL 116.361995 1086.039913 \nL 118.490412 1083.858072 \nL 119.199884 1084.624003 \nL 119.909356 1085.867911 \nL 120.618829 1086.202135 \nL 121.328301 1084.622418 \nL 123.456718 1083.157812 \nL 124.16619 1085.324528 \nL 124.875663 1084.213716 \nL 125.585135 1090.292866 \nL 133.389331 1103.345103 \nL 134.098803 1098.524245 \nL 135.517748 1093.47355 \nL 136.22722 1092.777536 \nL 138.355637 1092.979313 \nL 139.06511 1091.455633 \nL 139.774582 1088.545682 \nL 140.484054 1090.810413 \nL 141.193527 1090.184878 \nL 143.321944 1086.246206 \nL 144.031416 1086.766145 \nL 144.740889 1087.072895 \nL 145.450361 1084.541889 \nL 146.159833 1083.835369 \nL 148.28825 1084.972215 \nL 148.997723 1085.013277 \nL 149.707195 1086.578743 \nL 150.416667 1084.965795 \nL 151.12614 1091.183571 \nL 153.254557 1086.075552 \nL 153.964029 1084.799932 \nL 154.673501 1083.126743 \nL 155.382974 1079.043213 \nL 156.092446 1082.597847 \nL 158.220863 1089.351339 \nL 158.930335 1085.505697 \nL 159.639808 1087.389533 \nL 160.34928 1091.634377 \nL 161.058752 1094.148043 \nL 163.18717 1100.988153 \nL 163.896642 1102.651639 \nL 164.606114 1105.399724 \nL 165.315587 1109.736188 \nL 166.025059 1104.838873 \nL 168.153476 1110.529867 \nL 169.572421 1101.009863 \nL 170.281893 1101.668478 \nL 170.991365 1100.168706 \nL 173.119782 1104.497648 \nL 173.829255 1103.800633 \nL 174.538727 1103.888251 \nL 175.248199 1102.564202 \nL 175.957672 1103.531716 \nL 178.795561 1100.755681 \nL 179.505033 1100.956376 \nL 180.214506 1099.817102 \nL 180.923978 1100.433518 \nL 183.052395 1101.391402 \nL 183.761868 1097.316226 \nL 184.47134 1099.384947 \nL 185.180812 1099.232528 \nL 185.890285 1096.067847 \nL 188.018702 1095.308902 \nL 188.728174 1097.00478 \nL 189.437646 1096.419336 \nL 190.147119 1096.957479 \nL 190.856591 1098.495106 \nL 192.985008 1097.406278 \nL 193.69448 1093.874826 \nL 194.403953 1094.845333 \nL 195.113425 1091.887826 \nL 199.370259 1090.419947 \nL 200.079731 1090.442471 \nL 200.789204 1089.152555 \nL 202.917621 1089.125776 \nL 203.627093 1088.859987 \nL 204.336566 1087.796555 \nL 205.046038 1090.264509 \nL 205.75551 1090.854594 \nL 207.883927 1089.855683 \nL 208.5934 1088.306058 \nL 209.302872 1090.361432 \nL 210.012344 1091.89936 \nL 210.721817 1096.710244 \nL 212.850234 1095.819765 \nL 213.559706 1094.119619 \nL 214.269178 1094.330776 \nL 214.978651 1094.119981 \nL 215.688123 1094.232444 \nL 217.81654 1090.078012 \nL 218.526012 1089.863188 \nL 219.235485 1088.489721 \nL 219.944957 1089.526542 \nL 220.65443 1094.196672 \nL 222.782847 1094.324213 \nL 223.492319 1091.859694 \nL 224.201791 1090.114784 \nL 224.911264 1091.342464 \nL 225.620736 1090.773406 \nL 227.749153 1093.438549 \nL 228.458625 1090.580673 \nL 229.168098 1088.424084 \nL 229.87757 1088.893643 \nL 230.587042 1084.116281 \nL 232.715459 1084.92909 \nL 233.424932 1082.867341 \nL 237.681766 1082.236278 \nL 239.100711 1077.521877 \nL 239.810183 1076.244839 \nL 240.519655 1076.667843 \nL 242.648072 1072.718399 \nL 243.357545 1069.813387 \nL 244.067017 1070.132685 \nL 244.776489 1067.548094 \nL 245.485962 1066.23988 \nL 247.614379 1057.221257 \nL 248.323851 1057.426604 \nL 249.033323 1055.285484 \nL 249.742796 1069.253214 \nL 250.452268 1068.707393 \nL 252.580685 1064.589511 \nL 253.290157 1059.214074 \nL 253.99963 1058.637776 \nL 254.709102 1056.274529 \nL 255.418574 1064.267466 \nL 257.546991 1061.374149 \nL 258.256464 1059.92727 \nL 258.965936 1055.669515 \nL 259.675409 1052.554664 \nL 260.384881 1047.520634 \nL 262.513298 1046.294264 \nL 263.22277 1049.129415 \nL 263.932243 1047.413223 \nL 264.641715 1046.647961 \nL 265.351187 1049.875254 \nL 267.479604 1049.329924 \nL 268.189077 1050.810101 \nL 268.898549 1054.964386 \nL 269.608021 1054.501472 \nL 270.317494 1051.298153 \nL 272.445911 1047.211815 \nL 273.155383 1046.498261 \nL 273.864855 1047.985125 \nL 274.574328 1050.801065 \nL 275.2838 1048.900573 \nL 277.412217 1046.559951 \nL 278.12169 1046.993058 \nL 278.831162 1049.378324 \nL 279.540634 1047.116956 \nL 280.250107 1041.845175 \nL 282.378524 1041.194755 \nL 283.087996 1039.793152 \nL 283.797468 1040.892368 \nL 284.506941 1040.704897 \nL 285.216413 1041.63088 \nL 287.34483 1045.749326 \nL 288.054302 1045.363569 \nL 288.763775 1049.520974 \nL 289.473247 1047.678007 \nL 290.182719 1044.658306 \nL 292.311136 1043.944899 \nL 293.020609 1044.363621 \nL 293.730081 1044.959144 \nL 294.439553 1049.39007 \nL 295.149026 1046.052652 \nL 297.277443 1046.553234 \nL 297.986915 1049.338661 \nL 298.696388 1048.50894 \nL 299.40586 1051.528264 \nL 300.115332 1051.527496 \nL 302.243749 1050.99826 \nL 302.953222 1048.614035 \nL 303.662694 1048.921196 \nL 310.047945 1043.488194 \nL 312.176362 1037.313779 \nL 312.885834 1035.667613 \nL 313.595307 1037.53052 \nL 314.304779 1040.085609 \nL 315.014252 1041.033422 \nL 317.142669 1043.175128 \nL 317.852141 1041.812278 \nL 318.561613 1044.162467 \nL 319.271086 1044.881925 \nL 319.980558 1047.031417 \nL 322.108975 1048.409979 \nL 322.818447 1046.388165 \nL 323.52792 1042.373394 \nL 324.946864 1045.440196 \nL 327.075281 1045.125662 \nL 327.784754 1041.191239 \nL 328.494226 1039.115046 \nL 329.203698 1038.04925 \nL 329.913171 1039.776195 \nL 332.041588 1037.940359 \nL 332.75106 1040.304706 \nL 333.460533 1042.059818 \nL 334.170005 1041.159463 \nL 334.879477 1041.077648 \nL 337.007894 1039.073072 \nL 337.717367 1043.197035 \nL 338.426839 1042.185225 \nL 339.136311 1036.650875 \nL 339.845784 1033.976456 \nL 341.974201 1031.601668 \nL 342.683673 1031.361573 \nL 343.393145 1034.671346 \nL 344.102618 1032.602349 \nL 344.81209 1029.166048 \nL 346.940507 1032.199278 \nL 347.649979 1026.790325 \nL 348.359452 1027.844851 \nL 349.068924 1027.447547 \nL 349.778396 1025.175271 \nL 351.906813 1026.27679 \nL 352.616286 1026.880389 \nL 353.325758 1028.692339 \nL 354.035231 1027.617232 \nL 354.744703 1027.756948 \nL 356.87312 1026.543714 \nL 357.582592 1022.953675 \nL 358.292065 1020.423737 \nL 359.001537 1020.309818 \nL 359.711009 1020.776962 \nL 361.839426 1016.48444 \nL 362.548899 1020.481833 \nL 363.258371 1014.539947 \nL 363.967843 1016.093356 \nL 364.677316 1011.469726 \nL 366.805733 1007.790882 \nL 367.515205 1008.816249 \nL 368.93415 1001.683435 \nL 371.772039 994.780067 \nL 372.481512 988.923392 \nL 373.190984 986.591756 \nL 373.900456 979.048507 \nL 374.609929 979.177984 \nL 376.738346 983.437676 \nL 377.447818 977.601057 \nL 378.15729 978.870319 \nL 378.866763 985.238442 \nL 379.576235 986.418441 \nL 381.704652 983.43805 \nL 382.414124 989.286552 \nL 383.123597 986.772156 \nL 383.833069 981.56471 \nL 384.542541 978.382288 \nL 386.670958 976.972438 \nL 387.380431 978.645127 \nL 388.089903 978.70172 \nL 388.799375 985.734847 \nL 389.508848 985.190287 \nL 391.637265 978.169095 \nL 392.346737 976.729924 \nL 393.05621 974.050445 \nL 393.765682 972.586623 \nL 394.475154 974.336328 \nL 396.603571 965.156294 \nL 398.022516 955.820904 \nL 403.698295 952.364879 \nL 404.407767 956.424967 \nL 406.536184 959.232445 \nL 407.955129 966.161263 \nL 408.664601 961.012046 \nL 409.374074 965.408431 \nL 411.502491 964.469171 \nL 412.211963 970.311588 \nL 412.921435 967.11371 \nL 413.630908 977.685862 \nL 414.34038 981.75592 \nL 416.468797 989.178972 \nL 417.178269 995.515293 \nL 417.887742 986.775625 \nL 419.306686 975.95731 \nL 421.435103 982.240388 \nL 422.144576 976.064218 \nL 422.854048 974.279045 \nL 423.56352 973.618261 \nL 424.272993 978.410971 \nL 426.40141 979.70975 \nL 427.110882 982.661994 \nL 427.820354 987.975569 \nL 428.529827 985.729506 \nL 429.239299 977.666929 \nL 431.367716 974.459809 \nL 432.077189 974.140353 \nL 432.786661 980.413378 \nL 433.496133 975.731608 \nL 434.205606 969.55177 \nL 437.043495 972.233042 \nL 437.752967 976.333316 \nL 438.46244 971.176372 \nL 439.171912 976.882751 \nL 441.300329 981.788125 \nL 442.009801 980.887104 \nL 442.719274 980.268597 \nL 443.428746 981.71331 \nL 444.138218 980.678419 \nL 446.266635 975.801201 \nL 446.976108 974.554424 \nL 447.68558 973.915114 \nL 448.395053 974.972669 \nL 449.104525 974.059938 \nL 451.232942 976.418898 \nL 451.942414 975.84933 \nL 452.651887 974.195022 \nL 453.361359 975.791816 \nL 454.070831 976.340684 \nL 458.327665 976.481744 \nL 459.037138 978.793608 \nL 461.165555 976.816237 \nL 461.875027 975.609344 \nL 462.584499 974.844734 \nL 463.293972 977.200265 \nL 464.003444 973.296808 \nL 466.131861 970.114962 \nL 466.841334 970.519292 \nL 468.260278 971.011519 \nL 468.969751 972.942094 \nL 471.098168 972.636748 \nL 471.80764 966.699312 \nL 472.517112 966.22585 \nL 473.226585 966.845331 \nL 473.936057 966.976853 \nL 476.064474 966.38297 \nL 476.773946 967.985736 \nL 477.483419 969.05416 \nL 478.192891 969.847394 \nL 478.902363 968.486481 \nL 481.03078 968.218794 \nL 481.740253 966.533055 \nL 482.449725 966.250997 \nL 483.159197 964.16622 \nL 483.86867 967.606181 \nL 486.706559 968.201052 \nL 487.416032 972.352288 \nL 488.125504 973.921596 \nL 488.834976 972.720605 \nL 491.672866 972.84192 \nL 492.382338 978.403843 \nL 493.09181 977.92111 \nL 493.801283 976.140851 \nL 495.9297 974.169388 \nL 496.639172 975.993888 \nL 497.348644 974.651299 \nL 498.058117 978.047665 \nL 498.767589 983.790342 \nL 501.605478 979.206819 \nL 502.314951 975.194084 \nL 503.024423 976.505882 \nL 503.733896 979.594319 \nL 505.862313 976.512881 \nL 506.571785 975.287615 \nL 507.281257 981.713127 \nL 507.99073 979.748053 \nL 508.700202 977.406299 \nL 510.828619 975.521389 \nL 511.538091 976.111575 \nL 512.247564 974.89704 \nL 512.957036 975.278142 \nL 513.666508 977.619182 \nL 515.794925 980.689486 \nL 516.504398 988.769516 \nL 517.21387 990.158815 \nL 517.923342 986.315393 \nL 518.632815 984.818336 \nL 520.761232 975.519997 \nL 521.470704 974.846229 \nL 522.180176 970.898001 \nL 522.889649 968.753732 \nL 523.599121 970.915804 \nL 525.727538 969.729173 \nL 526.437011 967.108683 \nL 527.146483 969.07567 \nL 527.855955 968.867283 \nL 528.565428 969.904891 \nL 530.693845 969.677542 \nL 531.403317 973.674011 \nL 532.822262 976.026359 \nL 533.531734 983.692579 \nL 535.660151 975.140317 \nL 536.369623 973.440482 \nL 537.079096 970.741987 \nL 537.788568 973.986448 \nL 538.49804 971.391703 \nL 540.626457 968.691791 \nL 541.33593 969.618676 \nL 542.045402 967.041235 \nL 542.754875 968.758776 \nL 543.464347 968.857135 \nL 546.302236 961.462354 \nL 547.011709 965.822908 \nL 547.721181 965.139007 \nL 548.430653 958.213677 \nL 551.268543 956.152302 \nL 551.978015 960.456281 \nL 552.687487 958.927086 \nL 553.39696 951.923197 \nL 556.944321 954.79161 \nL 557.653794 954.622074 \nL 558.363266 950.243126 \nL 560.491683 947.4527 \nL 561.201156 950.973756 \nL 561.910628 952.559304 \nL 562.6201 952.403171 \nL 568.295879 948.363143 \nL 570.424296 951.326982 \nL 571.133768 950.917078 \nL 571.843241 946.41274 \nL 572.552713 945.550043 \nL 573.262185 944.060987 \nL 575.390602 944.48298 \nL 576.100075 943.388776 \nL 576.809547 942.575961 \nL 577.519019 943.709979 \nL 578.228492 942.925214 \nL 580.356909 941.529239 \nL 581.066381 942.446751 \nL 582.485326 946.029902 \nL 583.194798 943.972744 \nL 585.323215 947.662157 \nL 586.032688 949.233003 \nL 586.74216 951.838478 \nL 587.451632 948.744516 \nL 588.161105 949.257955 \nL 590.289522 948.720539 \nL 590.998994 949.114262 \nL 591.708466 950.859832 \nL 592.417939 949.113835 \nL 593.127411 948.543972 \nL 595.9653 946.731759 \nL 596.674773 947.397272 \nL 597.384245 949.717514 \nL 598.093717 947.598427 \nL 600.222135 948.045922 \nL 600.931607 948.760857 \nL 601.641079 948.959031 \nL 603.060024 951.131081 \nL 605.188441 951.960391 \nL 605.897913 953.524868 \nL 607.316858 951.512788 \nL 608.02633 949.235047 \nL 610.154747 948.465224 \nL 610.86422 948.000833 \nL 611.573692 943.278603 \nL 612.283164 940.912834 \nL 612.992637 940.926812 \nL 615.121054 938.845522 \nL 615.830526 940.276933 \nL 616.539998 943.128861 \nL 617.958943 951.819933 \nL 620.08736 951.583484 \nL 620.796833 952.917454 \nL 621.506305 953.990562 \nL 622.215777 953.532514 \nL 622.92525 955.085087 \nL 625.053667 955.505358 \nL 625.763139 953.777571 \nL 626.472611 960.839319 \nL 627.182084 959.877155 \nL 627.891556 959.705644 \nL 630.729445 960.549948 \nL 631.438918 962.569185 \nL 632.14839 963.777238 \nL 634.986279 963.587888 \nL 635.695752 965.333563 \nL 636.405224 964.383089 \nL 637.114697 968.653068 \nL 637.824169 969.328354 \nL 639.952586 968.701093 \nL 640.662058 967.78438 \nL 641.371531 968.970184 \nL 642.081003 969.400977 \nL 642.790475 969.55613 \nL 644.918892 969.887716 \nL 645.628365 973.948872 \nL 646.337837 973.134115 \nL 647.756782 980.863084 \nL 654.851505 979.276685 \nL 655.560978 980.332822 \nL 656.27045 975.773505 \nL 656.979922 975.172877 \nL 657.689395 972.649469 \nL 659.817812 972.271667 \nL 660.527284 970.961246 \nL 661.236756 970.36456 \nL 661.946229 971.037533 \nL 662.655701 970.339896 \nL 664.784118 970.873786 \nL 665.49359 972.810423 \nL 666.203063 971.83645 \nL 666.912535 976.082759 \nL 667.622007 975.468754 \nL 669.750424 974.772281 \nL 670.459897 973.689811 \nL 671.169369 974.253741 \nL 671.878841 974.141643 \nL 672.588314 976.10979 \nL 674.716731 981.321118 \nL 675.426203 984.918721 \nL 676.135676 986.45696 \nL 676.845148 985.269638 \nL 677.55462 983.149953 \nL 679.683037 985.716377 \nL 680.39251 994.514208 \nL 681.101982 986.874427 \nL 681.811454 983.073935 \nL 682.520927 981.312833 \nL 684.649344 982.425164 \nL 685.358816 983.223506 \nL 686.068288 982.778919 \nL 686.777761 984.741925 \nL 687.487233 987.097181 \nL 689.61565 988.019942 \nL 690.325122 987.719852 \nL 691.034595 981.801337 \nL 691.744067 983.518161 \nL 692.453539 980.508417 \nL 696.710374 982.805907 \nL 697.419846 982.344225 \nL 699.548263 986.671888 \nL 700.257735 983.580813 \nL 700.967208 984.602289 \nL 701.67668 982.780713 \nL 702.386152 983.562605 \nL 704.514569 985.605051 \nL 705.933514 989.870314 \nL 706.642986 991.827519 \nL 707.352459 991.849067 \nL 709.480876 1000.696223 \nL 710.190348 1000.56937 \nL 711.609293 994.901611 \nL 712.318765 992.67822 \nL 716.575599 990.076886 \nL 717.285072 995.123896 \nL 719.413489 996.512311 \nL 720.122961 996.56212 \nL 720.832433 991.517223 \nL 721.541906 991.982108 \nL 722.251378 990.874439 \nL 724.379795 991.910702 \nL 725.089267 988.970116 \nL 725.79874 988.386573 \nL 726.508212 990.002666 \nL 727.217684 985.76838 \nL 729.346101 987.687105 \nL 730.055574 990.634519 \nL 730.765046 988.427035 \nL 732.183991 987.962803 \nL 734.312408 986.116872 \nL 735.02188 986.22738 \nL 735.731353 986.930642 \nL 736.440825 986.948375 \nL 739.278714 986.172923 \nL 739.988187 985.834421 \nL 740.697659 982.861231 \nL 741.407131 984.1192 \nL 742.116604 981.518649 \nL 744.245021 984.959016 \nL 744.954493 982.050066 \nL 745.663965 978.085208 \nL 746.373438 980.473977 \nL 747.08291 975.42128 \nL 749.211327 976.039114 \nL 749.9208 976.378072 \nL 750.630272 979.267122 \nL 751.339744 976.244451 \nL 752.049217 973.78503 \nL 754.177634 971.184218 \nL 754.887106 971.647217 \nL 755.596578 973.081559 \nL 756.306051 969.195613 \nL 757.015523 970.882448 \nL 759.14394 971.698253 \nL 759.853412 971.746038 \nL 760.562885 975.929632 \nL 761.272357 975.634927 \nL 761.981829 975.965636 \nL 764.110246 979.863949 \nL 764.819719 982.020367 \nL 765.529191 980.852399 \nL 766.238663 980.49564 \nL 766.948136 983.491852 \nL 769.076553 980.480752 \nL 769.786025 981.950903 \nL 770.495498 980.590438 \nL 771.20497 981.801782 \nL 771.914442 981.595339 \nL 774.042859 982.338979 \nL 774.752332 982.467219 \nL 775.461804 984.102196 \nL 776.171276 983.965765 \nL 776.880749 988.556868 \nL 779.009166 989.773904 \nL 779.718638 993.542247 \nL 780.42811 993.319615 \nL 781.137583 990.83832 \nL 781.847055 989.269185 \nL 783.975472 989.04449 \nL 784.684944 988.104974 \nL 785.394417 989.747573 \nL 786.103889 986.913037 \nL 786.813361 985.479924 \nL 788.941779 986.424129 \nL 789.651251 987.701338 \nL 790.360723 987.025205 \nL 791.070196 988.818238 \nL 791.779668 991.24708 \nL 793.908085 988.174052 \nL 794.617557 988.77137 \nL 795.32703 991.559685 \nL 796.036502 989.561261 \nL 796.745974 989.527348 \nL 799.583864 991.07522 \nL 800.293336 992.065388 \nL 801.002808 993.622704 \nL 801.712281 996.246685 \nL 803.840698 998.449725 \nL 804.55017 994.407552 \nL 805.969115 995.140347 \nL 806.678587 993.367365 \nL 809.516477 991.680556 \nL 810.225949 993.850271 \nL 810.935421 995.421822 \nL 811.644894 1000.347384 \nL 813.773311 1000.794803 \nL 814.482783 1001.668466 \nL 815.192255 1003.310937 \nL 815.901728 1003.932588 \nL 816.6112 1004.837216 \nL 818.739617 1004.753375 \nL 819.449089 1002.035677 \nL 820.158562 1004.268975 \nL 820.868034 1003.906054 \nL 820.868034 1003.906054 \n\" clip-path=\"url(#p3989b2a8fc)\" style=\"fill: none; stroke: #228b22; stroke-opacity: 0.6; stroke-width: 3; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_71\">\n    <path d=\"M 75.177125 1087.85873 \nL 856.377125 1087.85873 \n\" clip-path=\"url(#p3989b2a8fc)\" style=\"fill: none; stroke-dasharray: 7.4,3.2; stroke-dashoffset: 0; stroke: #000000; stroke-width: 2\"/>\n   </g>\n   <g id=\"patch_14\">\n    <path d=\"M 75.177125 1131.124795 \nL 75.177125 929.689366 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_15\">\n    <path d=\"M 856.377125 1131.124795 \nL 856.377125 929.689366 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_16\">\n    <path d=\"M 75.177125 1131.124795 \nL 856.377125 1131.124795 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_17\">\n    <path d=\"M 75.177125 929.689366 \nL 856.377125 929.689366 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_24\">\n    <!-- Cumulative returns on logarithmic scale -->\n    <g transform=\"translate(333.560563 923.689366)scale(0.132 -0.132)\">\n     <defs>\n      <path id=\"DejaVuSans-67\" d=\"M 2906 1791 \nQ 2906 2416 2648 2759 \nQ 2391 3103 1925 3103 \nQ 1463 3103 1205 2759 \nQ 947 2416 947 1791 \nQ 947 1169 1205 825 \nQ 1463 481 1925 481 \nQ 2391 481 2648 825 \nQ 2906 1169 2906 1791 \nz\nM 3481 434 \nQ 3481 -459 3084 -895 \nQ 2688 -1331 1869 -1331 \nQ 1566 -1331 1297 -1286 \nQ 1028 -1241 775 -1147 \nL 775 -588 \nQ 1028 -725 1275 -790 \nQ 1522 -856 1778 -856 \nQ 2344 -856 2625 -561 \nQ 2906 -266 2906 331 \nL 2906 616 \nQ 2728 306 2450 153 \nQ 2172 0 1784 0 \nQ 1141 0 747 490 \nQ 353 981 353 1791 \nQ 353 2603 747 3093 \nQ 1141 3584 1784 3584 \nQ 2172 3584 2450 3431 \nQ 2728 3278 2906 2969 \nL 2906 3500 \nL 3481 3500 \nL 3481 434 \nz\n\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-43\"/>\n     <use xlink:href=\"#DejaVuSans-75\" x=\"69.824219\"/>\n     <use xlink:href=\"#DejaVuSans-6d\" x=\"133.203125\"/>\n     <use xlink:href=\"#DejaVuSans-75\" x=\"230.615234\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"293.994141\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"321.777344\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"383.056641\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"422.265625\"/>\n     <use xlink:href=\"#DejaVuSans-76\" x=\"450.048828\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"509.228516\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"570.751953\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"602.539062\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"641.402344\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"702.925781\"/>\n     <use xlink:href=\"#DejaVuSans-75\" x=\"742.134766\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"805.513672\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"844.876953\"/>\n     <use xlink:href=\"#DejaVuSans-73\" x=\"908.255859\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"960.355469\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"992.142578\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"1053.324219\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"1116.703125\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"1148.490234\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"1176.273438\"/>\n     <use xlink:href=\"#DejaVuSans-67\" x=\"1237.455078\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"1300.931641\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"1362.210938\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"1403.324219\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"1431.107422\"/>\n     <use xlink:href=\"#DejaVuSans-68\" x=\"1470.316406\"/>\n     <use xlink:href=\"#DejaVuSans-6d\" x=\"1533.695312\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"1631.107422\"/>\n     <use xlink:href=\"#DejaVuSans-63\" x=\"1658.890625\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"1713.871094\"/>\n     <use xlink:href=\"#DejaVuSans-73\" x=\"1745.658203\"/>\n     <use xlink:href=\"#DejaVuSans-63\" x=\"1797.757812\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"1852.738281\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"1914.017578\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"1941.800781\"/>\n    </g>\n   </g>\n   <g id=\"legend_2\">\n    <g id=\"patch_18\">\n     <path d=\"M 83.647125 975.22696 \nL 194.388594 975.22696 \nQ 196.808594 975.22696 196.808594 972.80696 \nL 196.808594 938.159366 \nQ 196.808594 935.739366 194.388594 935.739366 \nL 83.647125 935.739366 \nQ 81.227125 935.739366 81.227125 938.159366 \nL 81.227125 972.80696 \nQ 81.227125 975.22696 83.647125 975.22696 \nz\n\" style=\"fill: #ffffff; opacity: 0.5; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_72\">\n     <path d=\"M 86.067125 945.538475 \nL 98.167125 945.538475 \nL 110.267125 945.538475 \n\" style=\"fill: none; stroke: #808080; stroke-opacity: 0.6; stroke-width: 2; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_25\">\n     <!-- daily_return -->\n     <g transform=\"translate(119.947125 949.773475)scale(0.121 -0.121)\">\n      <use xlink:href=\"#DejaVuSans-64\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"63.476562\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"124.755859\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"152.539062\"/>\n      <use xlink:href=\"#DejaVuSans-79\" x=\"180.322266\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"239.501953\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"289.501953\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"328.365234\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"389.888672\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"429.097656\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"492.476562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"531.839844\"/>\n     </g>\n    </g>\n    <g id=\"line2d_73\">\n     <path d=\"M 86.067125 963.635538 \nL 98.167125 963.635538 \nL 110.267125 963.635538 \n\" style=\"fill: none; stroke: #228b22; stroke-opacity: 0.6; stroke-width: 3; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_26\">\n     <!-- Backtest -->\n     <g transform=\"translate(119.947125 967.870538)scale(0.121 -0.121)\">\n      <use xlink:href=\"#DejaVuSans-42\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"68.603516\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"129.882812\"/>\n      <use xlink:href=\"#DejaVuSans-6b\" x=\"184.863281\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"242.773438\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"281.982422\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"343.505859\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"395.605469\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_4\">\n   <g id=\"patch_19\">\n    <path d=\"M 75.177125 1433.277937 \nL 856.377125 1433.277937 \nL 856.377125 1231.842509 \nL 75.177125 1231.842509 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_7\">\n    <g id=\"xtick_43\">\n     <g id=\"line2d_74\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"109.976744\" y=\"1433.277937\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_44\">\n     <g id=\"line2d_75\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"195.822897\" y=\"1433.277937\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_45\">\n     <g id=\"line2d_76\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"283.087996\" y=\"1433.277937\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_46\">\n     <g id=\"line2d_77\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"369.643622\" y=\"1433.277937\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_47\">\n     <g id=\"line2d_78\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"454.780304\" y=\"1433.277937\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_48\">\n     <g id=\"line2d_79\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"542.045402\" y=\"1433.277937\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_49\">\n     <g id=\"line2d_80\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"628.601028\" y=\"1433.277937\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_50\">\n     <g id=\"line2d_81\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"713.73771\" y=\"1433.277937\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_51\">\n     <g id=\"line2d_82\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"801.002808\" y=\"1433.277937\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_52\">\n     <g id=\"line2d_83\">\n      <g>\n       <use xlink:href=\"#m3466dc2b85\" x=\"207.883927\" y=\"1433.277937\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_53\">\n     <g id=\"line2d_84\">\n      <g>\n       <use xlink:href=\"#m3466dc2b85\" x=\"349.778396\" y=\"1433.277937\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_54\">\n     <g id=\"line2d_85\">\n      <g>\n       <use xlink:href=\"#m3466dc2b85\" x=\"491.672866\" y=\"1433.277937\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_55\">\n     <g id=\"line2d_86\">\n      <g>\n       <use xlink:href=\"#m3466dc2b85\" x=\"633.567335\" y=\"1433.277937\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_56\">\n     <g id=\"line2d_87\">\n      <g>\n       <use xlink:href=\"#m3466dc2b85\" x=\"775.461804\" y=\"1433.277937\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_8\">\n    <g id=\"ytick_19\">\n     <g id=\"line2d_88\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"1432.312545\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_27\">\n      <!-- −0.08 -->\n      <g transform=\"translate(28.596297 1436.9096)scale(0.121 -0.121)\">\n       <defs>\n        <path id=\"DejaVuSans-2212\" d=\"M 678 2272 \nL 4684 2272 \nL 4684 1741 \nL 678 1741 \nL 678 2272 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"83.789062\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"147.412109\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"179.199219\"/>\n       <use xlink:href=\"#DejaVuSans-38\" x=\"242.822266\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_20\">\n     <g id=\"line2d_89\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"1403.489725\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_28\">\n      <!-- −0.06 -->\n      <g transform=\"translate(28.596297 1408.08678)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"83.789062\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"147.412109\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"179.199219\"/>\n       <use xlink:href=\"#DejaVuSans-36\" x=\"242.822266\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_21\">\n     <g id=\"line2d_90\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"1374.666905\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_29\">\n      <!-- −0.04 -->\n      <g transform=\"translate(28.596297 1379.26396)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"83.789062\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"147.412109\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"179.199219\"/>\n       <use xlink:href=\"#DejaVuSans-34\" x=\"242.822266\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_22\">\n     <g id=\"line2d_91\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"1345.844085\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_30\">\n      <!-- −0.02 -->\n      <g transform=\"translate(28.596297 1350.44114)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"83.789062\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"147.412109\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"179.199219\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"242.822266\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_23\">\n     <g id=\"line2d_92\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"1317.021265\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_31\">\n      <!-- 0.00 -->\n      <g transform=\"translate(38.735719 1321.61832)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_24\">\n     <g id=\"line2d_93\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"1288.198445\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_32\">\n      <!-- 0.02 -->\n      <g transform=\"translate(38.735719 1292.7955)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_25\">\n     <g id=\"line2d_94\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"1259.375625\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_33\">\n      <!-- 0.04 -->\n      <g transform=\"translate(38.735719 1263.97268)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-34\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_34\">\n     <!-- Returns -->\n     <g transform=\"translate(21.851109 1357.899067)rotate(-90)scale(0.132 -0.132)\">\n      <defs>\n       <path id=\"DejaVuSans-52\" d=\"M 2841 2188 \nQ 3044 2119 3236 1894 \nQ 3428 1669 3622 1275 \nL 4263 0 \nL 3584 0 \nL 2988 1197 \nQ 2756 1666 2539 1819 \nQ 2322 1972 1947 1972 \nL 1259 1972 \nL 1259 0 \nL 628 0 \nL 628 4666 \nL 2053 4666 \nQ 2853 4666 3247 4331 \nQ 3641 3997 3641 3322 \nQ 3641 2881 3436 2590 \nQ 3231 2300 2841 2188 \nz\nM 1259 4147 \nL 1259 2491 \nL 2053 2491 \nQ 2509 2491 2742 2702 \nQ 2975 2913 2975 3322 \nQ 2975 3731 2742 3939 \nQ 2509 4147 2053 4147 \nL 1259 4147 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-52\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"64.982422\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"126.505859\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"165.714844\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"229.09375\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"268.457031\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"331.835938\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_95\">\n    <path d=\"M 111.395688 1318.455391 \nL 113.524105 1321.535277 \nL 114.233578 1306.749162 \nL 114.94305 1330.809775 \nL 115.652522 1295.932145 \nL 116.361995 1313.887425 \nL 118.490412 1299.531999 \nL 119.199884 1323.110974 \nL 119.909356 1326.898203 \nL 120.618829 1319.681763 \nL 121.328301 1304.379622 \nL 123.456718 1305.304518 \nL 124.16619 1334.181766 \nL 124.875663 1308.143551 \nL 125.585135 1364.652478 \nL 133.389331 1417.352478 \nL 134.098803 1278.094225 \nL 134.808276 1296.833207 \nL 135.517748 1296.68526 \nL 136.22722 1311.465034 \nL 138.355637 1318.62804 \nL 139.06511 1304.829942 \nL 139.774582 1293.648484 \nL 140.484054 1334.953196 \nL 141.193527 1312.028641 \nL 143.321944 1285.295402 \nL 144.031416 1321.15797 \nL 144.740889 1319.463254 \nL 145.450361 1296.713514 \nL 146.159833 1311.381 \nL 148.28825 1326.050766 \nL 148.997723 1317.348397 \nL 149.707195 1329.440421 \nL 150.416667 1304.112497 \nL 151.12614 1365.72008 \nL 153.254557 1275.74258 \nL 153.964029 1306.82173 \nL 154.673501 1303.628145 \nL 155.382974 1284.115358 \nL 156.092446 1345.066619 \nL 158.220863 1369.838098 \nL 158.930335 1286.052747 \nL 159.639808 1331.952989 \nL 160.34928 1350.448636 \nL 161.058752 1336.910581 \nL 163.18717 1370.502786 \nL 163.896642 1330.214467 \nL 164.606114 1338.751358 \nL 165.315587 1351.161512 \nL 166.025059 1277.468462 \nL 168.153476 1361.658815 \nL 168.862948 1278.965426 \nL 169.572421 1278.218715 \nL 170.281893 1322.259296 \nL 170.991365 1305.022031 \nL 173.119782 1351.102994 \nL 173.829255 1311.457029 \nL 174.538727 1317.719195 \nL 175.248199 1306.43309 \nL 175.957672 1324.709433 \nL 178.795561 1294.732372 \nL 179.505033 1318.619436 \nL 180.214506 1307.915353 \nL 180.923978 1321.924251 \nL 183.052395 1324.633113 \nL 183.761868 1284.183435 \nL 184.47134 1333.410069 \nL 185.180812 1315.806344 \nL 185.890285 1291.584527 \nL 188.018702 1310.961603 \nL 188.728174 1330.470172 \nL 189.437646 1312.349129 \nL 190.856591 1329.220508 \nL 192.985008 1308.319774 \nL 193.69448 1288.607657 \nL 194.403953 1324.733148 \nL 195.113425 1293.26338 \nL 199.370259 1305.278235 \nL 200.079731 1317.200721 \nL 200.789204 1306.707018 \nL 202.917621 1316.80788 \nL 203.627093 1314.902013 \nL 204.336566 1308.523326 \nL 205.046038 1336.551356 \nL 205.75551 1321.715151 \nL 208.5934 1304.621461 \nL 209.302872 1333.304929 \nL 210.012344 1329.22289 \nL 210.721817 1354.847102 \nL 212.850234 1309.908809 \nL 213.559706 1303.411353 \nL 214.269178 1318.70269 \nL 214.978651 1315.34076 \nL 215.688123 1317.917049 \nL 217.81654 1283.537419 \nL 218.526012 1315.308624 \nL 219.235485 1306.0364 \nL 219.944957 1325.258589 \nL 220.65443 1353.754649 \nL 222.782847 1318.037097 \nL 223.492319 1297.250621 \nL 224.201791 1303.051278 \nL 224.911264 1326.769782 \nL 225.620736 1312.480114 \nL 227.749153 1338.100325 \nL 228.458625 1294.070071 \nL 229.168098 1299.735621 \nL 229.87757 1320.757662 \nL 230.587042 1278.4501 \nL 232.715459 1323.482865 \nL 233.424932 1300.50013 \nL 234.134404 1316.30103 \nL 237.681766 1312.706825 \nL 238.391238 1297.893589 \nL 239.100711 1298.340699 \nL 239.810183 1306.810361 \nL 240.519655 1320.387645 \nL 242.648072 1285.207686 \nL 243.357545 1293.688472 \nL 244.067017 1319.563051 \nL 244.776489 1296.280494 \nL 245.485962 1306.560177 \nL 247.614379 1243.34308 \nL 248.323851 1318.656453 \nL 249.033323 1299.860343 \nL 249.742796 1424.121782 \nL 250.452268 1312.665823 \nL 253.290157 1273.549256 \nL 253.99963 1312.422244 \nL 254.709102 1298.06835 \nL 255.418574 1379.319033 \nL 257.546991 1293.783161 \nL 258.256464 1305.446906 \nL 258.965936 1282.694824 \nL 259.675409 1291.988509 \nL 260.384881 1276.348852 \nL 262.513298 1307.21686 \nL 263.22277 1339.434449 \nL 263.932243 1303.282291 \nL 264.641715 1310.911058 \nL 265.351187 1342.506945 \nL 267.479604 1312.669747 \nL 268.189077 1328.766575 \nL 268.898549 1349.743657 \nL 269.608021 1313.328231 \nL 270.317494 1291.271213 \nL 272.445911 1284.092471 \nL 273.155383 1311.324736 \nL 273.864855 1328.819414 \nL 274.574328 1339.283753 \nL 275.2838 1301.79911 \nL 277.412217 1298.250982 \nL 278.12169 1320.467954 \nL 278.831162 1335.901301 \nL 279.540634 1298.890527 \nL 280.250107 1274.399814 \nL 282.378524 1311.829666 \nL 283.087996 1305.810499 \nL 283.797468 1325.7528 \nL 284.506941 1315.526799 \nL 285.216413 1324.380257 \nL 287.34483 1349.464562 \nL 288.054302 1313.944433 \nL 288.763775 1349.767954 \nL 289.473247 1302.262206 \nL 290.182719 1292.759593 \nL 292.311136 1311.325907 \nL 293.020609 1320.353609 \nL 293.730081 1321.758345 \nL 294.439553 1351.896117 \nL 295.149026 1290.183278 \nL 297.277443 1321.004177 \nL 297.986915 1339.044371 \nL 298.696388 1310.395214 \nL 299.40586 1340.878304 \nL 300.115332 1317.015141 \nL 302.243749 1312.798358 \nL 302.953222 1297.899008 \nL 303.662694 1319.466515 \nL 310.047945 1273.076695 \nL 312.176362 1266.976797 \nL 312.885834 1303.845442 \nL 313.595307 1331.787953 \nL 314.304779 1337.23603 \nL 315.014252 1324.553292 \nL 317.142669 1333.984857 \nL 317.852141 1306.121632 \nL 318.561613 1335.625461 \nL 319.271086 1322.742216 \nL 319.980558 1334.046162 \nL 322.108975 1327.963319 \nL 322.818447 1300.821923 \nL 323.52792 1284.675606 \nL 324.237392 1329.355877 \nL 324.946864 1329.01834 \nL 327.075281 1314.513013 \nL 327.784754 1285.330001 \nL 328.494226 1300.383717 \nL 329.203698 1308.504383 \nL 329.913171 1330.715368 \nL 332.041588 1302.319605 \nL 332.75106 1335.736805 \nL 333.460533 1330.937639 \nL 334.170005 1309.82973 \nL 334.879477 1316.369247 \nL 337.007894 1300.960807 \nL 337.717367 1349.507532 \nL 339.136311 1272.244338 \nL 339.845784 1295.554299 \nL 341.974201 1297.975188 \nL 342.683673 1315.107019 \nL 343.393145 1343.152335 \nL 344.102618 1300.441721 \nL 344.81209 1289.380528 \nL 346.940507 1340.987261 \nL 347.649979 1273.274136 \nL 348.359452 1325.398842 \nL 349.068924 1313.852229 \nL 349.778396 1298.80252 \nL 351.906813 1325.771043 \nL 352.616286 1321.822477 \nL 353.325758 1331.386052 \nL 354.035231 1308.429751 \nL 354.744703 1318.134037 \nL 356.87312 1307.322232 \nL 357.582592 1288.131582 \nL 358.292065 1296.722138 \nL 359.001537 1316.113323 \nL 359.711009 1320.738471 \nL 361.839426 1282.411189 \nL 362.548899 1348.521453 \nL 363.258371 1268.892599 \nL 363.967843 1329.345187 \nL 364.677316 1279.707221 \nL 366.805733 1287.409658 \nL 367.515205 1325.167847 \nL 368.224677 1288.591093 \nL 368.93415 1288.056124 \nL 371.772039 1260.954995 \nL 372.481512 1269.594033 \nL 373.190984 1298.323513 \nL 373.900456 1255.648964 \nL 374.609929 1318.052514 \nL 376.738346 1350.564188 \nL 377.447818 1269.75908 \nL 378.15729 1327.098817 \nL 378.866763 1366.877012 \nL 379.576235 1326.392409 \nL 381.704652 1293.078029 \nL 382.414124 1362.874375 \nL 383.123597 1296.847716 \nL 383.833069 1274.927471 \nL 384.542541 1291.440678 \nL 386.670958 1305.74428 \nL 387.380431 1330.287117 \nL 388.089903 1317.472106 \nL 388.799375 1371.982795 \nL 389.508848 1312.675902 \nL 391.637265 1259.979382 \nL 392.346737 1305.508811 \nL 393.05621 1295.513388 \nL 393.765682 1305.31082 \nL 394.475154 1330.894968 \nL 396.603571 1241.990674 \nL 397.313044 1282.079131 \nL 398.022516 1276.609808 \nL 403.698295 1289.220353 \nL 404.407767 1349.00998 \nL 406.536184 1339.217371 \nL 407.245656 1343.922519 \nL 407.955129 1344.800469 \nL 408.664601 1275.404889 \nL 409.374074 1351.627552 \nL 411.502491 1309.518166 \nL 412.211963 1362.82743 \nL 412.921435 1291.31534 \nL 413.630908 1398.841281 \nL 414.34038 1349.087653 \nL 416.468797 1374.967856 \nL 417.178269 1366.632377 \nL 417.887742 1245.677505 \nL 418.597214 1274.135894 \nL 419.306686 1272.408515 \nL 421.435103 1366.222707 \nL 422.144576 1266.962329 \nL 422.854048 1302.72733 \nL 423.56352 1311.746785 \nL 424.272993 1354.706102 \nL 426.40141 1327.332324 \nL 427.110882 1340.352586 \nL 427.820354 1358.741803 \nL 428.529827 1299.013999 \nL 429.239299 1251.328771 \nL 431.367716 1291.240388 \nL 432.077189 1314.473724 \nL 432.786661 1366.145334 \nL 433.496133 1279.231918 \nL 434.205606 1266.932092 \nL 437.043495 1338.226956 \nL 437.752967 1349.323025 \nL 438.46244 1275.34155 \nL 439.171912 1361.777593 \nL 441.300329 1355.580015 \nL 442.009801 1309.824398 \nL 442.719274 1312.084824 \nL 443.428746 1328.486283 \nL 444.138218 1308.752054 \nL 446.266635 1277.632972 \nL 446.976108 1307.053154 \nL 447.68558 1311.918498 \nL 448.395053 1325.422837 \nL 449.104525 1309.730627 \nL 451.232942 1335.694435 \nL 451.942414 1312.476031 \nL 452.651887 1303.779971 \nL 453.361359 1329.687865 \nL 454.070831 1321.387785 \nL 458.327665 1318.144736 \nL 459.037138 1335.32401 \nL 461.165555 1301.179968 \nL 461.875027 1307.373089 \nL 462.584499 1310.916277 \nL 463.293972 1335.667475 \nL 464.003444 1285.582128 \nL 466.131861 1291.445349 \nL 466.841334 1320.239203 \nL 467.550806 1318.843726 \nL 468.260278 1319.117984 \nL 468.969751 1332.321478 \nL 471.098168 1314.586343 \nL 471.80764 1268.92924 \nL 472.517112 1313.243976 \nL 473.226585 1321.948588 \nL 473.936057 1318.068796 \nL 476.064474 1312.281678 \nL 476.773946 1329.735015 \nL 477.483419 1325.508933 \nL 478.192891 1323.327585 \nL 478.902363 1306.137183 \nL 481.03078 1314.886867 \nL 481.740253 1303.527214 \nL 482.449725 1314.772193 \nL 483.159197 1300.314541 \nL 483.86867 1344.170447 \nL 486.706559 1321.753163 \nL 487.416032 1349.719918 \nL 488.834976 1307.420425 \nL 490.963393 1318.375495 \nL 491.672866 1316.63294 \nL 492.382338 1360.661925 \nL 493.09181 1313.169915 \nL 493.801283 1302.766867 \nL 495.9297 1301.227557 \nL 496.639172 1331.485047 \nL 497.348644 1306.284277 \nL 498.058117 1343.829609 \nL 498.767589 1362.057795 \nL 500.896006 1289.734795 \nL 501.605478 1307.501732 \nL 502.314951 1284.692178 \nL 503.024423 1327.435318 \nL 503.733896 1341.419746 \nL 505.862313 1292.259331 \nL 506.571785 1307.225711 \nL 507.281257 1367.318382 \nL 507.99073 1301.279017 \nL 508.700202 1298.241848 \nL 510.828619 1301.924561 \nL 511.538091 1321.71596 \nL 512.247564 1307.311793 \nL 512.957036 1320.05453 \nL 513.666508 1335.553504 \nL 515.794925 1341.277711 \nL 516.504398 1379.982797 \nL 517.21387 1328.048216 \nL 517.923342 1286.070813 \nL 518.632815 1305.043843 \nL 520.761232 1240.998665 \nL 521.470704 1311.64295 \nL 522.180176 1285.217593 \nL 522.889649 1299.834954 \nL 523.599121 1334.1452 \nL 525.727538 1307.535605 \nL 526.437011 1295.990322 \nL 527.146483 1332.608488 \nL 527.855955 1315.359961 \nL 528.565428 1325.264829 \nL 530.693845 1315.208705 \nL 531.403317 1348.514257 \nL 532.112789 1326.984438 \nL 532.822262 1325.739536 \nL 533.531734 1376.826167 \nL 535.660151 1247.243788 \nL 536.369623 1303.413854 \nL 537.079096 1295.359595 \nL 537.788568 1342.641305 \nL 538.49804 1296.198429 \nL 540.626457 1295.348139 \nL 541.33593 1324.387403 \nL 542.045402 1296.338279 \nL 542.754875 1330.641145 \nL 543.464347 1317.804737 \nL 545.592764 1273.685585 \nL 546.302236 1300.707999 \nL 547.011709 1351.348887 \nL 547.721181 1311.56191 \nL 548.430653 1260.773194 \nL 550.55907 1304.619739 \nL 551.268543 1312.939791 \nL 551.978015 1350.908791 \nL 553.39696 1260.122698 \nL 556.944321 1339.69532 \nL 557.653794 1315.669839 \nL 558.363266 1281.705871 \nL 560.491683 1294.615937 \nL 561.201156 1344.804267 \nL 562.6201 1315.776732 \nL 568.295879 1284.469826 \nL 570.424296 1340.443475 \nL 571.133768 1313.751619 \nL 571.843241 1280.681979 \nL 572.552713 1310.131242 \nL 573.262185 1305.108118 \nL 575.390602 1320.379609 \nL 576.100075 1308.276684 \nL 576.809547 1310.530517 \nL 577.519019 1326.028386 \nL 578.228492 1310.754997 \nL 580.356909 1305.855693 \nL 581.066381 1324.313101 \nL 581.775854 1330.593917 \nL 582.485326 1331.856459 \nL 583.194798 1300.537132 \nL 585.323215 1346.119197 \nL 586.032688 1329.482913 \nL 586.74216 1337.631801 \nL 587.451632 1292.157822 \nL 588.161105 1321.106336 \nL 590.289522 1312.732987 \nL 590.998994 1320.154881 \nL 591.708466 1330.86234 \nL 592.417939 1303.04253 \nL 593.127411 1312.473671 \nL 595.255828 1305.845741 \nL 596.674773 1322.314055 \nL 597.384245 1335.389915 \nL 598.093717 1300.037977 \nL 600.222135 1320.582307 \nL 600.931607 1322.706324 \nL 601.641079 1318.59937 \nL 602.350552 1324.96544 \nL 603.060024 1326.330903 \nL 605.188441 1323.613735 \nL 605.897913 1329.432612 \nL 606.607386 1309.520021 \nL 607.316858 1308.446232 \nL 608.02633 1298.758425 \nL 610.154747 1310.874567 \nL 610.86422 1313.316434 \nL 611.573692 1278.901067 \nL 612.992637 1317.132633 \nL 615.121054 1300.342639 \nL 615.830526 1328.381144 \nL 617.249471 1352.270076 \nL 617.958943 1350.193309 \nL 620.08736 1315.136104 \nL 620.796833 1327.610685 \nL 621.506305 1325.546029 \nL 622.215777 1313.367106 \nL 622.92525 1329.338579 \nL 625.053667 1320.365915 \nL 625.763139 1303.189022 \nL 626.472611 1372.202132 \nL 627.182084 1309.334718 \nL 627.891556 1315.654085 \nL 630.729445 1323.732652 \nL 631.438918 1333.020229 \nL 632.14839 1326.614454 \nL 632.857862 1316.65219 \nL 634.986279 1315.881183 \nL 635.695752 1330.863173 \nL 636.405224 1309.428349 \nL 637.114697 1350.644241 \nL 637.824169 1322.391634 \nL 639.952586 1312.014835 \nL 640.662058 1309.698736 \nL 641.371531 1326.438352 \nL 642.081003 1320.449563 \nL 642.790475 1318.256924 \nL 644.918892 1319.660789 \nL 645.628365 1349.0183 \nL 646.337837 1310.514981 \nL 647.047309 1347.458235 \nL 647.756782 1347.512294 \nL 654.851505 1304.325908 \nL 655.560978 1325.411607 \nL 656.27045 1280.232817 \nL 656.979922 1312.227761 \nL 657.689395 1296.774897 \nL 659.817812 1314.007958 \nL 660.527284 1306.542466 \nL 661.236756 1312.259268 \nL 661.946229 1322.373265 \nL 662.655701 1311.452057 \nL 664.784118 1321.268805 \nL 665.49359 1332.369268 \nL 666.203063 1309.240124 \nL 666.912535 1350.460028 \nL 667.622007 1312.120819 \nL 669.750424 1311.461362 \nL 670.459897 1308.370738 \nL 671.169369 1321.507428 \nL 671.878841 1316.127835 \nL 672.588314 1332.617633 \nL 674.716731 1357.950495 \nL 675.426203 1345.402276 \nL 676.135676 1329.225343 \nL 676.845148 1307.530068 \nL 677.55462 1300.033151 \nL 679.683037 1337.325072 \nL 680.39251 1385.441235 \nL 681.101982 1254.846873 \nL 681.811454 1286.420166 \nL 682.520927 1302.921009 \nL 684.649344 1325.856657 \nL 685.358816 1323.368106 \nL 686.068288 1313.474627 \nL 686.777761 1332.577111 \nL 687.487233 1335.665314 \nL 689.61565 1324.35471 \nL 690.325122 1314.628288 \nL 691.034595 1269.085019 \nL 691.744067 1330.635489 \nL 692.453539 1292.840259 \nL 696.000901 1331.4173 \nL 696.710374 1320.853181 \nL 697.419846 1313.338074 \nL 699.548263 1351.093044 \nL 700.257735 1292.181229 \nL 700.967208 1325.137021 \nL 701.67668 1302.434378 \nL 702.386152 1323.237608 \nL 704.514569 1333.203083 \nL 705.224042 1335.359836 \nL 705.933514 1332.465502 \nL 706.642986 1332.531389 \nL 707.352459 1317.192941 \nL 709.480876 1385.815525 \nL 710.190348 1316.010203 \nL 710.89982 1294.124628 \nL 711.609293 1294.403934 \nL 712.318765 1299.196891 \nL 716.575599 1296.145159 \nL 717.285072 1356.677886 \nL 720.122961 1317.418072 \nL 720.832433 1276.259824 \nL 721.541906 1320.72052 \nL 722.251378 1308.168745 \nL 724.379795 1325.254163 \nL 725.089267 1293.400423 \nL 726.508212 1329.840267 \nL 727.217684 1282.886249 \nL 729.346101 1332.228063 \nL 730.055574 1340.314732 \nL 730.765046 1299.325184 \nL 731.474519 1315.474859 \nL 732.183991 1314.86643 \nL 734.312408 1302.238351 \nL 735.02188 1317.901476 \nL 735.731353 1322.613689 \nL 736.440825 1317.162547 \nL 739.278714 1310.829526 \nL 739.988187 1314.321691 \nL 740.697659 1293.136365 \nL 741.407131 1327.009464 \nL 742.116604 1296.151494 \nL 744.245021 1344.173624 \nL 744.954493 1293.656589 \nL 745.663965 1285.082154 \nL 746.373438 1335.928848 \nL 747.08291 1276.195915 \nL 749.211327 1321.935511 \nL 749.9208 1319.719416 \nL 750.630272 1339.857146 \nL 751.339744 1292.735532 \nL 752.049217 1297.29179 \nL 754.177634 1296.14939 \nL 754.887106 1320.705527 \nL 755.596578 1328.404312 \nL 756.306051 1285.724681 \nL 757.015523 1330.398785 \nL 759.14394 1323.506628 \nL 759.853412 1317.401945 \nL 760.562885 1349.971855 \nL 761.272357 1314.671263 \nL 761.981829 1319.65381 \nL 764.110246 1347.749079 \nL 764.819719 1334.100682 \nL 765.529191 1307.685276 \nL 766.238663 1314.175955 \nL 766.948136 1340.697192 \nL 769.076553 1292.829271 \nL 769.786025 1328.687337 \nL 770.495498 1306.140784 \nL 771.20497 1326.640498 \nL 771.914442 1315.375474 \nL 774.042859 1322.934117 \nL 774.752332 1318.042665 \nL 775.461804 1329.989379 \nL 776.171276 1315.93383 \nL 776.880749 1353.140907 \nL 779.009166 1326.68555 \nL 779.718638 1346.735246 \nL 780.42811 1315.246334 \nL 781.137583 1297.115119 \nL 781.847055 1304.464667 \nL 783.975472 1315.229873 \nL 784.684944 1309.516123 \nL 785.394417 1330.049558 \nL 786.103889 1294.258978 \nL 786.813361 1305.557465 \nL 788.941779 1324.524689 \nL 789.651251 1327.161692 \nL 790.360723 1311.624042 \nL 791.070196 1331.236821 \nL 791.779668 1336.243912 \nL 793.908085 1292.32749 \nL 794.617557 1321.772592 \nL 795.32703 1339.06703 \nL 796.036502 1301.010375 \nL 796.745974 1316.75103 \nL 798.874391 1326.438237 \nL 799.583864 1319.903303 \nL 801.002808 1329.376044 \nL 801.712281 1337.77713 \nL 803.840698 1334.467707 \nL 804.55017 1284.452356 \nL 805.259642 1320.035597 \nL 805.969115 1319.839621 \nL 806.678587 1302.825422 \nL 809.516477 1303.518612 \nL 810.225949 1334.205376 \nL 810.935421 1329.488486 \nL 811.644894 1355.73655 \nL 813.773311 1320.581708 \nL 814.482783 1323.965459 \nL 815.192255 1330.048546 \nL 815.901728 1321.965821 \nL 816.6112 1324.210973 \nL 818.739617 1316.353094 \nL 819.449089 1295.204296 \nL 820.158562 1334.705847 \nL 820.868034 1314.126756 \nL 820.868034 1314.126756 \n\" clip-path=\"url(#p542aba9f2e)\" style=\"fill: none; stroke: #008000; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_20\">\n    <path d=\"M 75.177125 1433.277937 \nL 75.177125 1231.842509 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_21\">\n    <path d=\"M 856.377125 1433.277937 \nL 856.377125 1231.842509 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_22\">\n    <path d=\"M 75.177125 1433.277937 \nL 856.377125 1433.277937 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_23\">\n    <path d=\"M 75.177125 1231.842509 \nL 856.377125 1231.842509 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_35\">\n    <!-- Returns -->\n    <g transform=\"translate(440.438281 1225.842509)scale(0.132 -0.132)\">\n     <use xlink:href=\"#DejaVuSans-52\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"64.982422\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"126.505859\"/>\n     <use xlink:href=\"#DejaVuSans-75\" x=\"165.714844\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"229.09375\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"268.457031\"/>\n     <use xlink:href=\"#DejaVuSans-73\" x=\"331.835938\"/>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_5\">\n   <g id=\"patch_24\">\n    <path d=\"M 75.177125 1735.43108 \nL 856.377125 1735.43108 \nL 856.377125 1533.995652 \nL 75.177125 1533.995652 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_9\">\n    <g id=\"xtick_57\">\n     <g id=\"line2d_96\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"109.976744\" y=\"1735.43108\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_58\">\n     <g id=\"line2d_97\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"195.822897\" y=\"1735.43108\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_59\">\n     <g id=\"line2d_98\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"283.087996\" y=\"1735.43108\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_60\">\n     <g id=\"line2d_99\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"369.643622\" y=\"1735.43108\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_61\">\n     <g id=\"line2d_100\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"454.780304\" y=\"1735.43108\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_62\">\n     <g id=\"line2d_101\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"542.045402\" y=\"1735.43108\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_63\">\n     <g id=\"line2d_102\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"628.601028\" y=\"1735.43108\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_64\">\n     <g id=\"line2d_103\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"713.73771\" y=\"1735.43108\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_65\">\n     <g id=\"line2d_104\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"801.002808\" y=\"1735.43108\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_66\">\n     <g id=\"line2d_105\">\n      <g>\n       <use xlink:href=\"#m3466dc2b85\" x=\"207.883927\" y=\"1735.43108\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_67\">\n     <g id=\"line2d_106\">\n      <g>\n       <use xlink:href=\"#m3466dc2b85\" x=\"349.778396\" y=\"1735.43108\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_68\">\n     <g id=\"line2d_107\">\n      <g>\n       <use xlink:href=\"#m3466dc2b85\" x=\"491.672866\" y=\"1735.43108\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_69\">\n     <g id=\"line2d_108\">\n      <g>\n       <use xlink:href=\"#m3466dc2b85\" x=\"633.567335\" y=\"1735.43108\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_70\">\n     <g id=\"line2d_109\">\n      <g>\n       <use xlink:href=\"#m3466dc2b85\" x=\"775.461804\" y=\"1735.43108\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_10\">\n    <g id=\"ytick_26\">\n     <g id=\"line2d_110\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"1735.43108\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_36\">\n      <!-- -1.00 -->\n      <g transform=\"translate(34.370266 1740.028135)scale(0.121 -0.121)\">\n       <defs>\n        <path id=\"DejaVuSans-2d\" d=\"M 313 2009 \nL 1997 2009 \nL 1997 1497 \nL 313 1497 \nL 313 2009 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-2d\"/>\n       <use xlink:href=\"#DejaVuSans-31\" x=\"36.083984\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"99.707031\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"131.494141\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"195.117188\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_27\">\n     <g id=\"line2d_111\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"1710.251652\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_37\">\n      <!-- -0.75 -->\n      <g transform=\"translate(34.370266 1714.848706)scale(0.121 -0.121)\">\n       <defs>\n        <path id=\"DejaVuSans-37\" d=\"M 525 4666 \nL 3525 4666 \nL 3525 4397 \nL 1831 0 \nL 1172 0 \nL 2766 4134 \nL 525 4134 \nL 525 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-2d\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"36.083984\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"99.707031\"/>\n       <use xlink:href=\"#DejaVuSans-37\" x=\"131.494141\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"195.117188\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_28\">\n     <g id=\"line2d_112\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"1685.072223\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_38\">\n      <!-- -0.50 -->\n      <g transform=\"translate(34.370266 1689.669278)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-2d\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"36.083984\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"99.707031\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"131.494141\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"195.117188\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_29\">\n     <g id=\"line2d_113\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"1659.892795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_39\">\n      <!-- -0.25 -->\n      <g transform=\"translate(34.370266 1664.489849)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-2d\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"36.083984\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"99.707031\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"131.494141\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"195.117188\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_30\">\n     <g id=\"line2d_114\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"1634.713366\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_40\">\n      <!-- 0.00 -->\n      <g transform=\"translate(38.735719 1639.310421)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_31\">\n     <g id=\"line2d_115\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"1609.533937\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_41\">\n      <!-- 0.25 -->\n      <g transform=\"translate(38.735719 1614.130992)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_32\">\n     <g id=\"line2d_116\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"1584.354509\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_42\">\n      <!-- 0.50 -->\n      <g transform=\"translate(38.735719 1588.951564)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_33\">\n     <g id=\"line2d_117\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"1559.17508\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_43\">\n      <!-- 0.75 -->\n      <g transform=\"translate(38.735719 1563.772135)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-37\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_34\">\n     <g id=\"line2d_118\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"1533.995652\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_44\">\n      <!-- 1.00 -->\n      <g transform=\"translate(38.735719 1538.592706)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_45\">\n     <!-- Beta -->\n     <g transform=\"translate(27.625078 1649.934616)rotate(-90)scale(0.132 -0.132)\">\n      <use xlink:href=\"#DejaVuSans-42\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"68.603516\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"130.126953\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"169.335938\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_119\">\n    <path d=\"M 248.323851 1550.019755 \nL 249.033323 1550.72475 \nL 249.742796 1545.44651 \nL 250.452268 1545.486734 \nL 253.290157 1546.155687 \nL 254.709102 1546.417861 \nL 255.418574 1545.348058 \nL 258.256464 1545.332581 \nL 258.965936 1544.963075 \nL 259.675409 1545.240256 \nL 260.384881 1544.96185 \nL 262.513298 1544.906087 \nL 263.22277 1545.535454 \nL 263.932243 1546.592347 \nL 264.641715 1548.947221 \nL 265.351187 1548.925273 \nL 267.479604 1549.131426 \nL 268.189077 1549.056879 \nL 268.898549 1548.658982 \nL 269.608021 1548.715373 \nL 270.317494 1548.453401 \nL 272.445911 1548.523906 \nL 274.574328 1549.126451 \nL 275.2838 1548.927992 \nL 278.12169 1548.737187 \nL 279.540634 1548.172256 \nL 280.250107 1547.389647 \nL 283.087996 1547.758432 \nL 283.797468 1548.602242 \nL 284.506941 1548.795633 \nL 285.216413 1548.829065 \nL 287.34483 1548.25433 \nL 288.054302 1548.689071 \nL 288.763775 1548.441873 \nL 289.473247 1549.648081 \nL 292.311136 1549.922207 \nL 293.020609 1550.870671 \nL 293.730081 1551.054512 \nL 294.439553 1551.416632 \nL 295.149026 1551.90805 \nL 297.277443 1551.957972 \nL 297.986915 1552.299184 \nL 298.696388 1552.993638 \nL 299.40586 1554.029571 \nL 300.115332 1554.097285 \nL 302.953222 1555.240914 \nL 303.662694 1555.276562 \nL 310.047945 1554.737045 \nL 312.176362 1553.577209 \nL 312.885834 1553.650573 \nL 313.595307 1553.109608 \nL 315.014252 1553.114333 \nL 317.852141 1552.775143 \nL 318.561613 1553.015467 \nL 319.271086 1553.039731 \nL 319.980558 1553.305526 \nL 322.108975 1553.657228 \nL 322.818447 1553.925764 \nL 323.52792 1553.870625 \nL 324.946864 1554.088396 \nL 327.075281 1554.095239 \nL 327.784754 1553.599306 \nL 334.170005 1553.987372 \nL 334.879477 1555.103331 \nL 337.717367 1554.98847 \nL 338.426839 1554.92862 \nL 339.136311 1554.666558 \nL 339.845784 1554.738512 \nL 341.974201 1554.831501 \nL 342.683673 1555.106101 \nL 343.393145 1554.755556 \nL 344.102618 1554.800953 \nL 344.81209 1555.418774 \nL 346.940507 1554.883168 \nL 347.649979 1553.999804 \nL 348.359452 1553.862934 \nL 349.778396 1553.895613 \nL 351.906813 1554.190858 \nL 353.325758 1553.84346 \nL 354.035231 1554.055873 \nL 354.744703 1553.860887 \nL 356.87312 1553.976548 \nL 357.582592 1554.21048 \nL 358.292065 1553.614424 \nL 359.001537 1554.444367 \nL 359.711009 1554.564091 \nL 361.839426 1554.680385 \nL 363.258371 1553.314083 \nL 363.967843 1553.152105 \nL 364.677316 1553.449228 \nL 367.515205 1553.295388 \nL 368.93415 1552.473517 \nL 371.772039 1552.744092 \nL 373.190984 1549.521415 \nL 373.900456 1545.007917 \nL 374.609929 1529.314334 \nL 376.738346 1528.862871 \nL 377.447818 1528.580657 \nL 378.15729 1528.625299 \nL 378.866763 1521.931363 \nL 379.576235 1524.031029 \nL 381.704652 1523.038371 \nL 382.414124 1520.261215 \nL 383.123597 1527.417461 \nL 383.833069 1526.311357 \nL 384.542541 1523.745053 \nL 386.670958 1524.177395 \nL 387.380431 1526.015847 \nL 388.089903 1525.725096 \nL 388.799375 1524.140538 \nL 389.508848 1524.521543 \nL 391.637265 1523.011129 \nL 392.346737 1523.258455 \nL 393.05621 1522.611095 \nL 393.765682 1523.258838 \nL 394.475154 1524.342259 \nL 396.603571 1519.894132 \nL 397.313044 1518.810077 \nL 398.022516 1518.340665 \nL 403.698295 1519.770966 \nL 404.407767 1519.258146 \nL 406.536184 1523.736187 \nL 407.245656 1524.874221 \nL 407.955129 1525.416588 \nL 409.374074 1523.61783 \nL 411.502491 1523.890369 \nL 412.211963 1521.261247 \nL 412.921435 1523.66185 \nL 413.630908 1519.142698 \nL 414.34038 1518.613692 \nL 416.468797 1517.455528 \nL 417.887742 1515.053703 \nL 418.597214 1515.479607 \nL 419.306686 1514.881729 \nL 421.435103 1513.502025 \nL 422.144576 1512.653055 \nL 423.56352 1512.719951 \nL 424.272993 1513.503025 \nL 427.110882 1513.479149 \nL 427.820354 1512.490038 \nL 428.529827 1512.760461 \nL 429.239299 1510.545605 \nL 431.367716 1510.003499 \nL 432.077189 1510.670237 \nL 432.786661 1510.111528 \nL 433.496133 1507.687578 \nL 434.205606 1506.299087 \nL 437.043495 1506.101572 \nL 438.46244 1504.772948 \nL 439.171912 1503.595939 \nL 441.300329 1502.485839 \nL 442.719274 1502.47531 \nL 443.428746 1503.200542 \nL 444.138218 1502.005517 \nL 446.266635 1501.984244 \nL 446.976108 1502.194 \nL 448.395053 1502.156693 \nL 449.104525 1502.940615 \nL 451.232942 1503.405294 \nL 451.942414 1503.022304 \nL 452.651887 1503.122284 \nL 453.361359 1505.115867 \nL 454.070831 1504.880354 \nL 458.327665 1505.37971 \nL 459.037138 1505.778387 \nL 461.165555 1505.6473 \nL 461.875027 1505.801853 \nL 462.584499 1505.711876 \nL 463.293972 1505.750529 \nL 464.003444 1507.537952 \nL 466.131861 1506.868683 \nL 466.841334 1506.991511 \nL 467.550806 1505.920097 \nL 468.969751 1506.270691 \nL 471.098168 1506.262271 \nL 471.80764 1508.689354 \nL 472.517112 1508.477935 \nL 473.936057 1508.529838 \nL 476.064474 1509.165084 \nL 476.773946 1509.137263 \nL 477.483419 1508.389054 \nL 478.192891 1508.221942 \nL 478.902363 1508.696188 \nL 481.03078 1508.739871 \nL 481.740253 1508.967336 \nL 482.449725 1509.366695 \nL 483.86867 1508.599437 \nL 486.706559 1509.290178 \nL 487.416032 1508.736759 \nL 488.125504 1508.564029 \nL 488.834976 1509.116875 \nL 490.963393 1509.349518 \nL 491.672866 1509.938259 \nL 492.382338 1509.881115 \nL 493.09181 1509.392386 \nL 493.801283 1510.139016 \nL 495.9297 1510.56298 \nL 496.639172 1509.063692 \nL 497.348644 1508.79529 \nL 498.767589 1513.068435 \nL 500.896006 1513.894202 \nL 502.314951 1514.08126 \nL 503.024423 1514.907164 \nL 503.733896 1514.730167 \nL 505.862313 1514.387847 \nL 506.571785 1513.996486 \nL 507.281257 1512.951433 \nL 507.99073 1515.597345 \nL 508.700202 1516.599643 \nL 510.828619 1518.261805 \nL 511.538091 1518.168013 \nL 512.247564 1518.363173 \nL 512.957036 1516.953091 \nL 513.666508 1516.800536 \nL 515.794925 1522.68891 \nL 516.504398 1521.136866 \nL 517.21387 1522.312129 \nL 517.923342 1522.752422 \nL 518.632815 1524.419883 \nL 520.761232 1522.517472 \nL 521.470704 1522.60301 \nL 522.180176 1521.700047 \nL 522.889649 1520.516554 \nL 523.599121 1520.366228 \nL 525.727538 1522.384182 \nL 526.437011 1522.675814 \nL 527.146483 1523.779748 \nL 527.855955 1524.267659 \nL 528.565428 1524.360095 \nL 530.693845 1524.346746 \nL 531.403317 1523.29129 \nL 532.112789 1527.030152 \nL 532.822262 1527.941396 \nL 533.531734 1526.823872 \nL 535.660151 1524.87471 \nL 536.369623 1525.341038 \nL 537.079096 1522.389379 \nL 537.788568 1522.291769 \nL 538.49804 1521.715092 \nL 540.626457 1522.705782 \nL 541.33593 1522.519389 \nL 542.754875 1524.664235 \nL 543.464347 1523.065785 \nL 545.592764 1525.733541 \nL 547.011709 1526.937629 \nL 547.721181 1528.539672 \nL 548.430653 1528.308339 \nL 550.55907 1528.411829 \nL 551.268543 1530.333555 \nL 551.978015 1531.148216 \nL 552.687487 1532.716242 \nL 553.39696 1530.9986 \nL 556.944321 1530.628547 \nL 557.653794 1530.861315 \nL 558.363266 1529.503467 \nL 560.491683 1530.34913 \nL 561.201156 1532.131763 \nL 561.910628 1532.003357 \nL 562.6201 1534.623015 \nL 568.295879 1534.604571 \nL 570.424296 1534.784533 \nL 571.133768 1536.315752 \nL 571.843241 1536.394054 \nL 572.552713 1538.024068 \nL 573.262185 1538.378163 \nL 576.100075 1541.419258 \nL 577.519019 1544.663654 \nL 578.228492 1545.081562 \nL 581.775854 1545.103007 \nL 582.485326 1545.911674 \nL 586.032688 1545.394602 \nL 586.74216 1544.655898 \nL 587.451632 1544.294912 \nL 590.289522 1544.258466 \nL 590.998994 1542.589847 \nL 591.708466 1542.350392 \nL 592.417939 1542.999645 \nL 593.127411 1543.298904 \nL 595.255828 1543.185521 \nL 595.9653 1542.852535 \nL 597.384245 1542.850634 \nL 598.093717 1542.369481 \nL 600.931607 1543.021567 \nL 601.641079 1542.955498 \nL 602.350552 1542.757674 \nL 603.060024 1542.89944 \nL 605.188441 1542.79412 \nL 605.897913 1541.083474 \nL 607.316858 1540.829885 \nL 608.02633 1540.6986 \nL 610.154747 1540.649362 \nL 610.86422 1540.970734 \nL 611.573692 1539.940951 \nL 612.283164 1540.32847 \nL 612.992637 1540.332552 \nL 615.121054 1540.123293 \nL 616.539998 1539.055224 \nL 617.249471 1539.992268 \nL 617.958943 1539.690204 \nL 620.08736 1539.324696 \nL 620.796833 1540.750656 \nL 621.506305 1540.72114 \nL 622.215777 1540.48695 \nL 622.92525 1540.399996 \nL 625.053667 1539.761379 \nL 625.763139 1539.235062 \nL 626.472611 1536.708855 \nL 627.182084 1536.266894 \nL 627.891556 1536.084289 \nL 631.438918 1535.991792 \nL 632.14839 1534.338516 \nL 632.857862 1533.746189 \nL 634.986279 1533.795925 \nL 635.695752 1533.641471 \nL 636.405224 1534.399569 \nL 637.114697 1532.88307 \nL 637.824169 1534.043222 \nL 639.952586 1534.503253 \nL 640.662058 1535.292861 \nL 641.371531 1537.371073 \nL 642.081003 1537.528622 \nL 642.790475 1535.683886 \nL 644.918892 1535.862827 \nL 645.628365 1535.475884 \nL 646.337837 1535.635239 \nL 647.047309 1534.883136 \nL 647.756782 1534.943212 \nL 654.851505 1531.082137 \nL 655.560978 1533.829252 \nL 656.27045 1531.715576 \nL 656.979922 1532.48171 \nL 657.689395 1529.736819 \nL 659.817812 1536.308734 \nL 660.527284 1536.21402 \nL 661.236756 1536.760633 \nL 661.946229 1536.637101 \nL 662.655701 1537.045506 \nL 664.784118 1536.596187 \nL 665.49359 1536.606125 \nL 666.203063 1536.801525 \nL 666.912535 1535.033683 \nL 667.622007 1535.175978 \nL 669.750424 1535.138837 \nL 670.459897 1536.097664 \nL 671.169369 1534.121276 \nL 671.878841 1533.247684 \nL 672.588314 1536.938761 \nL 674.716731 1539.605045 \nL 675.426203 1538.211803 \nL 676.135676 1538.612171 \nL 676.845148 1538.093985 \nL 677.55462 1538.358611 \nL 679.683037 1540.893757 \nL 680.39251 1541.327212 \nL 681.101982 1540.430493 \nL 681.811454 1539.841392 \nL 682.520927 1539.936894 \nL 684.649344 1541.291642 \nL 685.358816 1541.500518 \nL 686.068288 1542.39668 \nL 686.777761 1542.173411 \nL 687.487233 1544.722155 \nL 689.61565 1544.56511 \nL 690.325122 1542.975603 \nL 691.034595 1542.220218 \nL 691.744067 1541.684741 \nL 692.453539 1543.317164 \nL 696.000901 1543.454359 \nL 696.710374 1543.823071 \nL 697.419846 1544.705377 \nL 699.548263 1544.992767 \nL 700.257735 1544.190595 \nL 700.967208 1544.244353 \nL 701.67668 1544.575364 \nL 702.386152 1545.320437 \nL 704.514569 1544.693672 \nL 705.224042 1544.340572 \nL 705.933514 1545.298687 \nL 706.642986 1545.076136 \nL 707.352459 1545.371518 \nL 709.480876 1542.629006 \nL 710.190348 1542.597462 \nL 710.89982 1542.755695 \nL 711.609293 1541.921338 \nL 712.318765 1541.442434 \nL 717.285072 1541.417717 \nL 719.413489 1541.280637 \nL 720.122961 1541.658783 \nL 720.832433 1540.88762 \nL 721.541906 1541.274043 \nL 722.251378 1541.233933 \nL 725.79874 1541.844531 \nL 726.508212 1541.860073 \nL 727.217684 1541.515159 \nL 729.346101 1541.538924 \nL 730.055574 1540.804858 \nL 730.765046 1540.509166 \nL 731.474519 1540.556004 \nL 732.183991 1540.716566 \nL 734.312408 1540.53283 \nL 735.02188 1541.325876 \nL 736.440825 1541.438388 \nL 739.988187 1541.840263 \nL 740.697659 1541.486861 \nL 741.407131 1541.330462 \nL 742.116604 1541.060141 \nL 744.245021 1541.051739 \nL 744.954493 1540.81524 \nL 745.663965 1540.266757 \nL 746.373438 1540.357305 \nL 747.08291 1539.39475 \nL 749.211327 1539.222838 \nL 749.9208 1540.103266 \nL 750.630272 1539.737143 \nL 751.339744 1539.505981 \nL 752.049217 1539.572458 \nL 754.177634 1539.465166 \nL 754.887106 1540.086921 \nL 755.596578 1539.667466 \nL 756.306051 1539.706129 \nL 757.015523 1539.384711 \nL 759.14394 1539.12901 \nL 759.853412 1539.16101 \nL 760.562885 1538.578382 \nL 761.981829 1538.559642 \nL 764.110246 1538.317893 \nL 764.819719 1539.727073 \nL 766.238663 1539.923398 \nL 766.948136 1540.071172 \nL 769.076553 1539.91574 \nL 769.786025 1539.54088 \nL 770.495498 1539.394411 \nL 771.914442 1539.754492 \nL 774.042859 1539.70438 \nL 774.752332 1540.436038 \nL 775.461804 1539.870915 \nL 776.171276 1539.883479 \nL 776.880749 1538.826284 \nL 779.009166 1538.763958 \nL 779.718638 1537.427809 \nL 780.42811 1537.586953 \nL 781.137583 1537.441721 \nL 781.847055 1537.869174 \nL 783.975472 1537.913044 \nL 784.684944 1538.33009 \nL 785.394417 1538.563843 \nL 786.103889 1538.030693 \nL 786.813361 1537.911131 \nL 788.941779 1538.528718 \nL 789.651251 1538.493627 \nL 790.360723 1538.574109 \nL 791.070196 1537.855749 \nL 794.617557 1537.631154 \nL 795.32703 1537.266783 \nL 796.036502 1537.595154 \nL 796.745974 1537.475633 \nL 798.874391 1537.485531 \nL 799.583864 1537.899064 \nL 800.293336 1538.917589 \nL 801.002808 1539.00236 \nL 801.712281 1538.255733 \nL 803.840698 1538.076002 \nL 804.55017 1537.426378 \nL 805.969115 1537.589721 \nL 806.678587 1538.623075 \nL 809.516477 1538.522289 \nL 810.225949 1538.28785 \nL 810.935421 1538.340855 \nL 811.644894 1536.238937 \nL 813.773311 1535.23824 \nL 814.482783 1534.591367 \nL 815.192255 1534.983904 \nL 816.6112 1535.025302 \nL 818.739617 1535.050107 \nL 819.449089 1534.636608 \nL 820.158562 1534.734759 \nL 820.868034 1534.430495 \nL 820.868034 1534.430495 \n\" clip-path=\"url(#paf90d92ba9)\" style=\"fill: none; stroke: #4682b4; stroke-opacity: 0.6; stroke-width: 3; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_120\">\n    <path d=\"M 379.576235 1539.977476 \nL 381.704652 1539.866634 \nL 382.414124 1539.298338 \nL 383.123597 1539.251131 \nL 383.833069 1538.930201 \nL 386.670958 1539.233389 \nL 387.380431 1539.691449 \nL 388.089903 1539.741679 \nL 388.799375 1538.886234 \nL 389.508848 1539.004938 \nL 391.637265 1538.511117 \nL 393.05621 1538.542267 \nL 393.765682 1538.421524 \nL 394.475154 1538.823143 \nL 396.603571 1538.366057 \nL 397.313044 1538.840917 \nL 398.022516 1538.602981 \nL 403.698295 1538.913522 \nL 404.407767 1538.774373 \nL 406.536184 1539.862185 \nL 407.245656 1540.023716 \nL 407.955129 1540.027064 \nL 408.664601 1539.736113 \nL 411.502491 1539.727572 \nL 412.211963 1539.126684 \nL 412.921435 1539.546699 \nL 413.630908 1537.577431 \nL 414.34038 1537.121615 \nL 416.468797 1536.305007 \nL 417.178269 1535.451159 \nL 417.887742 1534.878561 \nL 419.306686 1534.785319 \nL 421.435103 1534.370975 \nL 422.144576 1533.728441 \nL 423.56352 1533.798734 \nL 424.272993 1533.557817 \nL 426.40141 1533.927179 \nL 427.110882 1534.17342 \nL 427.820354 1533.661976 \nL 428.529827 1533.686919 \nL 429.239299 1533.023357 \nL 431.367716 1532.990946 \nL 432.077189 1533.341025 \nL 433.496133 1532.126558 \nL 434.205606 1531.881602 \nL 437.752967 1531.836208 \nL 439.171912 1530.561459 \nL 441.300329 1530.080669 \nL 442.009801 1530.204619 \nL 442.719274 1530.475572 \nL 444.138218 1530.516164 \nL 446.266635 1529.978186 \nL 446.976108 1530.044291 \nL 447.68558 1529.839011 \nL 448.395053 1529.826098 \nL 449.104525 1530.008059 \nL 451.942414 1530.144298 \nL 452.651887 1530.309374 \nL 453.361359 1531.092858 \nL 458.327665 1531.460369 \nL 459.037138 1531.397057 \nL 463.293972 1531.441788 \nL 464.003444 1531.700583 \nL 466.131861 1531.738815 \nL 466.841334 1531.521027 \nL 467.550806 1531.709465 \nL 468.969751 1531.707123 \nL 471.098168 1531.731201 \nL 471.80764 1532.685394 \nL 476.773946 1532.785802 \nL 477.483419 1532.765897 \nL 478.902363 1532.962085 \nL 481.03078 1533.164826 \nL 481.740253 1533.358203 \nL 483.159197 1533.306606 \nL 483.86867 1532.982567 \nL 486.706559 1533.268686 \nL 487.416032 1532.816635 \nL 488.125504 1532.704647 \nL 488.834976 1532.958103 \nL 493.801283 1533.100022 \nL 497.348644 1533.162274 \nL 498.058117 1533.841619 \nL 498.767589 1534.08827 \nL 500.896006 1534.128733 \nL 501.605478 1534.466998 \nL 502.314951 1534.323822 \nL 503.024423 1534.536749 \nL 503.733896 1534.302973 \nL 505.862313 1534.074286 \nL 506.571785 1534.129967 \nL 507.281257 1532.759223 \nL 507.99073 1532.280914 \nL 508.700202 1531.373787 \nL 510.828619 1522.700689 \nL 511.538091 1522.747539 \nL 512.247564 1522.017198 \nL 512.957036 1522.108905 \nL 513.666508 1519.659836 \nL 515.794925 1523.125142 \nL 516.504398 1521.978929 \nL 517.21387 1521.886955 \nL 517.923342 1524.611265 \nL 518.632815 1525.430519 \nL 520.761232 1522.74238 \nL 521.470704 1522.746443 \nL 522.889649 1522.596053 \nL 523.599121 1522.790628 \nL 527.855955 1523.512503 \nL 528.565428 1523.776528 \nL 530.693845 1523.632825 \nL 531.403317 1522.994054 \nL 532.112789 1523.568432 \nL 532.822262 1523.876885 \nL 533.531734 1523.019765 \nL 535.660151 1522.043725 \nL 536.369623 1522.480225 \nL 537.079096 1522.600112 \nL 537.788568 1522.877217 \nL 538.49804 1522.868041 \nL 541.33593 1522.571629 \nL 542.045402 1522.841063 \nL 543.464347 1523.034454 \nL 545.592764 1522.648014 \nL 546.302236 1522.670459 \nL 547.011709 1522.388291 \nL 547.721181 1522.486981 \nL 548.430653 1521.765963 \nL 550.55907 1521.664294 \nL 551.268543 1522.511129 \nL 551.978015 1522.171439 \nL 552.687487 1522.32467 \nL 553.39696 1521.595212 \nL 556.944321 1521.722371 \nL 557.653794 1521.363501 \nL 558.363266 1521.40977 \nL 560.491683 1521.737268 \nL 561.201156 1522.089637 \nL 562.6201 1521.603113 \nL 568.295879 1521.594375 \nL 570.424296 1522.387078 \nL 571.133768 1521.662442 \nL 571.843241 1521.153746 \nL 572.552713 1521.452136 \nL 573.262185 1521.499969 \nL 575.390602 1522.387953 \nL 576.100075 1522.456853 \nL 576.809547 1522.350238 \nL 577.519019 1522.5558 \nL 578.228492 1522.919452 \nL 580.356909 1523.374841 \nL 581.066381 1523.247837 \nL 582.485326 1523.372079 \nL 583.194798 1523.350205 \nL 585.323215 1523.050821 \nL 586.032688 1523.237257 \nL 586.74216 1523.101249 \nL 587.451632 1522.744841 \nL 590.998994 1522.7422 \nL 591.708466 1522.552332 \nL 592.417939 1523.542683 \nL 595.255828 1523.319374 \nL 595.9653 1523.26852 \nL 596.674773 1523.444795 \nL 598.093717 1523.261468 \nL 600.222135 1523.32653 \nL 600.931607 1522.88158 \nL 602.350552 1522.942952 \nL 603.060024 1522.912613 \nL 605.897913 1521.90916 \nL 607.316858 1521.890404 \nL 608.02633 1522.298602 \nL 610.154747 1522.322847 \nL 610.86422 1522.15186 \nL 611.573692 1521.692747 \nL 612.283164 1522.277494 \nL 612.992637 1522.296602 \nL 615.121054 1522.235475 \nL 615.830526 1522.388964 \nL 616.539998 1522.262386 \nL 617.249471 1522.612786 \nL 617.958943 1522.268941 \nL 620.08736 1522.445562 \nL 620.796833 1522.641496 \nL 621.506305 1522.620123 \nL 622.215777 1522.867434 \nL 622.92525 1522.850441 \nL 625.053667 1522.668754 \nL 625.763139 1522.422853 \nL 626.472611 1521.473606 \nL 627.182084 1521.634471 \nL 627.891556 1520.891326 \nL 630.729445 1520.731288 \nL 631.438918 1520.869023 \nL 632.857862 1521.935308 \nL 634.986279 1522.025803 \nL 636.405224 1522.503457 \nL 637.114697 1522.232161 \nL 637.824169 1522.645344 \nL 639.952586 1522.546393 \nL 641.371531 1523.668752 \nL 642.081003 1524.314716 \nL 642.790475 1525.477504 \nL 645.628365 1525.500653 \nL 646.337837 1525.009616 \nL 647.047309 1524.725703 \nL 647.756782 1525.541606 \nL 654.851505 1526.258118 \nL 656.979922 1526.746755 \nL 657.689395 1527.255022 \nL 659.817812 1527.706813 \nL 660.527284 1527.390763 \nL 661.236756 1526.677323 \nL 661.946229 1526.689497 \nL 662.655701 1527.779128 \nL 664.784118 1527.685785 \nL 665.49359 1528.582044 \nL 666.203063 1528.596114 \nL 666.912535 1528.437343 \nL 667.622007 1528.488123 \nL 669.750424 1527.801595 \nL 670.459897 1529.723706 \nL 671.878841 1530.537698 \nL 672.588314 1530.375886 \nL 674.716731 1530.34897 \nL 675.426203 1528.443887 \nL 676.135676 1528.093168 \nL 676.845148 1527.869892 \nL 677.55462 1528.408076 \nL 679.683037 1529.572138 \nL 680.39251 1530.343643 \nL 681.101982 1531.634409 \nL 681.811454 1530.779566 \nL 682.520927 1533.000154 \nL 684.649344 1533.216908 \nL 686.777761 1535.75788 \nL 687.487233 1536.07573 \nL 689.61565 1536.299062 \nL 690.325122 1537.17386 \nL 691.034595 1537.30798 \nL 692.453539 1537.126473 \nL 696.000901 1537.180693 \nL 696.710374 1536.99028 \nL 697.419846 1537.30044 \nL 699.548263 1538.021033 \nL 700.257735 1538.008973 \nL 700.967208 1539.430193 \nL 701.67668 1539.814035 \nL 702.386152 1539.530543 \nL 704.514569 1540.272608 \nL 705.224042 1540.665138 \nL 705.933514 1541.324879 \nL 706.642986 1541.498335 \nL 707.352459 1541.95716 \nL 709.480876 1541.635537 \nL 710.89982 1542.892583 \nL 711.609293 1542.691349 \nL 716.575599 1542.691308 \nL 717.285072 1542.585897 \nL 720.122961 1543.274879 \nL 720.832433 1542.808668 \nL 722.251378 1542.783983 \nL 724.379795 1542.812489 \nL 725.089267 1542.684667 \nL 725.79874 1542.734332 \nL 726.508212 1542.019754 \nL 727.217684 1541.859847 \nL 729.346101 1541.537303 \nL 730.055574 1541.556556 \nL 731.474519 1541.310195 \nL 732.183991 1541.416223 \nL 734.312408 1541.444675 \nL 735.731353 1541.898363 \nL 736.440825 1541.906461 \nL 739.988187 1542.160473 \nL 741.407131 1541.931467 \nL 742.116604 1541.259932 \nL 744.245021 1541.145299 \nL 744.954493 1540.977681 \nL 745.663965 1540.653188 \nL 746.373438 1540.543249 \nL 747.08291 1539.964019 \nL 749.9208 1539.89401 \nL 752.049217 1539.449792 \nL 754.177634 1539.393019 \nL 755.596578 1539.988304 \nL 756.306051 1539.453889 \nL 757.015523 1539.745783 \nL 759.14394 1539.798121 \nL 761.981829 1538.786257 \nL 764.110246 1538.533969 \nL 764.819719 1538.257298 \nL 765.529191 1538.178206 \nL 766.948136 1538.397101 \nL 769.786025 1537.182542 \nL 770.495498 1537.125697 \nL 771.20497 1537.304571 \nL 771.914442 1537.611295 \nL 774.042859 1537.360163 \nL 775.461804 1537.756771 \nL 776.171276 1537.787874 \nL 776.880749 1538.160816 \nL 779.009166 1537.531847 \nL 779.718638 1536.653091 \nL 780.42811 1536.864805 \nL 781.137583 1536.795258 \nL 781.847055 1536.946524 \nL 784.684944 1537.049197 \nL 785.394417 1535.090902 \nL 786.103889 1536.474341 \nL 786.813361 1535.994456 \nL 788.941779 1536.294635 \nL 789.651251 1535.289925 \nL 790.360723 1537.303278 \nL 791.070196 1537.273898 \nL 791.779668 1537.379815 \nL 793.908085 1537.224258 \nL 794.617557 1537.364569 \nL 795.32703 1537.008 \nL 796.745974 1537.237722 \nL 798.874391 1536.889883 \nL 799.583864 1536.908016 \nL 800.293336 1537.58686 \nL 801.002808 1537.644872 \nL 801.712281 1536.756301 \nL 803.840698 1536.351064 \nL 804.55017 1537.219817 \nL 805.259642 1538.31529 \nL 805.969115 1538.06128 \nL 806.678587 1538.615714 \nL 809.516477 1538.312399 \nL 810.225949 1538.350699 \nL 814.482783 1537.462576 \nL 815.192255 1537.405512 \nL 815.901728 1538.189486 \nL 816.6112 1538.218465 \nL 818.739617 1538.699519 \nL 819.449089 1538.493186 \nL 820.158562 1539.610447 \nL 820.868034 1539.52317 \nL 820.868034 1539.52317 \n\" clip-path=\"url(#paf90d92ba9)\" style=\"fill: none; stroke: #808080; stroke-opacity: 0.4; stroke-width: 3; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_121\">\n    <path d=\"M 75.177125 1534.62984 \nL 856.377125 1534.62984 \n\" clip-path=\"url(#paf90d92ba9)\" style=\"fill: none; stroke-dasharray: 11.1,4.8; stroke-dashoffset: 0; stroke: #4682b4; stroke-width: 3\"/>\n   </g>\n   <g id=\"line2d_122\">\n    <path d=\"M 75.177125 1634.713366 \nL 856.377125 1634.713366 \n\" clip-path=\"url(#paf90d92ba9)\" style=\"fill: none; stroke: #000000; stroke-width: 2; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_25\">\n    <path d=\"M 75.177125 1735.43108 \nL 75.177125 1533.995652 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_26\">\n    <path d=\"M 856.377125 1735.43108 \nL 856.377125 1533.995652 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_27\">\n    <path d=\"M 75.177125 1735.43108 \nL 856.377125 1735.43108 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_28\">\n    <path d=\"M 75.177125 1533.995652 \nL 856.377125 1533.995652 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_46\">\n    <!-- Rolling portfolio beta to daily_return -->\n    <g transform=\"translate(346.796656 1527.995652)scale(0.132 -0.132)\">\n     <defs>\n      <path id=\"DejaVuSans-70\" d=\"M 1159 525 \nL 1159 -1331 \nL 581 -1331 \nL 581 3500 \nL 1159 3500 \nL 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nz\nM 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-66\" d=\"M 2375 4863 \nL 2375 4384 \nL 1825 4384 \nQ 1516 4384 1395 4259 \nQ 1275 4134 1275 3809 \nL 1275 3500 \nL 2222 3500 \nL 2222 3053 \nL 1275 3053 \nL 1275 0 \nL 697 0 \nL 697 3053 \nL 147 3053 \nL 147 3500 \nL 697 3500 \nL 697 3744 \nQ 697 4328 969 4595 \nQ 1241 4863 1831 4863 \nL 2375 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-52\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"64.982422\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"126.164062\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"153.947266\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"181.730469\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"209.513672\"/>\n     <use xlink:href=\"#DejaVuSans-67\" x=\"272.892578\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"336.369141\"/>\n     <use xlink:href=\"#DejaVuSans-70\" x=\"368.15625\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"431.632812\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"492.814453\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"533.927734\"/>\n     <use xlink:href=\"#DejaVuSans-66\" x=\"573.136719\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"608.341797\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"669.523438\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"697.306641\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"725.089844\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"786.271484\"/>\n     <use xlink:href=\"#DejaVuSans-62\" x=\"818.058594\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"881.535156\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"943.058594\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"982.267578\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"1043.546875\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"1075.333984\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"1114.542969\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"1175.724609\"/>\n     <use xlink:href=\"#DejaVuSans-64\" x=\"1207.511719\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"1270.988281\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"1332.267578\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"1360.050781\"/>\n     <use xlink:href=\"#DejaVuSans-79\" x=\"1387.833984\"/>\n     <use xlink:href=\"#DejaVuSans-5f\" x=\"1447.013672\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"1497.013672\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"1535.876953\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"1597.400391\"/>\n     <use xlink:href=\"#DejaVuSans-75\" x=\"1636.609375\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"1699.988281\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"1739.351562\"/>\n    </g>\n   </g>\n   <g id=\"legend_3\">\n    <g id=\"patch_29\">\n     <path d=\"M 83.647125 1579.196714 \nL 161.319672 1579.196714 \nQ 163.739672 1579.196714 163.739672 1576.776714 \nL 163.739672 1542.465652 \nQ 163.739672 1540.045652 161.319672 1540.045652 \nL 83.647125 1540.045652 \nQ 81.227125 1540.045652 81.227125 1542.465652 \nL 81.227125 1576.776714 \nQ 81.227125 1579.196714 83.647125 1579.196714 \nz\n\" style=\"fill: #ffffff; opacity: 0.5; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_123\">\n     <path d=\"M 86.067125 1549.844761 \nL 98.167125 1549.844761 \nL 110.267125 1549.844761 \n\" style=\"fill: none; stroke: #4682b4; stroke-opacity: 0.6; stroke-width: 3; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_47\">\n     <!-- 6-mo -->\n     <g transform=\"translate(119.947125 1554.079761)scale(0.121 -0.121)\">\n      <use xlink:href=\"#DejaVuSans-36\"/>\n      <use xlink:href=\"#DejaVuSans-2d\" x=\"63.623047\"/>\n      <use xlink:href=\"#DejaVuSans-6d\" x=\"99.707031\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"197.119141\"/>\n     </g>\n    </g>\n    <g id=\"line2d_124\">\n     <path d=\"M 86.067125 1567.605292 \nL 98.167125 1567.605292 \nL 110.267125 1567.605292 \n\" style=\"fill: none; stroke: #808080; stroke-opacity: 0.4; stroke-width: 3; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_48\">\n     <!-- 12-mo -->\n     <g transform=\"translate(119.947125 1571.840292)scale(0.121 -0.121)\">\n      <use xlink:href=\"#DejaVuSans-31\"/>\n      <use xlink:href=\"#DejaVuSans-32\" x=\"63.623047\"/>\n      <use xlink:href=\"#DejaVuSans-2d\" x=\"127.246094\"/>\n      <use xlink:href=\"#DejaVuSans-6d\" x=\"163.330078\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"260.742188\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_6\">\n   <g id=\"patch_30\">\n    <path d=\"M 75.177125 2037.584223 \nL 856.377125 2037.584223 \nL 856.377125 1836.148795 \nL 75.177125 1836.148795 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_11\">\n    <g id=\"xtick_71\">\n     <g id=\"line2d_125\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"109.976744\" y=\"2037.584223\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_72\">\n     <g id=\"line2d_126\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"195.822897\" y=\"2037.584223\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_73\">\n     <g id=\"line2d_127\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"283.087996\" y=\"2037.584223\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_74\">\n     <g id=\"line2d_128\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"369.643622\" y=\"2037.584223\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_75\">\n     <g id=\"line2d_129\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"454.780304\" y=\"2037.584223\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_76\">\n     <g id=\"line2d_130\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"542.045402\" y=\"2037.584223\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_77\">\n     <g id=\"line2d_131\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"628.601028\" y=\"2037.584223\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_78\">\n     <g id=\"line2d_132\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"713.73771\" y=\"2037.584223\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_79\">\n     <g id=\"line2d_133\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"801.002808\" y=\"2037.584223\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_80\">\n     <g id=\"line2d_134\">\n      <g>\n       <use xlink:href=\"#m3466dc2b85\" x=\"207.883927\" y=\"2037.584223\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_81\">\n     <g id=\"line2d_135\">\n      <g>\n       <use xlink:href=\"#m3466dc2b85\" x=\"349.778396\" y=\"2037.584223\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_82\">\n     <g id=\"line2d_136\">\n      <g>\n       <use xlink:href=\"#m3466dc2b85\" x=\"491.672866\" y=\"2037.584223\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_83\">\n     <g id=\"line2d_137\">\n      <g>\n       <use xlink:href=\"#m3466dc2b85\" x=\"633.567335\" y=\"2037.584223\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_84\">\n     <g id=\"line2d_138\">\n      <g>\n       <use xlink:href=\"#m3466dc2b85\" x=\"775.461804\" y=\"2037.584223\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_12\">\n    <g id=\"ytick_35\">\n     <g id=\"line2d_139\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"2028.428067\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_49\">\n      <!-- 0.00 -->\n      <g transform=\"translate(38.735719 2033.025122)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_36\">\n     <g id=\"line2d_140\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"2001.976285\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_50\">\n      <!-- 0.05 -->\n      <g transform=\"translate(38.735719 2006.57334)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_37\">\n     <g id=\"line2d_141\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"1975.524502\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_51\">\n      <!-- 0.10 -->\n      <g transform=\"translate(38.735719 1980.121557)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-31\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_38\">\n     <g id=\"line2d_142\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"1949.07272\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_52\">\n      <!-- 0.15 -->\n      <g transform=\"translate(38.735719 1953.669775)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-31\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_39\">\n     <g id=\"line2d_143\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"1922.620938\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_53\">\n      <!-- 0.20 -->\n      <g transform=\"translate(38.735719 1927.217992)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_40\">\n     <g id=\"line2d_144\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"1896.169155\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_54\">\n      <!-- 0.25 -->\n      <g transform=\"translate(38.735719 1900.76621)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_41\">\n     <g id=\"line2d_145\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"1869.717373\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_55\">\n      <!-- 0.30 -->\n      <g transform=\"translate(38.735719 1874.314427)scale(0.121 -0.121)\">\n       <defs>\n        <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \nQ 3050 2419 3304 2112 \nQ 3559 1806 3559 1356 \nQ 3559 666 3084 287 \nQ 2609 -91 1734 -91 \nQ 1441 -91 1130 -33 \nQ 819 25 488 141 \nL 488 750 \nQ 750 597 1062 519 \nQ 1375 441 1716 441 \nQ 2309 441 2620 675 \nQ 2931 909 2931 1356 \nQ 2931 1769 2642 2001 \nQ 2353 2234 1838 2234 \nL 1294 2234 \nL 1294 2753 \nL 1863 2753 \nQ 2328 2753 2575 2939 \nQ 2822 3125 2822 3475 \nQ 2822 3834 2567 4026 \nQ 2313 4219 1838 4219 \nQ 1578 4219 1281 4162 \nQ 984 4106 628 3988 \nL 628 4550 \nQ 988 4650 1302 4700 \nQ 1616 4750 1894 4750 \nQ 2613 4750 3031 4423 \nQ 3450 4097 3450 3541 \nQ 3450 3153 3228 2886 \nQ 3006 2619 2597 2516 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-33\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_42\">\n     <g id=\"line2d_146\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"1843.26559\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_56\">\n      <!-- 0.35 -->\n      <g transform=\"translate(38.735719 1847.862645)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-33\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_57\">\n     <!-- Volatility -->\n     <g transform=\"translate(31.990531 1965.368196)rotate(-90)scale(0.132 -0.132)\">\n      <defs>\n       <path id=\"DejaVuSans-56\" d=\"M 1831 0 \nL 50 4666 \nL 709 4666 \nL 2188 738 \nL 3669 4666 \nL 4325 4666 \nL 2547 0 \nL 1831 0 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-56\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"60.658203\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"121.839844\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"149.623047\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"210.902344\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"250.111328\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"277.894531\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"305.677734\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"333.460938\"/>\n      <use xlink:href=\"#DejaVuSans-79\" x=\"372.669922\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_147\">\n    <path d=\"M 248.323851 1894.704883 \nL 249.033323 1894.490426 \nL 249.742796 1882.987209 \nL 250.452268 1883.052381 \nL 252.580685 1882.341523 \nL 253.290157 1881.080559 \nL 254.709102 1881.031517 \nL 255.418574 1877.35411 \nL 258.256464 1876.988254 \nL 258.965936 1876.15418 \nL 259.675409 1875.768572 \nL 260.384881 1874.809227 \nL 262.513298 1874.798243 \nL 263.22277 1876.491672 \nL 263.932243 1886.312052 \nL 264.641715 1887.502781 \nL 265.351187 1886.979437 \nL 267.479604 1887.264702 \nL 268.189077 1887.064268 \nL 268.898549 1885.879152 \nL 269.608021 1885.966027 \nL 270.317494 1885.8663 \nL 272.445911 1885.408439 \nL 273.155383 1885.405266 \nL 273.864855 1885.998634 \nL 274.574328 1885.454912 \nL 275.2838 1885.326249 \nL 278.12169 1885.350103 \nL 279.540634 1884.820174 \nL 280.250107 1883.547835 \nL 282.378524 1883.635191 \nL 283.087996 1886.125822 \nL 283.797468 1887.373606 \nL 285.216413 1887.425069 \nL 287.34483 1887.130883 \nL 288.054302 1888.026439 \nL 288.763775 1889.801529 \nL 289.473247 1890.445053 \nL 290.182719 1890.296902 \nL 293.020609 1892.095366 \nL 293.730081 1895.303999 \nL 294.439553 1894.084986 \nL 295.149026 1894.202413 \nL 297.277443 1895.62131 \nL 297.986915 1896.230864 \nL 298.696388 1898.665971 \nL 299.40586 1899.087388 \nL 300.115332 1900.393784 \nL 302.243749 1900.470997 \nL 302.953222 1900.287268 \nL 303.662694 1901.7593 \nL 310.047945 1900.048835 \nL 312.176362 1897.867723 \nL 312.885834 1897.827444 \nL 315.014252 1897.215 \nL 317.142669 1896.794909 \nL 317.852141 1896.821898 \nL 318.561613 1896.437774 \nL 319.271086 1897.226658 \nL 319.980558 1897.200055 \nL 322.108975 1896.99119 \nL 322.818447 1897.325002 \nL 323.52792 1896.468369 \nL 324.237392 1896.506055 \nL 324.946864 1896.261384 \nL 327.075281 1896.321674 \nL 327.784754 1895.771113 \nL 328.494226 1895.627676 \nL 329.203698 1896.226284 \nL 329.913171 1896.049475 \nL 332.041588 1896.339736 \nL 332.75106 1895.90451 \nL 333.460533 1895.613504 \nL 334.879477 1895.651285 \nL 337.007894 1895.485569 \nL 337.717367 1894.221584 \nL 338.426839 1894.716609 \nL 339.136311 1893.05644 \nL 339.845784 1892.757653 \nL 341.974201 1892.598426 \nL 342.683673 1893.00068 \nL 343.393145 1892.358566 \nL 344.102618 1893.959471 \nL 344.81209 1893.419269 \nL 346.940507 1892.707674 \nL 347.649979 1891.193514 \nL 348.359452 1891.038734 \nL 349.068924 1891.065012 \nL 349.778396 1891.715361 \nL 352.616286 1891.520452 \nL 353.325758 1891.333707 \nL 354.035231 1892.986843 \nL 354.744703 1892.985779 \nL 356.87312 1893.195482 \nL 357.582592 1892.685467 \nL 359.001537 1892.628367 \nL 359.711009 1893.224226 \nL 361.839426 1892.664405 \nL 362.548899 1891.517804 \nL 363.258371 1889.728804 \nL 363.967843 1890.570762 \nL 364.677316 1889.64639 \nL 367.515205 1889.032442 \nL 368.224677 1888.497939 \nL 368.93415 1888.136786 \nL 371.772039 1885.833679 \nL 372.481512 1884.196461 \nL 373.190984 1884.120254 \nL 373.900456 1881.880772 \nL 374.609929 1882.111022 \nL 376.738346 1880.742877 \nL 377.447818 1879.374295 \nL 378.15729 1879.162882 \nL 378.866763 1880.663294 \nL 379.576235 1880.517527 \nL 381.704652 1880.320766 \nL 382.414124 1889.778226 \nL 383.123597 1889.563233 \nL 383.833069 1889.002871 \nL 384.542541 1890.022518 \nL 386.670958 1889.988475 \nL 387.380431 1889.837087 \nL 388.089903 1894.364148 \nL 388.799375 1891.052877 \nL 389.508848 1891.095872 \nL 391.637265 1889.280327 \nL 392.346737 1889.629783 \nL 393.05621 1890.61491 \nL 393.765682 1890.592726 \nL 394.475154 1890.981025 \nL 396.603571 1886.309793 \nL 397.313044 1885.485604 \nL 398.022516 1885.290593 \nL 403.698295 1884.85434 \nL 404.407767 1883.780488 \nL 406.536184 1884.448142 \nL 407.245656 1883.426635 \nL 407.955129 1882.742792 \nL 408.664601 1882.231258 \nL 409.374074 1880.743093 \nL 411.502491 1881.0125 \nL 412.211963 1879.310599 \nL 412.921435 1879.022477 \nL 413.630908 1872.483527 \nL 414.34038 1871.378044 \nL 416.468797 1868.522482 \nL 417.887742 1863.742146 \nL 419.306686 1861.203183 \nL 421.435103 1859.0389 \nL 422.144576 1857.366304 \nL 422.854048 1857.40097 \nL 423.56352 1858.500659 \nL 424.272993 1857.072764 \nL 426.40141 1858.00565 \nL 427.110882 1857.469103 \nL 427.820354 1856.123826 \nL 428.529827 1855.970281 \nL 429.239299 1853.067649 \nL 431.367716 1852.790528 \nL 432.077189 1854.015535 \nL 432.786661 1852.14242 \nL 433.496133 1851.354535 \nL 434.205606 1850.36772 \nL 437.043495 1849.835407 \nL 437.752967 1849.409427 \nL 438.46244 1848.426145 \nL 439.171912 1846.551583 \nL 441.300329 1845.30495 \nL 442.009801 1845.336907 \nL 442.719274 1846.495146 \nL 443.428746 1847.89625 \nL 444.138218 1847.947145 \nL 446.266635 1847.273046 \nL 446.976108 1847.702846 \nL 447.68558 1847.812 \nL 448.395053 1848.034902 \nL 451.942414 1848.137902 \nL 452.651887 1848.444319 \nL 454.070831 1848.433978 \nL 458.327665 1848.989487 \nL 459.037138 1848.810722 \nL 461.875027 1848.907017 \nL 462.584499 1849.460438 \nL 463.293972 1849.171968 \nL 464.003444 1848.629411 \nL 466.841334 1848.577948 \nL 467.550806 1848.959418 \nL 468.260278 1849.188311 \nL 468.969751 1848.888897 \nL 471.098168 1848.897288 \nL 471.80764 1847.579415 \nL 472.517112 1848.640079 \nL 473.226585 1848.569849 \nL 473.936057 1849.746729 \nL 476.064474 1849.961356 \nL 477.483419 1849.77779 \nL 478.192891 1850.398877 \nL 478.902363 1850.479973 \nL 481.03078 1850.893544 \nL 481.740253 1851.442564 \nL 482.449725 1852.636973 \nL 483.159197 1852.640115 \nL 483.86867 1851.881989 \nL 486.706559 1851.978429 \nL 487.416032 1851.075442 \nL 488.125504 1850.931076 \nL 488.834976 1851.156762 \nL 491.672866 1851.163206 \nL 492.382338 1849.490857 \nL 493.09181 1849.989485 \nL 493.801283 1850.119554 \nL 495.9297 1850.002404 \nL 496.639172 1849.801405 \nL 497.348644 1850.514865 \nL 498.058117 1850.745287 \nL 498.767589 1850.590139 \nL 500.896006 1850.284333 \nL 501.605478 1851.174432 \nL 503.024423 1851.014888 \nL 503.733896 1851.003736 \nL 505.862313 1851.164298 \nL 506.571785 1853.39108 \nL 507.281257 1852.998581 \nL 507.99073 1853.073951 \nL 508.700202 1855.700194 \nL 510.828619 1855.53381 \nL 511.538091 1856.432214 \nL 512.247564 1858.093458 \nL 512.957036 1858.17267 \nL 513.666508 1859.923029 \nL 515.794925 1859.502982 \nL 516.504398 1856.755752 \nL 517.21387 1858.335955 \nL 517.923342 1857.90135 \nL 518.632815 1859.193601 \nL 520.761232 1855.151299 \nL 521.470704 1855.22406 \nL 522.180176 1854.613529 \nL 522.889649 1854.406853 \nL 523.599121 1856.614067 \nL 525.727538 1856.568079 \nL 526.437011 1858.739397 \nL 527.146483 1858.612702 \nL 527.855955 1858.958729 \nL 530.693845 1859.161829 \nL 531.403317 1862.897153 \nL 532.112789 1863.852717 \nL 532.822262 1865.209329 \nL 533.531734 1863.087257 \nL 535.660151 1859.744563 \nL 537.079096 1860.121467 \nL 537.788568 1860.213793 \nL 538.49804 1861.275322 \nL 540.626457 1861.85416 \nL 541.33593 1861.855459 \nL 542.045402 1863.247296 \nL 542.754875 1863.617386 \nL 543.464347 1869.29826 \nL 545.592764 1868.717356 \nL 546.302236 1871.588412 \nL 547.011709 1872.758476 \nL 547.721181 1877.018082 \nL 548.430653 1875.87362 \nL 550.55907 1877.42619 \nL 551.268543 1879.76639 \nL 551.978015 1880.773824 \nL 552.687487 1880.819523 \nL 553.39696 1878.024992 \nL 557.653794 1879.023209 \nL 558.363266 1878.602952 \nL 560.491683 1880.027197 \nL 561.201156 1879.400366 \nL 561.910628 1882.929955 \nL 562.6201 1883.47191 \nL 568.295879 1882.584885 \nL 570.424296 1884.426425 \nL 571.843241 1886.733642 \nL 572.552713 1887.215848 \nL 573.262185 1888.262585 \nL 575.390602 1889.763222 \nL 576.100075 1891.886521 \nL 576.809547 1893.556832 \nL 578.228492 1893.434244 \nL 581.066381 1893.493023 \nL 581.775854 1894.618862 \nL 583.194798 1894.189545 \nL 586.032688 1893.148018 \nL 586.74216 1893.064823 \nL 587.451632 1892.540475 \nL 590.289522 1892.839979 \nL 590.998994 1892.853946 \nL 591.708466 1892.616122 \nL 593.127411 1893.06617 \nL 595.9653 1893.055651 \nL 598.093717 1894.240397 \nL 601.641079 1894.19874 \nL 602.350552 1894.395836 \nL 603.060024 1894.276234 \nL 605.188441 1896.444864 \nL 605.897913 1896.266334 \nL 607.316858 1896.207407 \nL 608.02633 1895.921724 \nL 610.86422 1896.196974 \nL 611.573692 1894.905168 \nL 612.283164 1894.690797 \nL 615.121054 1894.601525 \nL 615.830526 1894.423882 \nL 616.539998 1894.05926 \nL 617.249471 1893.52514 \nL 617.958943 1892.368108 \nL 620.08736 1893.530941 \nL 621.506305 1893.54678 \nL 622.215777 1893.549189 \nL 622.92525 1893.361918 \nL 625.053667 1895.400382 \nL 625.763139 1895.25422 \nL 626.472611 1892.188216 \nL 627.891556 1892.603635 \nL 630.729445 1892.633828 \nL 631.438918 1893.121822 \nL 632.14839 1895.174106 \nL 632.857862 1895.861251 \nL 634.986279 1895.932209 \nL 635.695752 1896.716633 \nL 636.405224 1896.801385 \nL 637.114697 1896.233036 \nL 637.824169 1896.788218 \nL 639.952586 1896.855349 \nL 640.662058 1899.53669 \nL 641.371531 1899.654126 \nL 642.790475 1900.197069 \nL 644.918892 1900.215438 \nL 645.628365 1899.199816 \nL 646.337837 1899.170339 \nL 647.047309 1898.552743 \nL 647.756782 1898.193829 \nL 654.851505 1902.297774 \nL 655.560978 1902.357304 \nL 656.27045 1901.942021 \nL 656.979922 1902.059125 \nL 657.689395 1907.900004 \nL 659.817812 1907.920672 \nL 660.527284 1908.930451 \nL 661.946229 1909.542556 \nL 662.655701 1909.608872 \nL 664.784118 1910.094665 \nL 666.203063 1910.035801 \nL 666.912535 1908.84529 \nL 667.622007 1908.820107 \nL 669.750424 1909.910085 \nL 671.169369 1910.01073 \nL 671.878841 1914.25763 \nL 672.588314 1919.815764 \nL 674.716731 1917.989189 \nL 675.426203 1917.646713 \nL 676.135676 1918.246911 \nL 676.845148 1918.691148 \nL 677.55462 1918.924581 \nL 679.683037 1918.508386 \nL 681.101982 1909.134953 \nL 681.811454 1908.012013 \nL 682.520927 1909.979526 \nL 684.649344 1910.25802 \nL 685.358816 1911.503859 \nL 686.068288 1911.52818 \nL 686.777761 1915.191247 \nL 687.487233 1915.083171 \nL 689.61565 1915.088973 \nL 690.325122 1916.313778 \nL 691.034595 1913.617723 \nL 691.744067 1917.562155 \nL 692.453539 1917.282442 \nL 696.000901 1917.091688 \nL 696.710374 1918.778222 \nL 697.419846 1919.47877 \nL 699.548263 1919.027787 \nL 700.257735 1918.276174 \nL 700.967208 1918.240132 \nL 701.67668 1919.377756 \nL 702.386152 1919.929258 \nL 704.514569 1919.712174 \nL 705.224042 1921.265769 \nL 705.933514 1921.170529 \nL 707.352459 1921.230474 \nL 709.480876 1916.079567 \nL 710.190348 1916.175852 \nL 711.609293 1914.687603 \nL 712.318765 1914.407709 \nL 716.575599 1913.753289 \nL 717.285072 1912.301866 \nL 719.413489 1912.389914 \nL 720.122961 1912.831912 \nL 720.832433 1911.405744 \nL 721.541906 1911.517358 \nL 722.251378 1911.752734 \nL 724.379795 1912.586013 \nL 725.089267 1911.792882 \nL 725.79874 1911.787007 \nL 726.508212 1911.661415 \nL 727.217684 1910.285289 \nL 729.346101 1910.390396 \nL 730.055574 1909.94479 \nL 730.765046 1909.691994 \nL 732.183991 1909.696775 \nL 734.312408 1909.659237 \nL 735.02188 1910.079982 \nL 739.988187 1910.007376 \nL 740.697659 1909.302779 \nL 741.407131 1909.2531 \nL 742.116604 1908.799916 \nL 744.245021 1908.16692 \nL 744.954493 1907.573362 \nL 745.663965 1906.751382 \nL 746.373438 1906.493854 \nL 747.08291 1904.525698 \nL 749.9208 1906.759283 \nL 752.049217 1905.473192 \nL 754.177634 1905.381634 \nL 754.887106 1906.640626 \nL 755.596578 1907.665431 \nL 756.306051 1906.501917 \nL 757.015523 1906.433535 \nL 759.853412 1906.486747 \nL 760.562885 1905.500014 \nL 761.272357 1905.491911 \nL 761.981829 1905.738988 \nL 764.110246 1908.023722 \nL 765.529191 1907.707991 \nL 766.238663 1907.72482 \nL 766.948136 1907.402233 \nL 769.786025 1906.645332 \nL 770.495498 1906.493919 \nL 771.914442 1906.669193 \nL 774.042859 1907.845935 \nL 774.752332 1907.870391 \nL 775.461804 1907.739767 \nL 776.171276 1907.810741 \nL 776.880749 1906.50741 \nL 779.009166 1906.431917 \nL 779.718638 1905.533078 \nL 780.42811 1905.524172 \nL 781.137583 1906.090401 \nL 781.847055 1905.95044 \nL 783.975472 1906.925345 \nL 784.684944 1907.866238 \nL 785.394417 1907.880485 \nL 786.103889 1907.349715 \nL 786.813361 1908.749613 \nL 788.941779 1908.726221 \nL 789.651251 1909.122684 \nL 791.070196 1909.040309 \nL 791.779668 1908.705054 \nL 793.908085 1907.975988 \nL 794.617557 1908.008248 \nL 795.32703 1907.52503 \nL 796.036502 1907.428817 \nL 796.745974 1907.512584 \nL 798.874391 1908.62704 \nL 800.293336 1908.651236 \nL 801.002808 1908.612108 \nL 801.712281 1908.190736 \nL 803.840698 1907.902647 \nL 804.55017 1906.85583 \nL 805.259642 1908.65827 \nL 805.969115 1909.530946 \nL 806.678587 1909.446897 \nL 810.225949 1909.362408 \nL 810.935421 1909.646768 \nL 811.644894 1913.318959 \nL 813.773311 1918.039398 \nL 814.482783 1919.222353 \nL 815.901728 1919.391654 \nL 818.739617 1919.404177 \nL 819.449089 1919.009052 \nL 820.868034 1919.082956 \nL 820.868034 1919.082956 \n\" clip-path=\"url(#p437e60ca80)\" style=\"fill: none; stroke: #ff4500; stroke-opacity: 0.7; stroke-width: 3; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_148\">\n    <path d=\"M 248.323851 1897.13698 \nL 249.033323 1896.928093 \nL 249.742796 1892.515681 \nL 250.452268 1892.466257 \nL 252.580685 1890.74327 \nL 253.290157 1890.909 \nL 254.709102 1890.981258 \nL 255.418574 1887.952213 \nL 258.256464 1888.0354 \nL 258.965936 1887.437535 \nL 259.675409 1887.4275 \nL 260.384881 1888.045896 \nL 262.513298 1887.885713 \nL 263.22277 1889.46641 \nL 263.932243 1900.114766 \nL 264.641715 1901.304909 \nL 265.351187 1901.14256 \nL 267.479604 1901.490291 \nL 268.898549 1901.300589 \nL 269.608021 1901.466967 \nL 272.445911 1900.07871 \nL 273.155383 1900.137333 \nL 273.864855 1900.051716 \nL 274.574328 1899.825557 \nL 275.2838 1899.770245 \nL 277.412217 1900.429895 \nL 278.12169 1900.454873 \nL 279.540634 1900.739734 \nL 280.250107 1899.667949 \nL 282.378524 1899.519741 \nL 283.087996 1901.858012 \nL 283.797468 1903.772407 \nL 285.216413 1903.712083 \nL 287.34483 1904.204674 \nL 288.054302 1904.734047 \nL 288.763775 1906.592508 \nL 289.473247 1907.361793 \nL 290.182719 1907.710348 \nL 292.311136 1908.270648 \nL 293.020609 1908.83832 \nL 293.730081 1912.317403 \nL 294.439553 1912.077194 \nL 295.149026 1912.135265 \nL 297.277443 1913.062616 \nL 297.986915 1913.621562 \nL 298.696388 1915.580082 \nL 300.115332 1917.96661 \nL 303.662694 1917.996951 \nL 310.047945 1917.414765 \nL 312.176362 1915.359752 \nL 312.885834 1915.720323 \nL 313.595307 1915.685926 \nL 314.304779 1916.339463 \nL 315.014252 1916.447759 \nL 317.852141 1916.248104 \nL 318.561613 1916.312373 \nL 319.271086 1916.863845 \nL 319.980558 1916.900353 \nL 322.108975 1916.400718 \nL 322.818447 1916.794123 \nL 323.52792 1916.759289 \nL 324.237392 1917.241333 \nL 324.946864 1916.777957 \nL 329.913171 1916.59682 \nL 332.041588 1915.992226 \nL 334.170005 1916.005828 \nL 334.879477 1915.136428 \nL 337.717367 1914.893292 \nL 338.426839 1915.313425 \nL 339.845784 1915.410149 \nL 343.393145 1914.634462 \nL 344.102618 1916.321669 \nL 344.81209 1915.88821 \nL 346.940507 1915.691812 \nL 347.649979 1914.540977 \nL 349.068924 1914.492439 \nL 349.778396 1915.57336 \nL 352.616286 1915.271346 \nL 353.325758 1915.038428 \nL 354.035231 1915.01519 \nL 354.744703 1914.767603 \nL 356.87312 1914.570562 \nL 357.582592 1914.735325 \nL 358.292065 1915.10038 \nL 359.001537 1914.62512 \nL 359.711009 1915.105518 \nL 361.839426 1915.481218 \nL 362.548899 1914.828616 \nL 363.258371 1914.763668 \nL 363.967843 1915.055118 \nL 364.677316 1915.010541 \nL 367.515205 1915.029003 \nL 368.224677 1914.650613 \nL 368.93415 1913.984868 \nL 371.772039 1915.11136 \nL 372.481512 1916.230872 \nL 373.190984 1917.119813 \nL 373.900456 1928.175616 \nL 374.609929 1928.072352 \nL 376.738346 1928.528677 \nL 377.447818 1925.452058 \nL 378.15729 1927.268993 \nL 378.866763 1926.750303 \nL 379.576235 1927.25379 \nL 381.704652 1927.479195 \nL 382.414124 1933.480747 \nL 383.123597 1933.588852 \nL 383.833069 1936.23015 \nL 384.542541 1936.222782 \nL 386.670958 1935.77599 \nL 387.380431 1934.20318 \nL 388.089903 1939.051391 \nL 388.799375 1937.358313 \nL 389.508848 1937.305111 \nL 391.637265 1937.999715 \nL 393.05621 1938.038015 \nL 393.765682 1938.167007 \nL 394.475154 1938.121611 \nL 396.603571 1937.865485 \nL 398.022516 1936.589733 \nL 403.698295 1936.584624 \nL 404.407767 1936.806843 \nL 406.536184 1933.281172 \nL 407.245656 1933.307208 \nL 407.955129 1931.959618 \nL 408.664601 1933.208166 \nL 409.374074 1931.3095 \nL 411.502491 1932.184458 \nL 412.211963 1931.674563 \nL 412.921435 1929.891196 \nL 413.630908 1927.437834 \nL 414.34038 1927.345616 \nL 417.178269 1923.925833 \nL 417.887742 1925.279193 \nL 418.597214 1923.638843 \nL 419.306686 1923.653085 \nL 421.435103 1922.735999 \nL 422.144576 1922.600653 \nL 422.854048 1922.758523 \nL 423.56352 1923.565813 \nL 424.272993 1921.954971 \nL 426.40141 1922.614868 \nL 427.110882 1922.498557 \nL 427.820354 1921.986339 \nL 428.529827 1922.163834 \nL 429.239299 1921.375267 \nL 432.077189 1921.487943 \nL 432.786661 1922.782868 \nL 433.496133 1922.770802 \nL 434.205606 1923.032328 \nL 437.043495 1922.90482 \nL 437.752967 1923.47789 \nL 438.46244 1923.46768 \nL 439.171912 1922.752622 \nL 442.009801 1922.41081 \nL 442.719274 1923.11077 \nL 443.428746 1925.271566 \nL 444.138218 1925.213257 \nL 446.266635 1924.350099 \nL 448.395053 1924.331308 \nL 451.232942 1923.388183 \nL 451.942414 1923.394122 \nL 453.361359 1923.577846 \nL 454.070831 1923.445887 \nL 458.327665 1923.11758 \nL 459.037138 1922.691867 \nL 461.165555 1923.171616 \nL 461.875027 1922.929375 \nL 462.584499 1923.317051 \nL 463.293972 1923.174786 \nL 464.003444 1921.719501 \nL 466.131861 1921.483755 \nL 466.841334 1922.262859 \nL 467.550806 1922.106211 \nL 468.260278 1922.093395 \nL 468.969751 1921.773436 \nL 471.098168 1922.562299 \nL 471.80764 1918.597065 \nL 473.226585 1918.563893 \nL 473.936057 1918.647697 \nL 476.064474 1918.622841 \nL 476.773946 1919.316354 \nL 478.902363 1919.275046 \nL 481.740253 1919.921362 \nL 482.449725 1921.438811 \nL 483.159197 1921.379315 \nL 483.86867 1921.195041 \nL 488.125504 1920.566806 \nL 488.834976 1920.60873 \nL 491.672866 1920.481217 \nL 492.382338 1920.819925 \nL 493.09181 1920.787595 \nL 493.801283 1920.292574 \nL 495.9297 1920.869031 \nL 497.348644 1920.760472 \nL 498.058117 1921.047941 \nL 498.767589 1917.81487 \nL 500.896006 1917.81787 \nL 501.605478 1917.93521 \nL 502.314951 1917.879638 \nL 503.024423 1917.33351 \nL 503.733896 1917.999066 \nL 505.862313 1918.794821 \nL 506.571785 1918.781004 \nL 507.281257 1918.558163 \nL 507.99073 1917.882856 \nL 508.700202 1918.562947 \nL 511.538091 1918.54553 \nL 512.247564 1921.742046 \nL 512.957036 1921.874052 \nL 513.666508 1922.23887 \nL 515.794925 1918.614181 \nL 516.504398 1916.531399 \nL 517.21387 1916.460608 \nL 518.632815 1915.993804 \nL 520.761232 1914.253308 \nL 521.470704 1914.727778 \nL 522.180176 1915.726294 \nL 522.889649 1915.741665 \nL 523.599121 1916.622004 \nL 525.727538 1916.223999 \nL 526.437011 1915.701905 \nL 527.146483 1915.730258 \nL 527.855955 1915.489352 \nL 528.565428 1915.646788 \nL 530.693845 1915.962838 \nL 531.403317 1915.363463 \nL 532.112789 1915.613657 \nL 532.822262 1916.30215 \nL 533.531734 1915.222417 \nL 535.660151 1914.941048 \nL 536.369623 1916.646712 \nL 537.079096 1916.653948 \nL 538.49804 1916.843958 \nL 540.626457 1918.176699 \nL 541.33593 1918.38574 \nL 542.045402 1917.727037 \nL 543.464347 1921.603369 \nL 545.592764 1921.259412 \nL 546.302236 1923.311176 \nL 547.011709 1923.835476 \nL 547.721181 1923.957422 \nL 548.430653 1925.286762 \nL 550.55907 1925.293218 \nL 551.268543 1925.428802 \nL 553.39696 1924.940144 \nL 557.653794 1926.467212 \nL 558.363266 1926.434352 \nL 561.201156 1925.994537 \nL 561.910628 1927.034616 \nL 562.6201 1927.059341 \nL 568.295879 1926.423503 \nL 570.424296 1926.57154 \nL 571.133768 1926.970421 \nL 572.552713 1926.908898 \nL 573.262185 1926.98101 \nL 575.390602 1926.027145 \nL 576.100075 1926.498291 \nL 576.809547 1926.778291 \nL 577.519019 1926.662756 \nL 578.228492 1926.255784 \nL 580.356909 1926.561215 \nL 581.066381 1926.51719 \nL 581.775854 1927.115424 \nL 582.485326 1927.107312 \nL 583.194798 1926.892519 \nL 586.032688 1926.979068 \nL 586.74216 1927.416403 \nL 587.451632 1927.231547 \nL 588.161105 1927.227827 \nL 591.708466 1928.128759 \nL 592.417939 1927.385838 \nL 593.127411 1927.355683 \nL 596.674773 1927.964944 \nL 597.384245 1929.671061 \nL 598.093717 1929.536584 \nL 601.641079 1929.625805 \nL 602.350552 1929.929196 \nL 603.060024 1929.777857 \nL 605.188441 1934.924297 \nL 607.316858 1934.784384 \nL 608.02633 1934.456372 \nL 610.86422 1934.334303 \nL 611.573692 1933.745809 \nL 612.283164 1932.980924 \nL 615.830526 1932.995203 \nL 616.539998 1932.87468 \nL 617.249471 1933.014229 \nL 617.958943 1932.836327 \nL 620.08736 1933.095981 \nL 620.796833 1932.995942 \nL 621.506305 1933.121545 \nL 622.215777 1933.029803 \nL 622.92525 1933.325053 \nL 625.053667 1933.309792 \nL 625.763139 1933.16795 \nL 626.472611 1932.841689 \nL 627.182084 1932.73042 \nL 627.891556 1932.989182 \nL 630.729445 1933.042682 \nL 631.438918 1933.383363 \nL 632.14839 1936.664177 \nL 632.857862 1936.605634 \nL 635.695752 1936.538139 \nL 636.405224 1937.035663 \nL 637.114697 1936.297463 \nL 637.824169 1935.885621 \nL 639.952586 1935.874367 \nL 640.662058 1936.041003 \nL 641.371531 1937.520933 \nL 642.081003 1937.255181 \nL 644.918892 1937.261328 \nL 645.628365 1936.097138 \nL 646.337837 1935.978797 \nL 647.047309 1935.718266 \nL 647.756782 1938.891542 \nL 656.27045 1941.115273 \nL 656.979922 1941.907016 \nL 657.689395 1943.971184 \nL 660.527284 1943.468906 \nL 661.236756 1943.380968 \nL 664.784118 1944.852958 \nL 665.49359 1944.460842 \nL 666.203063 1944.763673 \nL 666.912535 1943.641704 \nL 667.622007 1943.550437 \nL 669.750424 1945.214842 \nL 670.459897 1945.058371 \nL 671.169369 1945.646738 \nL 671.878841 1947.401197 \nL 672.588314 1947.231521 \nL 675.426203 1944.749739 \nL 676.135676 1946.15308 \nL 676.845148 1946.299909 \nL 677.55462 1946.323527 \nL 679.683037 1943.733373 \nL 681.101982 1930.329157 \nL 681.811454 1929.409992 \nL 682.520927 1929.311638 \nL 684.649344 1929.62085 \nL 685.358816 1929.860793 \nL 686.068288 1929.765477 \nL 686.777761 1930.438615 \nL 687.487233 1929.775847 \nL 689.61565 1930.484213 \nL 690.325122 1930.891917 \nL 691.034595 1928.967953 \nL 691.744067 1929.249203 \nL 692.453539 1928.946969 \nL 696.000901 1928.922222 \nL 696.710374 1928.780833 \nL 697.419846 1929.499566 \nL 699.548263 1927.600197 \nL 700.257735 1926.758341 \nL 700.967208 1926.726205 \nL 701.67668 1926.974023 \nL 702.386152 1927.103495 \nL 704.514569 1926.628945 \nL 705.224042 1926.795569 \nL 705.933514 1926.701685 \nL 706.642986 1926.49077 \nL 707.352459 1927.320743 \nL 709.480876 1922.014063 \nL 710.190348 1922.01557 \nL 710.89982 1921.007859 \nL 711.609293 1920.950668 \nL 712.318765 1920.426575 \nL 716.575599 1920.505516 \nL 717.285072 1918.872606 \nL 720.122961 1918.71743 \nL 720.832433 1918.508971 \nL 721.541906 1918.715929 \nL 722.251378 1918.591834 \nL 724.379795 1918.605087 \nL 725.089267 1918.066064 \nL 726.508212 1918.051327 \nL 727.217684 1916.622982 \nL 729.346101 1917.560131 \nL 730.055574 1916.912558 \nL 732.183991 1916.733527 \nL 735.02188 1916.872435 \nL 736.440825 1916.874799 \nL 741.407131 1916.075586 \nL 744.245021 1915.081617 \nL 744.954493 1914.627988 \nL 747.08291 1913.625261 \nL 749.211327 1914.251294 \nL 749.9208 1915.025064 \nL 750.630272 1914.74588 \nL 752.049217 1913.698852 \nL 754.887106 1913.24628 \nL 755.596578 1913.58436 \nL 756.306051 1912.999787 \nL 757.015523 1913.047739 \nL 759.14394 1913.064809 \nL 759.853412 1913.244003 \nL 760.562885 1912.495363 \nL 761.272357 1912.507972 \nL 761.981829 1912.664745 \nL 765.529191 1912.902379 \nL 766.238663 1912.836542 \nL 766.948136 1912.024715 \nL 769.786025 1911.90907 \nL 770.495498 1911.930565 \nL 771.20497 1911.65499 \nL 771.914442 1911.735785 \nL 774.042859 1912.277595 \nL 774.752332 1912.600573 \nL 775.461804 1912.475689 \nL 776.171276 1912.916955 \nL 776.880749 1912.601786 \nL 779.009166 1913.178582 \nL 779.718638 1912.489918 \nL 780.42811 1912.40512 \nL 781.137583 1912.921067 \nL 781.847055 1912.619406 \nL 783.975472 1913.004455 \nL 784.684944 1913.990054 \nL 785.394417 1914.726768 \nL 786.103889 1913.600765 \nL 786.813361 1913.720179 \nL 789.651251 1913.655213 \nL 790.360723 1913.868319 \nL 791.070196 1913.76888 \nL 791.779668 1913.848046 \nL 795.32703 1913.761904 \nL 796.036502 1913.405758 \nL 796.745974 1913.491703 \nL 798.874391 1914.184074 \nL 799.583864 1914.270854 \nL 800.293336 1913.823413 \nL 801.002808 1914.177041 \nL 801.712281 1914.124237 \nL 804.55017 1914.069684 \nL 805.259642 1915.959171 \nL 805.969115 1916.407524 \nL 806.678587 1915.71369 \nL 809.516477 1915.881965 \nL 810.225949 1915.717253 \nL 810.935421 1917.727881 \nL 811.644894 1923.350187 \nL 813.773311 1929.29354 \nL 814.482783 1930.204429 \nL 815.192255 1930.535652 \nL 816.6112 1930.515305 \nL 818.739617 1930.555778 \nL 819.449089 1930.217246 \nL 820.158562 1930.565668 \nL 820.868034 1930.565213 \nL 820.868034 1930.565213 \n\" clip-path=\"url(#p437e60ca80)\" style=\"fill: none; stroke: #808080; stroke-opacity: 0.7; stroke-width: 3; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_149\">\n    <path d=\"M 75.177125 1887.864701 \nL 856.377125 1887.864701 \n\" clip-path=\"url(#p437e60ca80)\" style=\"fill: none; stroke-dasharray: 11.1,4.8; stroke-dashoffset: 0; stroke: #4682b4; stroke-width: 3\"/>\n   </g>\n   <g id=\"line2d_150\">\n    <path d=\"M 75.177125 2028.428067 \nL 856.377125 2028.428067 \n\" clip-path=\"url(#p437e60ca80)\" style=\"fill: none; stroke: #000000; stroke-width: 2; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_31\">\n    <path d=\"M 75.177125 2037.584223 \nL 75.177125 1836.148795 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_32\">\n    <path d=\"M 856.377125 2037.584223 \nL 856.377125 1836.148795 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_33\">\n    <path d=\"M 75.177125 2037.584223 \nL 856.377125 2037.584223 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_34\">\n    <path d=\"M 75.177125 1836.148795 \nL 856.377125 1836.148795 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_58\">\n    <!-- Rolling volatility (6-month) -->\n    <g transform=\"translate(377.825938 1830.148795)scale(0.132 -0.132)\">\n     <defs>\n      <path id=\"DejaVuSans-28\" d=\"M 1984 4856 \nQ 1566 4138 1362 3434 \nQ 1159 2731 1159 2009 \nQ 1159 1288 1364 580 \nQ 1569 -128 1984 -844 \nL 1484 -844 \nQ 1016 -109 783 600 \nQ 550 1309 550 2009 \nQ 550 2706 781 3412 \nQ 1013 4119 1484 4856 \nL 1984 4856 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-29\" d=\"M 513 4856 \nL 1013 4856 \nQ 1481 4119 1714 3412 \nQ 1947 2706 1947 2009 \nQ 1947 1309 1714 600 \nQ 1481 -109 1013 -844 \nL 513 -844 \nQ 928 -128 1133 580 \nQ 1338 1288 1338 2009 \nQ 1338 2731 1133 3434 \nQ 928 4138 513 4856 \nz\n\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-52\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"64.982422\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"126.164062\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"153.947266\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"181.730469\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"209.513672\"/>\n     <use xlink:href=\"#DejaVuSans-67\" x=\"272.892578\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"336.369141\"/>\n     <use xlink:href=\"#DejaVuSans-76\" x=\"368.15625\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"427.335938\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"488.517578\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"516.300781\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"577.580078\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"616.789062\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"644.572266\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"672.355469\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"700.138672\"/>\n     <use xlink:href=\"#DejaVuSans-79\" x=\"739.347656\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"798.527344\"/>\n     <use xlink:href=\"#DejaVuSans-28\" x=\"830.314453\"/>\n     <use xlink:href=\"#DejaVuSans-36\" x=\"869.328125\"/>\n     <use xlink:href=\"#DejaVuSans-2d\" x=\"932.951172\"/>\n     <use xlink:href=\"#DejaVuSans-6d\" x=\"969.035156\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"1066.447266\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"1127.628906\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"1191.007812\"/>\n     <use xlink:href=\"#DejaVuSans-68\" x=\"1230.216797\"/>\n     <use xlink:href=\"#DejaVuSans-29\" x=\"1293.595703\"/>\n    </g>\n   </g>\n   <g id=\"legend_4\">\n    <g id=\"patch_35\">\n     <path d=\"M 83.647125 1965.322306 \nL 247.206984 1965.322306 \nQ 249.626984 1965.322306 249.626984 1962.902306 \nL 249.626984 1910.830712 \nQ 249.626984 1908.410712 247.206984 1908.410712 \nL 83.647125 1908.410712 \nQ 81.227125 1908.410712 81.227125 1910.830712 \nL 81.227125 1962.902306 \nQ 81.227125 1965.322306 83.647125 1965.322306 \nz\n\" style=\"fill: #ffffff; opacity: 0.5; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_151\">\n     <path d=\"M 86.067125 1918.209821 \nL 98.167125 1918.209821 \nL 110.267125 1918.209821 \n\" style=\"fill: none; stroke: #ff4500; stroke-opacity: 0.7; stroke-width: 3; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_59\">\n     <!-- Volatility -->\n     <g transform=\"translate(119.947125 1922.444821)scale(0.121 -0.121)\">\n      <use xlink:href=\"#DejaVuSans-56\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"60.658203\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"121.839844\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"149.623047\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"210.902344\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"250.111328\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"277.894531\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"305.677734\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"333.460938\"/>\n      <use xlink:href=\"#DejaVuSans-79\" x=\"372.669922\"/>\n     </g>\n    </g>\n    <g id=\"line2d_152\">\n     <path d=\"M 86.067125 1935.970353 \nL 98.167125 1935.970353 \nL 110.267125 1935.970353 \n\" style=\"fill: none; stroke: #808080; stroke-opacity: 0.7; stroke-width: 3; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_60\">\n     <!-- Benchmark volatility -->\n     <g transform=\"translate(119.947125 1940.205353)scale(0.121 -0.121)\">\n      <use xlink:href=\"#DejaVuSans-42\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"68.603516\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"130.126953\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"193.505859\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"248.486328\"/>\n      <use xlink:href=\"#DejaVuSans-6d\" x=\"311.865234\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"409.277344\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"470.556641\"/>\n      <use xlink:href=\"#DejaVuSans-6b\" x=\"511.669922\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"569.580078\"/>\n      <use xlink:href=\"#DejaVuSans-76\" x=\"601.367188\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"660.546875\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"721.728516\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"749.511719\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"810.791016\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"850\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"877.783203\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"905.566406\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"933.349609\"/>\n      <use xlink:href=\"#DejaVuSans-79\" x=\"972.558594\"/>\n     </g>\n    </g>\n    <g id=\"line2d_153\">\n     <path d=\"M 86.067125 1953.730884 \nL 98.167125 1953.730884 \nL 110.267125 1953.730884 \n\" style=\"fill: none; stroke-dasharray: 11.1,4.8; stroke-dashoffset: 0; stroke: #4682b4; stroke-width: 3\"/>\n    </g>\n    <g id=\"text_61\">\n     <!-- Average volatility -->\n     <g transform=\"translate(119.947125 1957.965884)scale(0.121 -0.121)\">\n      <defs>\n       <path id=\"DejaVuSans-41\" d=\"M 2188 4044 \nL 1331 1722 \nL 3047 1722 \nL 2188 4044 \nz\nM 1831 4666 \nL 2547 4666 \nL 4325 0 \nL 3669 0 \nL 3244 1197 \nL 1141 1197 \nL 716 0 \nL 50 0 \nL 1831 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-41\"/>\n      <use xlink:href=\"#DejaVuSans-76\" x=\"62.533203\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"121.712891\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"183.236328\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"224.349609\"/>\n      <use xlink:href=\"#DejaVuSans-67\" x=\"285.628906\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"349.105469\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"410.628906\"/>\n      <use xlink:href=\"#DejaVuSans-76\" x=\"442.416016\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"501.595703\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"562.777344\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"590.560547\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"651.839844\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"691.048828\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"718.832031\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"746.615234\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"774.398438\"/>\n      <use xlink:href=\"#DejaVuSans-79\" x=\"813.607422\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_7\">\n   <g id=\"patch_36\">\n    <path d=\"M 75.177125 2339.737366 \nL 856.377125 2339.737366 \nL 856.377125 2138.301937 \nL 75.177125 2138.301937 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_13\">\n    <g id=\"xtick_85\">\n     <g id=\"line2d_154\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"109.976744\" y=\"2339.737366\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_86\">\n     <g id=\"line2d_155\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"195.822897\" y=\"2339.737366\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_87\">\n     <g id=\"line2d_156\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"283.087996\" y=\"2339.737366\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_88\">\n     <g id=\"line2d_157\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"369.643622\" y=\"2339.737366\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_89\">\n     <g id=\"line2d_158\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"454.780304\" y=\"2339.737366\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_90\">\n     <g id=\"line2d_159\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"542.045402\" y=\"2339.737366\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_91\">\n     <g id=\"line2d_160\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"628.601028\" y=\"2339.737366\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_92\">\n     <g id=\"line2d_161\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"713.73771\" y=\"2339.737366\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_93\">\n     <g id=\"line2d_162\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"801.002808\" y=\"2339.737366\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_94\">\n     <g id=\"line2d_163\">\n      <g>\n       <use xlink:href=\"#m3466dc2b85\" x=\"207.883927\" y=\"2339.737366\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_95\">\n     <g id=\"line2d_164\">\n      <g>\n       <use xlink:href=\"#m3466dc2b85\" x=\"349.778396\" y=\"2339.737366\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_96\">\n     <g id=\"line2d_165\">\n      <g>\n       <use xlink:href=\"#m3466dc2b85\" x=\"491.672866\" y=\"2339.737366\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_97\">\n     <g id=\"line2d_166\">\n      <g>\n       <use xlink:href=\"#m3466dc2b85\" x=\"633.567335\" y=\"2339.737366\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_98\">\n     <g id=\"line2d_167\">\n      <g>\n       <use xlink:href=\"#m3466dc2b85\" x=\"775.461804\" y=\"2339.737366\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_14\">\n    <g id=\"ytick_43\">\n     <g id=\"line2d_168\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"2332.867753\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_62\">\n      <!-- -3.00 -->\n      <g transform=\"translate(34.370266 2337.464808)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-2d\"/>\n       <use xlink:href=\"#DejaVuSans-33\" x=\"36.083984\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"99.707031\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"131.494141\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"195.117188\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_44\">\n     <g id=\"line2d_169\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"2306.727883\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_63\">\n      <!-- -2.00 -->\n      <g transform=\"translate(34.370266 2311.324938)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-2d\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"36.083984\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"99.707031\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"131.494141\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"195.117188\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_45\">\n     <g id=\"line2d_170\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"2280.588013\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_64\">\n      <!-- -1.00 -->\n      <g transform=\"translate(34.370266 2285.185067)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-2d\"/>\n       <use xlink:href=\"#DejaVuSans-31\" x=\"36.083984\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"99.707031\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"131.494141\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"195.117188\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_46\">\n     <g id=\"line2d_171\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"2254.448142\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_65\">\n      <!-- 0.00 -->\n      <g transform=\"translate(38.735719 2259.045197)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_47\">\n     <g id=\"line2d_172\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"2228.308272\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_66\">\n      <!-- 1.00 -->\n      <g transform=\"translate(38.735719 2232.905327)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_48\">\n     <g id=\"line2d_173\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"2202.168401\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_67\">\n      <!-- 2.00 -->\n      <g transform=\"translate(38.735719 2206.765456)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_49\">\n     <g id=\"line2d_174\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"2176.028531\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_68\">\n      <!-- 3.00 -->\n      <g transform=\"translate(38.735719 2180.625586)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-33\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_50\">\n     <g id=\"line2d_175\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"2149.888661\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_69\">\n      <!-- 4.00 -->\n      <g transform=\"translate(38.735719 2154.485715)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_70\">\n     <!-- Sharpe ratio -->\n     <g transform=\"translate(27.625078 2279.715871)rotate(-90)scale(0.132 -0.132)\">\n      <defs>\n       <path id=\"DejaVuSans-53\" d=\"M 3425 4513 \nL 3425 3897 \nQ 3066 4069 2747 4153 \nQ 2428 4238 2131 4238 \nQ 1616 4238 1336 4038 \nQ 1056 3838 1056 3469 \nQ 1056 3159 1242 3001 \nQ 1428 2844 1947 2747 \nL 2328 2669 \nQ 3034 2534 3370 2195 \nQ 3706 1856 3706 1288 \nQ 3706 609 3251 259 \nQ 2797 -91 1919 -91 \nQ 1588 -91 1214 -16 \nQ 841 59 441 206 \nL 441 856 \nQ 825 641 1194 531 \nQ 1563 422 1919 422 \nQ 2459 422 2753 634 \nQ 3047 847 3047 1241 \nQ 3047 1584 2836 1778 \nQ 2625 1972 2144 2069 \nL 1759 2144 \nQ 1053 2284 737 2584 \nQ 422 2884 422 3419 \nQ 422 4038 858 4394 \nQ 1294 4750 2059 4750 \nQ 2388 4750 2728 4690 \nQ 3069 4631 3425 4513 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-53\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"63.476562\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"126.855469\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"188.134766\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"229.248047\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"292.724609\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"354.248047\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"386.035156\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"427.148438\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"488.427734\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"527.636719\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"555.419922\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_176\">\n    <path d=\"M 248.323851 2216.324041 \nL 249.033323 2213.720641 \nL 249.742796 2230.478653 \nL 250.452268 2231.248989 \nL 252.580685 2225.190772 \nL 253.290157 2222.525836 \nL 254.709102 2222.155111 \nL 255.418574 2230.081553 \nL 257.546991 2225.931245 \nL 258.256464 2224.139872 \nL 258.965936 2221.57287 \nL 259.675409 2219.981885 \nL 260.384881 2212.972049 \nL 262.513298 2212.859251 \nL 263.22277 2209.210336 \nL 263.932243 2190.680085 \nL 264.641715 2194.610381 \nL 265.351187 2201.028749 \nL 267.479604 2203.093942 \nL 268.189077 2205.515623 \nL 268.898549 2210.11159 \nL 269.608021 2211.229391 \nL 270.317494 2210.939597 \nL 272.445911 2204.253945 \nL 273.155383 2204.160605 \nL 273.864855 2209.81574 \nL 274.574328 2212.418544 \nL 275.2838 2210.087364 \nL 277.412217 2210.27831 \nL 278.831162 2212.91561 \nL 279.540634 2210.513253 \nL 280.250107 2203.608108 \nL 282.378524 2204.600311 \nL 283.087996 2195.648132 \nL 283.797468 2201.932286 \nL 284.506941 2203.099479 \nL 285.216413 2205.922476 \nL 287.34483 2214.899537 \nL 288.054302 2210.393154 \nL 288.763775 2207.050501 \nL 289.473247 2209.083972 \nL 290.182719 2203.687185 \nL 292.311136 2197.714259 \nL 293.020609 2195.179497 \nL 293.730081 2186.723801 \nL 294.439553 2190.435664 \nL 295.149026 2183.435382 \nL 297.277443 2178.318713 \nL 297.986915 2186.906922 \nL 298.696388 2178.057633 \nL 299.40586 2186.9954 \nL 300.115332 2192.122517 \nL 302.243749 2190.665909 \nL 302.953222 2189.690546 \nL 303.662694 2184.144737 \nL 310.047945 2179.343885 \nL 312.176362 2173.139715 \nL 312.885834 2172.784539 \nL 313.595307 2173.96624 \nL 314.304779 2180.358355 \nL 315.014252 2181.285656 \nL 317.142669 2185.319983 \nL 317.852141 2183.00137 \nL 318.561613 2184.807605 \nL 319.271086 2190.029101 \nL 319.980558 2190.135187 \nL 322.108975 2192.012475 \nL 322.818447 2193.205726 \nL 323.52792 2189.780371 \nL 324.237392 2189.599793 \nL 324.946864 2192.140342 \nL 327.075281 2191.125556 \nL 327.784754 2185.038672 \nL 328.494226 2183.966762 \nL 329.203698 2186.536016 \nL 329.913171 2187.493996 \nL 332.041588 2188.66268 \nL 332.75106 2193.28964 \nL 333.460533 2195.40862 \nL 334.170005 2195.844283 \nL 334.879477 2195.779778 \nL 337.007894 2193.840352 \nL 337.717367 2200.271942 \nL 338.426839 2196.107878 \nL 339.136311 2189.809875 \nL 339.845784 2188.044522 \nL 341.974201 2187.183299 \nL 342.683673 2184.404651 \nL 343.393145 2186.699836 \nL 344.102618 2178.128417 \nL 344.81209 2175.515676 \nL 346.940507 2181.242972 \nL 347.649979 2175.697694 \nL 348.359452 2177.191405 \nL 349.068924 2176.608711 \nL 349.778396 2178.381329 \nL 351.906813 2179.938113 \nL 352.616286 2182.169121 \nL 353.325758 2183.125351 \nL 354.035231 2175.832409 \nL 354.744703 2175.846762 \nL 356.87312 2177.154197 \nL 357.582592 2175.335223 \nL 358.292065 2171.113406 \nL 359.001537 2171.635518 \nL 359.711009 2168.80611 \nL 361.839426 2167.511148 \nL 362.548899 2175.077869 \nL 363.258371 2168.92512 \nL 363.967843 2175.488087 \nL 364.677316 2169.960429 \nL 366.805733 2168.438205 \nL 367.515205 2169.751041 \nL 368.224677 2166.767057 \nL 368.93415 2165.647025 \nL 371.772039 2162.049588 \nL 372.481512 2158.146384 \nL 373.190984 2155.262911 \nL 373.900456 2152.907653 \nL 374.609929 2155.943567 \nL 376.738346 2160.884692 \nL 377.447818 2158.328971 \nL 378.15729 2161.105846 \nL 378.866763 2176.202582 \nL 379.576235 2177.283446 \nL 381.704652 2176.507113 \nL 382.414124 2162.712926 \nL 383.123597 2160.668831 \nL 383.833069 2159.819582 \nL 384.542541 2161.60331 \nL 386.670958 2160.700387 \nL 387.380431 2165.264342 \nL 388.089903 2153.399226 \nL 388.799375 2166.759563 \nL 389.508848 2167.742334 \nL 391.637265 2165.740662 \nL 392.346737 2167.386773 \nL 393.05621 2169.433255 \nL 393.765682 2169.181549 \nL 394.475154 2167.748302 \nL 396.603571 2162.321195 \nL 397.313044 2158.981379 \nL 398.022516 2150.276065 \nL 403.698295 2147.458093 \nL 404.407767 2150.938244 \nL 406.536184 2149.055167 \nL 407.245656 2153.84694 \nL 407.955129 2161.370755 \nL 408.664601 2160.555987 \nL 409.374074 2166.739444 \nL 411.502491 2164.066377 \nL 412.211963 2168.128023 \nL 412.921435 2166.947813 \nL 413.630908 2182.996161 \nL 414.34038 2186.996464 \nL 416.468797 2192.889712 \nL 417.178269 2201.755978 \nL 417.887742 2199.2237 \nL 419.306686 2191.902836 \nL 421.435103 2197.287178 \nL 422.144576 2192.397575 \nL 422.854048 2189.955236 \nL 423.56352 2185.278017 \nL 424.272993 2190.419676 \nL 426.40141 2187.542662 \nL 427.110882 2192.028619 \nL 427.820354 2199.86521 \nL 428.529827 2198.5437 \nL 429.239299 2191.914899 \nL 431.367716 2188.678916 \nL 432.077189 2184.099173 \nL 432.786661 2193.116399 \nL 433.496133 2188.861921 \nL 434.205606 2181.453024 \nL 437.043495 2184.661402 \nL 437.752967 2185.732775 \nL 438.46244 2181.664943 \nL 439.171912 2187.583399 \nL 441.300329 2194.083662 \nL 442.009801 2193.062439 \nL 442.719274 2196.786505 \nL 443.428746 2202.877827 \nL 444.138218 2203.385034 \nL 446.266635 2197.837847 \nL 446.976108 2194.498027 \nL 447.68558 2193.119268 \nL 448.395053 2192.132592 \nL 449.104525 2192.50822 \nL 451.232942 2192.516389 \nL 451.942414 2191.395685 \nL 452.651887 2188.061062 \nL 453.361359 2188.260971 \nL 454.070831 2190.441561 \nL 459.037138 2194.521074 \nL 461.165555 2191.50766 \nL 461.875027 2190.749588 \nL 462.584499 2193.296363 \nL 463.293972 2197.172345 \nL 464.003444 2194.898467 \nL 466.131861 2190.735335 \nL 466.841334 2192.637224 \nL 467.550806 2190.699366 \nL 468.260278 2189.352399 \nL 468.969751 2191.865187 \nL 471.098168 2191.671672 \nL 471.80764 2188.729949 \nL 472.517112 2184.471257 \nL 473.226585 2185.886973 \nL 473.936057 2190.357265 \nL 476.064474 2192.078987 \nL 476.773946 2195.515242 \nL 477.483419 2196.672327 \nL 478.192891 2194.333648 \nL 478.902363 2194.920505 \nL 481.03078 2197.539091 \nL 481.740253 2193.300532 \nL 482.449725 2197.41553 \nL 483.159197 2194.675935 \nL 483.86867 2198.228384 \nL 486.706559 2200.693895 \nL 487.416032 2203.559132 \nL 488.125504 2204.427484 \nL 488.834976 2201.769251 \nL 490.963393 2202.846894 \nL 491.672866 2202.681598 \nL 492.382338 2208.886274 \nL 493.09181 2211.451908 \nL 493.801283 2212.071148 \nL 495.9297 2210.497844 \nL 496.639172 2211.701911 \nL 497.348644 2214.105699 \nL 498.058117 2213.546614 \nL 498.767589 2223.63635 \nL 500.896006 2219.421969 \nL 501.605478 2222.255452 \nL 502.314951 2221.983035 \nL 503.024423 2222.235723 \nL 503.733896 2227.952116 \nL 505.862313 2228.383181 \nL 506.571785 2233.124862 \nL 507.281257 2243.863416 \nL 507.99073 2244.182332 \nL 508.700202 2248.7587 \nL 510.828619 2246.973939 \nL 511.538091 2243.715956 \nL 512.247564 2247.842358 \nL 512.957036 2247.045235 \nL 513.666508 2243.400792 \nL 515.794925 2245.119386 \nL 516.504398 2254.98395 \nL 517.21387 2251.059464 \nL 517.923342 2249.855232 \nL 518.632815 2253.235437 \nL 520.761232 2247.676917 \nL 521.470704 2248.327666 \nL 522.180176 2243.372839 \nL 522.889649 2241.44091 \nL 523.599121 2237.047351 \nL 525.727538 2236.477989 \nL 526.437011 2240.320849 \nL 527.146483 2243.394051 \nL 528.565428 2247.877234 \nL 530.693845 2246.092303 \nL 531.403317 2258.254077 \nL 532.822262 2269.364846 \nL 533.531734 2279.342081 \nL 536.369623 2263.207666 \nL 537.079096 2257.679122 \nL 537.788568 2257.434555 \nL 538.49804 2259.84093 \nL 540.626457 2253.375499 \nL 541.33593 2255.088647 \nL 542.045402 2247.36896 \nL 542.754875 2251.932417 \nL 543.464347 2242.069306 \nL 545.592764 2233.053644 \nL 546.302236 2223.575221 \nL 547.011709 2221.458954 \nL 547.721181 2228.881901 \nL 548.430653 2227.392646 \nL 550.55907 2231.208363 \nL 551.268543 2223.963915 \nL 551.978015 2234.667018 \nL 552.687487 2234.928508 \nL 553.39696 2228.703887 \nL 556.944321 2226.628344 \nL 557.653794 2225.105598 \nL 558.363266 2217.675637 \nL 560.491683 2209.029778 \nL 561.201156 2215.117637 \nL 561.910628 2224.487611 \nL 562.6201 2227.624113 \nL 568.295879 2223.839018 \nL 570.424296 2220.022197 \nL 571.133768 2224.36844 \nL 571.843241 2225.999454 \nL 572.552713 2222.083924 \nL 573.262185 2215.788272 \nL 575.390602 2221.603296 \nL 576.809547 2206.656124 \nL 577.519019 2209.000436 \nL 578.228492 2208.814135 \nL 580.356909 2205.550818 \nL 581.066381 2207.788764 \nL 581.775854 2214.992125 \nL 582.485326 2218.610437 \nL 583.194798 2217.037202 \nL 585.323215 2220.216948 \nL 586.032688 2223.063515 \nL 586.74216 2223.357482 \nL 587.451632 2220.607876 \nL 588.161105 2223.032916 \nL 590.289522 2220.585707 \nL 590.998994 2220.407691 \nL 591.708466 2222.264429 \nL 592.417939 2217.630921 \nL 593.127411 2219.181775 \nL 595.255828 2218.972001 \nL 595.9653 2219.36418 \nL 596.674773 2217.368268 \nL 597.384245 2224.344704 \nL 598.093717 2225.497081 \nL 600.222135 2225.546899 \nL 600.931607 2226.108139 \nL 601.641079 2226.033233 \nL 602.350552 2224.938161 \nL 603.060024 2226.644636 \nL 605.897913 2236.517685 \nL 606.607386 2234.713875 \nL 607.316858 2233.324987 \nL 608.02633 2231.411881 \nL 610.154747 2228.6454 \nL 610.86422 2226.856996 \nL 611.573692 2220.738382 \nL 612.283164 2219.631598 \nL 612.992637 2219.954936 \nL 615.121054 2219.520192 \nL 615.830526 2221.515522 \nL 616.539998 2227.211101 \nL 617.249471 2228.471214 \nL 617.958943 2232.703678 \nL 620.08736 2227.596046 \nL 620.796833 2227.3216 \nL 621.506305 2229.907238 \nL 622.215777 2229.194166 \nL 622.92525 2231.034533 \nL 625.053667 2224.862329 \nL 625.763139 2223.456458 \nL 626.472611 2233.935012 \nL 627.182084 2235.05259 \nL 627.891556 2232.78092 \nL 630.729445 2235.24206 \nL 631.438918 2233.639605 \nL 632.14839 2228.214471 \nL 632.857862 2231.97531 \nL 634.986279 2233.177013 \nL 635.695752 2239.777891 \nL 636.405224 2237.142966 \nL 637.114697 2238.556548 \nL 637.824169 2242.882482 \nL 639.952586 2243.575138 \nL 640.662058 2234.769512 \nL 642.081003 2241.778932 \nL 642.790475 2244.201711 \nL 644.918892 2243.892613 \nL 645.628365 2250.169386 \nL 646.337837 2248.75397 \nL 647.047309 2250.540206 \nL 647.756782 2251.469719 \nL 654.851505 2239.861069 \nL 655.560978 2239.452812 \nL 656.27045 2238.616251 \nL 656.979922 2239.6926 \nL 657.689395 2247.858761 \nL 659.817812 2248.234274 \nL 660.527284 2251.606597 \nL 661.236756 2253.599789 \nL 661.946229 2251.69728 \nL 662.655701 2252.328328 \nL 664.784118 2256.419359 \nL 665.49359 2256.380699 \nL 666.203063 2255.387562 \nL 666.912535 2259.421743 \nL 667.622007 2258.925231 \nL 669.750424 2252.966426 \nL 670.459897 2249.951007 \nL 671.169369 2249.262598 \nL 671.878841 2238.86654 \nL 672.588314 2253.154596 \nL 674.716731 2262.653153 \nL 675.426203 2271.297122 \nL 676.135676 2269.052079 \nL 676.845148 2271.092962 \nL 677.55462 2271.949542 \nL 679.683037 2274.142152 \nL 680.39251 2288.202717 \nL 681.101982 2274.735773 \nL 681.811454 2269.54458 \nL 682.520927 2274.532214 \nL 684.649344 2278.663862 \nL 685.358816 2274.329191 \nL 686.068288 2274.647341 \nL 686.777761 2287.470249 \nL 687.487233 2292.695418 \nL 689.61565 2294.630257 \nL 690.325122 2288.858765 \nL 691.034595 2282.083017 \nL 691.744067 2295.272458 \nL 692.453539 2287.079206 \nL 696.000901 2289.73777 \nL 696.710374 2297.132381 \nL 697.419846 2300.704783 \nL 699.548263 2301.617312 \nL 700.257735 2294.776197 \nL 700.967208 2296.393304 \nL 701.67668 2299.99244 \nL 702.386152 2297.180512 \nL 704.514569 2300.528953 \nL 705.224042 2310.989238 \nL 705.933514 2314.93531 \nL 706.642986 2319.884271 \nL 707.352459 2319.308224 \nL 709.480876 2329.57991 \nL 710.190348 2330.58121 \nL 710.89982 2324.628678 \nL 711.609293 2321.442917 \nL 712.318765 2320.157667 \nL 716.575599 2315.068576 \nL 717.285072 2318.621676 \nL 719.413489 2318.039366 \nL 720.122961 2321.085142 \nL 720.832433 2308.816108 \nL 721.541906 2307.42961 \nL 722.251378 2302.690189 \nL 724.379795 2308.520299 \nL 725.089267 2303.593758 \nL 725.79874 2303.530625 \nL 726.508212 2305.069712 \nL 727.217684 2296.686626 \nL 729.346101 2301.469485 \nL 730.055574 2305.802268 \nL 730.765046 2304.638997 \nL 731.474519 2304.932515 \nL 732.183991 2303.72231 \nL 734.312408 2298.349838 \nL 735.02188 2301.402706 \nL 735.731353 2301.72789 \nL 736.440825 2300.832074 \nL 739.278714 2299.541242 \nL 739.988187 2297.820522 \nL 740.697659 2292.216193 \nL 741.407131 2292.747288 \nL 742.116604 2287.262998 \nL 744.245021 2292.620402 \nL 745.663965 2287.686494 \nL 746.373438 2291.55967 \nL 747.08291 2285.220448 \nL 749.211327 2292.420616 \nL 750.630272 2299.40245 \nL 751.339744 2298.070054 \nL 752.049217 2293.064301 \nL 754.177634 2286.263845 \nL 754.887106 2281.618707 \nL 755.596578 2278.386566 \nL 756.306051 2273.52866 \nL 757.015523 2273.956576 \nL 759.14394 2273.640412 \nL 759.853412 2274.279139 \nL 760.562885 2277.341241 \nL 761.272357 2276.450737 \nL 761.981829 2279.07055 \nL 764.110246 2275.640123 \nL 764.819719 2279.546413 \nL 766.238663 2276.738867 \nL 766.948136 2277.896824 \nL 769.076553 2272.445549 \nL 769.786025 2274.323518 \nL 770.495498 2272.765763 \nL 771.20497 2272.115903 \nL 771.914442 2273.063939 \nL 774.042859 2268.835315 \nL 774.752332 2268.145919 \nL 775.461804 2270.989373 \nL 776.171276 2271.991183 \nL 776.880749 2276.006919 \nL 779.009166 2276.974582 \nL 779.718638 2281.257083 \nL 780.42811 2280.565816 \nL 781.137583 2272.544426 \nL 781.847055 2271.575693 \nL 783.975472 2266.622576 \nL 784.684944 2260.669169 \nL 785.394417 2264.765207 \nL 786.103889 2259.782105 \nL 786.813361 2263.905557 \nL 788.941779 2265.875258 \nL 789.651251 2270.801294 \nL 790.360723 2270.41418 \nL 791.779668 2278.165363 \nL 793.908085 2273.234615 \nL 794.617557 2274.88446 \nL 795.32703 2277.627995 \nL 796.036502 2272.635745 \nL 796.745974 2273.840471 \nL 798.874391 2270.172678 \nL 799.583864 2271.42395 \nL 800.293336 2273.574308 \nL 801.002808 2276.932606 \nL 801.712281 2279.450691 \nL 803.840698 2282.311242 \nL 804.55017 2274.467857 \nL 805.259642 2268.693744 \nL 806.678587 2260.406616 \nL 809.516477 2259.754762 \nL 810.225949 2265.26386 \nL 810.935421 2264.023586 \nL 811.644894 2259.37653 \nL 813.773311 2271.015613 \nL 814.482783 2277.793225 \nL 815.192255 2282.590126 \nL 815.901728 2281.919393 \nL 818.739617 2282.57762 \nL 819.449089 2275.921008 \nL 820.158562 2275.760703 \nL 820.868034 2273.971969 \nL 820.868034 2273.971969 \n\" clip-path=\"url(#pf783f5210c)\" style=\"fill: none; stroke: #ff4500; stroke-opacity: 0.7; stroke-width: 3; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_177\">\n    <path d=\"M 75.177125 2228.253645 \nL 856.377125 2228.253645 \n\" clip-path=\"url(#pf783f5210c)\" style=\"fill: none; stroke-dasharray: 11.1,4.8; stroke-dashoffset: 0; stroke: #4682b4; stroke-width: 3\"/>\n   </g>\n   <g id=\"line2d_178\">\n    <path d=\"M 75.177125 2254.448142 \nL 856.377125 2254.448142 \n\" clip-path=\"url(#pf783f5210c)\" style=\"fill: none; stroke: #000000; stroke-width: 3; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_37\">\n    <path d=\"M 75.177125 2339.737366 \nL 75.177125 2138.301937 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_38\">\n    <path d=\"M 856.377125 2339.737366 \nL 856.377125 2138.301937 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_39\">\n    <path d=\"M 75.177125 2339.737366 \nL 856.377125 2339.737366 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_40\">\n    <path d=\"M 75.177125 2138.301937 \nL 856.377125 2138.301937 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_71\">\n    <!-- Rolling Sharpe ratio (6-month) -->\n    <g transform=\"translate(365.534469 2132.301937)scale(0.132 -0.132)\">\n     <use xlink:href=\"#DejaVuSans-52\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"64.982422\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"126.164062\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"153.947266\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"181.730469\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"209.513672\"/>\n     <use xlink:href=\"#DejaVuSans-67\" x=\"272.892578\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"336.369141\"/>\n     <use xlink:href=\"#DejaVuSans-53\" x=\"368.15625\"/>\n     <use xlink:href=\"#DejaVuSans-68\" x=\"431.632812\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"495.011719\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"556.291016\"/>\n     <use xlink:href=\"#DejaVuSans-70\" x=\"597.404297\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"660.880859\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"722.404297\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"754.191406\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"795.304688\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"856.583984\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"895.792969\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"923.576172\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"984.757812\"/>\n     <use xlink:href=\"#DejaVuSans-28\" x=\"1016.544922\"/>\n     <use xlink:href=\"#DejaVuSans-36\" x=\"1055.558594\"/>\n     <use xlink:href=\"#DejaVuSans-2d\" x=\"1119.181641\"/>\n     <use xlink:href=\"#DejaVuSans-6d\" x=\"1155.265625\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"1252.677734\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"1313.859375\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"1377.238281\"/>\n     <use xlink:href=\"#DejaVuSans-68\" x=\"1416.447266\"/>\n     <use xlink:href=\"#DejaVuSans-29\" x=\"1479.826172\"/>\n    </g>\n   </g>\n   <g id=\"legend_5\">\n    <g id=\"patch_41\">\n     <path d=\"M 759.497719 2183.503 \nL 847.907125 2183.503 \nQ 850.327125 2183.503 850.327125 2181.083 \nL 850.327125 2146.771937 \nQ 850.327125 2144.351937 847.907125 2144.351937 \nL 759.497719 2144.351937 \nQ 757.077719 2144.351937 757.077719 2146.771937 \nL 757.077719 2181.083 \nQ 757.077719 2183.503 759.497719 2183.503 \nz\n\" style=\"fill: #ffffff; opacity: 0.5; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_179\">\n     <path d=\"M 761.917719 2154.151047 \nL 774.017719 2154.151047 \nL 786.117719 2154.151047 \n\" style=\"fill: none; stroke: #ff4500; stroke-opacity: 0.7; stroke-width: 3; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_72\">\n     <!-- Sharpe -->\n     <g transform=\"translate(795.797719 2158.386047)scale(0.121 -0.121)\">\n      <use xlink:href=\"#DejaVuSans-53\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"63.476562\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"126.855469\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"188.134766\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"229.248047\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"292.724609\"/>\n     </g>\n    </g>\n    <g id=\"line2d_180\">\n     <path d=\"M 761.917719 2171.911578 \nL 774.017719 2171.911578 \nL 786.117719 2171.911578 \n\" style=\"fill: none; stroke-dasharray: 11.1,4.8; stroke-dashoffset: 0; stroke: #4682b4; stroke-width: 3\"/>\n    </g>\n    <g id=\"text_73\">\n     <!-- Average -->\n     <g transform=\"translate(795.797719 2176.146578)scale(0.121 -0.121)\">\n      <use xlink:href=\"#DejaVuSans-41\"/>\n      <use xlink:href=\"#DejaVuSans-76\" x=\"62.533203\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"121.712891\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"183.236328\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"224.349609\"/>\n      <use xlink:href=\"#DejaVuSans-67\" x=\"285.628906\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"349.105469\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_8\">\n   <g id=\"patch_42\">\n    <path d=\"M 75.177125 2641.890509 \nL 856.377125 2641.890509 \nL 856.377125 2440.45508 \nL 75.177125 2440.45508 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"PolyCollection_1\">\n    <defs>\n     <path id=\"m88acb6b9eb\" d=\"M 615.121054 -1136.305388 \nL 615.121054 -934.86996 \nL 820.868034 -934.86996 \nL 820.868034 -1136.305388 \nL 820.868034 -1136.305388 \nL 615.121054 -1136.305388 \nz\n\" style=\"stroke: #2d1e3e; stroke-opacity: 0.4\"/>\n    </defs>\n    <g clip-path=\"url(#p1bedd59ef4)\">\n     <use xlink:href=\"#m88acb6b9eb\" x=\"0\" y=\"3576.760469\" style=\"fill: #2d1e3e; fill-opacity: 0.4; stroke: #2d1e3e; stroke-opacity: 0.4\"/>\n    </g>\n   </g>\n   <g id=\"PolyCollection_2\">\n    <defs>\n     <path id=\"mef8ce6219e\" d=\"M 403.698295 -1136.305388 \nL 403.698295 -934.86996 \nL 553.39696 -934.86996 \nL 553.39696 -1136.305388 \nL 553.39696 -1136.305388 \nL 403.698295 -1136.305388 \nz\n\" style=\"stroke: #6e4071; stroke-opacity: 0.4\"/>\n    </defs>\n    <g clip-path=\"url(#p1bedd59ef4)\">\n     <use xlink:href=\"#mef8ce6219e\" x=\"0\" y=\"3576.760469\" style=\"fill: #6e4071; fill-opacity: 0.4; stroke: #6e4071; stroke-opacity: 0.4\"/>\n    </g>\n   </g>\n   <g id=\"PolyCollection_3\">\n    <defs>\n     <path id=\"mc245be5853\" d=\"M 155.382974 -1136.305388 \nL 155.382974 -934.86996 \nL 239.100711 -934.86996 \nL 239.100711 -1136.305388 \nL 239.100711 -1136.305388 \nL 155.382974 -1136.305388 \nz\n\" style=\"stroke: #aa688f; stroke-opacity: 0.4\"/>\n    </defs>\n    <g clip-path=\"url(#p1bedd59ef4)\">\n     <use xlink:href=\"#mc245be5853\" x=\"0\" y=\"3576.760469\" style=\"fill: #aa688f; fill-opacity: 0.4; stroke: #aa688f; stroke-opacity: 0.4\"/>\n    </g>\n   </g>\n   <g id=\"PolyCollection_4\">\n    <defs>\n     <path id=\"m3afb85b8d4\" d=\"M 123.456718 -1136.305388 \nL 123.456718 -934.86996 \nL 154.673501 -934.86996 \nL 154.673501 -1136.305388 \nL 154.673501 -1136.305388 \nL 123.456718 -1136.305388 \nz\n\" style=\"stroke: #d499a7; stroke-opacity: 0.4\"/>\n    </defs>\n    <g clip-path=\"url(#p1bedd59ef4)\">\n     <use xlink:href=\"#m3afb85b8d4\" x=\"0\" y=\"3576.760469\" style=\"fill: #d499a7; fill-opacity: 0.4; stroke: #d499a7; stroke-opacity: 0.4\"/>\n    </g>\n   </g>\n   <g id=\"PolyCollection_5\">\n    <defs>\n     <path id=\"m21ce591d30\" d=\"M 249.033323 -1136.305388 \nL 249.033323 -934.86996 \nL 259.675409 -934.86996 \nL 259.675409 -1136.305388 \nL 259.675409 -1136.305388 \nL 249.033323 -1136.305388 \nz\n\" style=\"stroke: #edd1cb; stroke-opacity: 0.4\"/>\n    </defs>\n    <g clip-path=\"url(#p1bedd59ef4)\">\n     <use xlink:href=\"#m21ce591d30\" x=\"0\" y=\"3576.760469\" style=\"fill: #edd1cb; fill-opacity: 0.4; stroke: #edd1cb; stroke-opacity: 0.4\"/>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_15\">\n    <g id=\"xtick_99\">\n     <g id=\"line2d_181\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"109.976744\" y=\"2641.890509\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_100\">\n     <g id=\"line2d_182\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"195.822897\" y=\"2641.890509\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_101\">\n     <g id=\"line2d_183\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"283.087996\" y=\"2641.890509\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_102\">\n     <g id=\"line2d_184\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"369.643622\" y=\"2641.890509\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_103\">\n     <g id=\"line2d_185\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"454.780304\" y=\"2641.890509\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_104\">\n     <g id=\"line2d_186\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"542.045402\" y=\"2641.890509\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_105\">\n     <g id=\"line2d_187\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"628.601028\" y=\"2641.890509\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_106\">\n     <g id=\"line2d_188\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"713.73771\" y=\"2641.890509\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_107\">\n     <g id=\"line2d_189\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"801.002808\" y=\"2641.890509\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_108\">\n     <g id=\"line2d_190\">\n      <g>\n       <use xlink:href=\"#m3466dc2b85\" x=\"207.883927\" y=\"2641.890509\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_109\">\n     <g id=\"line2d_191\">\n      <g>\n       <use xlink:href=\"#m3466dc2b85\" x=\"349.778396\" y=\"2641.890509\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_110\">\n     <g id=\"line2d_192\">\n      <g>\n       <use xlink:href=\"#m3466dc2b85\" x=\"491.672866\" y=\"2641.890509\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_111\">\n     <g id=\"line2d_193\">\n      <g>\n       <use xlink:href=\"#m3466dc2b85\" x=\"633.567335\" y=\"2641.890509\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_112\">\n     <g id=\"line2d_194\">\n      <g>\n       <use xlink:href=\"#m3466dc2b85\" x=\"775.461804\" y=\"2641.890509\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_16\">\n    <g id=\"ytick_51\">\n     <g id=\"line2d_195\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"2617.292762\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_74\">\n      <!-- 1.00 -->\n      <g transform=\"translate(38.735719 2621.889817)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_52\">\n     <g id=\"line2d_196\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"2591.077036\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_75\">\n      <!-- 1.20 -->\n      <g transform=\"translate(38.735719 2595.674091)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_53\">\n     <g id=\"line2d_197\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"2564.86131\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_76\">\n      <!-- 1.40 -->\n      <g transform=\"translate(38.735719 2569.458365)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_54\">\n     <g id=\"line2d_198\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"2538.645584\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_77\">\n      <!-- 1.60 -->\n      <g transform=\"translate(38.735719 2543.242639)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_55\">\n     <g id=\"line2d_199\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"2512.429858\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_78\">\n      <!-- 1.80 -->\n      <g transform=\"translate(38.735719 2517.026913)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_56\">\n     <g id=\"line2d_200\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"2486.214132\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_79\">\n      <!-- 2.00 -->\n      <g transform=\"translate(38.735719 2490.811186)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_57\">\n     <g id=\"line2d_201\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"2459.998406\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_80\">\n      <!-- 2.20 -->\n      <g transform=\"translate(38.735719 2464.59546)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_81\">\n     <!-- Cumulative returns -->\n     <g transform=\"translate(31.990531 2604.554451)rotate(-90)scale(0.132 -0.132)\">\n      <use xlink:href=\"#DejaVuSans-43\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"69.824219\"/>\n      <use xlink:href=\"#DejaVuSans-6d\" x=\"133.203125\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"230.615234\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"293.994141\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"321.777344\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"383.056641\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"422.265625\"/>\n      <use xlink:href=\"#DejaVuSans-76\" x=\"450.048828\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"509.228516\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"570.751953\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"602.539062\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"641.402344\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"702.925781\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"742.134766\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"805.513672\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"844.876953\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"908.255859\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_202\">\n    <path d=\"M 110.686216 2617.292762 \nL 113.524105 2617.833365 \nL 114.233578 2616.902922 \nL 114.94305 2618.160782 \nL 115.652522 2616.255329 \nL 116.361995 2615.968035 \nL 118.490412 2614.361227 \nL 119.199884 2614.927502 \nL 119.909356 2615.842067 \nL 120.618829 2616.08673 \nL 121.328301 2614.926333 \nL 123.456718 2613.8414 \nL 124.16619 2615.443327 \nL 124.875663 2614.624463 \nL 125.585135 2619.044939 \nL 133.389331 2628.048555 \nL 134.098803 2624.798483 \nL 135.517748 2621.299256 \nL 136.22722 2620.809337 \nL 138.355637 2620.95156 \nL 139.06511 2619.873653 \nL 139.774582 2617.789645 \nL 140.484054 2619.414457 \nL 141.193527 2618.967704 \nL 143.321944 2616.118959 \nL 144.031416 2616.498581 \nL 144.740889 2616.722037 \nL 145.450361 2614.866908 \nL 146.159833 2614.344405 \nL 148.28825 2615.184154 \nL 148.997723 2615.214387 \nL 149.707195 2616.361879 \nL 150.416667 2615.179427 \nL 151.12614 2619.680229 \nL 153.254557 2615.994121 \nL 153.964029 2615.057234 \nL 154.673501 2613.81829 \nL 155.382974 2610.746008 \nL 156.092446 2613.424269 \nL 158.220863 2618.369989 \nL 158.930335 2615.576404 \nL 159.639808 2616.952298 \nL 160.34928 2620.000574 \nL 161.058752 2621.772231 \nL 163.18717 2626.470394 \nL 163.896642 2627.58636 \nL 164.606114 2629.407605 \nL 165.315587 2632.225825 \nL 166.025059 2629.038154 \nL 168.153476 2632.734353 \nL 169.572421 2626.485024 \nL 170.281893 2626.928038 \nL 170.991365 2625.916875 \nL 173.119782 2628.812818 \nL 173.829255 2628.351203 \nL 174.538727 2628.409328 \nL 175.248199 2627.527957 \nL 175.957672 2628.17263 \nL 178.795561 2626.313619 \nL 179.505033 2626.448976 \nL 180.214506 2625.678604 \nL 180.923978 2626.096024 \nL 183.052395 2626.741861 \nL 183.761868 2623.970411 \nL 184.47134 2625.385112 \nL 185.180812 2625.281431 \nL 185.890285 2623.108842 \nL 188.018702 2622.582142 \nL 188.728174 2623.756023 \nL 189.437646 2623.352024 \nL 190.147119 2623.72343 \nL 190.856591 2624.778574 \nL 192.985008 2624.03233 \nL 193.69448 2621.580855 \nL 194.403953 2622.259341 \nL 195.113425 2620.180325 \nL 199.370259 2619.13577 \nL 200.079731 2619.151862 \nL 200.789204 2618.227038 \nL 202.917621 2618.207768 \nL 203.627093 2618.016358 \nL 204.336566 2617.247696 \nL 205.046038 2619.024662 \nL 205.75551 2619.445952 \nL 207.883927 2618.731974 \nL 208.5934 2617.616536 \nL 209.302872 2619.093954 \nL 210.012344 2620.1885 \nL 210.721817 2623.552935 \nL 212.850234 2622.936919 \nL 213.559706 2621.752335 \nL 214.269178 2621.900065 \nL 214.978651 2621.752588 \nL 215.688123 2621.831292 \nL 217.81654 2618.891226 \nL 218.526012 2618.737353 \nL 219.235485 2617.749238 \nL 219.944957 2618.495853 \nL 220.65443 2621.806263 \nL 222.782847 2621.895476 \nL 223.492319 2620.160386 \nL 224.201791 2618.917547 \nL 224.911264 2619.79323 \nL 225.620736 2619.38807 \nL 227.749153 2621.274663 \nL 228.458625 2619.250558 \nL 229.168098 2617.701829 \nL 229.87757 2618.040611 \nL 230.587042 2614.552396 \nL 232.715459 2615.152396 \nL 233.424932 2613.625183 \nL 237.681766 2613.154241 \nL 239.100711 2609.583565 \nL 239.810183 2608.600212 \nL 240.519655 2608.926706 \nL 242.648072 2605.848426 \nL 243.357545 2603.540908 \nL 244.067017 2603.79635 \nL 244.776489 2601.715639 \nL 245.485962 2600.651081 \nL 247.614379 2593.098895 \nL 248.323851 2593.275075 \nL 249.033323 2591.428208 \nL 249.742796 2603.091672 \nL 250.452268 2602.652605 \nL 252.580685 2599.297064 \nL 253.290157 2594.800238 \nL 253.99963 2594.310156 \nL 254.709102 2592.284046 \nL 255.418574 2599.031404 \nL 257.546991 2596.623327 \nL 258.256464 2595.40458 \nL 258.965936 2591.761073 \nL 259.675409 2589.040737 \nL 260.384881 2584.544049 \nL 262.513298 2583.429494 \nL 263.22277 2585.994735 \nL 263.932243 2584.446733 \nL 264.641715 2583.751719 \nL 265.351187 2586.662915 \nL 267.479604 2586.174637 \nL 268.189077 2587.496542 \nL 268.898549 2591.149349 \nL 269.608021 2590.746455 \nL 270.317494 2587.930041 \nL 272.445911 2584.264098 \nL 273.155383 2583.615417 \nL 273.864855 2584.96422 \nL 274.574328 2587.488504 \nL 275.2838 2585.789167 \nL 277.412217 2583.671599 \nL 278.12169 2584.065502 \nL 278.831162 2586.218033 \nL 279.540634 2584.17801 \nL 280.250107 2579.322025 \nL 282.378524 2578.713037 \nL 283.087996 2577.39325 \nL 283.797468 2578.429166 \nL 284.506941 2578.252936 \nL 285.216413 2579.121623 \nL 287.34483 2582.931812 \nL 288.054302 2582.578599 \nL 288.763775 2586.345868 \nL 289.473247 2584.686527 \nL 290.182719 2581.930885 \nL 292.311136 2581.273115 \nL 293.020609 2581.659496 \nL 293.730081 2582.207484 \nL 294.439553 2586.228563 \nL 295.149026 2583.20902 \nL 297.277443 2583.665483 \nL 297.986915 2586.182471 \nL 298.696388 2585.436762 \nL 299.40586 2588.134026 \nL 300.115332 2588.133345 \nL 302.243749 2587.663807 \nL 302.953222 2585.531406 \nL 303.662694 2585.807704 \nL 310.047945 2580.850665 \nL 312.176362 2575.033409 \nL 312.885834 2573.448644 \nL 313.595307 2575.240994 \nL 314.304779 2577.66948 \nL 315.014252 2578.561642 \nL 317.142669 2580.560463 \nL 317.852141 2579.291276 \nL 318.561613 2581.473991 \nL 319.271086 2582.13653 \nL 319.980558 2584.100343 \nL 322.108975 2585.347592 \nL 322.818447 2583.515101 \nL 323.52792 2579.814988 \nL 324.946864 2582.648821 \nL 327.075281 2582.360387 \nL 327.784754 2578.709739 \nL 328.494226 2576.751046 \nL 329.203698 2575.7368 \nL 329.913171 2577.37722 \nL 332.041588 2575.632839 \nL 332.75106 2577.876128 \nL 333.460533 2579.522515 \nL 334.170005 2578.679931 \nL 334.879477 2578.603157 \nL 337.007894 2576.711215 \nL 337.717367 2580.580787 \nL 338.426839 2579.639543 \nL 339.136311 2574.396965 \nL 339.845784 2571.805475 \nL 341.974201 2569.471985 \nL 342.683673 2569.234356 \nL 343.393145 2572.482506 \nL 344.102618 2570.459 \nL 344.81209 2567.046683 \nL 346.940507 2570.06209 \nL 347.649979 2564.649351 \nL 348.359452 2565.717356 \nL 349.068924 2565.315704 \nL 349.778396 2563.001534 \nL 351.906813 2564.126993 \nL 352.616286 2564.74081 \nL 353.325758 2566.571175 \nL 354.035231 2565.487354 \nL 354.744703 2565.628567 \nL 356.87312 2564.398689 \nL 357.582592 2560.710699 \nL 358.292065 2558.067412 \nL 359.001537 2557.947518 \nL 359.711009 2558.438688 \nL 361.839426 2553.877312 \nL 362.548899 2558.128527 \nL 363.258371 2551.775134 \nL 363.967843 2553.456327 \nL 364.677316 2548.409584 \nL 366.805733 2544.300901 \nL 367.515205 2545.454485 \nL 368.93415 2537.292599 \nL 371.772039 2529.080772 \nL 372.481512 2521.864027 \nL 373.190984 2518.925259 \nL 373.900456 2509.154087 \nL 374.609929 2509.325266 \nL 376.738346 2514.889125 \nL 377.447818 2507.232079 \nL 378.15729 2508.918309 \nL 378.866763 2517.202101 \nL 379.576235 2518.705299 \nL 381.704652 2514.889608 \nL 382.414124 2522.31835 \nL 383.123597 2519.153988 \nL 383.833069 2512.458855 \nL 384.542541 2508.271353 \nL 386.670958 2506.392561 \nL 387.380431 2508.620001 \nL 388.089903 2508.695004 \nL 388.799375 2517.835665 \nL 389.508848 2517.140548 \nL 391.637265 2507.988187 \nL 392.346737 2506.067903 \nL 393.05621 2502.451717 \nL 393.765682 2500.453419 \nL 394.475154 2502.840098 \nL 396.603571 2490.056922 \nL 397.313044 2483.793788 \nL 398.022516 2476.37469 \nL 403.698295 2471.127628 \nL 404.407767 2477.281552 \nL 406.536184 2481.456812 \nL 407.955129 2491.488172 \nL 408.664601 2484.070058 \nL 409.374074 2490.416757 \nL 411.502491 2489.073752 \nL 412.211963 2497.315437 \nL 412.921435 2492.837301 \nL 413.630908 2507.345114 \nL 414.34038 2512.708116 \nL 416.468797 2522.18386 \nL 417.178269 2529.97034 \nL 417.887742 2519.158384 \nL 419.306686 2505.030685 \nL 421.435103 2513.338486 \nL 422.144576 2505.174471 \nL 422.854048 2502.762326 \nL 423.56352 2501.863413 \nL 424.272993 2508.309426 \nL 426.40141 2510.027018 \nL 427.110882 2513.885689 \nL 427.820354 2520.67397 \nL 428.529827 2517.828858 \nL 429.239299 2507.319883 \nL 431.367716 2503.007662 \nL 432.077189 2502.573926 \nL 432.786661 2510.952406 \nL 433.496133 2504.726847 \nL 434.205606 2496.258589 \nL 437.043495 2499.968307 \nL 437.752967 2505.536018 \nL 438.46244 2498.512896 \nL 439.171912 2506.272545 \nL 441.300329 2512.750072 \nL 442.009801 2511.57341 \nL 442.719274 2510.762289 \nL 443.428746 2512.652592 \nL 444.138218 2511.300047 \nL 446.266635 2504.820573 \nL 446.976108 2503.135976 \nL 447.68558 2502.267651 \nL 448.395053 2503.702388 \nL 449.104525 2502.464623 \nL 451.232942 2505.65089 \nL 451.942414 2504.88537 \nL 452.651887 2502.648205 \nL 453.361359 2504.807936 \nL 454.070831 2505.54591 \nL 458.327665 2505.73521 \nL 459.037138 2508.816732 \nL 461.165555 2506.183502 \nL 461.875027 2504.562098 \nL 462.584499 2503.529269 \nL 463.293972 2506.69716 \nL 464.003444 2501.424928 \nL 466.131861 2497.042371 \nL 466.841334 2497.603566 \nL 468.260278 2498.285068 \nL 468.969751 2500.940168 \nL 471.098168 2500.522113 \nL 471.80764 2492.251185 \nL 472.517112 2491.579884 \nL 473.226585 2492.457865 \nL 473.936057 2492.643882 \nL 476.064474 2491.802852 \nL 476.773946 2494.066301 \nL 477.483419 2495.564043 \nL 478.192891 2496.670308 \nL 478.902363 2494.769359 \nL 481.03078 2494.393762 \nL 481.740253 2492.015656 \nL 482.449725 2491.615582 \nL 483.159197 2488.639087 \nL 483.86867 2493.532099 \nL 486.706559 2494.368848 \nL 487.416032 2500.132019 \nL 488.125504 2502.27647 \nL 488.834976 2500.636993 \nL 490.963393 2500.869787 \nL 491.672866 2500.803096 \nL 492.382338 2508.299964 \nL 493.09181 2507.65839 \nL 493.801283 2505.277486 \nL 495.9297 2502.613378 \nL 496.639172 2505.07989 \nL 497.348644 2503.267286 \nL 498.058117 2507.826753 \nL 498.767589 2515.343919 \nL 501.605478 2509.363372 \nL 502.314951 2504.00171 \nL 503.024423 2505.767587 \nL 503.733896 2509.874864 \nL 505.862313 2505.776975 \nL 506.571785 2504.128041 \nL 507.281257 2512.652354 \nL 507.99073 2510.077486 \nL 508.700202 2506.972293 \nL 510.828619 2504.443511 \nL 511.538091 2505.238137 \nL 512.247564 2503.600063 \nL 512.957036 2504.115249 \nL 513.666508 2507.256242 \nL 515.794925 2511.314552 \nL 516.504398 2521.67125 \nL 517.21387 2523.405855 \nL 517.923342 2518.574416 \nL 518.632815 2516.664558 \nL 520.761232 2504.441634 \nL 521.470704 2503.531292 \nL 522.180176 2498.128064 \nL 522.889649 2495.14379 \nL 523.599121 2498.152692 \nL 525.727538 2496.505741 \nL 526.437011 2492.8302 \nL 527.146483 2495.594105 \nL 527.855955 2495.302711 \nL 528.565428 2496.750306 \nL 530.693845 2496.433836 \nL 531.403317 2501.939381 \nL 532.822262 2505.123561 \nL 533.531734 2515.217933 \nL 535.660151 2503.929058 \nL 536.369623 2501.621007 \nL 537.079096 2497.912123 \nL 537.788568 2502.364689 \nL 538.49804 2498.810174 \nL 540.626457 2495.057057 \nL 541.33593 2496.351828 \nL 542.045402 2492.734891 \nL 542.754875 2495.15085 \nL 543.464347 2495.288513 \nL 545.592764 2487.678211 \nL 546.302236 2484.727245 \nL 547.011709 2491.007183 \nL 547.721181 2490.032232 \nL 548.430653 2479.949194 \nL 551.268543 2476.872582 \nL 551.978015 2483.256707 \nL 552.687487 2481.005819 \nL 553.39696 2470.449796 \nL 556.944321 2474.822449 \nL 557.653794 2474.565929 \nL 558.363266 2467.856282 \nL 560.491683 2463.495131 \nL 561.201156 2468.987111 \nL 561.910628 2471.425479 \nL 562.6201 2471.186315 \nL 568.295879 2464.925462 \nL 570.424296 2469.532179 \nL 571.133768 2468.899552 \nL 571.843241 2461.852492 \nL 572.552713 2460.482659 \nL 573.262185 2458.102836 \nL 575.390602 2458.779259 \nL 576.100075 2457.022067 \nL 576.809547 2455.70986 \nL 577.519019 2457.538993 \nL 578.228492 2456.274416 \nL 580.356909 2454.011327 \nL 581.066381 2455.50072 \nL 582.485326 2461.245408 \nL 583.194798 2457.961189 \nL 585.323215 2463.824832 \nL 586.032688 2466.285326 \nL 586.74216 2470.319591 \nL 587.451632 2465.522472 \nL 588.161105 2466.324238 \nL 590.289522 2465.484975 \nL 590.998994 2466.100083 \nL 591.708466 2468.811087 \nL 592.417939 2466.099416 \nL 593.127411 2465.208692 \nL 595.9653 2462.357393 \nL 596.674773 2463.407819 \nL 597.384245 2467.039939 \nL 598.093717 2463.724556 \nL 600.222135 2464.427915 \nL 600.931607 2465.548025 \nL 601.641079 2465.857727 \nL 603.060024 2469.230013 \nL 605.188441 2470.50694 \nL 605.897913 2472.899955 \nL 607.316858 2469.818472 \nL 608.02633 2466.288514 \nL 610.154747 2465.085385 \nL 610.86422 2464.357124 \nL 611.573692 2456.844549 \nL 612.283164 2453.006467 \nL 612.992637 2453.029292 \nL 615.121054 2449.611236 \nL 615.830526 2451.966231 \nL 616.539998 2456.603102 \nL 617.958943 2470.291082 \nL 620.08736 2469.927324 \nL 620.796833 2471.973315 \nL 621.506305 2473.608289 \nL 622.215777 2472.911599 \nL 622.92525 2475.265932 \nL 625.053667 2475.899764 \nL 625.763139 2473.284549 \nL 626.472611 2483.817544 \nL 627.182084 2482.406505 \nL 627.891556 2482.15419 \nL 630.729445 2483.393962 \nL 631.438918 2486.335634 \nL 632.14839 2488.079918 \nL 634.986279 2487.807289 \nL 635.695752 2490.309962 \nL 636.405224 2488.950318 \nL 637.114697 2495.002819 \nL 637.824169 2495.94699 \nL 639.952586 2495.070084 \nL 640.662058 2493.783044 \nL 641.371531 2495.446643 \nL 642.081003 2496.04832 \nL 642.790475 2496.264666 \nL 644.918892 2496.726412 \nL 645.628365 2502.313578 \nL 646.337837 2501.202707 \nL 647.756782 2511.541961 \nL 654.851505 2509.455674 \nL 655.560978 2510.846644 \nL 656.27045 2504.783277 \nL 656.979922 2503.973058 \nL 657.689395 2500.539543 \nL 659.817812 2500.021347 \nL 660.527284 2498.215549 \nL 661.236756 2497.388953 \nL 661.946229 2498.321032 \nL 662.655701 2497.354727 \nL 664.784118 2498.094559 \nL 665.49359 2500.759982 \nL 666.203063 2499.423056 \nL 666.912535 2505.199398 \nL 667.622007 2504.372518 \nL 669.750424 2503.431173 \nL 670.459897 2501.960907 \nL 671.169369 2502.727964 \nL 671.878841 2502.575678 \nL 672.588314 2505.235737 \nL 674.716731 2512.140929 \nL 675.426203 2516.793118 \nL 676.135676 2518.754202 \nL 676.845148 2517.241969 \nL 677.55462 2514.517424 \nL 679.683037 2517.812123 \nL 680.39251 2528.758212 \nL 681.101982 2519.283556 \nL 681.811454 2514.419119 \nL 682.520927 2512.130108 \nL 684.649344 2513.578464 \nL 685.358816 2514.612501 \nL 686.068288 2514.037222 \nL 686.777761 2516.566653 \nL 687.487233 2519.565512 \nL 689.61565 2520.729822 \nL 690.325122 2520.351829 \nL 691.034595 2512.767282 \nL 691.744067 2514.992996 \nL 692.453539 2511.077123 \nL 696.000901 2513.447534 \nL 696.710374 2514.072184 \nL 697.419846 2513.473375 \nL 699.548263 2519.026886 \nL 700.257735 2515.07382 \nL 700.967208 2516.38763 \nL 701.67668 2514.039546 \nL 702.386152 2515.050333 \nL 704.514569 2517.670173 \nL 705.224042 2520.605855 \nL 706.642986 2525.471776 \nL 707.352459 2525.498328 \nL 709.480876 2536.13739 \nL 710.190348 2535.988493 \nL 711.609293 2529.228081 \nL 712.318765 2526.517664 \nL 716.575599 2523.303932 \nL 717.285072 2529.497229 \nL 719.413489 2531.170893 \nL 720.122961 2531.230697 \nL 720.832433 2525.089058 \nL 721.541906 2525.6622 \nL 722.251378 2524.294161 \nL 724.379795 2525.574261 \nL 725.089267 2521.922532 \nL 725.79874 2521.19078 \nL 726.508212 2523.21156 \nL 727.217684 2517.8784 \nL 729.346101 2520.310543 \nL 730.055574 2523.996739 \nL 730.765046 2521.241594 \nL 732.183991 2520.657899 \nL 734.312408 2518.322063 \nL 735.02188 2518.462571 \nL 735.731353 2519.354744 \nL 736.440825 2519.377196 \nL 739.278714 2518.393342 \nL 739.988187 2517.962542 \nL 740.697659 2514.143837 \nL 741.407131 2515.767212 \nL 742.116604 2512.398772 \nL 744.245021 2516.844703 \nL 744.954493 2513.091048 \nL 745.663965 2507.876676 \nL 746.373438 2511.031936 \nL 747.08291 2504.308467 \nL 749.211327 2505.140714 \nL 749.9208 2505.596099 \nL 750.630272 2509.443042 \nL 751.339744 2505.416684 \nL 752.049217 2502.090591 \nL 754.177634 2498.523735 \nL 754.887106 2499.162468 \nL 755.596578 2501.130878 \nL 756.306051 2495.761672 \nL 757.015523 2498.106544 \nL 759.14394 2499.232775 \nL 759.853412 2499.298586 \nL 760.562885 2504.993445 \nL 761.272357 2504.59658 \nL 761.981829 2505.041886 \nL 764.110246 2510.230125 \nL 764.819719 2513.052412 \nL 765.529191 2511.52797 \nL 766.238663 2511.06036 \nL 766.948136 2514.959047 \nL 769.076553 2511.040825 \nL 769.786025 2512.962022 \nL 770.495498 2511.184703 \nL 771.20497 2512.767861 \nL 771.914442 2512.498801 \nL 774.042859 2513.466562 \nL 774.752332 2513.633049 \nL 775.461804 2515.745343 \nL 776.171276 2515.569812 \nL 776.880749 2521.40457 \nL 779.009166 2522.926609 \nL 779.718638 2527.574913 \nL 780.42811 2527.302977 \nL 781.137583 2524.24941 \nL 781.847055 2522.296645 \nL 783.975472 2522.015626 \nL 784.684944 2520.836815 \nL 785.394417 2522.893787 \nL 786.103889 2519.332452 \nL 786.813361 2517.510523 \nL 788.941779 2518.71252 \nL 789.651251 2520.328489 \nL 790.360723 2519.474445 \nL 791.070196 2521.732307 \nL 791.779668 2524.75533 \nL 793.908085 2520.923696 \nL 794.617557 2521.673573 \nL 795.32703 2525.141469 \nL 796.036502 2522.661413 \nL 796.745974 2522.619089 \nL 799.583864 2524.542759 \nL 800.293336 2525.764717 \nL 801.002808 2527.673105 \nL 801.712281 2530.851687 \nL 803.840698 2533.484979 \nL 804.55017 2528.628676 \nL 805.969115 2529.517136 \nL 806.678587 2527.36133 \nL 809.516477 2525.290594 \nL 810.225949 2527.950601 \nL 810.935421 2529.857448 \nL 811.644894 2535.727678 \nL 813.773311 2536.25303 \nL 814.482783 2537.27513 \nL 815.192255 2539.183348 \nL 815.901728 2539.901072 \nL 816.6112 2540.941109 \nL 818.739617 2540.844936 \nL 819.449089 2537.70326 \nL 820.158562 2540.288419 \nL 820.868034 2539.870487 \nL 820.868034 2539.870487 \n\" clip-path=\"url(#p1bedd59ef4)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_43\">\n    <path d=\"M 75.177125 2641.890509 \nL 75.177125 2440.45508 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_44\">\n    <path d=\"M 856.377125 2641.890509 \nL 856.377125 2440.45508 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_45\">\n    <path d=\"M 75.177125 2641.890509 \nL 856.377125 2641.890509 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_46\">\n    <path d=\"M 75.177125 2440.45508 \nL 856.377125 2440.45508 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_82\">\n    <!-- Top 5 drawdown periods -->\n    <g transform=\"translate(385.529375 2434.45508)scale(0.132 -0.132)\">\n     <defs>\n      <path id=\"DejaVuSans-54\" d=\"M -19 4666 \nL 3928 4666 \nL 3928 4134 \nL 2272 4134 \nL 2272 0 \nL 1638 0 \nL 1638 4134 \nL -19 4134 \nL -19 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-77\" d=\"M 269 3500 \nL 844 3500 \nL 1563 769 \nL 2278 3500 \nL 2956 3500 \nL 3675 769 \nL 4391 3500 \nL 4966 3500 \nL 4050 0 \nL 3372 0 \nL 2619 2869 \nL 1863 0 \nL 1184 0 \nL 269 3500 \nz\n\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-54\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"44.083984\"/>\n     <use xlink:href=\"#DejaVuSans-70\" x=\"105.265625\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"168.742188\"/>\n     <use xlink:href=\"#DejaVuSans-35\" x=\"200.529297\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"264.152344\"/>\n     <use xlink:href=\"#DejaVuSans-64\" x=\"295.939453\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"359.416016\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"400.529297\"/>\n     <use xlink:href=\"#DejaVuSans-77\" x=\"461.808594\"/>\n     <use xlink:href=\"#DejaVuSans-64\" x=\"543.595703\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"607.072266\"/>\n     <use xlink:href=\"#DejaVuSans-77\" x=\"668.253906\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"750.041016\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"813.419922\"/>\n     <use xlink:href=\"#DejaVuSans-70\" x=\"845.207031\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"908.683594\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"970.207031\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"1011.320312\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"1039.103516\"/>\n     <use xlink:href=\"#DejaVuSans-64\" x=\"1100.285156\"/>\n     <use xlink:href=\"#DejaVuSans-73\" x=\"1163.761719\"/>\n    </g>\n   </g>\n   <g id=\"legend_6\">\n    <g id=\"patch_47\">\n     <path d=\"M 83.647125 2467.895612 \nL 172.135938 2467.895612 \nQ 174.555938 2467.895612 174.555938 2465.475612 \nL 174.555938 2448.92508 \nQ 174.555938 2446.50508 172.135938 2446.50508 \nL 83.647125 2446.50508 \nQ 81.227125 2446.50508 81.227125 2448.92508 \nL 81.227125 2465.475612 \nQ 81.227125 2467.895612 83.647125 2467.895612 \nz\n\" style=\"fill: #ffffff; opacity: 0.5; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_203\">\n     <path d=\"M 86.067125 2456.30419 \nL 98.167125 2456.30419 \nL 110.267125 2456.30419 \n\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_83\">\n     <!-- Portfolio -->\n     <g transform=\"translate(119.947125 2460.53919)scale(0.121 -0.121)\">\n      <defs>\n       <path id=\"DejaVuSans-50\" d=\"M 1259 4147 \nL 1259 2394 \nL 2053 2394 \nQ 2494 2394 2734 2622 \nQ 2975 2850 2975 3272 \nQ 2975 3691 2734 3919 \nQ 2494 4147 2053 4147 \nL 1259 4147 \nz\nM 628 4666 \nL 2053 4666 \nQ 2838 4666 3239 4311 \nQ 3641 3956 3641 3272 \nQ 3641 2581 3239 2228 \nQ 2838 1875 2053 1875 \nL 1259 1875 \nL 1259 0 \nL 628 0 \nL 628 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-50\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"56.677734\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"117.859375\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"158.972656\"/>\n      <use xlink:href=\"#DejaVuSans-66\" x=\"198.181641\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"233.386719\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"294.568359\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"322.351562\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"350.134766\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_9\">\n   <g id=\"patch_48\">\n    <path d=\"M 75.177125 2944.043652 \nL 856.377125 2944.043652 \nL 856.377125 2742.608223 \nL 75.177125 2742.608223 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"PolyCollection_6\">\n    <defs>\n     <path id=\"mfc534dbbdf\" d=\"M 110.686216 -834.152246 \nL 110.686216 -834.152246 \nL 111.395688 -834.152246 \nL 113.524105 -834.152246 \nL 114.233578 -834.152246 \nL 114.94305 -834.152246 \nL 115.652522 -834.152246 \nL 116.361995 -834.152246 \nL 118.490412 -834.152246 \nL 119.199884 -834.152246 \nL 119.909356 -834.152246 \nL 120.618829 -834.152246 \nL 121.328301 -834.152246 \nL 123.456718 -834.152246 \nL 124.16619 -834.152246 \nL 124.875663 -834.152246 \nL 125.585135 -834.152246 \nL 133.389331 -834.152246 \nL 134.098803 -834.152246 \nL 134.808276 -834.152246 \nL 135.517748 -834.152246 \nL 136.22722 -834.152246 \nL 138.355637 -834.152246 \nL 139.06511 -834.152246 \nL 139.774582 -834.152246 \nL 140.484054 -834.152246 \nL 141.193527 -834.152246 \nL 143.321944 -834.152246 \nL 144.031416 -834.152246 \nL 144.740889 -834.152246 \nL 145.450361 -834.152246 \nL 146.159833 -834.152246 \nL 148.28825 -834.152246 \nL 148.997723 -834.152246 \nL 149.707195 -834.152246 \nL 150.416667 -834.152246 \nL 151.12614 -834.152246 \nL 153.254557 -834.152246 \nL 153.964029 -834.152246 \nL 154.673501 -834.152246 \nL 155.382974 -834.152246 \nL 156.092446 -834.152246 \nL 158.220863 -834.152246 \nL 158.930335 -834.152246 \nL 159.639808 -834.152246 \nL 160.34928 -834.152246 \nL 161.058752 -834.152246 \nL 163.18717 -834.152246 \nL 163.896642 -834.152246 \nL 164.606114 -834.152246 \nL 165.315587 -834.152246 \nL 166.025059 -834.152246 \nL 168.153476 -834.152246 \nL 168.862948 -834.152246 \nL 169.572421 -834.152246 \nL 170.281893 -834.152246 \nL 170.991365 -834.152246 \nL 173.119782 -834.152246 \nL 173.829255 -834.152246 \nL 174.538727 -834.152246 \nL 175.248199 -834.152246 \nL 175.957672 -834.152246 \nL 178.795561 -834.152246 \nL 179.505033 -834.152246 \nL 180.214506 -834.152246 \nL 180.923978 -834.152246 \nL 183.052395 -834.152246 \nL 183.761868 -834.152246 \nL 184.47134 -834.152246 \nL 185.180812 -834.152246 \nL 185.890285 -834.152246 \nL 188.018702 -834.152246 \nL 188.728174 -834.152246 \nL 189.437646 -834.152246 \nL 190.147119 -834.152246 \nL 190.856591 -834.152246 \nL 192.985008 -834.152246 \nL 193.69448 -834.152246 \nL 194.403953 -834.152246 \nL 195.113425 -834.152246 \nL 199.370259 -834.152246 \nL 200.079731 -834.152246 \nL 200.789204 -834.152246 \nL 202.917621 -834.152246 \nL 203.627093 -834.152246 \nL 204.336566 -834.152246 \nL 205.046038 -834.152246 \nL 205.75551 -834.152246 \nL 207.883927 -834.152246 \nL 208.5934 -834.152246 \nL 209.302872 -834.152246 \nL 210.012344 -834.152246 \nL 210.721817 -834.152246 \nL 212.850234 -834.152246 \nL 213.559706 -834.152246 \nL 214.269178 -834.152246 \nL 214.978651 -834.152246 \nL 215.688123 -834.152246 \nL 217.81654 -834.152246 \nL 218.526012 -834.152246 \nL 219.235485 -834.152246 \nL 219.944957 -834.152246 \nL 220.65443 -834.152246 \nL 222.782847 -834.152246 \nL 223.492319 -834.152246 \nL 224.201791 -834.152246 \nL 224.911264 -834.152246 \nL 225.620736 -834.152246 \nL 227.749153 -834.152246 \nL 228.458625 -834.152246 \nL 229.168098 -834.152246 \nL 229.87757 -834.152246 \nL 230.587042 -834.152246 \nL 232.715459 -834.152246 \nL 233.424932 -834.152246 \nL 234.134404 -834.152246 \nL 237.681766 -834.152246 \nL 238.391238 -834.152246 \nL 239.100711 -834.152246 \nL 239.810183 -834.152246 \nL 240.519655 -834.152246 \nL 242.648072 -834.152246 \nL 243.357545 -834.152246 \nL 244.067017 -834.152246 \nL 244.776489 -834.152246 \nL 245.485962 -834.152246 \nL 247.614379 -834.152246 \nL 248.323851 -834.152246 \nL 249.033323 -834.152246 \nL 249.742796 -834.152246 \nL 250.452268 -834.152246 \nL 252.580685 -834.152246 \nL 253.290157 -834.152246 \nL 253.99963 -834.152246 \nL 254.709102 -834.152246 \nL 255.418574 -834.152246 \nL 257.546991 -834.152246 \nL 258.256464 -834.152246 \nL 258.965936 -834.152246 \nL 259.675409 -834.152246 \nL 260.384881 -834.152246 \nL 262.513298 -834.152246 \nL 263.22277 -834.152246 \nL 263.932243 -834.152246 \nL 264.641715 -834.152246 \nL 265.351187 -834.152246 \nL 267.479604 -834.152246 \nL 268.189077 -834.152246 \nL 268.898549 -834.152246 \nL 269.608021 -834.152246 \nL 270.317494 -834.152246 \nL 272.445911 -834.152246 \nL 273.155383 -834.152246 \nL 273.864855 -834.152246 \nL 274.574328 -834.152246 \nL 275.2838 -834.152246 \nL 277.412217 -834.152246 \nL 278.12169 -834.152246 \nL 278.831162 -834.152246 \nL 279.540634 -834.152246 \nL 280.250107 -834.152246 \nL 282.378524 -834.152246 \nL 283.087996 -834.152246 \nL 283.797468 -834.152246 \nL 284.506941 -834.152246 \nL 285.216413 -834.152246 \nL 287.34483 -834.152246 \nL 288.054302 -834.152246 \nL 288.763775 -834.152246 \nL 289.473247 -834.152246 \nL 290.182719 -834.152246 \nL 292.311136 -834.152246 \nL 293.020609 -834.152246 \nL 293.730081 -834.152246 \nL 294.439553 -834.152246 \nL 295.149026 -834.152246 \nL 297.277443 -834.152246 \nL 297.986915 -834.152246 \nL 298.696388 -834.152246 \nL 299.40586 -834.152246 \nL 300.115332 -834.152246 \nL 302.243749 -834.152246 \nL 302.953222 -834.152246 \nL 303.662694 -834.152246 \nL 310.047945 -834.152246 \nL 312.176362 -834.152246 \nL 312.885834 -834.152246 \nL 313.595307 -834.152246 \nL 314.304779 -834.152246 \nL 315.014252 -834.152246 \nL 317.142669 -834.152246 \nL 317.852141 -834.152246 \nL 318.561613 -834.152246 \nL 319.271086 -834.152246 \nL 319.980558 -834.152246 \nL 322.108975 -834.152246 \nL 322.818447 -834.152246 \nL 323.52792 -834.152246 \nL 324.237392 -834.152246 \nL 324.946864 -834.152246 \nL 327.075281 -834.152246 \nL 327.784754 -834.152246 \nL 328.494226 -834.152246 \nL 329.203698 -834.152246 \nL 329.913171 -834.152246 \nL 332.041588 -834.152246 \nL 332.75106 -834.152246 \nL 333.460533 -834.152246 \nL 334.170005 -834.152246 \nL 334.879477 -834.152246 \nL 337.007894 -834.152246 \nL 337.717367 -834.152246 \nL 338.426839 -834.152246 \nL 339.136311 -834.152246 \nL 339.845784 -834.152246 \nL 341.974201 -834.152246 \nL 342.683673 -834.152246 \nL 343.393145 -834.152246 \nL 344.102618 -834.152246 \nL 344.81209 -834.152246 \nL 346.940507 -834.152246 \nL 347.649979 -834.152246 \nL 348.359452 -834.152246 \nL 349.068924 -834.152246 \nL 349.778396 -834.152246 \nL 351.906813 -834.152246 \nL 352.616286 -834.152246 \nL 353.325758 -834.152246 \nL 354.035231 -834.152246 \nL 354.744703 -834.152246 \nL 356.87312 -834.152246 \nL 357.582592 -834.152246 \nL 358.292065 -834.152246 \nL 359.001537 -834.152246 \nL 359.711009 -834.152246 \nL 361.839426 -834.152246 \nL 362.548899 -834.152246 \nL 363.258371 -834.152246 \nL 363.967843 -834.152246 \nL 364.677316 -834.152246 \nL 366.805733 -834.152246 \nL 367.515205 -834.152246 \nL 368.224677 -834.152246 \nL 368.93415 -834.152246 \nL 371.772039 -834.152246 \nL 372.481512 -834.152246 \nL 373.190984 -834.152246 \nL 373.900456 -834.152246 \nL 374.609929 -834.152246 \nL 376.738346 -834.152246 \nL 377.447818 -834.152246 \nL 378.15729 -834.152246 \nL 378.866763 -834.152246 \nL 379.576235 -834.152246 \nL 381.704652 -834.152246 \nL 382.414124 -834.152246 \nL 383.123597 -834.152246 \nL 383.833069 -834.152246 \nL 384.542541 -834.152246 \nL 386.670958 -834.152246 \nL 387.380431 -834.152246 \nL 388.089903 -834.152246 \nL 388.799375 -834.152246 \nL 389.508848 -834.152246 \nL 391.637265 -834.152246 \nL 392.346737 -834.152246 \nL 393.05621 -834.152246 \nL 393.765682 -834.152246 \nL 394.475154 -834.152246 \nL 396.603571 -834.152246 \nL 397.313044 -834.152246 \nL 398.022516 -834.152246 \nL 403.698295 -834.152246 \nL 404.407767 -834.152246 \nL 406.536184 -834.152246 \nL 407.245656 -834.152246 \nL 407.955129 -834.152246 \nL 408.664601 -834.152246 \nL 409.374074 -834.152246 \nL 411.502491 -834.152246 \nL 412.211963 -834.152246 \nL 412.921435 -834.152246 \nL 413.630908 -834.152246 \nL 414.34038 -834.152246 \nL 416.468797 -834.152246 \nL 417.178269 -834.152246 \nL 417.887742 -834.152246 \nL 418.597214 -834.152246 \nL 419.306686 -834.152246 \nL 421.435103 -834.152246 \nL 422.144576 -834.152246 \nL 422.854048 -834.152246 \nL 423.56352 -834.152246 \nL 424.272993 -834.152246 \nL 426.40141 -834.152246 \nL 427.110882 -834.152246 \nL 427.820354 -834.152246 \nL 428.529827 -834.152246 \nL 429.239299 -834.152246 \nL 431.367716 -834.152246 \nL 432.077189 -834.152246 \nL 432.786661 -834.152246 \nL 433.496133 -834.152246 \nL 434.205606 -834.152246 \nL 437.043495 -834.152246 \nL 437.752967 -834.152246 \nL 438.46244 -834.152246 \nL 439.171912 -834.152246 \nL 441.300329 -834.152246 \nL 442.009801 -834.152246 \nL 442.719274 -834.152246 \nL 443.428746 -834.152246 \nL 444.138218 -834.152246 \nL 446.266635 -834.152246 \nL 446.976108 -834.152246 \nL 447.68558 -834.152246 \nL 448.395053 -834.152246 \nL 449.104525 -834.152246 \nL 451.232942 -834.152246 \nL 451.942414 -834.152246 \nL 452.651887 -834.152246 \nL 453.361359 -834.152246 \nL 454.070831 -834.152246 \nL 458.327665 -834.152246 \nL 459.037138 -834.152246 \nL 461.165555 -834.152246 \nL 461.875027 -834.152246 \nL 462.584499 -834.152246 \nL 463.293972 -834.152246 \nL 464.003444 -834.152246 \nL 466.131861 -834.152246 \nL 466.841334 -834.152246 \nL 467.550806 -834.152246 \nL 468.260278 -834.152246 \nL 468.969751 -834.152246 \nL 471.098168 -834.152246 \nL 471.80764 -834.152246 \nL 472.517112 -834.152246 \nL 473.226585 -834.152246 \nL 473.936057 -834.152246 \nL 476.064474 -834.152246 \nL 476.773946 -834.152246 \nL 477.483419 -834.152246 \nL 478.192891 -834.152246 \nL 478.902363 -834.152246 \nL 481.03078 -834.152246 \nL 481.740253 -834.152246 \nL 482.449725 -834.152246 \nL 483.159197 -834.152246 \nL 483.86867 -834.152246 \nL 486.706559 -834.152246 \nL 487.416032 -834.152246 \nL 488.125504 -834.152246 \nL 488.834976 -834.152246 \nL 490.963393 -834.152246 \nL 491.672866 -834.152246 \nL 492.382338 -834.152246 \nL 493.09181 -834.152246 \nL 493.801283 -834.152246 \nL 495.9297 -834.152246 \nL 496.639172 -834.152246 \nL 497.348644 -834.152246 \nL 498.058117 -834.152246 \nL 498.767589 -834.152246 \nL 500.896006 -834.152246 \nL 501.605478 -834.152246 \nL 502.314951 -834.152246 \nL 503.024423 -834.152246 \nL 503.733896 -834.152246 \nL 505.862313 -834.152246 \nL 506.571785 -834.152246 \nL 507.281257 -834.152246 \nL 507.99073 -834.152246 \nL 508.700202 -834.152246 \nL 510.828619 -834.152246 \nL 511.538091 -834.152246 \nL 512.247564 -834.152246 \nL 512.957036 -834.152246 \nL 513.666508 -834.152246 \nL 515.794925 -834.152246 \nL 516.504398 -834.152246 \nL 517.21387 -834.152246 \nL 517.923342 -834.152246 \nL 518.632815 -834.152246 \nL 520.761232 -834.152246 \nL 521.470704 -834.152246 \nL 522.180176 -834.152246 \nL 522.889649 -834.152246 \nL 523.599121 -834.152246 \nL 525.727538 -834.152246 \nL 526.437011 -834.152246 \nL 527.146483 -834.152246 \nL 527.855955 -834.152246 \nL 528.565428 -834.152246 \nL 530.693845 -834.152246 \nL 531.403317 -834.152246 \nL 532.112789 -834.152246 \nL 532.822262 -834.152246 \nL 533.531734 -834.152246 \nL 535.660151 -834.152246 \nL 536.369623 -834.152246 \nL 537.079096 -834.152246 \nL 537.788568 -834.152246 \nL 538.49804 -834.152246 \nL 540.626457 -834.152246 \nL 541.33593 -834.152246 \nL 542.045402 -834.152246 \nL 542.754875 -834.152246 \nL 543.464347 -834.152246 \nL 545.592764 -834.152246 \nL 546.302236 -834.152246 \nL 547.011709 -834.152246 \nL 547.721181 -834.152246 \nL 548.430653 -834.152246 \nL 550.55907 -834.152246 \nL 551.268543 -834.152246 \nL 551.978015 -834.152246 \nL 552.687487 -834.152246 \nL 553.39696 -834.152246 \nL 556.944321 -834.152246 \nL 557.653794 -834.152246 \nL 558.363266 -834.152246 \nL 560.491683 -834.152246 \nL 561.201156 -834.152246 \nL 561.910628 -834.152246 \nL 562.6201 -834.152246 \nL 568.295879 -834.152246 \nL 570.424296 -834.152246 \nL 571.133768 -834.152246 \nL 571.843241 -834.152246 \nL 572.552713 -834.152246 \nL 573.262185 -834.152246 \nL 575.390602 -834.152246 \nL 576.100075 -834.152246 \nL 576.809547 -834.152246 \nL 577.519019 -834.152246 \nL 578.228492 -834.152246 \nL 580.356909 -834.152246 \nL 581.066381 -834.152246 \nL 581.775854 -834.152246 \nL 582.485326 -834.152246 \nL 583.194798 -834.152246 \nL 585.323215 -834.152246 \nL 586.032688 -834.152246 \nL 586.74216 -834.152246 \nL 587.451632 -834.152246 \nL 588.161105 -834.152246 \nL 590.289522 -834.152246 \nL 590.998994 -834.152246 \nL 591.708466 -834.152246 \nL 592.417939 -834.152246 \nL 593.127411 -834.152246 \nL 595.255828 -834.152246 \nL 595.9653 -834.152246 \nL 596.674773 -834.152246 \nL 597.384245 -834.152246 \nL 598.093717 -834.152246 \nL 600.222135 -834.152246 \nL 600.931607 -834.152246 \nL 601.641079 -834.152246 \nL 602.350552 -834.152246 \nL 603.060024 -834.152246 \nL 605.188441 -834.152246 \nL 605.897913 -834.152246 \nL 606.607386 -834.152246 \nL 607.316858 -834.152246 \nL 608.02633 -834.152246 \nL 610.154747 -834.152246 \nL 610.86422 -834.152246 \nL 611.573692 -834.152246 \nL 612.283164 -834.152246 \nL 612.992637 -834.152246 \nL 615.121054 -834.152246 \nL 615.830526 -834.152246 \nL 616.539998 -834.152246 \nL 617.249471 -834.152246 \nL 617.958943 -834.152246 \nL 620.08736 -834.152246 \nL 620.796833 -834.152246 \nL 621.506305 -834.152246 \nL 622.215777 -834.152246 \nL 622.92525 -834.152246 \nL 625.053667 -834.152246 \nL 625.763139 -834.152246 \nL 626.472611 -834.152246 \nL 627.182084 -834.152246 \nL 627.891556 -834.152246 \nL 630.729445 -834.152246 \nL 631.438918 -834.152246 \nL 632.14839 -834.152246 \nL 632.857862 -834.152246 \nL 634.986279 -834.152246 \nL 635.695752 -834.152246 \nL 636.405224 -834.152246 \nL 637.114697 -834.152246 \nL 637.824169 -834.152246 \nL 639.952586 -834.152246 \nL 640.662058 -834.152246 \nL 641.371531 -834.152246 \nL 642.081003 -834.152246 \nL 642.790475 -834.152246 \nL 644.918892 -834.152246 \nL 645.628365 -834.152246 \nL 646.337837 -834.152246 \nL 647.047309 -834.152246 \nL 647.756782 -834.152246 \nL 654.851505 -834.152246 \nL 655.560978 -834.152246 \nL 656.27045 -834.152246 \nL 656.979922 -834.152246 \nL 657.689395 -834.152246 \nL 659.817812 -834.152246 \nL 660.527284 -834.152246 \nL 661.236756 -834.152246 \nL 661.946229 -834.152246 \nL 662.655701 -834.152246 \nL 664.784118 -834.152246 \nL 665.49359 -834.152246 \nL 666.203063 -834.152246 \nL 666.912535 -834.152246 \nL 667.622007 -834.152246 \nL 669.750424 -834.152246 \nL 670.459897 -834.152246 \nL 671.169369 -834.152246 \nL 671.878841 -834.152246 \nL 672.588314 -834.152246 \nL 674.716731 -834.152246 \nL 675.426203 -834.152246 \nL 676.135676 -834.152246 \nL 676.845148 -834.152246 \nL 677.55462 -834.152246 \nL 679.683037 -834.152246 \nL 680.39251 -834.152246 \nL 681.101982 -834.152246 \nL 681.811454 -834.152246 \nL 682.520927 -834.152246 \nL 684.649344 -834.152246 \nL 685.358816 -834.152246 \nL 686.068288 -834.152246 \nL 686.777761 -834.152246 \nL 687.487233 -834.152246 \nL 689.61565 -834.152246 \nL 690.325122 -834.152246 \nL 691.034595 -834.152246 \nL 691.744067 -834.152246 \nL 692.453539 -834.152246 \nL 696.000901 -834.152246 \nL 696.710374 -834.152246 \nL 697.419846 -834.152246 \nL 699.548263 -834.152246 \nL 700.257735 -834.152246 \nL 700.967208 -834.152246 \nL 701.67668 -834.152246 \nL 702.386152 -834.152246 \nL 704.514569 -834.152246 \nL 705.224042 -834.152246 \nL 705.933514 -834.152246 \nL 706.642986 -834.152246 \nL 707.352459 -834.152246 \nL 709.480876 -834.152246 \nL 710.190348 -834.152246 \nL 710.89982 -834.152246 \nL 711.609293 -834.152246 \nL 712.318765 -834.152246 \nL 716.575599 -834.152246 \nL 717.285072 -834.152246 \nL 719.413489 -834.152246 \nL 720.122961 -834.152246 \nL 720.832433 -834.152246 \nL 721.541906 -834.152246 \nL 722.251378 -834.152246 \nL 724.379795 -834.152246 \nL 725.089267 -834.152246 \nL 725.79874 -834.152246 \nL 726.508212 -834.152246 \nL 727.217684 -834.152246 \nL 729.346101 -834.152246 \nL 730.055574 -834.152246 \nL 730.765046 -834.152246 \nL 731.474519 -834.152246 \nL 732.183991 -834.152246 \nL 734.312408 -834.152246 \nL 735.02188 -834.152246 \nL 735.731353 -834.152246 \nL 736.440825 -834.152246 \nL 739.278714 -834.152246 \nL 739.988187 -834.152246 \nL 740.697659 -834.152246 \nL 741.407131 -834.152246 \nL 742.116604 -834.152246 \nL 744.245021 -834.152246 \nL 744.954493 -834.152246 \nL 745.663965 -834.152246 \nL 746.373438 -834.152246 \nL 747.08291 -834.152246 \nL 749.211327 -834.152246 \nL 749.9208 -834.152246 \nL 750.630272 -834.152246 \nL 751.339744 -834.152246 \nL 752.049217 -834.152246 \nL 754.177634 -834.152246 \nL 754.887106 -834.152246 \nL 755.596578 -834.152246 \nL 756.306051 -834.152246 \nL 757.015523 -834.152246 \nL 759.14394 -834.152246 \nL 759.853412 -834.152246 \nL 760.562885 -834.152246 \nL 761.272357 -834.152246 \nL 761.981829 -834.152246 \nL 764.110246 -834.152246 \nL 764.819719 -834.152246 \nL 765.529191 -834.152246 \nL 766.238663 -834.152246 \nL 766.948136 -834.152246 \nL 769.076553 -834.152246 \nL 769.786025 -834.152246 \nL 770.495498 -834.152246 \nL 771.20497 -834.152246 \nL 771.914442 -834.152246 \nL 774.042859 -834.152246 \nL 774.752332 -834.152246 \nL 775.461804 -834.152246 \nL 776.171276 -834.152246 \nL 776.880749 -834.152246 \nL 779.009166 -834.152246 \nL 779.718638 -834.152246 \nL 780.42811 -834.152246 \nL 781.137583 -834.152246 \nL 781.847055 -834.152246 \nL 783.975472 -834.152246 \nL 784.684944 -834.152246 \nL 785.394417 -834.152246 \nL 786.103889 -834.152246 \nL 786.813361 -834.152246 \nL 788.941779 -834.152246 \nL 789.651251 -834.152246 \nL 790.360723 -834.152246 \nL 791.070196 -834.152246 \nL 791.779668 -834.152246 \nL 793.908085 -834.152246 \nL 794.617557 -834.152246 \nL 795.32703 -834.152246 \nL 796.036502 -834.152246 \nL 796.745974 -834.152246 \nL 798.874391 -834.152246 \nL 799.583864 -834.152246 \nL 800.293336 -834.152246 \nL 801.002808 -834.152246 \nL 801.712281 -834.152246 \nL 803.840698 -834.152246 \nL 804.55017 -834.152246 \nL 805.259642 -834.152246 \nL 805.969115 -834.152246 \nL 806.678587 -834.152246 \nL 809.516477 -834.152246 \nL 810.225949 -834.152246 \nL 810.935421 -834.152246 \nL 811.644894 -834.152246 \nL 813.773311 -834.152246 \nL 814.482783 -834.152246 \nL 815.192255 -834.152246 \nL 815.901728 -834.152246 \nL 816.6112 -834.152246 \nL 818.739617 -834.152246 \nL 819.449089 -834.152246 \nL 820.158562 -834.152246 \nL 820.868034 -834.152246 \nL 820.868034 -644.557879 \nL 820.868034 -644.557879 \nL 820.158562 -643.679992 \nL 819.449089 -649.110255 \nL 818.739617 -642.510997 \nL 816.6112 -642.30898 \nL 815.901728 -644.493634 \nL 815.192255 -646.001253 \nL 814.482783 -650.009565 \nL 813.773311 -652.156542 \nL 811.644894 -653.260071 \nL 810.935421 -665.590803 \nL 810.225949 -669.596235 \nL 809.516477 -675.183722 \nL 806.678587 -670.834031 \nL 805.969115 -666.305646 \nL 805.259642 -667.206445 \nL 804.55017 -668.171902 \nL 803.840698 -657.97098 \nL 801.712281 -663.50235 \nL 801.002808 -670.179129 \nL 800.293336 -674.1878 \nL 799.583864 -676.75459 \nL 798.874391 -677.696722 \nL 796.745974 -680.795359 \nL 796.036502 -680.706456 \nL 795.32703 -675.496967 \nL 794.617557 -682.781467 \nL 793.908085 -684.356623 \nL 791.779668 -676.308072 \nL 791.070196 -682.658094 \nL 790.360723 -687.400854 \nL 789.651251 -685.606888 \nL 788.941779 -689.001316 \nL 786.813361 -691.526175 \nL 786.103889 -687.699116 \nL 785.394417 -680.218342 \nL 784.684944 -684.539122 \nL 783.975472 -682.062967 \nL 781.847055 -681.472671 \nL 781.137583 -677.370784 \nL 780.42811 -670.956605 \nL 779.718638 -670.385388 \nL 779.009166 -680.149399 \nL 776.880749 -683.346522 \nL 776.171276 -695.602743 \nL 775.461804 -695.23403 \nL 774.752332 -699.671016 \nL 774.042859 -700.020732 \nL 771.914442 -702.053565 \nL 771.20497 -701.488389 \nL 770.495498 -704.813897 \nL 769.786025 -701.080544 \nL 769.076553 -705.11612 \nL 766.948136 -696.885686 \nL 766.238663 -705.075088 \nL 765.529191 -704.092846 \nL 764.819719 -700.890675 \nL 764.110246 -706.81904 \nL 761.981829 -717.717213 \nL 761.272357 -718.652601 \nL 760.562885 -717.818964 \nL 759.853412 -729.78132 \nL 759.14394 -729.919558 \nL 757.015523 -732.285268 \nL 756.306051 -737.210797 \nL 755.596578 -725.932492 \nL 754.887106 -730.067243 \nL 754.177634 -731.408936 \nL 752.049217 -723.916565 \nL 751.339744 -716.92993 \nL 750.630272 -708.472349 \nL 749.9208 -716.553059 \nL 749.211327 -717.509618 \nL 747.08291 -719.257797 \nL 746.373438 -705.134793 \nL 745.663965 -711.762584 \nL 744.954493 -700.809518 \nL 744.245021 -692.924766 \nL 742.116604 -702.26368 \nL 741.407131 -695.188094 \nL 740.697659 -698.598079 \nL 739.988187 -690.576685 \nL 739.278714 -689.671768 \nL 736.440825 -687.60513 \nL 735.731353 -687.652291 \nL 735.02188 -689.526348 \nL 734.312408 -689.821493 \nL 732.183991 -684.914945 \nL 731.474519 -684.200809 \nL 730.765046 -683.688862 \nL 730.055574 -677.901534 \nL 729.346101 -685.644584 \nL 727.217684 -690.753429 \nL 726.508212 -679.550844 \nL 725.79874 -683.7956 \nL 725.089267 -682.258515 \nL 724.379795 -674.587865 \nL 722.251378 -677.276783 \nL 721.541906 -674.403144 \nL 720.832433 -675.607059 \nL 720.122961 -662.706219 \nL 719.413489 -662.831841 \nL 717.285072 -666.347461 \nL 716.575599 -679.356812 \nL 712.318765 -672.606195 \nL 711.609293 -666.912821 \nL 710.89982 -659.800131 \nL 710.190348 -652.712216 \nL 709.480876 -652.399449 \nL 707.352459 -674.747364 \nL 706.642986 -674.80314 \nL 705.933514 -679.897049 \nL 705.224042 -685.024267 \nL 704.514569 -691.190821 \nL 702.386152 -696.693935 \nL 701.67668 -698.817148 \nL 700.967208 -693.884871 \nL 700.257735 -696.6446 \nL 699.548263 -688.340974 \nL 697.419846 -700.006421 \nL 696.710374 -698.74859 \nL 696.000901 -700.0607 \nL 692.453539 -705.039875 \nL 691.744067 -696.814376 \nL 691.034595 -701.489606 \nL 690.325122 -685.55786 \nL 689.61565 -684.763866 \nL 687.487233 -687.209562 \nL 686.777761 -693.508826 \nL 686.068288 -698.82203 \nL 685.358816 -697.613625 \nL 684.649344 -699.785675 \nL 682.520927 -702.828023 \nL 681.811454 -698.019834 \nL 681.101982 -687.801825 \nL 680.39251 -667.899804 \nL 679.683037 -690.892649 \nL 677.55462 -697.81334 \nL 676.845148 -692.090288 \nL 676.135676 -688.913761 \nL 675.426203 -693.033124 \nL 674.716731 -702.805293 \nL 672.588314 -717.310017 \nL 671.878841 -722.897613 \nL 671.169369 -722.577729 \nL 670.459897 -724.188974 \nL 669.750424 -721.100599 \nL 667.622007 -719.123255 \nL 666.912535 -717.386349 \nL 666.203063 -729.519865 \nL 665.49359 -726.71158 \nL 664.784118 -732.310442 \nL 662.655701 -733.8645 \nL 661.946229 -731.834724 \nL 661.236756 -733.792606 \nL 660.527284 -732.056298 \nL 659.817812 -728.263121 \nL 657.689395 -727.174623 \nL 656.979922 -719.962343 \nL 656.27045 -718.260433 \nL 655.560978 -705.524008 \nL 654.851505 -708.445815 \nL 647.756782 -704.063458 \nL 647.047309 -714.816273 \nL 646.337837 -725.781613 \nL 645.628365 -723.448169 \nL 644.918892 -735.184308 \nL 642.790475 -736.154231 \nL 642.081003 -736.608677 \nL 641.371531 -737.872532 \nL 640.662058 -741.36701 \nL 639.952586 -738.663514 \nL 637.824169 -736.821526 \nL 637.114697 -738.804806 \nL 636.405224 -751.518409 \nL 635.695752 -748.662404 \nL 634.986279 -753.919401 \nL 632.857862 -753.486753 \nL 632.14839 -753.34673 \nL 631.438918 -757.01069 \nL 630.729445 -763.189829 \nL 627.891556 -765.794037 \nL 627.182084 -765.264035 \nL 626.472611 -762.300074 \nL 625.763139 -784.42519 \nL 625.053667 -778.931791 \nL 622.92525 -780.263191 \nL 622.215777 -785.208591 \nL 621.506305 -783.745157 \nL 620.796833 -787.179508 \nL 620.08736 -791.47722 \nL 617.958943 -790.713128 \nL 617.249471 -804.475177 \nL 616.539998 -819.465458 \nL 615.830526 -829.205454 \nL 615.121054 -834.152246 \nL 612.992637 -834.103749 \nL 612.283164 -834.152246 \nL 611.573692 -828.111951 \nL 610.86422 -812.095499 \nL 610.154747 -810.542881 \nL 608.02633 -807.977868 \nL 607.316858 -800.452165 \nL 606.607386 -796.939489 \nL 605.897913 -793.882592 \nL 605.188441 -798.984386 \nL 603.060024 -801.706732 \nL 602.350552 -805.576123 \nL 601.641079 -808.896285 \nL 600.931607 -809.556556 \nL 600.222135 -811.944576 \nL 598.093717 -813.444103 \nL 597.384245 -806.375867 \nL 596.674773 -814.119372 \nL 595.9653 -816.35883 \nL 595.255828 -814.961388 \nL 593.127411 -810.279996 \nL 592.417939 -808.381016 \nL 591.708466 -802.599864 \nL 590.998994 -808.379594 \nL 590.289522 -809.690975 \nL 588.161105 -807.901706 \nL 587.451632 -809.611033 \nL 586.74216 -799.383803 \nL 586.032688 -807.984664 \nL 585.323215 -813.230321 \nL 583.194798 -825.731328 \nL 582.485326 -818.729529 \nL 581.775854 -825.096466 \nL 581.066381 -830.976931 \nL 580.356909 -834.152246 \nL 578.228492 -832.941655 \nL 577.519019 -830.22999 \nL 576.809547 -834.152246 \nL 576.100075 -834.152246 \nL 575.390602 -832.689815 \nL 573.262185 -834.152246 \nL 572.552713 -834.152246 \nL 571.843241 -834.152246 \nL 571.133768 -822.2467 \nL 570.424296 -820.853068 \nL 568.295879 -831.001331 \nL 562.6201 -817.209127 \nL 561.910628 -816.682267 \nL 561.201156 -822.053814 \nL 560.491683 -834.152246 \nL 558.363266 -834.152246 \nL 557.653794 -824.857799 \nL 556.944321 -824.278564 \nL 553.39696 -834.152246 \nL 552.687487 -811.792235 \nL 551.978015 -806.697185 \nL 551.268543 -821.148119 \nL 550.55907 -819.412538 \nL 548.430653 -814.183983 \nL 547.721181 -791.360286 \nL 547.011709 -789.153412 \nL 546.302236 -803.368513 \nL 545.592764 -796.688786 \nL 543.464347 -779.462308 \nL 542.754875 -779.773917 \nL 542.045402 -785.242619 \nL 541.33593 -777.055415 \nL 540.626457 -779.986226 \nL 538.49804 -771.490768 \nL 537.788568 -763.444862 \nL 537.079096 -773.523575 \nL 536.369623 -765.128242 \nL 535.660151 -759.903799 \nL 533.531734 -734.350601 \nL 532.822262 -757.199953 \nL 532.112789 -760.551171 \nL 531.403317 -764.407579 \nL 530.693845 -776.869786 \nL 528.565428 -776.153432 \nL 527.855955 -779.430169 \nL 527.146483 -778.770577 \nL 526.437011 -785.02688 \nL 525.727538 -776.707023 \nL 523.599121 -772.979027 \nL 522.889649 -779.789899 \nL 522.180176 -773.034776 \nL 521.470704 -760.804171 \nL 520.761232 -758.743545 \nL 518.632815 -731.07606 \nL 517.923342 -726.752955 \nL 517.21387 -715.816638 \nL 516.504398 -719.743045 \nL 515.794925 -743.186192 \nL 513.666508 -752.372474 \nL 512.957036 -759.482342 \nL 512.247564 -760.648504 \nL 511.538091 -756.940604 \nL 510.828619 -758.739296 \nL 508.700202 -753.015213 \nL 507.99073 -745.986381 \nL 507.281257 -740.157979 \nL 506.571785 -759.453387 \nL 505.862313 -755.720903 \nL 503.733896 -746.445031 \nL 503.024423 -755.742153 \nL 502.314951 -759.739347 \nL 501.605478 -747.602831 \nL 500.896006 -744.052597 \nL 498.767589 -734.065424 \nL 498.058117 -751.081081 \nL 497.348644 -761.40177 \nL 496.639172 -757.298807 \nL 495.9297 -762.881937 \nL 493.801283 -756.851534 \nL 493.09181 -751.462182 \nL 492.382338 -750.009932 \nL 491.672866 -766.979643 \nL 490.963393 -766.828683 \nL 488.834976 -767.35563 \nL 488.125504 -763.644553 \nL 487.416032 -768.498677 \nL 486.706559 -781.544036 \nL 483.86867 -783.438079 \nL 483.159197 -794.513771 \nL 482.449725 -787.776257 \nL 481.740253 -786.870661 \nL 481.03078 -781.487641 \nL 478.902363 -780.637451 \nL 478.192891 -776.334514 \nL 477.483419 -778.838626 \nL 476.773946 -782.228875 \nL 476.064474 -787.352357 \nL 473.936057 -785.448623 \nL 473.226585 -785.869687 \nL 472.517112 -787.857062 \nL 471.80764 -786.337522 \nL 471.098168 -767.615669 \nL 468.969751 -766.669371 \nL 468.260278 -772.679386 \nL 467.550806 -773.50419 \nL 466.841334 -774.222014 \nL 466.131861 -775.49232 \nL 464.003444 -765.572081 \nL 463.293972 -753.637997 \nL 462.584499 -760.808751 \nL 461.875027 -758.470866 \nL 461.165555 -754.8007 \nL 459.037138 -748.840189 \nL 458.327665 -755.815441 \nL 454.070831 -756.243935 \nL 453.361359 -757.914393 \nL 452.651887 -762.803104 \nL 451.942414 -757.739117 \nL 451.232942 -756.006307 \nL 449.104525 -763.218655 \nL 448.395053 -760.416884 \nL 447.68558 -763.664516 \nL 446.976108 -761.698998 \nL 446.266635 -757.88579 \nL 444.138218 -743.219024 \nL 443.428746 -740.157439 \nL 442.719274 -744.436278 \nL 442.009801 -742.600247 \nL 441.300329 -739.936787 \nL 439.171912 -754.599144 \nL 438.46244 -772.16368 \nL 437.752967 -756.266327 \nL 437.043495 -768.86925 \nL 434.205606 -777.266469 \nL 433.496133 -758.097944 \nL 432.786661 -744.005934 \nL 432.077189 -762.97124 \nL 431.367716 -761.989448 \nL 429.239299 -752.228417 \nL 428.529827 -728.440581 \nL 427.820354 -722.000461 \nL 427.110882 -737.366233 \nL 426.40141 -746.100618 \nL 424.272993 -749.988515 \nL 423.56352 -764.579538 \nL 422.854048 -762.544783 \nL 422.144576 -757.084716 \nL 421.435103 -738.604867 \nL 419.306686 -757.410187 \nL 418.597214 -740.870719 \nL 417.887742 -725.431101 \nL 417.178269 -700.957445 \nL 416.468797 -718.582714 \nL 414.34038 -740.031757 \nL 413.630908 -752.171306 \nL 412.921435 -785.010806 \nL 412.211963 -774.874216 \nL 411.502491 -793.529876 \nL 409.374074 -790.489886 \nL 408.664601 -804.856104 \nL 407.955129 -788.064658 \nL 407.245656 -799.493356 \nL 406.536184 -810.771379 \nL 404.407767 -820.222387 \nL 403.698295 -834.152246 \nL 398.022516 -834.152246 \nL 397.313044 -834.152246 \nL 396.603571 -834.152246 \nL 394.475154 -828.11078 \nL 393.765682 -834.152246 \nL 393.05621 -834.152246 \nL 392.346737 -834.152246 \nL 391.637265 -830.014059 \nL 389.508848 -806.277806 \nL 388.799375 -804.475051 \nL 388.089903 -828.180959 \nL 387.380431 -828.375476 \nL 386.670958 -834.152246 \nL 384.542541 -831.44755 \nL 383.833069 -820.549635 \nL 383.123597 -803.125648 \nL 382.414124 -794.89044 \nL 381.704652 -814.223638 \nL 379.576235 -804.293355 \nL 378.866763 -808.205407 \nL 378.15729 -829.763858 \nL 377.447818 -834.152246 \nL 376.738346 -819.106972 \nL 374.609929 -833.703176 \nL 373.900456 -834.152246 \nL 373.190984 -834.152246 \nL 372.481512 -834.152246 \nL 371.772039 -834.152246 \nL 368.93415 -834.152246 \nL 368.224677 -834.152246 \nL 367.515205 -830.604722 \nL 366.805733 -834.152246 \nL 364.677316 -834.152246 \nL 363.967843 -828.78565 \nL 363.258371 -834.152246 \nL 362.548899 -820.435122 \nL 361.839426 -834.152246 \nL 359.711009 -832.533545 \nL 359.001537 -834.152246 \nL 358.292065 -834.152246 \nL 357.582592 -834.152246 \nL 356.87312 -829.422241 \nL 354.744703 -825.258539 \nL 354.035231 -825.736611 \nL 353.325758 -822.067381 \nL 352.616286 -828.264003 \nL 351.906813 -830.342053 \nL 349.778396 -834.152246 \nL 349.068924 -831.876104 \nL 348.359452 -830.504132 \nL 347.649979 -834.152246 \nL 346.940507 -823.715973 \nL 344.81209 -834.152246 \nL 344.102618 -829.862012 \nL 343.393145 -822.773167 \nL 342.683673 -834.152246 \nL 341.974201 -834.152246 \nL 339.845784 -834.152246 \nL 339.136311 -830.749999 \nL 338.426839 -811.941464 \nL 337.717367 -808.564612 \nL 337.007894 -822.447282 \nL 334.879477 -815.659654 \nL 334.170005 -815.384217 \nL 333.460533 -812.36132 \nL 332.75106 -818.267981 \nL 332.041588 -826.316116 \nL 329.913171 -820.057889 \nL 329.203698 -825.94314 \nL 328.494226 -822.304383 \nL 327.784754 -815.277275 \nL 327.075281 -802.180027 \nL 324.946864 -801.145227 \nL 324.237392 -806.136268 \nL 323.52792 -811.312031 \nL 322.818447 -798.037318 \nL 322.108975 -791.462981 \nL 319.980558 -795.937676 \nL 319.271086 -802.98315 \nL 318.561613 -805.360108 \nL 317.852141 -813.190925 \nL 317.142669 -808.637525 \nL 315.014252 -815.808597 \nL 314.304779 -819.009363 \nL 313.595307 -827.721919 \nL 312.885834 -834.152246 \nL 312.176362 -834.152246 \nL 310.047945 -821.462078 \nL 303.662694 -803.267663 \nL 302.953222 -804.281793 \nL 302.243749 -796.454982 \nL 300.115332 -794.731581 \nL 299.40586 -794.729082 \nL 298.696388 -804.629174 \nL 297.986915 -801.892108 \nL 297.277443 -811.130515 \nL 295.149026 -812.805925 \nL 294.439553 -801.722934 \nL 293.730081 -816.481983 \nL 293.020609 -818.493328 \nL 292.311136 -819.911507 \nL 290.182719 -817.497218 \nL 289.473247 -807.382854 \nL 288.763775 -801.292375 \nL 288.054302 -815.119834 \nL 287.34483 -813.823393 \nL 285.216413 -827.80839 \nL 284.506941 -830.996837 \nL 283.797468 -830.349997 \nL 283.087996 -834.152246 \nL 282.378524 -834.152246 \nL 280.250107 -834.152246 \nL 279.540634 -831.304334 \nL 278.831162 -823.542572 \nL 278.12169 -831.732401 \nL 277.412217 -833.231099 \nL 275.2838 -825.174295 \nL 274.574328 -818.708753 \nL 273.864855 -828.313009 \nL 273.155383 -833.44486 \nL 272.445911 -830.976791 \nL 270.317494 -817.02882 \nL 269.608021 -806.313085 \nL 268.898549 -804.780179 \nL 268.189077 -818.678173 \nL 267.479604 -823.707681 \nL 265.351187 -821.849909 \nL 264.641715 -832.926264 \nL 263.932243 -830.281913 \nL 263.22277 -824.392163 \nL 262.513298 -834.152246 \nL 260.384881 -834.152246 \nL 259.675409 -834.152246 \nL 258.965936 -832.821232 \nL 258.256464 -818.252108 \nL 257.546991 -813.378758 \nL 255.418574 -803.74969 \nL 254.709102 -830.730044 \nL 253.99963 -822.628331 \nL 253.290157 -820.668663 \nL 252.580685 -802.687407 \nL 250.452268 -789.269756 \nL 249.742796 -787.514078 \nL 249.033323 -834.152246 \nL 248.323851 -833.440184 \nL 247.614379 -834.152246 \nL 245.485962 -834.152246 \nL 244.776489 -834.152246 \nL 244.067017 -833.045395 \nL 243.357545 -834.152246 \nL 242.648072 -834.152246 \nL 240.519655 -832.686316 \nL 239.810183 -834.152246 \nL 239.100711 -834.152246 \nL 238.391238 -831.354496 \nL 237.681766 -823.170878 \nL 234.134404 -821.33049 \nL 233.424932 -821.023417 \nL 232.715459 -814.059439 \nL 230.587042 -816.795395 \nL 229.87757 -800.88939 \nL 229.168098 -802.434213 \nL 228.458625 -795.372123 \nL 227.749153 -786.14235 \nL 225.620736 -794.745077 \nL 224.911264 -792.897577 \nL 224.201791 -796.890628 \nL 223.492319 -791.223374 \nL 222.782847 -783.311489 \nL 220.65443 -783.718294 \nL 219.944957 -798.813522 \nL 219.235485 -802.21803 \nL 218.526012 -797.7123 \nL 217.81654 -797.010649 \nL 215.688123 -783.604166 \nL 214.978651 -783.963049 \nL 214.269178 -783.290563 \nL 213.559706 -783.964203 \nL 212.850234 -778.562588 \nL 210.721817 -775.753601 \nL 210.012344 -791.095177 \nL 209.302872 -796.086225 \nL 208.5934 -802.823144 \nL 207.883927 -797.736829 \nL 205.75551 -794.481139 \nL 205.046038 -796.402192 \nL 204.336566 -804.505023 \nL 203.627093 -800.999985 \nL 202.917621 -800.127167 \nL 200.789204 -800.039297 \nL 200.079731 -795.822167 \nL 199.370259 -795.895549 \nL 195.113425 -791.132453 \nL 194.403953 -781.652292 \nL 193.69448 -784.746137 \nL 192.985008 -773.567591 \nL 190.856591 -770.164777 \nL 190.147119 -774.976154 \nL 189.437646 -776.669741 \nL 188.728174 -774.827533 \nL 188.018702 -780.180344 \nL 185.890285 -777.778632 \nL 185.180812 -767.871785 \nL 184.47134 -767.399008 \nL 183.761868 -773.84994 \nL 183.052395 -761.212333 \nL 180.923978 -764.1573 \nL 180.214506 -766.060704 \nL 179.505033 -762.547865 \nL 178.795561 -763.165085 \nL 175.957672 -754.68813 \nL 175.248199 -757.627791 \nL 174.538727 -753.608806 \nL 173.829255 -753.87385 \nL 173.119782 -751.76892 \nL 170.991365 -764.974205 \nL 170.281893 -760.36338 \nL 169.572421 -762.383488 \nL 168.862948 -747.811188 \nL 168.153476 -733.887008 \nL 166.025059 -750.741402 \nL 165.315587 -736.205859 \nL 164.606114 -749.056737 \nL 163.896642 -757.361477 \nL 163.18717 -762.4502 \nL 161.058752 -783.873479 \nL 160.34928 -791.952106 \nL 159.639808 -805.852018 \nL 158.930335 -812.125996 \nL 158.220863 -799.387451 \nL 156.092446 -821.93957 \nL 155.382974 -834.152246 \nL 154.673501 -834.152246 \nL 153.964029 -828.48057 \nL 153.254557 -824.110135 \nL 151.12614 -806.915009 \nL 150.416667 -827.910557 \nL 149.707195 -822.394601 \nL 148.997723 -827.747473 \nL 148.28825 -827.888505 \nL 146.159833 -831.805805 \nL 145.450361 -829.368408 \nL 144.740889 -820.714519 \nL 144.031416 -821.756907 \nL 143.321944 -823.527787 \nL 141.193527 -810.23883 \nL 140.484054 -808.154798 \nL 139.774582 -815.734294 \nL 139.06511 -806.012718 \nL 138.355637 -800.984447 \nL 136.22722 -801.647896 \nL 135.517748 -799.3625 \nL 134.808276 -791.114261 \nL 134.098803 -783.039148 \nL 133.389331 -767.878064 \nL 125.585135 -809.878541 \nL 124.875663 -830.499376 \nL 124.16619 -826.679506 \nL 123.456718 -834.152246 \nL 121.328301 -831.505885 \nL 120.618829 -826.071815 \nL 119.909356 -827.217558 \nL 119.199884 -831.500411 \nL 118.490412 -834.152246 \nL 116.361995 -834.152246 \nL 115.652522 -834.152246 \nL 114.94305 -828.147878 \nL 114.233578 -834.152246 \nL 113.524105 -831.564016 \nL 111.395688 -833.527739 \nL 110.686216 -834.152246 \nz\n\" style=\"stroke: #ff7f50; stroke-opacity: 0.7\"/>\n    </defs>\n    <g clip-path=\"url(#p742258926d)\">\n     <use xlink:href=\"#mfc534dbbdf\" x=\"0\" y=\"3576.760469\" style=\"fill: #ff7f50; fill-opacity: 0.7; stroke: #ff7f50; stroke-opacity: 0.7\"/>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_17\">\n    <g id=\"xtick_113\">\n     <g id=\"line2d_204\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"109.976744\" y=\"2944.043652\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_114\">\n     <g id=\"line2d_205\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"195.822897\" y=\"2944.043652\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_115\">\n     <g id=\"line2d_206\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"283.087996\" y=\"2944.043652\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_116\">\n     <g id=\"line2d_207\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"369.643622\" y=\"2944.043652\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_117\">\n     <g id=\"line2d_208\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"454.780304\" y=\"2944.043652\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_118\">\n     <g id=\"line2d_209\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"542.045402\" y=\"2944.043652\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_119\">\n     <g id=\"line2d_210\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"628.601028\" y=\"2944.043652\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_120\">\n     <g id=\"line2d_211\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"713.73771\" y=\"2944.043652\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_121\">\n     <g id=\"line2d_212\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"801.002808\" y=\"2944.043652\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_122\">\n     <g id=\"line2d_213\">\n      <g>\n       <use xlink:href=\"#m3466dc2b85\" x=\"207.883927\" y=\"2944.043652\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_123\">\n     <g id=\"line2d_214\">\n      <g>\n       <use xlink:href=\"#m3466dc2b85\" x=\"349.778396\" y=\"2944.043652\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_124\">\n     <g id=\"line2d_215\">\n      <g>\n       <use xlink:href=\"#m3466dc2b85\" x=\"491.672866\" y=\"2944.043652\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_125\">\n     <g id=\"line2d_216\">\n      <g>\n       <use xlink:href=\"#m3466dc2b85\" x=\"633.567335\" y=\"2944.043652\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_126\">\n     <g id=\"line2d_217\">\n      <g>\n       <use xlink:href=\"#m3466dc2b85\" x=\"775.461804\" y=\"2944.043652\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_18\">\n    <g id=\"ytick_58\">\n     <g id=\"line2d_218\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"2930.876712\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_84\">\n      <!-- -30% -->\n      <g transform=\"translate(34.417531 2935.473767)scale(0.121 -0.121)\">\n       <defs>\n        <path id=\"DejaVuSans-25\" d=\"M 4653 2053 \nQ 4381 2053 4226 1822 \nQ 4072 1591 4072 1178 \nQ 4072 772 4226 539 \nQ 4381 306 4653 306 \nQ 4919 306 5073 539 \nQ 5228 772 5228 1178 \nQ 5228 1588 5073 1820 \nQ 4919 2053 4653 2053 \nz\nM 4653 2450 \nQ 5147 2450 5437 2106 \nQ 5728 1763 5728 1178 \nQ 5728 594 5436 251 \nQ 5144 -91 4653 -91 \nQ 4153 -91 3862 251 \nQ 3572 594 3572 1178 \nQ 3572 1766 3864 2108 \nQ 4156 2450 4653 2450 \nz\nM 1428 4353 \nQ 1159 4353 1004 4120 \nQ 850 3888 850 3481 \nQ 850 3069 1003 2837 \nQ 1156 2606 1428 2606 \nQ 1700 2606 1854 2837 \nQ 2009 3069 2009 3481 \nQ 2009 3884 1853 4118 \nQ 1697 4353 1428 4353 \nz\nM 4250 4750 \nL 4750 4750 \nL 1831 -91 \nL 1331 -91 \nL 4250 4750 \nz\nM 1428 4750 \nQ 1922 4750 2215 4408 \nQ 2509 4066 2509 3481 \nQ 2509 2891 2217 2550 \nQ 1925 2209 1428 2209 \nQ 931 2209 642 2551 \nQ 353 2894 353 3481 \nQ 353 4063 643 4406 \nQ 934 4750 1428 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-2d\"/>\n       <use xlink:href=\"#DejaVuSans-33\" x=\"36.083984\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"99.707031\"/>\n       <use xlink:href=\"#DejaVuSans-25\" x=\"163.330078\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_59\">\n     <g id=\"line2d_219\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"2899.49863\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_85\">\n      <!-- -25% -->\n      <g transform=\"translate(34.417531 2904.095685)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-2d\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"36.083984\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"99.707031\"/>\n       <use xlink:href=\"#DejaVuSans-25\" x=\"163.330078\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_60\">\n     <g id=\"line2d_220\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"2868.120549\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_86\">\n      <!-- -20% -->\n      <g transform=\"translate(34.417531 2872.717604)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-2d\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"36.083984\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"99.707031\"/>\n       <use xlink:href=\"#DejaVuSans-25\" x=\"163.330078\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_61\">\n     <g id=\"line2d_221\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"2836.742468\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_87\">\n      <!-- -15% -->\n      <g transform=\"translate(34.417531 2841.339522)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-2d\"/>\n       <use xlink:href=\"#DejaVuSans-31\" x=\"36.083984\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"99.707031\"/>\n       <use xlink:href=\"#DejaVuSans-25\" x=\"163.330078\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_62\">\n     <g id=\"line2d_222\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"2805.364386\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_88\">\n      <!-- -10% -->\n      <g transform=\"translate(34.417531 2809.961441)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-2d\"/>\n       <use xlink:href=\"#DejaVuSans-31\" x=\"36.083984\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"99.707031\"/>\n       <use xlink:href=\"#DejaVuSans-25\" x=\"163.330078\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_63\">\n     <g id=\"line2d_223\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"2773.986305\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_89\">\n      <!-- -5% -->\n      <g transform=\"translate(42.116156 2778.583359)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-2d\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"36.083984\"/>\n       <use xlink:href=\"#DejaVuSans-25\" x=\"99.707031\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_64\">\n     <g id=\"line2d_224\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"2742.608223\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_90\">\n      <!-- 0% -->\n      <g transform=\"translate(46.481609 2747.205278)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-25\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_91\">\n     <!-- Drawdown -->\n     <g transform=\"translate(27.672344 2878.371937)rotate(-90)scale(0.132 -0.132)\">\n      <defs>\n       <path id=\"DejaVuSans-44\" d=\"M 1259 4147 \nL 1259 519 \nL 2022 519 \nQ 2988 519 3436 956 \nQ 3884 1394 3884 2338 \nQ 3884 3275 3436 3711 \nQ 2988 4147 2022 4147 \nL 1259 4147 \nz\nM 628 4666 \nL 1925 4666 \nQ 3281 4666 3915 4102 \nQ 4550 3538 4550 2338 \nQ 4550 1131 3912 565 \nQ 3275 0 1925 0 \nL 628 0 \nL 628 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-44\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"77.001953\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"118.115234\"/>\n      <use xlink:href=\"#DejaVuSans-77\" x=\"179.394531\"/>\n      <use xlink:href=\"#DejaVuSans-64\" x=\"261.181641\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"324.658203\"/>\n      <use xlink:href=\"#DejaVuSans-77\" x=\"385.839844\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"467.626953\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_225\">\n    <path d=\"M 110.686216 2742.608223 \nL 113.524105 2745.196453 \nL 114.233578 2742.608223 \nL 114.94305 2748.612591 \nL 115.652522 2742.608223 \nL 118.490412 2742.608223 \nL 119.199884 2745.260058 \nL 119.909356 2749.542911 \nL 120.618829 2750.688653 \nL 121.328301 2745.254584 \nL 123.456718 2742.608223 \nL 124.16619 2750.080963 \nL 124.875663 2746.261092 \nL 125.585135 2766.881927 \nL 133.389331 2808.882404 \nL 134.098803 2793.721321 \nL 135.517748 2777.397969 \nL 136.22722 2775.112573 \nL 138.355637 2775.776022 \nL 139.06511 2770.747751 \nL 139.774582 2761.026175 \nL 140.484054 2768.605671 \nL 141.193527 2766.521639 \nL 143.321944 2753.232682 \nL 144.031416 2755.003562 \nL 144.740889 2756.04595 \nL 145.450361 2747.392061 \nL 146.159833 2744.954664 \nL 148.28825 2748.871964 \nL 148.997723 2749.012996 \nL 149.707195 2754.365868 \nL 150.416667 2748.849912 \nL 151.12614 2769.84546 \nL 153.254557 2752.650333 \nL 153.964029 2748.279899 \nL 154.673501 2742.608223 \nL 155.382974 2742.608223 \nL 156.092446 2754.820899 \nL 158.220863 2777.373018 \nL 158.930335 2764.634473 \nL 159.639808 2770.908451 \nL 160.34928 2784.808363 \nL 161.058752 2792.886989 \nL 163.18717 2814.310268 \nL 163.896642 2819.398992 \nL 164.606114 2827.703732 \nL 165.315587 2840.55461 \nL 166.025059 2826.019067 \nL 168.153476 2842.87346 \nL 169.572421 2814.376981 \nL 170.281893 2816.397089 \nL 170.991365 2811.786264 \nL 173.119782 2824.991549 \nL 173.829255 2822.886619 \nL 174.538727 2823.151663 \nL 175.248199 2819.132678 \nL 175.957672 2822.072339 \nL 178.795561 2813.595384 \nL 179.505033 2814.212604 \nL 180.214506 2810.699764 \nL 180.923978 2812.603169 \nL 183.052395 2815.548136 \nL 183.761868 2802.910529 \nL 184.47134 2809.36146 \nL 185.180812 2808.888683 \nL 185.890285 2798.981837 \nL 188.018702 2796.580125 \nL 188.728174 2801.932935 \nL 189.437646 2800.090728 \nL 190.147119 2801.784315 \nL 190.856591 2806.595692 \nL 192.985008 2803.192878 \nL 193.69448 2792.014331 \nL 194.403953 2795.108177 \nL 195.113425 2785.628016 \nL 199.370259 2780.86492 \nL 200.079731 2780.938302 \nL 200.789204 2776.721172 \nL 202.917621 2776.633301 \nL 203.627093 2775.760484 \nL 204.336566 2772.255445 \nL 205.046038 2780.358277 \nL 205.75551 2782.27933 \nL 207.883927 2779.02364 \nL 208.5934 2773.937325 \nL 209.302872 2780.674244 \nL 210.012344 2785.665292 \nL 210.721817 2801.006868 \nL 212.850234 2798.19788 \nL 213.559706 2792.796266 \nL 214.269178 2793.469906 \nL 214.978651 2792.79742 \nL 215.688123 2793.156303 \nL 217.81654 2779.74982 \nL 218.526012 2779.048169 \nL 219.235485 2774.542439 \nL 219.944957 2777.946947 \nL 220.65443 2793.042174 \nL 222.782847 2793.44898 \nL 223.492319 2785.537094 \nL 224.201791 2779.869841 \nL 224.911264 2783.862892 \nL 225.620736 2782.015391 \nL 227.749153 2790.618119 \nL 228.458625 2781.388346 \nL 229.168098 2774.326256 \nL 229.87757 2775.871079 \nL 230.587042 2759.965074 \nL 232.715459 2762.70103 \nL 233.424932 2755.737052 \nL 234.134404 2755.429979 \nL 237.681766 2753.589591 \nL 238.391238 2745.405973 \nL 239.100711 2742.608223 \nL 239.810183 2742.608223 \nL 240.519655 2744.074153 \nL 242.648072 2742.608223 \nL 243.357545 2742.608223 \nL 244.067017 2743.715074 \nL 244.776489 2742.608223 \nL 247.614379 2742.608223 \nL 248.323851 2743.320285 \nL 249.033323 2742.608223 \nL 249.742796 2789.24639 \nL 250.452268 2787.490713 \nL 252.580685 2774.073062 \nL 253.290157 2756.091806 \nL 253.99963 2754.132138 \nL 254.709102 2746.030425 \nL 255.418574 2773.010778 \nL 257.546991 2763.381711 \nL 258.256464 2758.508361 \nL 258.965936 2743.939237 \nL 259.675409 2742.608223 \nL 262.513298 2742.608223 \nL 263.22277 2752.368305 \nL 263.932243 2746.478556 \nL 264.641715 2743.834204 \nL 265.351187 2754.91056 \nL 267.479604 2753.052787 \nL 268.189077 2758.082296 \nL 268.898549 2771.98029 \nL 269.608021 2770.447384 \nL 270.317494 2759.731649 \nL 272.445911 2745.783677 \nL 273.155383 2743.315609 \nL 273.864855 2748.447459 \nL 274.574328 2758.051716 \nL 275.2838 2751.586174 \nL 277.412217 2743.52937 \nL 278.12169 2745.028068 \nL 278.831162 2753.217897 \nL 279.540634 2745.456134 \nL 280.250107 2742.608223 \nL 283.087996 2742.608223 \nL 283.797468 2746.410472 \nL 284.506941 2745.763632 \nL 285.216413 2748.952078 \nL 287.34483 2762.937075 \nL 288.054302 2761.640635 \nL 288.763775 2775.468093 \nL 289.473247 2769.377615 \nL 290.182719 2759.263251 \nL 292.311136 2756.848961 \nL 293.020609 2758.26714 \nL 293.730081 2760.278486 \nL 294.439553 2775.037535 \nL 295.149026 2763.954544 \nL 297.277443 2765.629954 \nL 297.986915 2774.86836 \nL 298.696388 2772.131294 \nL 299.40586 2782.031387 \nL 300.115332 2782.028888 \nL 302.243749 2780.305486 \nL 302.953222 2772.478675 \nL 303.662694 2773.492805 \nL 310.047945 2755.298391 \nL 312.176362 2742.608223 \nL 312.885834 2742.608223 \nL 313.595307 2749.038549 \nL 314.304779 2757.751106 \nL 315.014252 2760.951872 \nL 317.142669 2768.122943 \nL 317.852141 2763.569544 \nL 318.561613 2771.400361 \nL 319.271086 2773.777319 \nL 319.980558 2780.822793 \nL 322.108975 2785.297488 \nL 322.818447 2778.723151 \nL 323.52792 2765.448438 \nL 324.946864 2775.615242 \nL 327.075281 2774.580442 \nL 327.784754 2761.483193 \nL 328.494226 2754.456085 \nL 329.203698 2750.817328 \nL 329.913171 2756.70258 \nL 332.041588 2750.444353 \nL 332.75106 2758.492488 \nL 333.460533 2764.399149 \nL 334.170005 2761.376252 \nL 334.879477 2761.100814 \nL 337.007894 2754.313187 \nL 337.717367 2768.195856 \nL 338.426839 2764.819004 \nL 339.136311 2746.010469 \nL 339.845784 2742.608223 \nL 342.683673 2742.608223 \nL 343.393145 2753.987302 \nL 344.102618 2746.898456 \nL 344.81209 2742.608223 \nL 346.940507 2753.044495 \nL 347.649979 2742.608223 \nL 348.359452 2746.256336 \nL 349.068924 2744.884365 \nL 349.778396 2742.608223 \nL 351.906813 2746.418416 \nL 352.616286 2748.496466 \nL 353.325758 2754.693088 \nL 354.035231 2751.023858 \nL 354.744703 2751.501929 \nL 356.87312 2747.338228 \nL 357.582592 2742.608223 \nL 359.001537 2742.608223 \nL 359.711009 2744.226924 \nL 361.839426 2742.608223 \nL 362.548899 2756.325347 \nL 363.258371 2742.608223 \nL 363.967843 2747.974819 \nL 364.677316 2742.608223 \nL 366.805733 2742.608223 \nL 367.515205 2746.155747 \nL 368.224677 2742.608223 \nL 373.900456 2742.608223 \nL 374.609929 2743.057292 \nL 376.738346 2757.653497 \nL 377.447818 2742.608223 \nL 378.15729 2746.99661 \nL 378.866763 2768.555061 \nL 379.576235 2772.467114 \nL 381.704652 2762.536831 \nL 382.414124 2781.870029 \nL 383.123597 2773.634821 \nL 383.833069 2756.210833 \nL 384.542541 2745.312918 \nL 386.670958 2742.608223 \nL 387.380431 2748.384993 \nL 388.089903 2748.57951 \nL 388.799375 2772.285418 \nL 389.508848 2770.482663 \nL 391.637265 2746.74641 \nL 392.346737 2742.608223 \nL 393.765682 2742.608223 \nL 394.475154 2748.649689 \nL 396.603571 2742.608223 \nL 403.698295 2742.608223 \nL 404.407767 2756.538082 \nL 406.536184 2765.98909 \nL 407.955129 2788.695811 \nL 408.664601 2771.904364 \nL 409.374074 2786.270583 \nL 411.502491 2783.230593 \nL 412.211963 2801.886253 \nL 412.921435 2791.749663 \nL 413.630908 2824.589162 \nL 414.34038 2836.728711 \nL 416.468797 2858.177755 \nL 417.178269 2875.803023 \nL 417.887742 2851.329368 \nL 419.306686 2819.350282 \nL 421.435103 2838.155602 \nL 422.144576 2819.675753 \nL 422.854048 2814.215686 \nL 423.56352 2812.180931 \nL 424.272993 2826.771953 \nL 426.40141 2830.659851 \nL 427.110882 2839.394236 \nL 427.820354 2854.760008 \nL 428.529827 2848.319887 \nL 429.239299 2824.532051 \nL 431.367716 2814.771021 \nL 432.077189 2813.789228 \nL 432.786661 2832.754535 \nL 433.496133 2818.662524 \nL 434.205606 2799.494 \nL 437.043495 2807.891219 \nL 437.752967 2820.494142 \nL 438.46244 2804.596789 \nL 439.171912 2822.161325 \nL 441.300329 2836.823682 \nL 442.009801 2834.160222 \nL 442.719274 2832.324191 \nL 443.428746 2836.60303 \nL 444.138218 2833.541444 \nL 446.266635 2818.874679 \nL 446.976108 2815.06147 \nL 447.68558 2813.095952 \nL 448.395053 2816.343585 \nL 449.104525 2813.541814 \nL 451.232942 2820.754162 \nL 451.942414 2819.021352 \nL 452.651887 2813.957365 \nL 453.361359 2818.846075 \nL 454.070831 2820.516534 \nL 458.327665 2820.945027 \nL 459.037138 2827.92028 \nL 461.165555 2821.959769 \nL 461.875027 2818.289602 \nL 462.584499 2815.951717 \nL 463.293972 2823.122472 \nL 464.003444 2811.188387 \nL 466.131861 2801.268149 \nL 466.841334 2802.538455 \nL 468.260278 2804.081083 \nL 468.969751 2810.091098 \nL 471.098168 2809.1448 \nL 471.80764 2790.422947 \nL 472.517112 2788.903407 \nL 473.226585 2790.890782 \nL 473.936057 2791.311846 \nL 476.064474 2789.408112 \nL 476.773946 2794.531594 \nL 477.483419 2797.921843 \nL 478.192891 2800.425955 \nL 478.902363 2796.123018 \nL 481.03078 2795.272828 \nL 481.740253 2789.889808 \nL 482.449725 2788.984212 \nL 483.159197 2782.246698 \nL 483.86867 2793.322389 \nL 486.706559 2795.216433 \nL 487.416032 2808.261792 \nL 488.125504 2813.115916 \nL 488.834976 2809.404839 \nL 490.963393 2809.931786 \nL 491.672866 2809.780826 \nL 492.382338 2826.750537 \nL 493.09181 2825.298287 \nL 493.801283 2819.908935 \nL 495.9297 2813.878532 \nL 496.639172 2819.461661 \nL 497.348644 2815.358699 \nL 498.058117 2825.679388 \nL 498.767589 2842.695045 \nL 501.605478 2829.157638 \nL 502.314951 2817.021122 \nL 503.024423 2821.018316 \nL 503.733896 2830.315438 \nL 505.862313 2821.039566 \nL 506.571785 2817.307082 \nL 507.281257 2836.60249 \nL 507.99073 2830.774088 \nL 508.700202 2823.745256 \nL 510.828619 2818.021173 \nL 511.538091 2819.819865 \nL 512.247564 2816.111965 \nL 512.957036 2817.278127 \nL 513.666508 2824.387995 \nL 515.794925 2833.574277 \nL 516.504398 2857.017424 \nL 517.21387 2860.943831 \nL 517.923342 2850.007514 \nL 518.632815 2845.684409 \nL 520.761232 2818.016923 \nL 521.470704 2815.956298 \nL 522.180176 2803.725693 \nL 522.889649 2796.970569 \nL 523.599121 2803.781441 \nL 525.727538 2800.053445 \nL 526.437011 2791.733589 \nL 527.146483 2797.989892 \nL 527.855955 2797.3303 \nL 528.565428 2800.607037 \nL 530.693845 2799.890683 \nL 531.403317 2812.35289 \nL 532.822262 2819.560516 \nL 533.531734 2842.409867 \nL 535.660151 2816.85667 \nL 536.369623 2811.632226 \nL 537.079096 2803.236894 \nL 537.788568 2813.315606 \nL 538.49804 2805.269701 \nL 540.626457 2796.774243 \nL 541.33593 2799.705054 \nL 542.045402 2791.51785 \nL 542.754875 2796.986552 \nL 543.464347 2797.298161 \nL 545.592764 2780.071683 \nL 546.302236 2773.391955 \nL 547.011709 2787.607057 \nL 547.721181 2785.400183 \nL 548.430653 2762.576486 \nL 551.268543 2755.61235 \nL 551.978015 2770.063283 \nL 552.687487 2764.968234 \nL 553.39696 2742.608223 \nL 556.944321 2752.481904 \nL 557.653794 2751.902669 \nL 558.363266 2742.608223 \nL 560.491683 2742.608223 \nL 561.201156 2754.706655 \nL 561.910628 2760.078202 \nL 562.6201 2759.551342 \nL 568.295879 2745.759138 \nL 570.424296 2755.907401 \nL 571.133768 2754.513769 \nL 571.843241 2742.608223 \nL 573.262185 2742.608223 \nL 575.390602 2744.070653 \nL 576.100075 2742.608223 \nL 576.809547 2742.608223 \nL 577.519019 2746.530479 \nL 578.228492 2743.818814 \nL 580.356909 2742.608223 \nL 581.066381 2745.783538 \nL 582.485326 2758.030939 \nL 583.194798 2751.029141 \nL 585.323215 2763.530148 \nL 586.032688 2768.775804 \nL 586.74216 2777.376665 \nL 587.451632 2767.149436 \nL 588.161105 2768.858763 \nL 590.289522 2767.069494 \nL 590.998994 2768.380875 \nL 591.708466 2774.160605 \nL 592.417939 2768.379453 \nL 593.127411 2766.480472 \nL 595.9653 2760.401639 \nL 596.674773 2762.641097 \nL 597.384245 2770.384602 \nL 598.093717 2763.316365 \nL 600.222135 2764.815893 \nL 600.931607 2767.203913 \nL 601.641079 2767.864183 \nL 602.350552 2771.184346 \nL 603.060024 2775.053737 \nL 605.188441 2777.776083 \nL 605.897913 2782.877877 \nL 607.316858 2776.308304 \nL 608.02633 2768.782601 \nL 610.154747 2766.217588 \nL 610.86422 2764.66497 \nL 611.573692 2748.648517 \nL 612.283164 2742.608223 \nL 612.992637 2742.65672 \nL 615.121054 2742.608223 \nL 615.830526 2747.555015 \nL 616.539998 2757.29501 \nL 617.958943 2786.047341 \nL 620.08736 2785.283248 \nL 620.796833 2789.580961 \nL 621.506305 2793.015312 \nL 622.215777 2791.551878 \nL 622.92525 2796.497278 \nL 625.053667 2797.828677 \nL 625.763139 2792.335279 \nL 626.472611 2814.460395 \nL 627.182084 2811.496433 \nL 627.891556 2810.966432 \nL 630.729445 2813.57064 \nL 631.438918 2819.749779 \nL 632.14839 2823.413739 \nL 634.986279 2822.841067 \nL 635.695752 2828.098065 \nL 636.405224 2825.24206 \nL 637.114697 2837.955663 \nL 637.824169 2839.938943 \nL 639.952586 2838.096955 \nL 640.662058 2835.393459 \nL 641.371531 2838.887937 \nL 642.081003 2840.151791 \nL 642.790475 2840.606238 \nL 644.918892 2841.576161 \nL 645.628365 2853.3123 \nL 646.337837 2850.978856 \nL 647.756782 2872.697011 \nL 654.851505 2868.314653 \nL 655.560978 2871.236461 \nL 656.27045 2858.500035 \nL 656.979922 2856.798126 \nL 657.689395 2849.585846 \nL 659.817812 2848.497347 \nL 660.527284 2844.704171 \nL 661.236756 2842.967862 \nL 661.946229 2844.925745 \nL 662.655701 2842.895969 \nL 664.784118 2844.450027 \nL 665.49359 2850.048889 \nL 666.203063 2847.240604 \nL 666.912535 2859.37412 \nL 667.622007 2857.637213 \nL 669.750424 2855.659869 \nL 670.459897 2852.571495 \nL 671.169369 2854.18274 \nL 671.878841 2853.862856 \nL 672.588314 2859.450452 \nL 674.716731 2873.955176 \nL 675.426203 2883.727345 \nL 676.135676 2887.846708 \nL 676.845148 2884.67018 \nL 677.55462 2878.947129 \nL 679.683037 2885.86782 \nL 680.39251 2908.860664 \nL 681.101982 2888.958643 \nL 681.811454 2878.740634 \nL 682.520927 2873.932446 \nL 684.649344 2876.974793 \nL 685.358816 2879.146843 \nL 686.068288 2877.938439 \nL 686.777761 2883.251643 \nL 687.487233 2889.550906 \nL 689.61565 2891.996602 \nL 690.325122 2891.202608 \nL 691.034595 2875.270863 \nL 691.744067 2879.946093 \nL 692.453539 2871.720594 \nL 696.000901 2876.699768 \nL 696.710374 2878.011879 \nL 697.419846 2876.754048 \nL 699.548263 2888.419495 \nL 700.257735 2880.115869 \nL 700.967208 2882.875598 \nL 701.67668 2877.943321 \nL 702.386152 2880.066534 \nL 704.514569 2885.569647 \nL 705.224042 2891.736202 \nL 706.642986 2901.957329 \nL 707.352459 2902.013104 \nL 709.480876 2924.361019 \nL 710.190348 2924.048253 \nL 711.609293 2909.847648 \nL 712.318765 2904.154274 \nL 716.575599 2897.403657 \nL 717.285072 2910.413008 \nL 719.413489 2913.928627 \nL 720.122961 2914.05425 \nL 720.832433 2901.15341 \nL 721.541906 2902.357325 \nL 722.251378 2899.483685 \nL 724.379795 2902.172604 \nL 725.089267 2894.501954 \nL 725.79874 2892.964869 \nL 726.508212 2897.209625 \nL 727.217684 2886.007039 \nL 729.346101 2891.115885 \nL 730.055574 2898.858935 \nL 730.765046 2893.071607 \nL 731.474519 2892.55966 \nL 732.183991 2891.845524 \nL 734.312408 2886.938976 \nL 735.02188 2887.23412 \nL 735.731353 2889.108178 \nL 736.440825 2889.155339 \nL 739.278714 2887.088701 \nL 739.988187 2886.183784 \nL 740.697659 2878.16239 \nL 741.407131 2881.572375 \nL 742.116604 2874.496788 \nL 744.245021 2883.835703 \nL 744.954493 2875.950951 \nL 745.663965 2864.997885 \nL 746.373438 2871.625676 \nL 747.08291 2857.502672 \nL 749.211327 2859.250851 \nL 749.9208 2860.20741 \nL 750.630272 2868.288119 \nL 751.339744 2859.830539 \nL 752.049217 2852.843904 \nL 754.177634 2845.351533 \nL 754.887106 2846.693225 \nL 755.596578 2850.827976 \nL 756.306051 2839.549672 \nL 757.015523 2844.475201 \nL 759.14394 2846.84091 \nL 759.853412 2846.979148 \nL 760.562885 2858.941505 \nL 761.272357 2858.107868 \nL 761.981829 2859.043256 \nL 764.110246 2869.941428 \nL 764.819719 2875.869793 \nL 765.529191 2872.667622 \nL 766.238663 2871.685381 \nL 766.948136 2879.874782 \nL 769.076553 2871.644349 \nL 769.786025 2875.679925 \nL 770.495498 2871.946572 \nL 771.20497 2875.27208 \nL 771.914442 2874.706904 \nL 774.042859 2876.739737 \nL 774.752332 2877.089452 \nL 775.461804 2881.526439 \nL 776.171276 2881.157725 \nL 776.880749 2893.413947 \nL 779.009166 2896.61107 \nL 779.718638 2906.375081 \nL 780.42811 2905.803864 \nL 781.137583 2899.389684 \nL 781.847055 2895.287797 \nL 783.975472 2894.697501 \nL 784.684944 2892.221347 \nL 785.394417 2896.542127 \nL 786.103889 2889.061353 \nL 786.813361 2885.234294 \nL 788.941779 2887.759152 \nL 789.651251 2891.153581 \nL 790.360723 2889.359615 \nL 791.070196 2894.102375 \nL 791.779668 2900.452396 \nL 793.908085 2892.403845 \nL 794.617557 2893.979002 \nL 795.32703 2901.263502 \nL 796.036502 2896.054013 \nL 796.745974 2895.965109 \nL 799.583864 2900.005879 \nL 800.293336 2902.572668 \nL 801.002808 2906.581339 \nL 801.712281 2913.258119 \nL 803.840698 2918.789488 \nL 804.55017 2908.588567 \nL 805.969115 2910.454823 \nL 806.678587 2905.926438 \nL 809.516477 2901.576747 \nL 810.225949 2907.164233 \nL 810.935421 2911.169666 \nL 811.644894 2923.500398 \nL 813.773311 2924.603927 \nL 814.482783 2926.750904 \nL 815.192255 2930.759216 \nL 815.901728 2932.266834 \nL 816.6112 2934.451489 \nL 818.739617 2934.249472 \nL 819.449089 2927.650214 \nL 820.158562 2933.080477 \nL 820.868034 2932.20259 \nL 820.868034 2932.20259 \n\" clip-path=\"url(#p742258926d)\" style=\"fill: none; stroke: #ff7f50; stroke-opacity: 0.7; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_49\">\n    <path d=\"M 75.177125 2944.043652 \nL 75.177125 2742.608223 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_50\">\n    <path d=\"M 856.377125 2944.043652 \nL 856.377125 2742.608223 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_51\">\n    <path d=\"M 75.177125 2944.043652 \nL 856.377125 2944.043652 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_52\">\n    <path d=\"M 75.177125 2742.608223 \nL 856.377125 2742.608223 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_92\">\n    <!-- Underwater plot -->\n    <g transform=\"translate(412.249063 2736.608223)scale(0.132 -0.132)\">\n     <defs>\n      <path id=\"DejaVuSans-55\" d=\"M 556 4666 \nL 1191 4666 \nL 1191 1831 \nQ 1191 1081 1462 751 \nQ 1734 422 2344 422 \nQ 2950 422 3222 751 \nQ 3494 1081 3494 1831 \nL 3494 4666 \nL 4128 4666 \nL 4128 1753 \nQ 4128 841 3676 375 \nQ 3225 -91 2344 -91 \nQ 1459 -91 1007 375 \nQ 556 841 556 1753 \nL 556 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-55\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"73.193359\"/>\n     <use xlink:href=\"#DejaVuSans-64\" x=\"136.572266\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"200.048828\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"261.572266\"/>\n     <use xlink:href=\"#DejaVuSans-77\" x=\"302.685547\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"384.472656\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"445.751953\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"484.960938\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"546.484375\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"587.597656\"/>\n     <use xlink:href=\"#DejaVuSans-70\" x=\"619.384766\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"682.861328\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"710.644531\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"771.826172\"/>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_10\">\n   <g id=\"patch_53\">\n    <path d=\"M 75.177125 3246.196795 \nL 270.477125 3246.196795 \nL 270.477125 3044.761366 \nL 75.177125 3044.761366 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"QuadMesh_1\">\n    <path d=\"M 75.177125 3044.761366 \nL 91.452125 3044.761366 \nL 91.452125 3111.906509 \nL 75.177125 3111.906509 \nL 75.177125 3044.761366 \n\" clip-path=\"url(#pf6d595b45d)\" style=\"fill: #fff5ae\"/>\n    <path d=\"M 91.452125 3044.761366 \nL 107.727125 3044.761366 \nL 107.727125 3111.906509 \nL 91.452125 3111.906509 \nL 91.452125 3044.761366 \n\" clip-path=\"url(#pf6d595b45d)\" style=\"fill: #fffbb8\"/>\n    <path d=\"M 107.727125 3044.761366 \nL 124.002125 3044.761366 \nL 124.002125 3111.906509 \nL 107.727125 3111.906509 \nL 107.727125 3044.761366 \n\" clip-path=\"url(#pf6d595b45d)\" style=\"fill: #fdbb6c\"/>\n    <path d=\"M 124.002125 3044.761366 \nL 140.277125 3044.761366 \nL 140.277125 3111.906509 \nL 124.002125 3111.906509 \nL 124.002125 3044.761366 \n\" clip-path=\"url(#pf6d595b45d)\" style=\"fill: #b3df72\"/>\n    <path d=\"M 140.277125 3044.761366 \nL 156.552125 3044.761366 \nL 156.552125 3111.906509 \nL 140.277125 3111.906509 \nL 140.277125 3044.761366 \n\" clip-path=\"url(#pf6d595b45d)\" style=\"fill: #fff5ae\"/>\n    <path d=\"M 156.552125 3044.761366 \nL 172.827125 3044.761366 \nL 172.827125 3111.906509 \nL 156.552125 3111.906509 \nL 156.552125 3044.761366 \n\" clip-path=\"url(#pf6d595b45d)\" style=\"fill: #9dd569\"/>\n    <path d=\"M 172.827125 3044.761366 \nL 189.102125 3044.761366 \nL 189.102125 3111.906509 \nL 172.827125 3111.906509 \nL 172.827125 3044.761366 \n\" clip-path=\"url(#pf6d595b45d)\" style=\"fill: #006837\"/>\n    <path d=\"M 189.102125 3044.761366 \nL 205.377125 3044.761366 \nL 205.377125 3111.906509 \nL 189.102125 3111.906509 \nL 189.102125 3044.761366 \n\" clip-path=\"url(#pf6d595b45d)\" style=\"fill: #dcf08f\"/>\n    <path d=\"M 205.377125 3044.761366 \nL 221.652125 3044.761366 \nL 221.652125 3111.906509 \nL 205.377125 3111.906509 \nL 205.377125 3044.761366 \n\" clip-path=\"url(#pf6d595b45d)\" style=\"fill: #fedc88\"/>\n    <path d=\"M 221.652125 3044.761366 \nL 237.927125 3044.761366 \nL 237.927125 3111.906509 \nL 221.652125 3111.906509 \nL 221.652125 3044.761366 \n\" clip-path=\"url(#pf6d595b45d)\" style=\"fill: #ecf7a6\"/>\n    <path d=\"M 237.927125 3044.761366 \nL 254.202125 3044.761366 \nL 254.202125 3111.906509 \nL 237.927125 3111.906509 \nL 237.927125 3044.761366 \n\" clip-path=\"url(#pf6d595b45d)\" style=\"fill: #a9da6c\"/>\n    <path d=\"M 254.202125 3044.761366 \nL 270.477125 3044.761366 \nL 270.477125 3111.906509 \nL 254.202125 3111.906509 \nL 254.202125 3044.761366 \n\" clip-path=\"url(#pf6d595b45d)\" style=\"fill: #07753e\"/>\n    <path d=\"M 75.177125 3111.906509 \nL 91.452125 3111.906509 \nL 91.452125 3179.051652 \nL 75.177125 3179.051652 \nL 75.177125 3111.906509 \n\" clip-path=\"url(#pf6d595b45d)\" style=\"fill: #89cc67\"/>\n    <path d=\"M 91.452125 3111.906509 \nL 107.727125 3111.906509 \nL 107.727125 3179.051652 \nL 91.452125 3179.051652 \nL 91.452125 3111.906509 \n\" clip-path=\"url(#pf6d595b45d)\" style=\"fill: #66bd63\"/>\n    <path d=\"M 107.727125 3111.906509 \nL 124.002125 3111.906509 \nL 124.002125 3179.051652 \nL 107.727125 3179.051652 \nL 107.727125 3111.906509 \n\" clip-path=\"url(#pf6d595b45d)\" style=\"fill: #fcaa5f\"/>\n    <path d=\"M 124.002125 3111.906509 \nL 140.277125 3111.906509 \nL 140.277125 3179.051652 \nL 124.002125 3179.051652 \nL 124.002125 3111.906509 \n\" clip-path=\"url(#pf6d595b45d)\" style=\"fill: #e8f59f\"/>\n    <path d=\"M 140.277125 3111.906509 \nL 156.552125 3111.906509 \nL 156.552125 3179.051652 \nL 140.277125 3179.051652 \nL 140.277125 3111.906509 \n\" clip-path=\"url(#pf6d595b45d)\" style=\"fill: #c1e57b\"/>\n    <path d=\"M 156.552125 3111.906509 \nL 172.827125 3111.906509 \nL 172.827125 3179.051652 \nL 156.552125 3179.051652 \nL 156.552125 3111.906509 \n\" clip-path=\"url(#pf6d595b45d)\" style=\"fill: #fed884\"/>\n    <path d=\"M 172.827125 3111.906509 \nL 189.102125 3111.906509 \nL 189.102125 3179.051652 \nL 172.827125 3179.051652 \nL 172.827125 3111.906509 \n\" clip-path=\"url(#pf6d595b45d)\" style=\"fill: #fecc7b\"/>\n    <path d=\"M 189.102125 3111.906509 \nL 205.377125 3111.906509 \nL 205.377125 3179.051652 \nL 189.102125 3179.051652 \nL 189.102125 3111.906509 \n\" clip-path=\"url(#pf6d595b45d)\" style=\"fill: #96d268\"/>\n    <path d=\"M 205.377125 3111.906509 \nL 221.652125 3111.906509 \nL 221.652125 3179.051652 \nL 205.377125 3179.051652 \nL 205.377125 3111.906509 \n\" clip-path=\"url(#pf6d595b45d)\" style=\"fill: #82c966\"/>\n    <path d=\"M 221.652125 3111.906509 \nL 237.927125 3111.906509 \nL 237.927125 3179.051652 \nL 221.652125 3179.051652 \nL 221.652125 3111.906509 \n\" clip-path=\"url(#pf6d595b45d)\" style=\"fill: #cdea83\"/>\n    <path d=\"M 237.927125 3111.906509 \nL 254.202125 3111.906509 \nL 254.202125 3179.051652 \nL 237.927125 3179.051652 \nL 237.927125 3111.906509 \n\" clip-path=\"url(#pf6d595b45d)\" style=\"fill: #fed07e\"/>\n    <path d=\"M 254.202125 3111.906509 \nL 270.477125 3111.906509 \nL 270.477125 3179.051652 \nL 254.202125 3179.051652 \nL 254.202125 3111.906509 \n\" clip-path=\"url(#pf6d595b45d)\" style=\"fill: #fee491\"/>\n    <path d=\"M 75.177125 3179.051652 \nL 91.452125 3179.051652 \nL 91.452125 3246.196795 \nL 75.177125 3246.196795 \nL 75.177125 3179.051652 \n\" clip-path=\"url(#pf6d595b45d)\" style=\"fill: #f67a49\"/>\n    <path d=\"M 91.452125 3179.051652 \nL 107.727125 3179.051652 \nL 107.727125 3246.196795 \nL 91.452125 3246.196795 \nL 91.452125 3179.051652 \n\" clip-path=\"url(#pf6d595b45d)\" style=\"fill: #ddf191\"/>\n    <path d=\"M 107.727125 3179.051652 \nL 124.002125 3179.051652 \nL 124.002125 3246.196795 \nL 107.727125 3246.196795 \nL 107.727125 3179.051652 \n\" clip-path=\"url(#pf6d595b45d)\" style=\"fill: #fed481\"/>\n    <path d=\"M 124.002125 3179.051652 \nL 140.277125 3179.051652 \nL 140.277125 3246.196795 \nL 124.002125 3246.196795 \nL 124.002125 3179.051652 \n\" clip-path=\"url(#pf6d595b45d)\" style=\"fill: #fed481\"/>\n    <path d=\"M 140.277125 3179.051652 \nL 156.552125 3179.051652 \nL 156.552125 3246.196795 \nL 140.277125 3246.196795 \nL 140.277125 3179.051652 \n\" clip-path=\"url(#pf6d595b45d)\" style=\"fill: #dcf08f\"/>\n    <path d=\"M 156.552125 3179.051652 \nL 172.827125 3179.051652 \nL 172.827125 3246.196795 \nL 156.552125 3246.196795 \nL 156.552125 3179.051652 \n\" clip-path=\"url(#pf6d595b45d)\" style=\"fill: #84ca66\"/>\n    <path d=\"M 172.827125 3179.051652 \nL 189.102125 3179.051652 \nL 189.102125 3246.196795 \nL 172.827125 3246.196795 \nL 172.827125 3179.051652 \n\" clip-path=\"url(#pf6d595b45d)\" style=\"fill: #f7844e\"/>\n    <path d=\"M 189.102125 3179.051652 \nL 205.377125 3179.051652 \nL 205.377125 3246.196795 \nL 189.102125 3246.196795 \nL 189.102125 3179.051652 \n\" clip-path=\"url(#pf6d595b45d)\" style=\"fill: #fff0a6\"/>\n    <path d=\"M 205.377125 3179.051652 \nL 221.652125 3179.051652 \nL 221.652125 3246.196795 \nL 205.377125 3246.196795 \nL 205.377125 3179.051652 \n\" clip-path=\"url(#pf6d595b45d)\" style=\"fill: #fdc171\"/>\n    <path d=\"M 221.652125 3179.051652 \nL 237.927125 3179.051652 \nL 237.927125 3246.196795 \nL 221.652125 3246.196795 \nL 221.652125 3179.051652 \n\" clip-path=\"url(#pf6d595b45d)\" style=\"fill: #feffbe\"/>\n    <path d=\"M 237.927125 3179.051652 \nL 254.202125 3179.051652 \nL 254.202125 3246.196795 \nL 237.927125 3246.196795 \nL 237.927125 3179.051652 \n\" clip-path=\"url(#pf6d595b45d)\" style=\"fill: #feffbe\"/>\n    <path d=\"M 254.202125 3179.051652 \nL 270.477125 3179.051652 \nL 270.477125 3246.196795 \nL 254.202125 3246.196795 \nL 254.202125 3179.051652 \n\" clip-path=\"url(#pf6d595b45d)\" style=\"fill: #feffbe\"/>\n   </g>\n   <g id=\"matplotlib.axis_19\">\n    <g id=\"xtick_127\">\n     <g id=\"line2d_226\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"83.314625\" y=\"3246.196795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_93\">\n      <!-- 1 -->\n      <g transform=\"translate(79.465313 3264.890904)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_128\">\n     <g id=\"line2d_227\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"99.589625\" y=\"3246.196795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_94\">\n      <!-- 2 -->\n      <g transform=\"translate(95.740313 3264.890904)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_129\">\n     <g id=\"line2d_228\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"115.864625\" y=\"3246.196795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_95\">\n      <!-- 3 -->\n      <g transform=\"translate(112.015313 3264.890904)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-33\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_130\">\n     <g id=\"line2d_229\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"132.139625\" y=\"3246.196795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_96\">\n      <!-- 4 -->\n      <g transform=\"translate(128.290313 3264.890904)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-34\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_131\">\n     <g id=\"line2d_230\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"148.414625\" y=\"3246.196795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_97\">\n      <!-- 5 -->\n      <g transform=\"translate(144.565313 3264.890904)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_132\">\n     <g id=\"line2d_231\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"164.689625\" y=\"3246.196795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_98\">\n      <!-- 6 -->\n      <g transform=\"translate(160.840313 3264.890904)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-36\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_133\">\n     <g id=\"line2d_232\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"180.964625\" y=\"3246.196795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_99\">\n      <!-- 7 -->\n      <g transform=\"translate(177.115313 3264.890904)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-37\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_134\">\n     <g id=\"line2d_233\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"197.239625\" y=\"3246.196795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_100\">\n      <!-- 8 -->\n      <g transform=\"translate(193.390312 3264.890904)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-38\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_135\">\n     <g id=\"line2d_234\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"213.514625\" y=\"3246.196795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_101\">\n      <!-- 9 -->\n      <g transform=\"translate(209.665312 3264.890904)scale(0.121 -0.121)\">\n       <defs>\n        <path id=\"DejaVuSans-39\" d=\"M 703 97 \nL 703 672 \nQ 941 559 1184 500 \nQ 1428 441 1663 441 \nQ 2288 441 2617 861 \nQ 2947 1281 2994 2138 \nQ 2813 1869 2534 1725 \nQ 2256 1581 1919 1581 \nQ 1219 1581 811 2004 \nQ 403 2428 403 3163 \nQ 403 3881 828 4315 \nQ 1253 4750 1959 4750 \nQ 2769 4750 3195 4129 \nQ 3622 3509 3622 2328 \nQ 3622 1225 3098 567 \nQ 2575 -91 1691 -91 \nQ 1453 -91 1209 -44 \nQ 966 3 703 97 \nz\nM 1959 2075 \nQ 2384 2075 2632 2365 \nQ 2881 2656 2881 3163 \nQ 2881 3666 2632 3958 \nQ 2384 4250 1959 4250 \nQ 1534 4250 1286 3958 \nQ 1038 3666 1038 3163 \nQ 1038 2656 1286 2365 \nQ 1534 2075 1959 2075 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-39\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_136\">\n     <g id=\"line2d_235\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"229.789625\" y=\"3246.196795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_102\">\n      <!-- 10 -->\n      <g transform=\"translate(222.091 3264.890904)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_137\">\n     <g id=\"line2d_236\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"246.064625\" y=\"3246.196795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_103\">\n      <!-- 11 -->\n      <g transform=\"translate(238.366 3264.890904)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-31\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_138\">\n     <g id=\"line2d_237\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"262.339625\" y=\"3246.196795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_104\">\n      <!-- 12 -->\n      <g transform=\"translate(254.641 3264.890904)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_105\">\n     <!-- Month -->\n     <g transform=\"translate(152.141281 3281.437263)scale(0.132 -0.132)\">\n      <defs>\n       <path id=\"DejaVuSans-4d\" d=\"M 628 4666 \nL 1569 4666 \nL 2759 1491 \nL 3956 4666 \nL 4897 4666 \nL 4897 0 \nL 4281 0 \nL 4281 4097 \nL 3078 897 \nL 2444 897 \nL 1241 4097 \nL 1241 0 \nL 628 0 \nL 628 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-4d\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"86.279297\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"147.460938\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"210.839844\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"250.048828\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_20\">\n    <g id=\"ytick_65\">\n     <g id=\"line2d_238\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"3078.333937\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_106\">\n      <!-- 2020 -->\n      <g transform=\"translate(63.160703 3093.731187)rotate(-90)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_66\">\n     <g id=\"line2d_239\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"3145.47908\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_107\">\n      <!-- 2021 -->\n      <g transform=\"translate(63.160703 3160.87633)rotate(-90)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-31\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_67\">\n     <g id=\"line2d_240\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"3212.624223\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_108\">\n      <!-- 2022 -->\n      <g transform=\"translate(63.160703 3228.021473)rotate(-90)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_109\">\n     <!-- Year -->\n     <g transform=\"translate(47.221406 3159.45458)rotate(-90)scale(0.132 -0.132)\">\n      <defs>\n       <path id=\"DejaVuSans-59\" d=\"M -13 4666 \nL 666 4666 \nL 1959 2747 \nL 3244 4666 \nL 3922 4666 \nL 2272 2222 \nL 2272 0 \nL 1638 0 \nL 1638 2222 \nL -13 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-59\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"47.833984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"109.357422\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"170.636719\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"text_110\">\n    <!-- -1.3 -->\n    <g style=\"fill: #262626\" transform=\"translate(74.534703 3080.817375)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-2d\"/>\n     <use xlink:href=\"#DejaVuSans-31\" x=\"36.083984\"/>\n     <use xlink:href=\"#DejaVuSans-2e\" x=\"99.707031\"/>\n     <use xlink:href=\"#DejaVuSans-33\" x=\"131.494141\"/>\n    </g>\n   </g>\n   <g id=\"text_111\">\n    <!-- -0.5 -->\n    <g style=\"fill: #262626\" transform=\"translate(90.809703 3080.817375)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-2d\"/>\n     <use xlink:href=\"#DejaVuSans-30\" x=\"36.083984\"/>\n     <use xlink:href=\"#DejaVuSans-2e\" x=\"99.707031\"/>\n     <use xlink:href=\"#DejaVuSans-35\" x=\"131.494141\"/>\n    </g>\n   </g>\n   <g id=\"text_112\">\n    <!-- -6.7 -->\n    <g style=\"fill: #262626\" transform=\"translate(107.084703 3080.817375)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-2d\"/>\n     <use xlink:href=\"#DejaVuSans-36\" x=\"36.083984\"/>\n     <use xlink:href=\"#DejaVuSans-2e\" x=\"99.707031\"/>\n     <use xlink:href=\"#DejaVuSans-37\" x=\"131.494141\"/>\n    </g>\n   </g>\n   <g id=\"text_113\">\n    <!-- 6.8 -->\n    <g style=\"fill: #262626\" transform=\"translate(124.983219 3080.817375)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-36\"/>\n     <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n     <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n    </g>\n   </g>\n   <g id=\"text_114\">\n    <!-- -1.3 -->\n    <g style=\"fill: #262626\" transform=\"translate(139.634703 3080.817375)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-2d\"/>\n     <use xlink:href=\"#DejaVuSans-31\" x=\"36.083984\"/>\n     <use xlink:href=\"#DejaVuSans-2e\" x=\"99.707031\"/>\n     <use xlink:href=\"#DejaVuSans-33\" x=\"131.494141\"/>\n    </g>\n   </g>\n   <g id=\"text_115\">\n    <!-- 8.3 -->\n    <g style=\"fill: #262626\" transform=\"translate(157.533219 3080.817375)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-38\"/>\n     <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n     <use xlink:href=\"#DejaVuSans-33\" x=\"95.410156\"/>\n    </g>\n   </g>\n   <g id=\"text_116\">\n    <!-- 20 -->\n    <g style=\"fill: #ffffff\" transform=\"translate(175.238375 3080.817375)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-32\"/>\n     <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n    </g>\n   </g>\n   <g id=\"text_117\">\n    <!-- 3.6 -->\n    <g style=\"fill: #262626\" transform=\"translate(190.083219 3080.817375)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-33\"/>\n     <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n     <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n    </g>\n   </g>\n   <g id=\"text_118\">\n    <!-- -4.2 -->\n    <g style=\"fill: #262626\" transform=\"translate(204.734703 3080.817375)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-2d\"/>\n     <use xlink:href=\"#DejaVuSans-34\" x=\"36.083984\"/>\n     <use xlink:href=\"#DejaVuSans-2e\" x=\"99.707031\"/>\n     <use xlink:href=\"#DejaVuSans-32\" x=\"131.494141\"/>\n    </g>\n   </g>\n   <g id=\"text_119\">\n    <!-- 1.9 -->\n    <g style=\"fill: #262626\" transform=\"translate(222.633219 3080.817375)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-31\"/>\n     <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n     <use xlink:href=\"#DejaVuSans-39\" x=\"95.410156\"/>\n    </g>\n   </g>\n   <g id=\"text_120\">\n    <!-- 7.6 -->\n    <g style=\"fill: #262626\" transform=\"translate(238.908219 3080.817375)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-37\"/>\n     <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n     <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n    </g>\n   </g>\n   <g id=\"text_121\">\n    <!-- 18 -->\n    <g style=\"fill: #ffffff\" transform=\"translate(256.613375 3080.817375)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-31\"/>\n     <use xlink:href=\"#DejaVuSans-38\" x=\"63.623047\"/>\n    </g>\n   </g>\n   <g id=\"text_122\">\n    <!-- 9.5 -->\n    <g style=\"fill: #262626\" transform=\"translate(76.158219 3147.962518)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-39\"/>\n     <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n     <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n    </g>\n   </g>\n   <g id=\"text_123\">\n    <!-- 12 -->\n    <g style=\"fill: #ffffff\" transform=\"translate(93.863375 3147.962518)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-31\"/>\n     <use xlink:href=\"#DejaVuSans-32\" x=\"63.623047\"/>\n    </g>\n   </g>\n   <g id=\"text_124\">\n    <!-- -8 -->\n    <g style=\"fill: #262626\" transform=\"translate(111.377984 3147.962518)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-2d\"/>\n     <use xlink:href=\"#DejaVuSans-38\" x=\"36.083984\"/>\n    </g>\n   </g>\n   <g id=\"text_125\">\n    <!-- 2.3 -->\n    <g style=\"fill: #262626\" transform=\"translate(124.983219 3147.962518)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-32\"/>\n     <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n     <use xlink:href=\"#DejaVuSans-33\" x=\"95.410156\"/>\n    </g>\n   </g>\n   <g id=\"text_126\">\n    <!-- 5.7 -->\n    <g style=\"fill: #262626\" transform=\"translate(141.258219 3147.962518)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-35\"/>\n     <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n     <use xlink:href=\"#DejaVuSans-37\" x=\"95.410156\"/>\n    </g>\n   </g>\n   <g id=\"text_127\">\n    <!-- -4.5 -->\n    <g style=\"fill: #262626\" transform=\"translate(155.909703 3147.962518)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-2d\"/>\n     <use xlink:href=\"#DejaVuSans-34\" x=\"36.083984\"/>\n     <use xlink:href=\"#DejaVuSans-2e\" x=\"99.707031\"/>\n     <use xlink:href=\"#DejaVuSans-35\" x=\"131.494141\"/>\n    </g>\n   </g>\n   <g id=\"text_128\">\n    <!-- -5.5 -->\n    <g style=\"fill: #262626\" transform=\"translate(172.184703 3147.962518)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-2d\"/>\n     <use xlink:href=\"#DejaVuSans-35\" x=\"36.083984\"/>\n     <use xlink:href=\"#DejaVuSans-2e\" x=\"99.707031\"/>\n     <use xlink:href=\"#DejaVuSans-35\" x=\"131.494141\"/>\n    </g>\n   </g>\n   <g id=\"text_129\">\n    <!-- 8.8 -->\n    <g style=\"fill: #262626\" transform=\"translate(190.083219 3147.962518)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-38\"/>\n     <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n     <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n    </g>\n   </g>\n   <g id=\"text_130\">\n    <!-- 10 -->\n    <g style=\"fill: #262626\" transform=\"translate(207.788375 3147.962518)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-31\"/>\n     <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n    </g>\n   </g>\n   <g id=\"text_131\">\n    <!-- 4.8 -->\n    <g style=\"fill: #262626\" transform=\"translate(222.633219 3147.962518)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-34\"/>\n     <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n     <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n    </g>\n   </g>\n   <g id=\"text_132\">\n    <!-- -5.1 -->\n    <g style=\"fill: #262626\" transform=\"translate(237.284703 3147.962518)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-2d\"/>\n     <use xlink:href=\"#DejaVuSans-35\" x=\"36.083984\"/>\n     <use xlink:href=\"#DejaVuSans-2e\" x=\"99.707031\"/>\n     <use xlink:href=\"#DejaVuSans-31\" x=\"131.494141\"/>\n    </g>\n   </g>\n   <g id=\"text_133\">\n    <!-- -3.4 -->\n    <g style=\"fill: #262626\" transform=\"translate(253.559703 3147.962518)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-2d\"/>\n     <use xlink:href=\"#DejaVuSans-33\" x=\"36.083984\"/>\n     <use xlink:href=\"#DejaVuSans-2e\" x=\"99.707031\"/>\n     <use xlink:href=\"#DejaVuSans-34\" x=\"131.494141\"/>\n    </g>\n   </g>\n   <g id=\"text_134\">\n    <!-- -11 -->\n    <g style=\"fill: #ffffff\" transform=\"translate(75.964859 3215.107661)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-2d\"/>\n     <use xlink:href=\"#DejaVuSans-31\" x=\"36.083984\"/>\n     <use xlink:href=\"#DejaVuSans-31\" x=\"99.707031\"/>\n    </g>\n   </g>\n   <g id=\"text_135\">\n    <!-- 3.4 -->\n    <g style=\"fill: #262626\" transform=\"translate(92.433219 3215.107661)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-33\"/>\n     <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n     <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n    </g>\n   </g>\n   <g id=\"text_136\">\n    <!-- -4.7 -->\n    <g style=\"fill: #262626\" transform=\"translate(107.084703 3215.107661)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-2d\"/>\n     <use xlink:href=\"#DejaVuSans-34\" x=\"36.083984\"/>\n     <use xlink:href=\"#DejaVuSans-2e\" x=\"99.707031\"/>\n     <use xlink:href=\"#DejaVuSans-37\" x=\"131.494141\"/>\n    </g>\n   </g>\n   <g id=\"text_137\">\n    <!-- -4.9 -->\n    <g style=\"fill: #262626\" transform=\"translate(123.359703 3215.107661)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-2d\"/>\n     <use xlink:href=\"#DejaVuSans-34\" x=\"36.083984\"/>\n     <use xlink:href=\"#DejaVuSans-2e\" x=\"99.707031\"/>\n     <use xlink:href=\"#DejaVuSans-39\" x=\"131.494141\"/>\n    </g>\n   </g>\n   <g id=\"text_138\">\n    <!-- 3.6 -->\n    <g style=\"fill: #262626\" transform=\"translate(141.258219 3215.107661)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-33\"/>\n     <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n     <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n    </g>\n   </g>\n   <g id=\"text_139\">\n    <!-- 9.9 -->\n    <g style=\"fill: #262626\" transform=\"translate(157.533219 3215.107661)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-39\"/>\n     <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n     <use xlink:href=\"#DejaVuSans-39\" x=\"95.410156\"/>\n    </g>\n   </g>\n   <g id=\"text_140\">\n    <!-- -10 -->\n    <g style=\"fill: #ffffff\" transform=\"translate(173.614859 3215.107661)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-2d\"/>\n     <use xlink:href=\"#DejaVuSans-31\" x=\"36.083984\"/>\n     <use xlink:href=\"#DejaVuSans-30\" x=\"99.707031\"/>\n    </g>\n   </g>\n   <g id=\"text_141\">\n    <!-- -1.9 -->\n    <g style=\"fill: #262626\" transform=\"translate(188.459703 3215.107661)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-2d\"/>\n     <use xlink:href=\"#DejaVuSans-31\" x=\"36.083984\"/>\n     <use xlink:href=\"#DejaVuSans-2e\" x=\"99.707031\"/>\n     <use xlink:href=\"#DejaVuSans-39\" x=\"131.494141\"/>\n    </g>\n   </g>\n   <g id=\"text_142\">\n    <!-- -6.3 -->\n    <g style=\"fill: #262626\" transform=\"translate(204.734703 3215.107661)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-2d\"/>\n     <use xlink:href=\"#DejaVuSans-36\" x=\"36.083984\"/>\n     <use xlink:href=\"#DejaVuSans-2e\" x=\"99.707031\"/>\n     <use xlink:href=\"#DejaVuSans-33\" x=\"131.494141\"/>\n    </g>\n   </g>\n   <g id=\"text_143\">\n    <!-- 0 -->\n    <g style=\"fill: #262626\" transform=\"translate(226.9265 3215.107661)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-30\"/>\n    </g>\n   </g>\n   <g id=\"text_144\">\n    <!-- 0 -->\n    <g style=\"fill: #262626\" transform=\"translate(243.2015 3215.107661)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-30\"/>\n    </g>\n   </g>\n   <g id=\"text_145\">\n    <!-- 0 -->\n    <g style=\"fill: #262626\" transform=\"translate(259.4765 3215.107661)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-30\"/>\n    </g>\n   </g>\n   <g id=\"text_146\">\n    <!-- Monthly returns (%) -->\n    <g transform=\"translate(107.170531 3038.761366)scale(0.132 -0.132)\">\n     <use xlink:href=\"#DejaVuSans-4d\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"86.279297\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"147.460938\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"210.839844\"/>\n     <use xlink:href=\"#DejaVuSans-68\" x=\"250.048828\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"313.427734\"/>\n     <use xlink:href=\"#DejaVuSans-79\" x=\"341.210938\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"400.390625\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"432.177734\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"471.041016\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"532.564453\"/>\n     <use xlink:href=\"#DejaVuSans-75\" x=\"571.773438\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"635.152344\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"674.515625\"/>\n     <use xlink:href=\"#DejaVuSans-73\" x=\"737.894531\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"789.994141\"/>\n     <use xlink:href=\"#DejaVuSans-28\" x=\"821.78125\"/>\n     <use xlink:href=\"#DejaVuSans-25\" x=\"860.794922\"/>\n     <use xlink:href=\"#DejaVuSans-29\" x=\"955.814453\"/>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_11\">\n   <g id=\"patch_54\">\n    <path d=\"M 368.127125 3246.196795 \nL 563.427125 3246.196795 \nL 563.427125 3044.761366 \nL 368.127125 3044.761366 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"patch_55\">\n    <path d=\"M 423.541739 3229.410509 \nL 377.004398 3229.410509 \nL 377.004398 3195.837937 \nL 423.541739 3195.837937 \nz\n\" clip-path=\"url(#p5f0ed3a3c6)\" style=\"fill: #1f77b4; opacity: 0.7\"/>\n   </g>\n   <g id=\"patch_56\">\n    <path d=\"M 423.541739 3162.265366 \nL 479.6141 3162.265366 \nL 479.6141 3128.692795 \nL 423.541739 3128.692795 \nz\n\" clip-path=\"url(#p5f0ed3a3c6)\" style=\"fill: #1f77b4; opacity: 0.7\"/>\n   </g>\n   <g id=\"patch_57\">\n    <path d=\"M 423.541739 3095.120223 \nL 554.549852 3095.120223 \nL 554.549852 3061.547652 \nL 423.541739 3061.547652 \nz\n\" clip-path=\"url(#p5f0ed3a3c6)\" style=\"fill: #1f77b4; opacity: 0.7\"/>\n   </g>\n   <g id=\"matplotlib.axis_21\">\n    <g id=\"xtick_139\">\n     <g id=\"line2d_241\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"380.610916\" y=\"3246.196795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_147\">\n      <!-- -20% -->\n      <g transform=\"translate(364.981119 3264.890904)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-2d\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"36.083984\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"99.707031\"/>\n       <use xlink:href=\"#DejaVuSans-25\" x=\"163.330078\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_140\">\n     <g id=\"line2d_242\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"423.541739\" y=\"3246.196795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_148\">\n      <!-- 0% -->\n      <g transform=\"translate(413.943981 3264.890904)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-25\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_141\">\n     <g id=\"line2d_243\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"466.472561\" y=\"3246.196795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_149\">\n      <!-- 20% -->\n      <g transform=\"translate(453.025491 3264.890904)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-25\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_142\">\n     <g id=\"line2d_244\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"509.403384\" y=\"3246.196795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_150\">\n      <!-- 40% -->\n      <g transform=\"translate(495.956314 3264.890904)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-25\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_143\">\n     <g id=\"line2d_245\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"552.334207\" y=\"3246.196795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_151\">\n      <!-- 60% -->\n      <g transform=\"translate(538.887137 3264.890904)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-36\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-25\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_152\">\n     <!-- Returns -->\n     <g transform=\"translate(440.438281 3281.437263)scale(0.132 -0.132)\">\n      <use xlink:href=\"#DejaVuSans-52\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"64.982422\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"126.505859\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"165.714844\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"229.09375\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"268.457031\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"331.835938\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_22\">\n    <g id=\"ytick_68\">\n     <g id=\"line2d_246\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"368.127125\" y=\"3212.624223\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_153\">\n      <!-- 2022 -->\n      <g transform=\"translate(327.832625 3217.221278)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_69\">\n     <g id=\"line2d_247\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"368.127125\" y=\"3145.47908\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_154\">\n      <!-- 2021 -->\n      <g transform=\"translate(327.832625 3150.076135)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-31\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_70\">\n     <g id=\"line2d_248\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"368.127125\" y=\"3078.333937\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_155\">\n      <!-- 2020 -->\n      <g transform=\"translate(327.832625 3082.930992)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_156\">\n     <!-- Year -->\n     <g transform=\"translate(321.087438 3159.45458)rotate(-90)scale(0.132 -0.132)\">\n      <use xlink:href=\"#DejaVuSans-59\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"47.833984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"109.357422\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"170.636719\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_249\">\n    <path d=\"M 470.38945 3246.196795 \nL 470.38945 3044.761366 \n\" clip-path=\"url(#p5f0ed3a3c6)\" style=\"fill: none; stroke-dasharray: 14.8,6.4; stroke-dashoffset: 0; stroke: #4682b4; stroke-opacity: 0.7; stroke-width: 4\"/>\n   </g>\n   <g id=\"line2d_250\">\n    <path d=\"M 423.541739 3246.196795 \nL 423.541739 3044.761366 \n\" clip-path=\"url(#p5f0ed3a3c6)\" style=\"fill: none; stroke: #000000; stroke-width: 3; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_58\">\n    <path d=\"M 368.127125 3246.196795 \nL 368.127125 3044.761366 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_59\">\n    <path d=\"M 563.427125 3246.196795 \nL 563.427125 3044.761366 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_60\">\n    <path d=\"M 368.127125 3246.196795 \nL 563.427125 3246.196795 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_61\">\n    <path d=\"M 368.127125 3044.761366 \nL 563.427125 3044.761366 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_157\">\n    <!-- Annual returns -->\n    <g transform=\"translate(417.123781 3038.761366)scale(0.132 -0.132)\">\n     <use xlink:href=\"#DejaVuSans-41\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"68.408203\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"131.787109\"/>\n     <use xlink:href=\"#DejaVuSans-75\" x=\"195.166016\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"258.544922\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"319.824219\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"347.607422\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"379.394531\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"418.257812\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"479.78125\"/>\n     <use xlink:href=\"#DejaVuSans-75\" x=\"518.990234\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"582.369141\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"621.732422\"/>\n     <use xlink:href=\"#DejaVuSans-73\" x=\"685.111328\"/>\n    </g>\n   </g>\n   <g id=\"legend_7\">\n    <g id=\"patch_62\">\n     <path d=\"M 483.268406 3240.146795 \nL 554.957125 3240.146795 \nQ 557.377125 3240.146795 557.377125 3237.726795 \nL 557.377125 3221.176263 \nQ 557.377125 3218.756263 554.957125 3218.756263 \nL 483.268406 3218.756263 \nQ 480.848406 3218.756263 480.848406 3221.176263 \nL 480.848406 3237.726795 \nQ 480.848406 3240.146795 483.268406 3240.146795 \nz\n\" style=\"fill: #ffffff; opacity: 0.5; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_251\">\n     <path d=\"M 485.688406 3228.555373 \nL 497.788406 3228.555373 \nL 509.888406 3228.555373 \n\" style=\"fill: none; stroke-dasharray: 14.8,6.4; stroke-dashoffset: 0; stroke: #4682b4; stroke-opacity: 0.7; stroke-width: 4\"/>\n    </g>\n    <g id=\"text_158\">\n     <!-- Mean -->\n     <g transform=\"translate(519.568406 3232.790373)scale(0.121 -0.121)\">\n      <use xlink:href=\"#DejaVuSans-4d\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"86.279297\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"147.802734\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"209.082031\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_12\">\n   <g id=\"patch_63\">\n    <path d=\"M 661.077125 3246.196795 \nL 856.377125 3246.196795 \nL 856.377125 3044.761366 \nL 661.077125 3044.761366 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"patch_64\">\n    <path d=\"M 669.954398 3246.196795 \nL 678.83167 3246.196795 \nL 678.83167 3150.275162 \nL 669.954398 3150.275162 \nz\n\" clip-path=\"url(#pb36c16de2e)\" style=\"fill: #ff4500; opacity: 0.8\"/>\n   </g>\n   <g id=\"patch_65\">\n    <path d=\"M 678.83167 3246.196795 \nL 687.708943 3246.196795 \nL 687.708943 3246.196795 \nL 678.83167 3246.196795 \nz\n\" clip-path=\"url(#pb36c16de2e)\" style=\"fill: #ff4500; opacity: 0.8\"/>\n   </g>\n   <g id=\"patch_66\">\n    <path d=\"M 687.708943 3246.196795 \nL 696.586216 3246.196795 \nL 696.586216 3150.275162 \nL 687.708943 3150.275162 \nz\n\" clip-path=\"url(#pb36c16de2e)\" style=\"fill: #ff4500; opacity: 0.8\"/>\n   </g>\n   <g id=\"patch_67\">\n    <path d=\"M 696.586216 3246.196795 \nL 705.463489 3246.196795 \nL 705.463489 3054.353529 \nL 696.586216 3054.353529 \nz\n\" clip-path=\"url(#pb36c16de2e)\" style=\"fill: #ff4500; opacity: 0.8\"/>\n   </g>\n   <g id=\"patch_68\">\n    <path d=\"M 705.463489 3246.196795 \nL 714.340761 3246.196795 \nL 714.340761 3102.314346 \nL 705.463489 3102.314346 \nz\n\" clip-path=\"url(#pb36c16de2e)\" style=\"fill: #ff4500; opacity: 0.8\"/>\n   </g>\n   <g id=\"patch_69\">\n    <path d=\"M 714.340761 3246.196795 \nL 723.218034 3246.196795 \nL 723.218034 3150.275162 \nL 714.340761 3150.275162 \nz\n\" clip-path=\"url(#pb36c16de2e)\" style=\"fill: #ff4500; opacity: 0.8\"/>\n   </g>\n   <g id=\"patch_70\">\n    <path d=\"M 723.218034 3246.196795 \nL 732.095307 3246.196795 \nL 732.095307 3102.314346 \nL 723.218034 3102.314346 \nz\n\" clip-path=\"url(#pb36c16de2e)\" style=\"fill: #ff4500; opacity: 0.8\"/>\n   </g>\n   <g id=\"patch_71\">\n    <path d=\"M 732.095307 3246.196795 \nL 740.97258 3246.196795 \nL 740.97258 3246.196795 \nL 732.095307 3246.196795 \nz\n\" clip-path=\"url(#pb36c16de2e)\" style=\"fill: #ff4500; opacity: 0.8\"/>\n   </g>\n   <g id=\"patch_72\">\n    <path d=\"M 740.97258 3246.196795 \nL 749.849852 3246.196795 \nL 749.849852 3150.275162 \nL 740.97258 3150.275162 \nz\n\" clip-path=\"url(#pb36c16de2e)\" style=\"fill: #ff4500; opacity: 0.8\"/>\n   </g>\n   <g id=\"patch_73\">\n    <path d=\"M 749.849852 3246.196795 \nL 758.727125 3246.196795 \nL 758.727125 3102.314346 \nL 749.849852 3102.314346 \nz\n\" clip-path=\"url(#pb36c16de2e)\" style=\"fill: #ff4500; opacity: 0.8\"/>\n   </g>\n   <g id=\"patch_74\">\n    <path d=\"M 758.727125 3246.196795 \nL 767.604398 3246.196795 \nL 767.604398 3150.275162 \nL 758.727125 3150.275162 \nz\n\" clip-path=\"url(#pb36c16de2e)\" style=\"fill: #ff4500; opacity: 0.8\"/>\n   </g>\n   <g id=\"patch_75\">\n    <path d=\"M 767.604398 3246.196795 \nL 776.48167 3246.196795 \nL 776.48167 3198.235978 \nL 767.604398 3198.235978 \nz\n\" clip-path=\"url(#pb36c16de2e)\" style=\"fill: #ff4500; opacity: 0.8\"/>\n   </g>\n   <g id=\"patch_76\">\n    <path d=\"M 776.48167 3246.196795 \nL 785.358943 3246.196795 \nL 785.358943 3102.314346 \nL 776.48167 3102.314346 \nz\n\" clip-path=\"url(#pb36c16de2e)\" style=\"fill: #ff4500; opacity: 0.8\"/>\n   </g>\n   <g id=\"patch_77\">\n    <path d=\"M 785.358943 3246.196795 \nL 794.236216 3246.196795 \nL 794.236216 3102.314346 \nL 785.358943 3102.314346 \nz\n\" clip-path=\"url(#pb36c16de2e)\" style=\"fill: #ff4500; opacity: 0.8\"/>\n   </g>\n   <g id=\"patch_78\">\n    <path d=\"M 794.236216 3246.196795 \nL 803.113489 3246.196795 \nL 803.113489 3198.235978 \nL 794.236216 3198.235978 \nz\n\" clip-path=\"url(#pb36c16de2e)\" style=\"fill: #ff4500; opacity: 0.8\"/>\n   </g>\n   <g id=\"patch_79\">\n    <path d=\"M 803.113489 3246.196795 \nL 811.990761 3246.196795 \nL 811.990761 3246.196795 \nL 803.113489 3246.196795 \nz\n\" clip-path=\"url(#pb36c16de2e)\" style=\"fill: #ff4500; opacity: 0.8\"/>\n   </g>\n   <g id=\"patch_80\">\n    <path d=\"M 811.990761 3246.196795 \nL 820.868034 3246.196795 \nL 820.868034 3246.196795 \nL 811.990761 3246.196795 \nz\n\" clip-path=\"url(#pb36c16de2e)\" style=\"fill: #ff4500; opacity: 0.8\"/>\n   </g>\n   <g id=\"patch_81\">\n    <path d=\"M 820.868034 3246.196795 \nL 829.745307 3246.196795 \nL 829.745307 3246.196795 \nL 820.868034 3246.196795 \nz\n\" clip-path=\"url(#pb36c16de2e)\" style=\"fill: #ff4500; opacity: 0.8\"/>\n   </g>\n   <g id=\"patch_82\">\n    <path d=\"M 829.745307 3246.196795 \nL 838.62258 3246.196795 \nL 838.62258 3246.196795 \nL 829.745307 3246.196795 \nz\n\" clip-path=\"url(#pb36c16de2e)\" style=\"fill: #ff4500; opacity: 0.8\"/>\n   </g>\n   <g id=\"patch_83\">\n    <path d=\"M 838.62258 3246.196795 \nL 847.499852 3246.196795 \nL 847.499852 3150.275162 \nL 838.62258 3150.275162 \nz\n\" clip-path=\"url(#pb36c16de2e)\" style=\"fill: #ff4500; opacity: 0.8\"/>\n   </g>\n   <g id=\"matplotlib.axis_23\">\n    <g id=\"xtick_144\">\n     <g id=\"line2d_252\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"675.980832\" y=\"3246.196795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_159\">\n      <!-- -10% -->\n      <g transform=\"translate(660.351035 3264.890904)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-2d\"/>\n       <use xlink:href=\"#DejaVuSans-31\" x=\"36.083984\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"99.707031\"/>\n       <use xlink:href=\"#DejaVuSans-25\" x=\"163.330078\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_145\">\n     <g id=\"line2d_253\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"733.98195\" y=\"3246.196795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_160\">\n      <!-- 0% -->\n      <g transform=\"translate(724.384192 3264.890904)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-25\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_146\">\n     <g id=\"line2d_254\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"791.983068\" y=\"3246.196795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_161\">\n      <!-- 10% -->\n      <g transform=\"translate(778.535998 3264.890904)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-25\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_147\">\n     <g id=\"line2d_255\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"849.984186\" y=\"3246.196795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_162\">\n      <!-- 20% -->\n      <g transform=\"translate(836.537116 3264.890904)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-25\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_163\">\n     <!-- Returns -->\n     <g transform=\"translate(733.388281 3281.437263)scale(0.132 -0.132)\">\n      <use xlink:href=\"#DejaVuSans-52\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"64.982422\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"126.505859\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"165.714844\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"229.09375\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"268.457031\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"331.835938\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_24\">\n    <g id=\"ytick_71\">\n     <g id=\"line2d_256\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"661.077125\" y=\"3246.196795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_164\">\n      <!-- 0.0 -->\n      <g transform=\"translate(632.334344 3250.793849)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_72\">\n     <g id=\"line2d_257\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"661.077125\" y=\"3222.216386\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_165\">\n      <!-- 0.5 -->\n      <g transform=\"translate(632.334344 3226.813441)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_73\">\n     <g id=\"line2d_258\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"661.077125\" y=\"3198.235978\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_166\">\n      <!-- 1.0 -->\n      <g transform=\"translate(632.334344 3202.833033)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_74\">\n     <g id=\"line2d_259\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"661.077125\" y=\"3174.25557\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_167\">\n      <!-- 1.5 -->\n      <g transform=\"translate(632.334344 3178.852625)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_75\">\n     <g id=\"line2d_260\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"661.077125\" y=\"3150.275162\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_168\">\n      <!-- 2.0 -->\n      <g transform=\"translate(632.334344 3154.872217)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_76\">\n     <g id=\"line2d_261\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"661.077125\" y=\"3126.294754\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_169\">\n      <!-- 2.5 -->\n      <g transform=\"translate(632.334344 3130.891809)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_77\">\n     <g id=\"line2d_262\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"661.077125\" y=\"3102.314346\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_170\">\n      <!-- 3.0 -->\n      <g transform=\"translate(632.334344 3106.9114)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-33\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_78\">\n     <g id=\"line2d_263\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"661.077125\" y=\"3078.333937\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_171\">\n      <!-- 3.5 -->\n      <g transform=\"translate(632.334344 3082.930992)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-33\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_79\">\n     <g id=\"line2d_264\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"661.077125\" y=\"3054.353529\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_172\">\n      <!-- 4.0 -->\n      <g transform=\"translate(632.334344 3058.950584)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_173\">\n     <!-- Number of months -->\n     <g transform=\"translate(625.589156 3207.407705)rotate(-90)scale(0.132 -0.132)\">\n      <defs>\n       <path id=\"DejaVuSans-4e\" d=\"M 628 4666 \nL 1478 4666 \nL 3547 763 \nL 3547 4666 \nL 4159 4666 \nL 4159 0 \nL 3309 0 \nL 1241 3903 \nL 1241 0 \nL 628 0 \nL 628 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-4e\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"74.804688\"/>\n      <use xlink:href=\"#DejaVuSans-6d\" x=\"138.183594\"/>\n      <use xlink:href=\"#DejaVuSans-62\" x=\"235.595703\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"299.072266\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"360.595703\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"401.708984\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"433.496094\"/>\n      <use xlink:href=\"#DejaVuSans-66\" x=\"494.677734\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"529.882812\"/>\n      <use xlink:href=\"#DejaVuSans-6d\" x=\"561.669922\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"659.082031\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"720.263672\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"783.642578\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"822.851562\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"886.230469\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_265\">\n    <path d=\"M 743.839302 3246.196795 \nL 743.839302 3044.761366 \n\" clip-path=\"url(#pb36c16de2e)\" style=\"fill: none; stroke-dasharray: 14.8,6.4; stroke-dashoffset: 0; stroke: #ffd700; stroke-width: 4\"/>\n   </g>\n   <g id=\"line2d_266\">\n    <path d=\"M 733.98195 3246.196795 \nL 733.98195 3044.761366 \n\" clip-path=\"url(#pb36c16de2e)\" style=\"fill: none; stroke: #000000; stroke-opacity: 0.75; stroke-width: 3; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_84\">\n    <path d=\"M 661.077125 3246.196795 \nL 661.077125 3044.761366 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_85\">\n    <path d=\"M 856.377125 3246.196795 \nL 856.377125 3044.761366 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_86\">\n    <path d=\"M 661.077125 3246.196795 \nL 856.377125 3246.196795 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_87\">\n    <path d=\"M 661.077125 3044.761366 \nL 856.377125 3044.761366 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_174\">\n    <!-- Distribution of monthly returns -->\n    <g transform=\"translate(656.795281 3038.761366)scale(0.132 -0.132)\">\n     <use xlink:href=\"#DejaVuSans-44\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"77.001953\"/>\n     <use xlink:href=\"#DejaVuSans-73\" x=\"104.785156\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"156.884766\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"196.09375\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"237.207031\"/>\n     <use xlink:href=\"#DejaVuSans-62\" x=\"264.990234\"/>\n     <use xlink:href=\"#DejaVuSans-75\" x=\"328.466797\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"391.845703\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"431.054688\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"458.837891\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"520.019531\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"583.398438\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"615.185547\"/>\n     <use xlink:href=\"#DejaVuSans-66\" x=\"676.367188\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"711.572266\"/>\n     <use xlink:href=\"#DejaVuSans-6d\" x=\"743.359375\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"840.771484\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"901.953125\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"965.332031\"/>\n     <use xlink:href=\"#DejaVuSans-68\" x=\"1004.541016\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"1067.919922\"/>\n     <use xlink:href=\"#DejaVuSans-79\" x=\"1095.703125\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"1154.882812\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"1186.669922\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"1225.533203\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"1287.056641\"/>\n     <use xlink:href=\"#DejaVuSans-75\" x=\"1326.265625\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"1389.644531\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"1429.007812\"/>\n     <use xlink:href=\"#DejaVuSans-73\" x=\"1492.386719\"/>\n    </g>\n   </g>\n   <g id=\"legend_8\">\n    <g id=\"patch_88\">\n     <path d=\"M 776.218406 3072.201897 \nL 847.907125 3072.201897 \nQ 850.327125 3072.201897 850.327125 3069.781897 \nL 850.327125 3053.231366 \nQ 850.327125 3050.811366 847.907125 3050.811366 \nL 776.218406 3050.811366 \nQ 773.798406 3050.811366 773.798406 3053.231366 \nL 773.798406 3069.781897 \nQ 773.798406 3072.201897 776.218406 3072.201897 \nz\n\" style=\"fill: #ffffff; opacity: 0.5; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_267\">\n     <path d=\"M 778.638406 3060.610475 \nL 790.738406 3060.610475 \nL 802.838406 3060.610475 \n\" style=\"fill: none; stroke-dasharray: 14.8,6.4; stroke-dashoffset: 0; stroke: #ffd700; stroke-width: 4\"/>\n    </g>\n    <g id=\"text_175\">\n     <!-- Mean -->\n     <g transform=\"translate(812.518406 3064.845475)scale(0.121 -0.121)\">\n      <use xlink:href=\"#DejaVuSans-4d\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"86.279297\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"147.802734\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"209.082031\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_13\">\n   <g id=\"patch_89\">\n    <path d=\"M 75.177125 3548.349937 \nL 856.377125 3548.349937 \nL 856.377125 3346.914509 \nL 75.177125 3346.914509 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"patch_90\">\n    <path d=\"M 101.217125 3478.281281 \nL 309.537125 3478.281281 \nL 309.537125 3466.920545 \nL 101.217125 3466.920545 \nL 101.217125 3478.281281 \nz\n\" clip-path=\"url(#pf53e223b83)\" style=\"fill: #5875a4; stroke: #4c4c4c; stroke-width: 1.5; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_91\">\n    <path d=\"M 361.617125 3484.314257 \nL 569.937125 3484.314257 \nL 569.937125 3458.351246 \nL 361.617125 3458.351246 \nL 361.617125 3484.314257 \nz\n\" clip-path=\"url(#pf53e223b83)\" style=\"fill: #5f9e6e; stroke: #4c4c4c; stroke-width: 1.5; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_92\">\n    <path d=\"M 622.017125 3501.392922 \nL 830.337125 3501.392922 \nL 830.337125 3427.718655 \nL 622.017125 3427.718655 \nL 622.017125 3501.392922 \nz\n\" clip-path=\"url(#pf53e223b83)\" style=\"fill: #c1b37f; stroke: #4c4c4c; stroke-width: 1.5; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"matplotlib.axis_25\">\n    <g id=\"xtick_148\">\n     <g id=\"line2d_268\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"205.377125\" y=\"3548.349937\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_176\">\n      <!-- Daily -->\n      <g transform=\"translate(190.068734 3567.044047)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-44\"/>\n       <use xlink:href=\"#DejaVuSans-61\" x=\"77.001953\"/>\n       <use xlink:href=\"#DejaVuSans-69\" x=\"138.28125\"/>\n       <use xlink:href=\"#DejaVuSans-6c\" x=\"166.064453\"/>\n       <use xlink:href=\"#DejaVuSans-79\" x=\"193.847656\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_149\">\n     <g id=\"line2d_269\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"465.777125\" y=\"3548.349937\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_177\">\n      <!-- Weekly -->\n      <g transform=\"translate(443.940406 3567.044047)scale(0.121 -0.121)\">\n       <defs>\n        <path id=\"DejaVuSans-57\" d=\"M 213 4666 \nL 850 4666 \nL 1831 722 \nL 2809 4666 \nL 3519 4666 \nL 4500 722 \nL 5478 4666 \nL 6119 4666 \nL 4947 0 \nL 4153 0 \nL 3169 4050 \nL 2175 0 \nL 1381 0 \nL 213 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-57\"/>\n       <use xlink:href=\"#DejaVuSans-65\" x=\"93.001953\"/>\n       <use xlink:href=\"#DejaVuSans-65\" x=\"154.525391\"/>\n       <use xlink:href=\"#DejaVuSans-6b\" x=\"216.048828\"/>\n       <use xlink:href=\"#DejaVuSans-6c\" x=\"273.958984\"/>\n       <use xlink:href=\"#DejaVuSans-79\" x=\"301.742188\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_150\">\n     <g id=\"line2d_270\">\n      <g>\n       <use xlink:href=\"#m3df85e8871\" x=\"726.177125\" y=\"3548.349937\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_178\">\n      <!-- Monthly -->\n      <g transform=\"translate(701.953492 3567.044047)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-4d\"/>\n       <use xlink:href=\"#DejaVuSans-6f\" x=\"86.279297\"/>\n       <use xlink:href=\"#DejaVuSans-6e\" x=\"147.460938\"/>\n       <use xlink:href=\"#DejaVuSans-74\" x=\"210.839844\"/>\n       <use xlink:href=\"#DejaVuSans-68\" x=\"250.048828\"/>\n       <use xlink:href=\"#DejaVuSans-6c\" x=\"313.427734\"/>\n       <use xlink:href=\"#DejaVuSans-79\" x=\"341.210938\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_26\">\n    <g id=\"ytick_80\">\n     <g id=\"line2d_271\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"3532.978025\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_179\">\n      <!-- −0.10 -->\n      <g transform=\"translate(28.596297 3537.575079)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"83.789062\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"147.412109\"/>\n       <use xlink:href=\"#DejaVuSans-31\" x=\"179.199219\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"242.822266\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_81\">\n     <g id=\"line2d_272\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"3503.066401\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_180\">\n      <!-- −0.05 -->\n      <g transform=\"translate(28.596297 3507.663456)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"83.789062\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"147.412109\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"179.199219\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"242.822266\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_82\">\n     <g id=\"line2d_273\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"3473.154778\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_181\">\n      <!-- 0.00 -->\n      <g transform=\"translate(38.735719 3477.751833)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_83\">\n     <g id=\"line2d_274\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"3443.243155\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_182\">\n      <!-- 0.05 -->\n      <g transform=\"translate(38.735719 3447.840209)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_84\">\n     <g id=\"line2d_275\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"3413.331531\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_183\">\n      <!-- 0.10 -->\n      <g transform=\"translate(38.735719 3417.928586)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-31\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_85\">\n     <g id=\"line2d_276\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"3383.419908\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_184\">\n      <!-- 0.15 -->\n      <g transform=\"translate(38.735719 3388.016963)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-31\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_86\">\n     <g id=\"line2d_277\">\n      <g>\n       <use xlink:href=\"#m3e69cb0aea\" x=\"75.177125\" y=\"3353.508285\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_185\">\n      <!-- 0.20 -->\n      <g transform=\"translate(38.735719 3358.105339)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_278\">\n    <path d=\"M 205.377125 3478.281281 \nL 205.377125 3495.079589 \n\" clip-path=\"url(#pf53e223b83)\" style=\"fill: none; stroke: #4c4c4c; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_279\">\n    <path d=\"M 205.377125 3466.920545 \nL 205.377125 3449.881092 \n\" clip-path=\"url(#pf53e223b83)\" style=\"fill: none; stroke: #4c4c4c; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_280\">\n    <path d=\"M 153.297125 3495.079589 \nL 257.457125 3495.079589 \n\" clip-path=\"url(#pf53e223b83)\" style=\"fill: none; stroke: #4c4c4c; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_281\">\n    <path d=\"M 153.297125 3449.881092 \nL 257.457125 3449.881092 \n\" clip-path=\"url(#pf53e223b83)\" style=\"fill: none; stroke: #4c4c4c; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_282\">\n    <defs>\n     <path id=\"m336fee2a77\" d=\"M -0 3.535534 \nL 2.12132 0 \nL -0 -3.535534 \nL -2.12132 -0 \nz\n\" style=\"stroke: #4c4c4c; stroke-linejoin: miter\"/>\n    </defs>\n    <g clip-path=\"url(#pf53e223b83)\">\n     <use xlink:href=\"#m336fee2a77\" x=\"205.377125\" y=\"3514.803298\" style=\"fill: #4c4c4c; stroke: #4c4c4c; stroke-linejoin: miter\"/>\n     <use xlink:href=\"#m336fee2a77\" x=\"205.377125\" y=\"3495.355508\" style=\"fill: #4c4c4c; stroke: #4c4c4c; stroke-linejoin: miter\"/>\n     <use xlink:href=\"#m336fee2a77\" x=\"205.377125\" y=\"3517.613305\" style=\"fill: #4c4c4c; stroke: #4c4c4c; stroke-linejoin: miter\"/>\n     <use xlink:href=\"#m336fee2a77\" x=\"205.377125\" y=\"3499.015223\" style=\"fill: #4c4c4c; stroke: #4c4c4c; stroke-linejoin: miter\"/>\n     <use xlink:href=\"#m336fee2a77\" x=\"205.377125\" y=\"3495.969875\" style=\"fill: #4c4c4c; stroke: #4c4c4c; stroke-linejoin: miter\"/>\n     <use xlink:href=\"#m336fee2a77\" x=\"205.377125\" y=\"3507.119109\" style=\"fill: #4c4c4c; stroke: #4c4c4c; stroke-linejoin: miter\"/>\n     <use xlink:href=\"#m336fee2a77\" x=\"205.377125\" y=\"3497.209005\" style=\"fill: #4c4c4c; stroke: #4c4c4c; stroke-linejoin: miter\"/>\n     <use xlink:href=\"#m336fee2a77\" x=\"205.377125\" y=\"3499.290758\" style=\"fill: #4c4c4c; stroke: #4c4c4c; stroke-linejoin: miter\"/>\n     <use xlink:href=\"#m336fee2a77\" x=\"205.377125\" y=\"3497.980408\" style=\"fill: #4c4c4c; stroke: #4c4c4c; stroke-linejoin: miter\"/>\n     <use xlink:href=\"#m336fee2a77\" x=\"205.377125\" y=\"3496.060924\" style=\"fill: #4c4c4c; stroke: #4c4c4c; stroke-linejoin: miter\"/>\n     <use xlink:href=\"#m336fee2a77\" x=\"205.377125\" y=\"3501.556612\" style=\"fill: #4c4c4c; stroke: #4c4c4c; stroke-linejoin: miter\"/>\n     <use xlink:href=\"#m336fee2a77\" x=\"205.377125\" y=\"3501.711983\" style=\"fill: #4c4c4c; stroke: #4c4c4c; stroke-linejoin: miter\"/>\n     <use xlink:href=\"#m336fee2a77\" x=\"205.377125\" y=\"3442.570205\" style=\"fill: #4c4c4c; stroke: #4c4c4c; stroke-linejoin: miter\"/>\n     <use xlink:href=\"#m336fee2a77\" x=\"205.377125\" y=\"3447.678504\" style=\"fill: #4c4c4c; stroke: #4c4c4c; stroke-linejoin: miter\"/>\n     <use xlink:href=\"#m336fee2a77\" x=\"205.377125\" y=\"3449.476105\" style=\"fill: #4c4c4c; stroke: #4c4c4c; stroke-linejoin: miter\"/>\n     <use xlink:href=\"#m336fee2a77\" x=\"205.377125\" y=\"3442.008807\" style=\"fill: #4c4c4c; stroke: #4c4c4c; stroke-linejoin: miter\"/>\n     <use xlink:href=\"#m336fee2a77\" x=\"205.377125\" y=\"3443.539248\" style=\"fill: #4c4c4c; stroke: #4c4c4c; stroke-linejoin: miter\"/>\n     <use xlink:href=\"#m336fee2a77\" x=\"205.377125\" y=\"3445.885147\" style=\"fill: #4c4c4c; stroke: #4c4c4c; stroke-linejoin: miter\"/>\n     <use xlink:href=\"#m336fee2a77\" x=\"205.377125\" y=\"3441.597014\" style=\"fill: #4c4c4c; stroke: #4c4c4c; stroke-linejoin: miter\"/>\n     <use xlink:href=\"#m336fee2a77\" x=\"205.377125\" y=\"3444.189429\" style=\"fill: #4c4c4c; stroke: #4c4c4c; stroke-linejoin: miter\"/>\n     <use xlink:href=\"#m336fee2a77\" x=\"205.377125\" y=\"3449.805625\" style=\"fill: #4c4c4c; stroke: #4c4c4c; stroke-linejoin: miter\"/>\n     <use xlink:href=\"#m336fee2a77\" x=\"205.377125\" y=\"3449.535597\" style=\"fill: #4c4c4c; stroke: #4c4c4c; stroke-linejoin: miter\"/>\n     <use xlink:href=\"#m336fee2a77\" x=\"205.377125\" y=\"3447.345548\" style=\"fill: #4c4c4c; stroke: #4c4c4c; stroke-linejoin: miter\"/>\n    </g>\n   </g>\n   <g id=\"line2d_283\">\n    <path d=\"M 465.777125 3484.314257 \nL 465.777125 3517.061806 \n\" clip-path=\"url(#pf53e223b83)\" style=\"fill: none; stroke: #4c4c4c; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_284\">\n    <path d=\"M 465.777125 3458.351246 \nL 465.777125 3425.359904 \n\" clip-path=\"url(#pf53e223b83)\" style=\"fill: none; stroke: #4c4c4c; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_285\">\n    <path d=\"M 413.697125 3517.061806 \nL 517.857125 3517.061806 \n\" clip-path=\"url(#pf53e223b83)\" style=\"fill: none; stroke: #4c4c4c; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_286\">\n    <path d=\"M 413.697125 3425.359904 \nL 517.857125 3425.359904 \n\" clip-path=\"url(#pf53e223b83)\" style=\"fill: none; stroke: #4c4c4c; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_287\">\n    <g clip-path=\"url(#pf53e223b83)\">\n     <use xlink:href=\"#m336fee2a77\" x=\"465.777125\" y=\"3524.851521\" style=\"fill: #4c4c4c; stroke: #4c4c4c; stroke-linejoin: miter\"/>\n     <use xlink:href=\"#m336fee2a77\" x=\"465.777125\" y=\"3415.120716\" style=\"fill: #4c4c4c; stroke: #4c4c4c; stroke-linejoin: miter\"/>\n     <use xlink:href=\"#m336fee2a77\" x=\"465.777125\" y=\"3393.890695\" style=\"fill: #4c4c4c; stroke: #4c4c4c; stroke-linejoin: miter\"/>\n     <use xlink:href=\"#m336fee2a77\" x=\"465.777125\" y=\"3408.672302\" style=\"fill: #4c4c4c; stroke: #4c4c4c; stroke-linejoin: miter\"/>\n    </g>\n   </g>\n   <g id=\"line2d_288\">\n    <path d=\"M 726.177125 3501.392922 \nL 726.177125 3539.193782 \n\" clip-path=\"url(#pf53e223b83)\" style=\"fill: none; stroke: #4c4c4c; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_289\">\n    <path d=\"M 726.177125 3427.718655 \nL 726.177125 3356.070665 \n\" clip-path=\"url(#pf53e223b83)\" style=\"fill: none; stroke: #4c4c4c; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_290\">\n    <path d=\"M 674.097125 3539.193782 \nL 778.257125 3539.193782 \n\" clip-path=\"url(#pf53e223b83)\" style=\"fill: none; stroke: #4c4c4c; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_291\">\n    <path d=\"M 674.097125 3356.070665 \nL 778.257125 3356.070665 \n\" clip-path=\"url(#pf53e223b83)\" style=\"fill: none; stroke: #4c4c4c; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_292\"/>\n   <g id=\"line2d_293\">\n    <path d=\"M 101.217125 3472.560829 \nL 309.537125 3472.560829 \n\" clip-path=\"url(#pf53e223b83)\" style=\"fill: none; stroke: #4c4c4c; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_294\">\n    <path d=\"M 361.617125 3470.15162 \nL 569.937125 3470.15162 \n\" clip-path=\"url(#pf53e223b83)\" style=\"fill: none; stroke: #4c4c4c; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_295\">\n    <path d=\"M 622.017125 3461.530128 \nL 830.337125 3461.530128 \n\" clip-path=\"url(#pf53e223b83)\" style=\"fill: none; stroke: #4c4c4c; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_93\">\n    <path d=\"M 75.177125 3548.349937 \nL 75.177125 3346.914509 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_94\">\n    <path d=\"M 856.377125 3548.349937 \nL 856.377125 3346.914509 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_95\">\n    <path d=\"M 75.177125 3548.349937 \nL 856.377125 3548.349937 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_96\">\n    <path d=\"M 75.177125 3346.914509 \nL 856.377125 3346.914509 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_186\">\n    <!-- Return quantiles -->\n    <g transform=\"translate(411.425094 3340.914509)scale(0.132 -0.132)\">\n     <defs>\n      <path id=\"DejaVuSans-71\" d=\"M 947 1747 \nQ 947 1113 1208 752 \nQ 1469 391 1925 391 \nQ 2381 391 2643 752 \nQ 2906 1113 2906 1747 \nQ 2906 2381 2643 2742 \nQ 2381 3103 1925 3103 \nQ 1469 3103 1208 2742 \nQ 947 2381 947 1747 \nz\nM 2906 525 \nQ 2725 213 2448 61 \nQ 2172 -91 1784 -91 \nQ 1150 -91 751 415 \nQ 353 922 353 1747 \nQ 353 2572 751 3078 \nQ 1150 3584 1784 3584 \nQ 2172 3584 2448 3432 \nQ 2725 3281 2906 2969 \nL 2906 3500 \nL 3481 3500 \nL 3481 -1331 \nL 2906 -1331 \nL 2906 525 \nz\n\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-52\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"64.982422\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"126.505859\"/>\n     <use xlink:href=\"#DejaVuSans-75\" x=\"165.714844\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"229.09375\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"268.457031\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"331.835938\"/>\n     <use xlink:href=\"#DejaVuSans-71\" x=\"363.623047\"/>\n     <use xlink:href=\"#DejaVuSans-75\" x=\"427.099609\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"490.478516\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"551.757812\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"615.136719\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"654.345703\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"682.128906\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"709.912109\"/>\n     <use xlink:href=\"#DejaVuSans-73\" x=\"771.435547\"/>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p359f445ed0\">\n   <rect x=\"75.177125\" y=\"23.229937\" width=\"781.2\" height=\"503.588571\"/>\n  </clipPath>\n  <clipPath id=\"p5b198ceb87\">\n   <rect x=\"75.177125\" y=\"627.536223\" width=\"781.2\" height=\"201.435429\"/>\n  </clipPath>\n  <clipPath id=\"p3989b2a8fc\">\n   <rect x=\"75.177125\" y=\"929.689366\" width=\"781.2\" height=\"201.435429\"/>\n  </clipPath>\n  <clipPath id=\"p542aba9f2e\">\n   <rect x=\"75.177125\" y=\"1231.842509\" width=\"781.2\" height=\"201.435429\"/>\n  </clipPath>\n  <clipPath id=\"paf90d92ba9\">\n   <rect x=\"75.177125\" y=\"1533.995652\" width=\"781.2\" height=\"201.435429\"/>\n  </clipPath>\n  <clipPath id=\"p437e60ca80\">\n   <rect x=\"75.177125\" y=\"1836.148795\" width=\"781.2\" height=\"201.435429\"/>\n  </clipPath>\n  <clipPath id=\"pf783f5210c\">\n   <rect x=\"75.177125\" y=\"2138.301937\" width=\"781.2\" height=\"201.435429\"/>\n  </clipPath>\n  <clipPath id=\"p1bedd59ef4\">\n   <rect x=\"75.177125\" y=\"2440.45508\" width=\"781.2\" height=\"201.435429\"/>\n  </clipPath>\n  <clipPath id=\"p742258926d\">\n   <rect x=\"75.177125\" y=\"2742.608223\" width=\"781.2\" height=\"201.435429\"/>\n  </clipPath>\n  <clipPath id=\"pf6d595b45d\">\n   <rect x=\"75.177125\" y=\"3044.761366\" width=\"195.3\" height=\"201.435429\"/>\n  </clipPath>\n  <clipPath id=\"p5f0ed3a3c6\">\n   <rect x=\"368.127125\" y=\"3044.761366\" width=\"195.3\" height=\"201.435429\"/>\n  </clipPath>\n  <clipPath id=\"pb36c16de2e\">\n   <rect x=\"661.077125\" y=\"3044.761366\" width=\"195.3\" height=\"201.435429\"/>\n  </clipPath>\n  <clipPath id=\"pf53e223b83\">\n   <rect x=\"75.177125\" y=\"3346.914509\" width=\"781.2\" height=\"201.435429\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "text/plain": [
       "<Figure size 1400x7200 with 13 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"382.537328pt\" height=\"369.110157pt\" viewBox=\"0 0 382.537328 369.110157\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2022-10-18T19:00:38.978024</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.5.3, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M -0 369.110157 \nL 382.537328 369.110157 \nL 382.537328 0 \nL -0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 62.857328 316.989937 \nL 375.337328 316.989937 \nL 375.337328 23.229937 \nL 62.857328 23.229937 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path id=\"m7fa8af279c\" d=\"M 0 0 \nL 0 6 \n\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m7fa8af279c\" x=\"76.777176\" y=\"316.989937\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 2020-01 -->\n      <g transform=\"translate(31.735142 359.730871)rotate(-30)scale(0.121 -0.121)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-2d\" d=\"M 313 2009 \nL 1997 2009 \nL 1997 1497 \nL 313 1497 \nL 313 2009 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n       <use xlink:href=\"#DejaVuSans-2d\" x=\"254.492188\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"290.576172\"/>\n       <use xlink:href=\"#DejaVuSans-31\" x=\"354.199219\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use xlink:href=\"#m7fa8af279c\" x=\"111.115637\" y=\"316.989937\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 2020-05 -->\n      <g transform=\"translate(66.073604 359.730871)rotate(-30)scale(0.121 -0.121)\">\n       <defs>\n        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n       <use xlink:href=\"#DejaVuSans-2d\" x=\"254.492188\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"290.576172\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"354.199219\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use xlink:href=\"#m7fa8af279c\" x=\"146.021677\" y=\"316.989937\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 2020-09 -->\n      <g transform=\"translate(100.979643 359.730871)rotate(-30)scale(0.121 -0.121)\">\n       <defs>\n        <path id=\"DejaVuSans-39\" d=\"M 703 97 \nL 703 672 \nQ 941 559 1184 500 \nQ 1428 441 1663 441 \nQ 2288 441 2617 861 \nQ 2947 1281 2994 2138 \nQ 2813 1869 2534 1725 \nQ 2256 1581 1919 1581 \nQ 1219 1581 811 2004 \nQ 403 2428 403 3163 \nQ 403 3881 828 4315 \nQ 1253 4750 1959 4750 \nQ 2769 4750 3195 4129 \nQ 3622 3509 3622 2328 \nQ 3622 1225 3098 567 \nQ 2575 -91 1691 -91 \nQ 1453 -91 1209 -44 \nQ 966 3 703 97 \nz\nM 1959 2075 \nQ 2384 2075 2632 2365 \nQ 2881 2656 2881 3163 \nQ 2881 3666 2632 3958 \nQ 2384 4250 1959 4250 \nQ 1534 4250 1286 3958 \nQ 1038 3666 1038 3163 \nQ 1038 2656 1286 2365 \nQ 1534 2075 1959 2075 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n       <use xlink:href=\"#DejaVuSans-2d\" x=\"254.492188\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"290.576172\"/>\n       <use xlink:href=\"#DejaVuSans-39\" x=\"354.199219\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#m7fa8af279c\" x=\"180.643927\" y=\"316.989937\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 2021-01 -->\n      <g transform=\"translate(135.601894 359.730871)rotate(-30)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-31\" x=\"190.869141\"/>\n       <use xlink:href=\"#DejaVuSans-2d\" x=\"254.492188\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"290.576172\"/>\n       <use xlink:href=\"#DejaVuSans-31\" x=\"354.199219\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use xlink:href=\"#m7fa8af279c\" x=\"214.6986\" y=\"316.989937\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 2021-05 -->\n      <g transform=\"translate(169.656566 359.730871)rotate(-30)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-31\" x=\"190.869141\"/>\n       <use xlink:href=\"#DejaVuSans-2d\" x=\"254.492188\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"290.576172\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"354.199219\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#m7fa8af279c\" x=\"249.604639\" y=\"316.989937\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 2021-09 -->\n      <g transform=\"translate(204.562606 359.730871)rotate(-30)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-31\" x=\"190.869141\"/>\n       <use xlink:href=\"#DejaVuSans-2d\" x=\"254.492188\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"290.576172\"/>\n       <use xlink:href=\"#DejaVuSans-39\" x=\"354.199219\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use xlink:href=\"#m7fa8af279c\" x=\"284.226889\" y=\"316.989937\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 2022-01 -->\n      <g transform=\"translate(239.184856 359.730871)rotate(-30)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"190.869141\"/>\n       <use xlink:href=\"#DejaVuSans-2d\" x=\"254.492188\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"290.576172\"/>\n       <use xlink:href=\"#DejaVuSans-31\" x=\"354.199219\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#m7fa8af279c\" x=\"318.281562\" y=\"316.989937\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 2022-05 -->\n      <g transform=\"translate(273.239529 359.730871)rotate(-30)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"190.869141\"/>\n       <use xlink:href=\"#DejaVuSans-2d\" x=\"254.492188\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"290.576172\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"354.199219\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_9\">\n      <g>\n       <use xlink:href=\"#m7fa8af279c\" x=\"353.187601\" y=\"316.989937\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 2022-09 -->\n      <g transform=\"translate(308.145568 359.730871)rotate(-30)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"190.869141\"/>\n       <use xlink:href=\"#DejaVuSans-2d\" x=\"254.492188\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"290.576172\"/>\n       <use xlink:href=\"#DejaVuSans-39\" x=\"354.199219\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_10\">\n      <defs>\n       <path id=\"m84bbb6fa96\" d=\"M 0 0 \nL -6 0 \n\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m84bbb6fa96\" x=\"62.857328\" y=\"308.814552\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- −0.2 -->\n      <g transform=\"translate(23.975125 313.411607)scale(0.121 -0.121)\">\n       <defs>\n        <path id=\"DejaVuSans-2212\" d=\"M 678 2272 \nL 4684 2272 \nL 4684 1741 \nL 678 1741 \nL 678 2272 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"83.789062\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"147.412109\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"179.199219\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_11\">\n      <g>\n       <use xlink:href=\"#m84bbb6fa96\" x=\"62.857328\" y=\"272.007653\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.0 -->\n      <g transform=\"translate(34.114547 276.604708)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_12\">\n      <g>\n       <use xlink:href=\"#m84bbb6fa96\" x=\"62.857328\" y=\"235.200754\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.2 -->\n      <g transform=\"translate(34.114547 239.797809)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_13\">\n      <g>\n       <use xlink:href=\"#m84bbb6fa96\" x=\"62.857328\" y=\"198.393855\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 0.4 -->\n      <g transform=\"translate(34.114547 202.99091)scale(0.121 -0.121)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_14\">\n      <g>\n       <use xlink:href=\"#m84bbb6fa96\" x=\"62.857328\" y=\"161.586956\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 0.6 -->\n      <g transform=\"translate(34.114547 166.18401)scale(0.121 -0.121)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_15\">\n      <g>\n       <use xlink:href=\"#m84bbb6fa96\" x=\"62.857328\" y=\"124.780057\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 0.8 -->\n      <g transform=\"translate(34.114547 129.377111)scale(0.121 -0.121)\">\n       <defs>\n        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_16\">\n      <g>\n       <use xlink:href=\"#m84bbb6fa96\" x=\"62.857328\" y=\"87.973158\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 1.0 -->\n      <g transform=\"translate(34.114547 92.570212)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_17\">\n      <g>\n       <use xlink:href=\"#m84bbb6fa96\" x=\"62.857328\" y=\"51.166258\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_17\">\n      <!-- 1.2 -->\n      <g transform=\"translate(34.114547 55.763313)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_18\">\n     <!-- Returns -->\n     <g transform=\"translate(17.229938 195.448781)rotate(-90)scale(0.132 -0.132)\">\n      <defs>\n       <path id=\"DejaVuSans-52\" d=\"M 2841 2188 \nQ 3044 2119 3236 1894 \nQ 3428 1669 3622 1275 \nL 4263 0 \nL 3584 0 \nL 2988 1197 \nQ 2756 1666 2539 1819 \nQ 2322 1972 1947 1972 \nL 1259 1972 \nL 1259 0 \nL 628 0 \nL 628 4666 \nL 2053 4666 \nQ 2853 4666 3247 4331 \nQ 3641 3997 3641 3322 \nQ 3641 2881 3436 2590 \nQ 3231 2300 2841 2188 \nz\nM 1259 4147 \nL 1259 2491 \nL 2053 2491 \nQ 2509 2491 2742 2702 \nQ 2975 2913 2975 3322 \nQ 2975 3731 2742 3939 \nQ 2509 4147 2053 4147 \nL 1259 4147 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-75\" d=\"M 544 1381 \nL 544 3500 \nL 1119 3500 \nL 1119 1403 \nQ 1119 906 1312 657 \nQ 1506 409 1894 409 \nQ 2359 409 2629 706 \nQ 2900 1003 2900 1516 \nL 2900 3500 \nL 3475 3500 \nL 3475 0 \nL 2900 0 \nL 2900 538 \nQ 2691 219 2414 64 \nQ 2138 -91 1772 -91 \nQ 1169 -91 856 284 \nQ 544 659 544 1381 \nz\nM 1991 3584 \nL 1991 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-52\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"64.982422\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"126.505859\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"165.714844\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"229.09375\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"268.457031\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"331.835938\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_18\">\n    <path d=\"M 77.060964 272.007653 \nL 78.19612 272.76666 \nL 78.479909 271.460317 \nL 78.763698 273.226354 \nL 79.047487 270.551096 \nL 79.331276 270.147735 \nL 80.182643 267.891775 \nL 80.466432 268.686826 \nL 80.750221 269.970876 \nL 81.03401 270.314383 \nL 81.317799 268.685185 \nL 82.169165 267.161938 \nL 82.452954 269.411044 \nL 82.736743 268.261359 \nL 83.020532 274.46771 \nL 86.142211 287.108794 \nL 86.425999 282.54569 \nL 86.993577 277.632773 \nL 87.277366 276.944927 \nL 88.128733 277.144608 \nL 88.412522 275.631225 \nL 88.696311 272.705277 \nL 88.9801 274.986514 \nL 89.263889 274.359273 \nL 90.115256 270.359632 \nL 90.682834 271.206355 \nL 90.966622 268.601752 \nL 91.250411 267.868157 \nL 92.101778 269.047166 \nL 92.385567 269.089613 \nL 92.669356 270.700692 \nL 92.953145 269.040529 \nL 93.236934 275.359659 \nL 94.655879 267.129491 \nL 94.939668 262.816005 \nL 95.223457 266.576286 \nL 96.074823 273.520081 \nL 96.358612 269.597884 \nL 96.642401 271.529641 \nL 96.92619 275.809422 \nL 98.061346 284.893055 \nL 98.345135 286.459872 \nL 98.628924 289.016901 \nL 98.912713 292.973684 \nL 99.196502 288.498193 \nL 100.047868 293.687658 \nL 100.615446 284.913596 \nL 100.899235 285.535587 \nL 101.183024 284.115914 \nL 102.034391 288.18182 \nL 102.31818 287.533712 \nL 102.601969 287.615319 \nL 102.885758 286.377874 \nL 103.169547 287.282996 \nL 104.304703 284.672942 \nL 104.588492 284.862984 \nL 104.87228 283.781381 \nL 105.156069 284.367439 \nL 106.007436 285.274194 \nL 106.291225 281.383077 \nL 106.575014 283.369318 \nL 106.858803 283.22375 \nL 107.142592 280.173433 \nL 107.993959 279.433946 \nL 108.277748 281.082076 \nL 108.561537 280.514861 \nL 108.845326 281.036316 \nL 109.129115 282.517738 \nL 109.980481 281.470012 \nL 110.26427 278.028139 \nL 110.548059 278.980734 \nL 110.831848 276.061793 \nL 112.534582 274.595237 \nL 112.818371 274.617831 \nL 113.10216 273.319377 \nL 113.953526 273.292322 \nL 114.237315 273.023581 \nL 114.521104 271.944381 \nL 114.804893 274.439241 \nL 115.088682 275.030733 \nL 115.940049 274.028307 \nL 116.223838 272.462231 \nL 116.791416 276.073271 \nL 117.075205 280.79694 \nL 117.926572 279.932053 \nL 118.210361 278.268896 \nL 118.494149 278.47631 \nL 118.777938 278.269252 \nL 119.061727 278.379752 \nL 119.913094 274.251897 \nL 120.196883 274.035859 \nL 120.480672 272.648546 \nL 120.764461 273.696793 \nL 121.04825 278.344612 \nL 121.899617 278.469867 \nL 122.467195 274.288852 \nL 122.750984 275.518312 \nL 123.034772 274.949467 \nL 123.886139 277.598245 \nL 124.453717 272.581983 \nL 124.737506 273.057634 \nL 125.021295 268.160177 \nL 125.872662 269.002577 \nL 126.156451 266.858369 \nL 127.859184 266.197166 \nL 128.426762 261.183934 \nL 128.710551 259.803307 \nL 128.99434 260.261703 \nL 129.845707 255.939797 \nL 130.129496 252.70004 \nL 130.413285 253.058681 \nL 130.697074 250.137361 \nL 130.980863 248.64272 \nL 131.83223 238.039446 \nL 132.116019 238.286802 \nL 132.399807 235.693799 \nL 132.683596 252.069312 \nL 132.967385 251.452861 \nL 133.818752 246.741679 \nL 134.102541 240.428132 \nL 134.38633 239.740056 \nL 134.670119 236.895397 \nL 134.953908 246.368692 \nL 135.805275 242.98775 \nL 136.089064 241.276628 \nL 136.94043 226.028434 \nL 137.791797 224.4636 \nL 138.075586 228.065199 \nL 138.359375 225.891804 \nL 138.643164 224.916003 \nL 138.926953 229.003325 \nL 139.77832 228.317782 \nL 140.062109 230.173737 \nL 140.345898 235.302281 \nL 140.629687 234.736618 \nL 140.913476 230.78237 \nL 141.764842 225.635384 \nL 142.048631 224.724634 \nL 142.33242 226.618355 \nL 142.616209 230.162453 \nL 142.899998 227.776582 \nL 143.751365 224.803515 \nL 144.035154 225.356554 \nL 144.318943 228.37871 \nL 144.602732 225.514517 \nL 144.886521 218.696709 \nL 145.737888 217.84169 \nL 146.021677 215.988707 \nL 146.305465 217.443135 \nL 146.589254 217.195707 \nL 146.873043 218.415344 \nL 147.72441 223.764853 \nL 148.008199 223.268942 \nL 148.291988 228.55819 \nL 148.575777 226.228474 \nL 148.859566 222.35955 \nL 149.710933 221.436042 \nL 150.278511 222.747896 \nL 150.5623 228.393494 \nL 150.846088 224.154053 \nL 151.697455 224.794927 \nL 151.981244 228.328781 \nL 152.265033 227.281805 \nL 152.548822 231.068766 \nL 152.832611 231.06781 \nL 153.683978 230.408578 \nL 153.967767 227.414684 \nL 154.251556 227.802607 \nL 156.805656 220.842921 \nL 157.940812 210.450478 \nL 158.792179 217.629131 \nL 159.643546 220.435478 \nL 159.927334 218.653538 \nL 160.211123 221.718071 \nL 160.494912 222.648276 \nL 160.778701 225.405471 \nL 161.630068 227.156611 \nL 161.913857 224.583792 \nL 162.197646 219.388829 \nL 162.765224 223.367534 \nL 163.616591 222.962573 \nL 163.90038 217.83706 \nL 164.184169 215.087052 \nL 164.467957 213.663051 \nL 164.751746 215.966202 \nL 165.603113 213.51709 \nL 166.170691 218.978198 \nL 166.45448 217.795209 \nL 166.738269 217.687419 \nL 167.589636 215.03113 \nL 167.873425 220.464012 \nL 168.157214 219.142505 \nL 168.441003 211.781922 \nL 168.724792 208.143468 \nL 169.576158 204.867246 \nL 169.859947 204.533614 \nL 170.143736 209.09402 \nL 170.427525 206.253016 \nL 170.711314 201.46212 \nL 171.562681 205.695754 \nL 171.84647 198.096265 \nL 172.130259 199.595744 \nL 172.414048 199.031824 \nL 172.697837 195.782728 \nL 173.549204 197.362874 \nL 173.832992 198.224673 \nL 174.116781 200.794507 \nL 174.40057 199.272821 \nL 174.684359 199.471085 \nL 175.535726 197.744334 \nL 176.103304 188.855218 \nL 176.387093 188.686886 \nL 176.670882 189.376488 \nL 177.522249 182.972313 \nL 177.806038 188.941022 \nL 178.089827 180.020854 \nL 178.373615 182.381251 \nL 178.657404 175.295619 \nL 179.508771 169.527026 \nL 179.79256 171.146658 \nL 180.360138 159.687364 \nL 181.495294 148.157953 \nL 181.779083 138.025637 \nL 182.062872 133.899605 \nL 182.346661 120.180872 \nL 182.63045 120.421207 \nL 183.481816 128.232869 \nL 183.765605 117.482372 \nL 184.049394 119.849839 \nL 184.333183 131.480289 \nL 184.616972 133.590781 \nL 185.468339 128.233547 \nL 185.752128 138.663508 \nL 186.035917 134.220741 \nL 186.603495 118.941513 \nL 187.454862 116.303687 \nL 187.73865 119.431015 \nL 188.022439 119.536319 \nL 188.306228 132.369814 \nL 188.590017 131.393869 \nL 190.008962 110.770739 \nL 190.292751 107.965127 \nL 190.57654 111.316026 \nL 191.427907 93.368438 \nL 191.995485 74.158574 \nL 194.265796 66.791695 \nL 194.549585 75.431809 \nL 195.400952 81.293877 \nL 195.96853 95.377915 \nL 196.252319 84.962877 \nL 196.536108 93.873646 \nL 197.387474 91.988067 \nL 197.671263 103.559399 \nL 197.955052 97.272092 \nL 198.238841 117.641072 \nL 198.52263 125.170731 \nL 199.373997 138.474683 \nL 199.657786 149.406906 \nL 200.225364 124.650358 \nL 200.509153 114.391612 \nL 201.360519 126.055772 \nL 201.644308 114.593488 \nL 201.928097 111.206835 \nL 202.211886 109.94476 \nL 202.495675 118.994967 \nL 203.347042 121.406468 \nL 203.630831 126.824045 \nL 203.91462 136.354796 \nL 204.198409 132.360257 \nL 204.482198 117.605648 \nL 205.333565 111.551286 \nL 205.617354 110.942321 \nL 205.901142 122.705714 \nL 206.46872 102.075583 \nL 207.603876 107.28403 \nL 207.887665 115.101101 \nL 208.171454 105.240632 \nL 208.455243 116.135185 \nL 209.30661 125.229637 \nL 209.874188 122.438789 \nL 210.157977 125.092776 \nL 210.441766 123.193801 \nL 211.576921 111.73144 \nL 211.86071 110.51231 \nL 212.144499 112.526682 \nL 212.428288 110.78886 \nL 213.279655 115.26238 \nL 213.563444 114.18759 \nL 213.847233 111.046609 \nL 214.131022 114.078873 \nL 214.414811 115.114989 \nL 216.117544 115.380766 \nL 216.401333 119.707226 \nL 217.2527 116.010168 \nL 217.820278 112.283623 \nL 218.104067 116.731344 \nL 218.387856 109.329127 \nL 219.239223 103.176014 \nL 219.523012 103.963932 \nL 220.090589 104.920761 \nL 220.374378 108.648524 \nL 221.225745 108.061575 \nL 221.509534 96.449185 \nL 221.793323 95.506677 \nL 222.077112 96.739364 \nL 222.360901 97.000532 \nL 223.212268 95.819725 \nL 223.779846 101.100439 \nL 224.063635 102.653636 \nL 224.347423 99.984703 \nL 225.19879 99.457365 \nL 225.482579 96.118501 \nL 225.766368 95.556798 \nL 226.050157 91.377797 \nL 226.333946 98.247589 \nL 227.469102 99.422386 \nL 227.752891 107.513881 \nL 228.03668 110.524693 \nL 228.320469 108.222866 \nL 229.171835 108.549709 \nL 229.455624 108.456075 \nL 229.739413 118.981683 \nL 230.023202 118.080912 \nL 230.306991 114.738121 \nL 231.158358 110.997712 \nL 231.442147 114.460696 \nL 231.725936 111.915798 \nL 232.009725 118.317294 \nL 232.293514 128.8714 \nL 233.42867 120.474708 \nL 233.712458 112.94693 \nL 233.996247 115.426224 \nL 234.280036 121.192843 \nL 235.415192 113.1243 \nL 235.698981 125.092441 \nL 236.266559 117.117632 \nL 237.117926 113.56722 \nL 237.401715 114.682875 \nL 237.685504 112.383018 \nL 237.969293 113.10634 \nL 238.253081 117.516296 \nL 239.104448 123.214166 \nL 239.388237 137.754978 \nL 239.672026 140.190365 \nL 239.955815 133.407021 \nL 240.239604 130.725578 \nL 241.090971 113.564585 \nL 241.37476 112.286464 \nL 241.658549 104.700327 \nL 241.942338 100.510404 \nL 242.226127 104.734906 \nL 243.077493 102.422584 \nL 243.361282 97.262122 \nL 243.645071 101.142648 \nL 243.92886 100.73353 \nL 244.212649 102.765954 \nL 245.064016 102.321629 \nL 245.347805 110.05142 \nL 245.915383 114.522011 \nL 246.199172 128.694516 \nL 247.334327 109.604422 \nL 247.618116 104.397145 \nL 247.901905 110.648553 \nL 248.185694 105.658011 \nL 249.037061 100.388631 \nL 249.32085 102.206491 \nL 249.604639 97.128308 \nL 249.888428 100.520317 \nL 250.172217 100.713596 \nL 251.307373 85.885568 \nL 251.591162 94.702606 \nL 251.874951 93.333773 \nL 252.158739 79.17718 \nL 253.293895 74.857615 \nL 253.577684 83.82093 \nL 253.861473 80.660682 \nL 254.145262 65.840018 \nL 255.564207 71.979226 \nL 255.847996 71.619072 \nL 256.131785 62.198722 \nL 256.983151 56.075663 \nL 257.26694 63.786407 \nL 257.550729 67.209878 \nL 257.834518 66.874092 \nL 260.10483 58.083849 \nL 260.956197 64.551684 \nL 261.239985 63.663474 \nL 261.523774 53.769397 \nL 261.807563 51.846151 \nL 262.091352 48.504877 \nL 262.942719 49.454576 \nL 263.510297 45.145138 \nL 263.794086 47.713241 \nL 264.077875 45.937774 \nL 264.929242 42.760396 \nL 265.213031 44.851504 \nL 265.780608 52.917051 \nL 266.064397 48.306005 \nL 267.199553 59.9931 \nL 267.483342 65.657211 \nL 267.767131 58.922052 \nL 268.05092 60.047732 \nL 268.902287 58.869406 \nL 269.186076 59.733018 \nL 269.469865 63.539269 \nL 269.753654 59.732082 \nL 270.037443 58.481505 \nL 271.172598 54.478279 \nL 271.456387 55.953078 \nL 271.740176 61.052576 \nL 272.023965 56.397777 \nL 272.875332 57.385293 \nL 273.159121 58.957928 \nL 273.44291 59.39275 \nL 274.010488 64.127442 \nL 274.861855 65.920248 \nL 275.145643 69.280043 \nL 275.713221 64.95364 \nL 275.99701 59.997576 \nL 276.848377 58.308382 \nL 277.132166 57.285903 \nL 277.415955 46.738241 \nL 277.699744 41.349571 \nL 277.983533 41.381618 \nL 278.8349 36.582665 \nL 279.118689 39.889079 \nL 279.402478 46.39925 \nL 279.970055 65.617184 \nL 280.821422 65.106467 \nL 281.389 70.274545 \nL 281.672789 69.296392 \nL 281.956578 72.601877 \nL 282.807945 73.491778 \nL 283.091734 69.820014 \nL 283.375523 84.608346 \nL 283.659312 82.627247 \nL 283.943101 82.272996 \nL 285.078256 84.013638 \nL 285.362045 88.143747 \nL 285.645834 90.592723 \nL 286.78099 90.209951 \nL 287.064779 93.723706 \nL 287.348568 91.814765 \nL 287.632357 100.312482 \nL 287.916146 101.638098 \nL 288.767512 100.406921 \nL 289.051301 98.599916 \nL 289.33509 100.93561 \nL 289.618879 101.780365 \nL 289.902668 102.084115 \nL 290.754035 102.732407 \nL 291.037824 110.576792 \nL 291.321613 109.017128 \nL 291.889191 123.533449 \nL 294.72708 120.6043 \nL 295.010869 122.557224 \nL 295.294658 114.044252 \nL 295.578447 112.906703 \nL 295.862236 108.086046 \nL 296.713603 107.358498 \nL 296.997392 104.823156 \nL 297.281181 103.662614 \nL 297.56497 104.971255 \nL 297.848759 103.614561 \nL 298.700125 104.653287 \nL 298.983914 108.395542 \nL 299.267703 106.518496 \nL 299.551492 114.628486 \nL 299.835281 113.467545 \nL 300.686648 112.145897 \nL 300.970437 110.081641 \nL 301.254226 111.15859 \nL 301.538015 110.944781 \nL 301.821804 114.679506 \nL 302.67317 124.374401 \nL 302.956959 130.906077 \nL 303.240748 133.659441 \nL 303.524537 131.536264 \nL 303.808326 127.711001 \nL 304.659693 132.336761 \nL 304.943482 147.705079 \nL 305.227271 134.402654 \nL 305.51106 127.572981 \nL 305.794849 124.359208 \nL 306.646216 126.3927 \nL 306.930005 127.844489 \nL 307.213793 127.036797 \nL 307.781371 134.79852 \nL 308.632738 136.433213 \nL 308.916527 135.90251 \nL 309.200316 125.2538 \nL 309.484105 128.378704 \nL 309.767894 122.880816 \nL 311.470628 127.085884 \nL 311.754416 126.245155 \nL 312.605783 134.042289 \nL 312.889572 128.492182 \nL 313.173361 130.336772 \nL 313.45715 127.04006 \nL 313.740939 128.459206 \nL 314.592306 132.137464 \nL 315.443673 143.090919 \nL 315.727462 143.128199 \nL 316.578828 158.065449 \nL 316.862617 157.856397 \nL 317.713984 144.559348 \nL 319.416718 140.047264 \nL 319.700507 148.742659 \nL 320.551874 151.092484 \nL 320.835663 151.176449 \nL 321.119451 142.553583 \nL 321.40324 143.358275 \nL 321.687029 141.437546 \nL 322.538396 143.234808 \nL 322.822185 138.107779 \nL 323.105974 137.080398 \nL 323.389763 139.917574 \nL 323.673552 132.429815 \nL 324.524919 135.844545 \nL 324.808708 141.019966 \nL 325.092497 137.151741 \nL 325.660074 136.332232 \nL 326.511441 133.052717 \nL 326.79523 133.24999 \nL 327.079019 134.502602 \nL 327.362808 134.534124 \nL 328.497964 133.152793 \nL 328.781753 132.54795 \nL 329.065542 127.186485 \nL 329.349331 129.465704 \nL 329.63312 124.736412 \nL 330.484486 130.978503 \nL 331.052064 118.387387 \nL 331.335853 122.817373 \nL 331.619642 113.377618 \nL 332.471009 114.546094 \nL 332.754798 115.185454 \nL 333.038587 120.586565 \nL 333.606165 110.263718 \nL 334.457532 105.25585 \nL 334.74132 106.152631 \nL 335.025109 108.916281 \nL 335.308898 101.377911 \nL 335.592687 104.670113 \nL 336.444054 106.251343 \nL 336.727843 106.343741 \nL 337.011632 114.339328 \nL 337.295421 113.782129 \nL 337.57921 114.407338 \nL 338.430577 121.691629 \nL 338.714366 125.654123 \nL 338.998155 123.513806 \nL 339.281944 122.85728 \nL 339.565732 128.33104 \nL 340.417099 122.829854 \nL 340.700888 125.527216 \nL 340.984677 123.031859 \nL 341.268466 125.254614 \nL 341.552255 124.876853 \nL 342.403622 126.235589 \nL 342.687411 126.469338 \nL 342.9712 129.435 \nL 343.254989 129.188554 \nL 343.538778 137.380559 \nL 344.390144 139.517503 \nL 344.673933 146.043725 \nL 344.957722 145.661927 \nL 345.5253 138.633033 \nL 346.376667 138.238482 \nL 346.660456 136.583431 \nL 346.944245 139.471422 \nL 347.228034 134.471305 \nL 347.511823 131.913315 \nL 348.36319 133.600919 \nL 348.646978 135.869741 \nL 348.930767 134.670662 \nL 349.498345 142.085029 \nL 350.349712 136.705412 \nL 350.633501 137.75824 \nL 350.91729 142.627168 \nL 351.201079 139.145168 \nL 351.484868 139.085746 \nL 352.620024 141.786578 \nL 352.903813 143.502209 \nL 353.187601 146.181588 \nL 353.47139 150.644318 \nL 354.322757 154.341462 \nL 354.606546 147.52321 \nL 355.174124 148.770608 \nL 355.457913 145.743854 \nL 356.593069 142.83654 \nL 357.160647 149.248406 \nL 357.444436 157.490214 \nL 358.295802 158.227808 \nL 358.579591 159.662838 \nL 358.86338 162.341976 \nL 359.147169 163.349662 \nL 359.430958 164.809875 \nL 360.282325 164.674848 \nL 360.566114 160.263933 \nL 360.849903 163.893497 \nL 361.133692 163.306721 \nL 361.133692 163.306721 \n\" clip-path=\"url(#p94186ddf35)\" style=\"fill: none; stroke: #228b22; stroke-opacity: 0.7; stroke-width: 2; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_19\">\n    <path d=\"M 77.060964 272.007653 \nL 77.344753 272.755132 \nL 78.19612 274.031916 \nL 78.479909 273.009025 \nL 78.763698 275.162226 \nL 79.047487 273.394238 \nL 79.331276 273.374268 \nL 80.182643 272.049612 \nL 80.466432 272.616857 \nL 81.03401 274.85019 \nL 81.317799 274.250018 \nL 82.169165 273.486826 \nL 82.452954 276.69485 \nL 82.736743 276.351519 \nL 83.020532 281.435533 \nL 86.142211 293.665473 \nL 86.425999 289.642367 \nL 86.709788 288.556397 \nL 86.993577 286.056317 \nL 87.277366 286.2455 \nL 88.128733 286.343524 \nL 88.412522 284.56957 \nL 88.696311 283.633069 \nL 88.9801 284.830251 \nL 90.115256 280.388981 \nL 90.399045 281.917532 \nL 90.682834 281.955329 \nL 90.966622 278.715075 \nL 91.250411 279.313163 \nL 92.101778 281.582007 \nL 92.385567 282.815074 \nL 92.669356 283.270607 \nL 92.953145 282.653573 \nL 93.236934 288.07157 \nL 94.088301 282.900678 \nL 94.37209 282.093455 \nL 94.655879 280.538032 \nL 94.939668 276.34011 \nL 95.223457 279.509848 \nL 96.074823 285.226188 \nL 96.358612 281.928345 \nL 96.92619 286.82473 \nL 97.209979 289.397714 \nL 98.061346 295.63454 \nL 98.345135 296.136611 \nL 98.912713 303.031674 \nL 99.196502 299.540903 \nL 100.047868 303.63721 \nL 100.615446 295.267547 \nL 100.899235 295.916924 \nL 101.183024 295.192631 \nL 102.034391 295.871571 \nL 102.31818 295.911048 \nL 102.601969 296.345675 \nL 102.885758 294.094575 \nL 103.169547 294.753217 \nL 104.304703 291.860558 \nL 104.588492 292.66556 \nL 104.87228 292.147455 \nL 105.156069 292.310684 \nL 106.007436 292.946592 \nL 106.291225 290.174708 \nL 106.575014 291.438887 \nL 106.858803 291.214217 \nL 107.142592 288.784062 \nL 107.993959 288.145885 \nL 108.277748 290.245397 \nL 108.561537 289.072151 \nL 108.845326 289.463705 \nL 109.129115 290.751998 \nL 109.980481 289.013627 \nL 110.831848 285.638337 \nL 112.534582 285.522975 \nL 112.818371 286.083992 \nL 113.10216 284.977135 \nL 114.237315 285.180483 \nL 114.521104 285.29272 \nL 114.804893 287.268295 \nL 115.088682 288.152 \nL 115.940049 287.111145 \nL 116.223838 285.71214 \nL 116.507627 285.98177 \nL 116.791416 286.536458 \nL 117.075205 290.764794 \nL 117.926572 289.937165 \nL 118.210361 288.797983 \nL 118.494149 289.593536 \nL 118.777938 288.748986 \nL 119.061727 288.927642 \nL 120.196883 284.208549 \nL 120.480672 284.018741 \nL 120.764461 284.360827 \nL 121.04825 283.587603 \nL 121.899617 282.799433 \nL 122.183406 281.684949 \nL 122.467195 282.865608 \nL 122.750984 284.768708 \nL 123.034772 284.316028 \nL 123.886139 287.025685 \nL 124.169928 284.62108 \nL 124.453717 284.493678 \nL 124.737506 284.027737 \nL 125.021295 281.825986 \nL 125.872662 282.06678 \nL 126.156451 281.856924 \nL 126.44024 280.781756 \nL 127.859184 281.852911 \nL 128.142973 280.865067 \nL 129.845707 255.13921 \nL 130.129496 254.685226 \nL 130.413285 251.816246 \nL 130.697074 251.09724 \nL 130.980863 256.470343 \nL 131.83223 254.187799 \nL 132.399807 258.733858 \nL 132.683596 267.768736 \nL 132.967385 266.347718 \nL 133.818752 260.272996 \nL 134.102541 260.338516 \nL 134.38633 260.067843 \nL 134.670119 260.499535 \nL 134.953908 267.991406 \nL 135.805275 267.696959 \nL 136.089064 266.347748 \nL 136.372853 262.924408 \nL 136.656642 263.63091 \nL 136.94043 262.569978 \nL 137.791797 260.678703 \nL 138.075586 258.830971 \nL 138.359375 260.011344 \nL 138.643164 260.01784 \nL 138.926953 261.712097 \nL 139.77832 260.401297 \nL 140.062109 261.766941 \nL 140.629687 263.016121 \nL 140.913476 260.237324 \nL 141.764842 255.454032 \nL 142.048631 255.544387 \nL 142.616209 261.665213 \nL 142.899998 260.462833 \nL 143.751365 259.629614 \nL 144.035154 258.90806 \nL 144.318943 260.869898 \nL 144.602732 260.10208 \nL 144.886521 255.478468 \nL 145.737888 256.940243 \nL 146.021677 256.272902 \nL 146.305465 256.736842 \nL 146.589254 257.504475 \nL 146.873043 259.005072 \nL 147.72441 262.326547 \nL 148.008199 260.153959 \nL 148.291988 263.381792 \nL 148.575777 262.79837 \nL 148.859566 261.607833 \nL 149.710933 259.901709 \nL 149.994722 258.503097 \nL 150.278511 259.816391 \nL 150.5623 261.656074 \nL 150.846088 256.708607 \nL 151.697455 258.863123 \nL 151.981244 261.308789 \nL 152.265033 260.997997 \nL 152.548822 264.393245 \nL 152.832611 263.734656 \nL 153.683978 262.500654 \nL 154.251556 263.577382 \nL 156.805656 260.335979 \nL 157.657023 254.32059 \nL 157.940812 254.379644 \nL 158.224601 255.41539 \nL 158.50839 255.302045 \nL 158.792179 254.78001 \nL 159.643546 256.319851 \nL 159.927334 255.772332 \nL 160.211123 254.943412 \nL 160.494912 255.413472 \nL 160.778701 256.778295 \nL 161.913857 259.905437 \nL 162.197646 258.765606 \nL 162.481435 258.098241 \nL 162.765224 260.721436 \nL 163.616591 261.584034 \nL 163.90038 259.107782 \nL 164.184169 257.636766 \nL 164.467957 255.415086 \nL 164.751746 256.033347 \nL 165.603113 252.511078 \nL 165.886902 252.63817 \nL 166.170691 252.930599 \nL 166.45448 253.756751 \nL 166.738269 257.272369 \nL 167.589636 254.962144 \nL 167.873425 254.833283 \nL 168.157214 254.370611 \nL 168.441003 252.998227 \nL 168.724792 252.888753 \nL 169.576158 249.442918 \nL 170.143736 252.391023 \nL 170.427525 250.875845 \nL 170.711314 247.724875 \nL 171.562681 249.465949 \nL 171.84647 244.428925 \nL 172.414048 245.453019 \nL 172.697837 245.172784 \nL 173.832992 247.701159 \nL 174.116781 249.518995 \nL 174.40057 250.084186 \nL 174.684359 251.940594 \nL 175.535726 249.564247 \nL 175.819515 249.501031 \nL 176.103304 248.514045 \nL 176.387093 245.290725 \nL 176.670882 247.170217 \nL 177.522249 246.319498 \nL 177.806038 249.377553 \nL 178.089827 247.967336 \nL 178.373615 248.283659 \nL 178.657404 246.901569 \nL 179.508771 246.225725 \nL 179.79256 246.611969 \nL 180.360138 239.271096 \nL 181.495294 239.109124 \nL 182.062872 233.554519 \nL 182.346661 229.301938 \nL 182.63045 230.477917 \nL 183.481816 231.179905 \nL 183.765605 223.463662 \nL 184.049394 225.422238 \nL 184.333183 229.1141 \nL 184.616972 228.714555 \nL 185.468339 226.841143 \nL 185.752128 229.264754 \nL 186.035917 228.909901 \nL 186.319706 226.801982 \nL 186.603495 227.019989 \nL 187.454862 223.938522 \nL 187.73865 228.991086 \nL 188.022439 228.694686 \nL 188.306228 233.650638 \nL 188.590017 234.947856 \nL 189.441384 232.97555 \nL 189.725173 231.481146 \nL 190.008962 231.22795 \nL 190.292751 229.686085 \nL 190.57654 227.355104 \nL 191.427907 224.395918 \nL 191.995485 216.175336 \nL 194.549585 217.013241 \nL 195.400952 224.907819 \nL 195.684741 223.964179 \nL 195.96853 229.456604 \nL 196.252319 226.744042 \nL 196.536108 232.351073 \nL 197.387474 230.504687 \nL 197.671263 234.618779 \nL 197.955052 228.745618 \nL 198.238841 235.220946 \nL 198.52263 236.410524 \nL 199.373997 243.272792 \nL 199.657786 247.072604 \nL 199.941575 245.736564 \nL 200.225364 240.184096 \nL 200.509153 239.751035 \nL 201.360519 243.663012 \nL 201.644308 241.740561 \nL 201.928097 242.236587 \nL 202.211886 241.357104 \nL 202.495675 246.92931 \nL 203.347042 245.356995 \nL 203.630831 246.67076 \nL 203.91462 249.666939 \nL 204.198409 249.796116 \nL 204.482198 245.874945 \nL 205.333565 245.399633 \nL 205.617354 243.045794 \nL 205.901142 245.300877 \nL 206.46872 240.69268 \nL 207.603876 242.005838 \nL 207.887665 244.163671 \nL 208.171454 243.296251 \nL 208.455243 246.804849 \nL 209.590399 249.939821 \nL 209.874188 249.480543 \nL 210.157977 251.724063 \nL 210.441766 250.735004 \nL 211.293132 246.847439 \nL 211.576921 247.042225 \nL 211.86071 246.686539 \nL 212.144499 248.393639 \nL 212.428288 246.214728 \nL 213.279655 249.570583 \nL 213.563444 249.056062 \nL 213.847233 249.250342 \nL 214.131022 246.620281 \nL 214.414811 248.169725 \nL 216.117544 250.625786 \nL 216.401333 253.223498 \nL 217.2527 253.600126 \nL 217.536489 251.353688 \nL 217.820278 250.749443 \nL 218.104067 252.772271 \nL 218.387856 247.464194 \nL 219.239223 245.268551 \nL 219.523012 245.400508 \nL 219.8068 246.96223 \nL 220.090589 246.308233 \nL 220.374378 248.725002 \nL 221.225745 247.779177 \nL 221.509534 239.232221 \nL 221.793323 238.285622 \nL 222.077112 237.824058 \nL 222.360901 238.160233 \nL 223.212268 238.70035 \nL 223.496057 238.659927 \nL 224.063635 242.217403 \nL 224.347423 240.934552 \nL 225.19879 241.624781 \nL 225.482579 242.864774 \nL 225.766368 242.433183 \nL 226.050157 241.233584 \nL 226.333946 243.073546 \nL 227.469102 245.938054 \nL 227.752891 248.461487 \nL 228.03668 248.740572 \nL 228.320469 250.348916 \nL 229.171835 251.738407 \nL 229.455624 249.746517 \nL 229.739413 249.351432 \nL 230.023202 248.603096 \nL 230.306991 245.55995 \nL 231.158358 246.409919 \nL 231.442147 248.673117 \nL 231.725936 247.725494 \nL 232.009725 245.546226 \nL 232.293514 253.108785 \nL 233.42867 253.284916 \nL 233.712458 252.147014 \nL 233.996247 255.191648 \nL 234.280036 255.885962 \nL 235.415192 254.090925 \nL 235.698981 257.208605 \nL 235.98277 252.927068 \nL 236.266559 255.391477 \nL 237.117926 254.470541 \nL 237.401715 254.871687 \nL 237.685504 254.282763 \nL 237.969293 254.032901 \nL 238.253081 256.132919 \nL 239.104448 263.818438 \nL 239.388237 269.891374 \nL 239.955815 266.531995 \nL 240.239604 269.507638 \nL 241.090971 264.844091 \nL 241.658549 263.536614 \nL 241.942338 263.878611 \nL 242.226127 265.763903 \nL 243.077493 263.411373 \nL 243.361282 260.229155 \nL 243.645071 261.781785 \nL 243.92886 263.952783 \nL 244.212649 264.445606 \nL 245.064016 264.160662 \nL 245.347805 268.491982 \nL 245.631594 266.070199 \nL 245.915383 268.819683 \nL 246.199172 273.08409 \nL 247.050539 271.468583 \nL 247.334327 268.617603 \nL 247.618116 267.901021 \nL 247.901905 272.126838 \nL 248.185694 270.089453 \nL 249.037061 270.705522 \nL 249.32085 271.636986 \nL 249.604639 267.589396 \nL 249.888428 267.466733 \nL 250.172217 266.943841 \nL 251.023584 264.840882 \nL 251.307373 262.646496 \nL 251.591162 264.718303 \nL 251.874951 265.252901 \nL 252.158739 262.39212 \nL 253.010106 263.004701 \nL 253.577684 268.685172 \nL 253.861473 269.759614 \nL 254.145262 267.774869 \nL 255.564207 270.131841 \nL 255.847996 269.805336 \nL 257.26694 264.843514 \nL 257.550729 265.553725 \nL 257.834518 265.686825 \nL 260.956197 260.958199 \nL 261.239985 261.972051 \nL 261.523774 259.984371 \nL 261.807563 261.298488 \nL 262.091352 259.861066 \nL 262.942719 263.743326 \nL 263.226508 262.133506 \nL 263.510297 262.232935 \nL 263.794086 260.831089 \nL 264.077875 258.474082 \nL 264.929242 258.820878 \nL 265.213031 260.146689 \nL 265.49682 262.703406 \nL 265.780608 263.14915 \nL 266.064397 261.503485 \nL 266.915764 262.476051 \nL 267.483342 266.612109 \nL 267.767131 265.075126 \nL 268.05092 265.41557 \nL 268.902287 265.729719 \nL 269.186076 266.284199 \nL 269.469865 267.269804 \nL 269.753654 263.520704 \nL 270.037443 264.284158 \nL 271.172598 264.187402 \nL 271.456387 264.985099 \nL 271.740176 267.092893 \nL 272.023965 264.739083 \nL 272.875332 264.784115 \nL 273.44291 263.612089 \nL 273.726699 264.432817 \nL 274.010488 266.26037 \nL 274.861855 266.278792 \nL 275.145643 267.570789 \nL 275.713221 266.051145 \nL 275.99701 264.232106 \nL 276.848377 263.83199 \nL 277.132166 262.262628 \nL 277.699744 255.969976 \nL 277.983533 256.360179 \nL 278.8349 255.619619 \nL 279.118689 256.546718 \nL 279.402478 258.423316 \nL 279.686266 257.716195 \nL 279.970055 260.809856 \nL 280.821422 262.211893 \nL 281.105211 261.159201 \nL 281.389 261.901107 \nL 281.672789 260.3163 \nL 281.956578 260.134816 \nL 282.807945 260.837365 \nL 283.091734 259.350975 \nL 283.375523 263.075627 \nL 283.659312 261.828311 \nL 283.943101 261.082416 \nL 285.078256 261.693031 \nL 285.362045 262.275734 \nL 285.645834 264.889272 \nL 285.929623 264.122269 \nL 286.78099 263.357196 \nL 287.064779 264.642565 \nL 287.348568 263.345775 \nL 287.916146 269.137001 \nL 288.767512 268.62176 \nL 289.051301 266.250456 \nL 289.33509 266.270242 \nL 289.618879 263.501002 \nL 289.902668 264.392102 \nL 290.754035 264.927426 \nL 291.037824 268.785482 \nL 291.321613 267.67054 \nL 291.605402 270.316332 \nL 291.889191 274.199526 \nL 294.72708 270.61275 \nL 295.010869 270.479108 \nL 295.294658 269.10614 \nL 295.578447 268.775741 \nL 295.862236 268.906787 \nL 296.713603 271.223848 \nL 297.281181 269.313436 \nL 297.56497 269.129153 \nL 297.848759 267.721317 \nL 298.700125 268.79049 \nL 298.983914 271.323408 \nL 299.267703 270.387842 \nL 299.551492 273.8649 \nL 299.835281 272.915425 \nL 300.686648 272.60639 \nL 300.970437 269.932173 \nL 301.254226 271.030723 \nL 301.538015 271.635182 \nL 301.821804 273.701666 \nL 302.67317 278.923871 \nL 303.240748 282.942846 \nL 303.524537 281.377902 \nL 303.808326 281.245546 \nL 304.659693 286.235592 \nL 304.943482 295.108766 \nL 305.227271 287.672174 \nL 305.794849 282.585159 \nL 306.646216 283.840216 \nL 306.930005 283.32454 \nL 307.213793 282.387319 \nL 307.497582 283.154881 \nL 307.781371 285.964628 \nL 308.632738 286.157889 \nL 308.916527 286.814567 \nL 309.200316 282.447903 \nL 309.484105 283.440141 \nL 309.767894 280.795426 \nL 311.186839 281.512634 \nL 311.470628 283.222473 \nL 311.754416 281.85244 \nL 312.605783 286.562888 \nL 312.889572 283.712117 \nL 313.173361 284.425401 \nL 313.45715 281.667568 \nL 313.740939 281.549544 \nL 314.592306 284.101373 \nL 315.159884 287.219536 \nL 315.443673 289.471559 \nL 315.727462 288.48328 \nL 316.578828 296.266293 \nL 316.862617 296.408277 \nL 317.430195 291.127845 \nL 317.713984 289.006738 \nL 319.416718 289.269127 \nL 319.700507 294.102035 \nL 320.551874 295.568472 \nL 321.119451 292.823591 \nL 321.40324 293.982427 \nL 321.687029 292.406528 \nL 322.538396 294.063667 \nL 322.822185 291.900236 \nL 323.105974 292.567828 \nL 323.389763 292.626352 \nL 323.673552 288.851565 \nL 324.524919 290.363588 \nL 324.808708 293.242772 \nL 325.092497 292.693539 \nL 325.376286 292.605309 \nL 325.660074 291.523234 \nL 326.511441 290.607537 \nL 326.79523 288.537374 \nL 327.079019 289.439477 \nL 327.362808 289.901029 \nL 328.497964 287.797165 \nL 328.781753 286.537297 \nL 329.065542 284.602092 \nL 329.349331 285.250368 \nL 329.63312 283.395341 \nL 330.484486 286.661514 \nL 331.052064 281.941896 \nL 331.335853 283.886152 \nL 331.619642 281.214829 \nL 332.471009 281.886749 \nL 332.754798 281.793869 \nL 333.038587 283.829546 \nL 333.606165 278.919257 \nL 334.457532 276.585548 \nL 334.74132 275.069293 \nL 335.025109 276.866117 \nL 335.308898 273.938929 \nL 335.592687 274.72065 \nL 336.727843 274.313228 \nL 337.011632 277.610868 \nL 337.295421 278.058613 \nL 337.57921 277.814597 \nL 339.281944 283.650152 \nL 339.565732 286.978873 \nL 340.417099 284.642104 \nL 340.700888 285.418318 \nL 340.984677 284.913723 \nL 341.268466 287.141548 \nL 341.552255 286.44047 \nL 342.403622 287.105936 \nL 342.687411 286.071149 \nL 342.9712 287.542849 \nL 343.254989 287.71046 \nL 343.538778 289.781213 \nL 344.390144 290.415127 \nL 344.673933 293.447418 \nL 344.957722 294.640135 \nL 345.5253 290.852588 \nL 346.376667 291.637233 \nL 346.660456 291.463912 \nL 346.944245 293.435183 \nL 347.228034 290.094737 \nL 347.511823 289.509701 \nL 348.36319 290.35655 \nL 348.646978 291.154717 \nL 348.930767 290.166795 \nL 349.214556 291.748142 \nL 349.498345 292.264009 \nL 350.349712 291.922338 \nL 350.91729 294.796945 \nL 351.201079 292.14936 \nL 351.484868 292.206914 \nL 352.620024 293.691249 \nL 352.903813 291.59996 \nL 353.47139 294.607958 \nL 354.322757 295.411639 \nL 354.606546 293.819991 \nL 354.890335 294.642373 \nL 355.174124 294.785751 \nL 355.457913 291.851061 \nL 356.593069 291.156271 \nL 356.876858 292.573752 \nL 357.160647 292.671389 \nL 357.444436 296.586606 \nL 358.295802 296.494161 \nL 358.579591 296.833866 \nL 359.147169 299.4841 \nL 359.430958 299.457973 \nL 360.282325 300.345691 \nL 360.566114 298.67724 \nL 360.849903 300.519452 \nL 361.133692 300.519452 \nL 361.133692 300.519452 \n\" clip-path=\"url(#p94186ddf35)\" style=\"fill: none; stroke: #808080; stroke-opacity: 0.6; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 62.857328 316.989937 \nL 62.857328 23.229937 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 375.337328 316.989937 \nL 375.337328 23.229937 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 62.857328 316.989937 \nL 375.337328 316.989937 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 62.857328 23.229937 \nL 375.337328 23.229937 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_19\">\n    <!-- New Normal -->\n    <g transform=\"translate(178.722859 17.229937)scale(0.132 -0.132)\">\n     <defs>\n      <path id=\"DejaVuSans-4e\" d=\"M 628 4666 \nL 1478 4666 \nL 3547 763 \nL 3547 4666 \nL 4159 4666 \nL 4159 0 \nL 3309 0 \nL 1241 3903 \nL 1241 0 \nL 628 0 \nL 628 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-77\" d=\"M 269 3500 \nL 844 3500 \nL 1563 769 \nL 2278 3500 \nL 2956 3500 \nL 3675 769 \nL 4391 3500 \nL 4966 3500 \nL 4050 0 \nL 3372 0 \nL 2619 2869 \nL 1863 0 \nL 1184 0 \nL 269 3500 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-6d\" d=\"M 3328 2828 \nQ 3544 3216 3844 3400 \nQ 4144 3584 4550 3584 \nQ 5097 3584 5394 3201 \nQ 5691 2819 5691 2113 \nL 5691 0 \nL 5113 0 \nL 5113 2094 \nQ 5113 2597 4934 2840 \nQ 4756 3084 4391 3084 \nQ 3944 3084 3684 2787 \nQ 3425 2491 3425 1978 \nL 3425 0 \nL 2847 0 \nL 2847 2094 \nQ 2847 2600 2669 2842 \nQ 2491 3084 2119 3084 \nQ 1678 3084 1418 2786 \nQ 1159 2488 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1356 3278 1631 3431 \nQ 1906 3584 2284 3584 \nQ 2666 3584 2933 3390 \nQ 3200 3197 3328 2828 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-4e\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"74.804688\"/>\n     <use xlink:href=\"#DejaVuSans-77\" x=\"136.328125\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"218.115234\"/>\n     <use xlink:href=\"#DejaVuSans-4e\" x=\"249.902344\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"324.707031\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"385.888672\"/>\n     <use xlink:href=\"#DejaVuSans-6d\" x=\"425.251953\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"522.664062\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"583.943359\"/>\n    </g>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 71.327328 68.431 \nL 178.346156 68.431 \nQ 180.766156 68.431 180.766156 66.011 \nL 180.766156 31.699937 \nQ 180.766156 29.279937 178.346156 29.279937 \nL 71.327328 29.279937 \nQ 68.907328 29.279937 68.907328 31.699937 \nL 68.907328 66.011 \nQ 68.907328 68.431 71.327328 68.431 \nz\n\" style=\"fill: #ffffff; opacity: 0.5; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_20\">\n     <path d=\"M 73.747328 39.079047 \nL 85.847328 39.079047 \nL 97.947328 39.079047 \n\" style=\"fill: none; stroke: #228b22; stroke-opacity: 0.7; stroke-width: 2; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_20\">\n     <!-- Algo -->\n     <g transform=\"translate(107.627328 43.314047)scale(0.121 -0.121)\">\n      <defs>\n       <path id=\"DejaVuSans-41\" d=\"M 2188 4044 \nL 1331 1722 \nL 3047 1722 \nL 2188 4044 \nz\nM 1831 4666 \nL 2547 4666 \nL 4325 0 \nL 3669 0 \nL 3244 1197 \nL 1141 1197 \nL 716 0 \nL 50 0 \nL 1831 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-67\" d=\"M 2906 1791 \nQ 2906 2416 2648 2759 \nQ 2391 3103 1925 3103 \nQ 1463 3103 1205 2759 \nQ 947 2416 947 1791 \nQ 947 1169 1205 825 \nQ 1463 481 1925 481 \nQ 2391 481 2648 825 \nQ 2906 1169 2906 1791 \nz\nM 3481 434 \nQ 3481 -459 3084 -895 \nQ 2688 -1331 1869 -1331 \nQ 1566 -1331 1297 -1286 \nQ 1028 -1241 775 -1147 \nL 775 -588 \nQ 1028 -725 1275 -790 \nQ 1522 -856 1778 -856 \nQ 2344 -856 2625 -561 \nQ 2906 -266 2906 331 \nL 2906 616 \nQ 2728 306 2450 153 \nQ 2172 0 1784 0 \nQ 1141 0 747 490 \nQ 353 981 353 1791 \nQ 353 2603 747 3093 \nQ 1141 3584 1784 3584 \nQ 2172 3584 2450 3431 \nQ 2728 3278 2906 2969 \nL 2906 3500 \nL 3481 3500 \nL 3481 434 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-41\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"68.408203\"/>\n      <use xlink:href=\"#DejaVuSans-67\" x=\"96.191406\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"159.667969\"/>\n     </g>\n    </g>\n    <g id=\"line2d_21\">\n     <path d=\"M 73.747328 56.839578 \nL 85.847328 56.839578 \nL 97.947328 56.839578 \n\" style=\"fill: none; stroke: #808080; stroke-opacity: 0.6; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_21\">\n     <!-- benchmark -->\n     <g transform=\"translate(107.627328 61.074578)scale(0.121 -0.121)\">\n      <defs>\n       <path id=\"DejaVuSans-62\" d=\"M 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\nM 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2969 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6b\" d=\"M 581 4863 \nL 1159 4863 \nL 1159 1991 \nL 2875 3500 \nL 3609 3500 \nL 1753 1863 \nL 3688 0 \nL 2938 0 \nL 1159 1709 \nL 1159 0 \nL 581 0 \nL 581 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-62\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"63.476562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"125\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"188.378906\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"243.359375\"/>\n      <use xlink:href=\"#DejaVuSans-6d\" x=\"306.738281\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"404.150391\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"465.429688\"/>\n      <use xlink:href=\"#DejaVuSans-6b\" x=\"506.542969\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p94186ddf35\">\n   <rect x=\"62.857328\" y=\"23.229937\" width=\"312.48\" height=\"293.76\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "text/plain": [
       "<Figure size 1400x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pyfolio\n",
    "from pyfolio import timeseries\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "daily_return = get_daily_return(df_account_value)\n",
    "daily_return_base = get_daily_return(baseline_df, value_col_name='close')\n",
    "\n",
    "with pyfolio.plotting.plotting_context(font_scale=1.1):\n",
    "        pyfolio.create_full_tear_sheet(returns = daily_return,\n",
    "                                       benchmark_rets = daily_return_base, set_context=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dab1e11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Demo_China_A_share_market.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "7a792fcb311f9eb9f3c1b942a8c87ada8484712b89b670347c16a1088e0a1f69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
